{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gatBUxgazGvU",
   "metadata": {
    "id": "gatBUxgazGvU"
   },
   "outputs": [],
   "source": [
    "#!pip install 'monai[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a21ef3",
   "metadata": {
    "id": "c0a21ef3"
   },
   "outputs": [],
   "source": [
    "#Thank god-> Starting from Python 3.7, dictionaries maintain the insertion order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc7846",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bdff076",
    "outputId": "341bb6d4-f243-47de-a725-d91e321c8098"
   },
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "def check_and_install_packages(package_list):\n",
    "    missing_packages = []\n",
    "\n",
    "    for package in package_list:\n",
    "        try:\n",
    "            __import__(package)\n",
    "        except ImportError:\n",
    "            missing_packages.append(package)\n",
    "\n",
    "    if missing_packages:\n",
    "        print(\"Installing missing packages:\")\n",
    "        for package in missing_packages:\n",
    "            subprocess.run([\"pip\", \"install\", package])\n",
    "            print(f\"Installed {package}\")\n",
    "    else:\n",
    "        print(\"All required packages are already installed.\")\n",
    "\n",
    "# List of packages to check and install if necessary\n",
    "required_packages = [\n",
    "    \"numpy\",\n",
    "    \"matplotlib\",\n",
    "    \"pandas\",\n",
    "    #\"cv2\",\n",
    "    \"imageio\",\n",
    "    \"PIL\",\n",
    "    \"torch\",\n",
    "    \"monai\",\n",
    "    \"sys\"\n",
    "]\n",
    "\n",
    "check_and_install_packages(required_packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4b4944",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb4b4944",
    "outputId": "0a3d22ae-8436-438b-a5d3-eb1872974794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d5f3763",
   "metadata": {
    "id": "4d5f3763"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "699fe820",
   "metadata": {
    "id": "699fe820"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import imageio.v3 as iio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4533dc8",
   "metadata": {
    "id": "f4533dc8"
   },
   "outputs": [],
   "source": [
    "#updated_raw_dict, new_analyzed_dict\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc342e6d",
   "metadata": {
    "id": "cc342e6d"
   },
   "outputs": [],
   "source": [
    "def convert_to_numpy(data):\n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data.astype(np.float64)\n",
    "    elif isinstance(data, PIL.Image.Image):\n",
    "        return np.array(data).astype(np.float64)\n",
    "    elif isinstance(data, torch.Tensor):\n",
    "        return data.numpy().astype(np.float64)\n",
    "    # Add more conversion cases if needed\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported data format\")\n",
    "\n",
    "def check_and_convert_format(updated_raw_dict, new_analyzed_dict):\n",
    "    converted_raw_dict = {key: convert_to_numpy(value) for key, value in updated_raw_dict.items()}\n",
    "    converted_analyzed_dict = {key: convert_to_numpy(value) for key, value in new_analyzed_dict.items()}\n",
    "\n",
    "    return converted_raw_dict, converted_analyzed_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tLpiBTlj-gg1",
   "metadata": {
    "id": "tLpiBTlj-gg1"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "r_EdUKnDtwwj",
   "metadata": {
    "id": "r_EdUKnDtwwj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "#os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'MAX_SPLIT_SIZE_MB=256'  # Adjust the size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "MrSUOh5HedwJ",
   "metadata": {
    "id": "MrSUOh5HedwJ"
   },
   "outputs": [],
   "source": [
    "#weight_values = [1.0, 1.5, 2.0, 2.5, 5.0, 10.0, 20.0]  # Example weight values to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "pJU1SmFgPQJb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pJU1SmFgPQJb",
    "outputId": "6a2251fd-ee37-4782-c3e4-106724233209"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorboardX\n",
    "import tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Fnc6jWoUdL1c",
   "metadata": {
    "id": "Fnc6jWoUdL1c"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Set a random seed for Python's built-in random module\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Set a random seed for NumPy\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Set a random seed for PyTorch on both CPU and CUDA (if available)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f245d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ee7e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71abcb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.utils as nn_utils\n",
    "import torch.autograd as autograd\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af790db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e061064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80902998",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.data import create_test_image_2d, list_data_collate, decollate_batch, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39f5a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import sliding_window_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd89429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.metrics import DiceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d77b5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    ScaleIntensityd,\n",
    "    ToTensor,\n",
    "    AsDiscrete\n",
    ")\n",
    "#   DivisiblePadd deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87c6e4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import Transform\n",
    "#from monai.visualize import plot_2d_or_3d_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61a5603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.networks.layers import Norm\n",
    "from monai.transforms import Resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c03f930a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f586bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "546d4f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da45ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b80a9c06",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b80a9c06",
    "outputId": "1f9ee0be-74d6-477c-db30-7c80528c3200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.26.0\n",
      "Pytorch version: 2.0.1\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: C:\\Users\\ge59gor\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "scikit-image version: 0.22.0\n",
      "Pillow version: 9.4.0\n",
      "Tensorboard version: 2.14.1\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.15.2\n",
      "tqdm version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 2.0.3\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "--------------------------------------------------\n",
      "epoch 1/50\n",
      "1/1088, train_loss: 0.3872\n",
      "2/1088, train_loss: 0.3736\n",
      "3/1088, train_loss: 0.3650\n",
      "4/1088, train_loss: 0.3707\n",
      "5/1088, train_loss: 0.3615\n",
      "6/1088, train_loss: 0.3350\n",
      "7/1088, train_loss: 0.3019\n",
      "8/1088, train_loss: 0.3092\n",
      "9/1088, train_loss: 0.2971\n",
      "10/1088, train_loss: 0.2705\n",
      "11/1088, train_loss: 0.2545\n",
      "12/1088, train_loss: 0.2726\n",
      "13/1088, train_loss: 0.2331\n",
      "14/1088, train_loss: 0.2273\n",
      "15/1088, train_loss: 0.2201\n",
      "16/1088, train_loss: 0.2536\n",
      "17/1088, train_loss: 0.2116\n",
      "18/1088, train_loss: 0.2252\n",
      "19/1088, train_loss: 0.2078\n",
      "20/1088, train_loss: 0.1855\n",
      "21/1088, train_loss: 0.1900\n",
      "22/1088, train_loss: 0.1941\n",
      "23/1088, train_loss: 0.1845\n",
      "24/1088, train_loss: 0.1638\n",
      "25/1088, train_loss: 0.1834\n",
      "26/1088, train_loss: 0.1454\n",
      "27/1088, train_loss: 0.1646\n",
      "28/1088, train_loss: 0.1578\n",
      "29/1088, train_loss: 0.1491\n",
      "30/1088, train_loss: 0.1549\n",
      "31/1088, train_loss: 0.1377\n",
      "32/1088, train_loss: 0.1386\n",
      "33/1088, train_loss: 0.1434\n",
      "34/1088, train_loss: 0.1069\n",
      "35/1088, train_loss: 0.1077\n",
      "36/1088, train_loss: 0.1191\n",
      "37/1088, train_loss: 0.1360\n",
      "38/1088, train_loss: 0.1490\n",
      "39/1088, train_loss: 0.1052\n",
      "40/1088, train_loss: 0.1291\n",
      "41/1088, train_loss: 0.1191\n",
      "42/1088, train_loss: 0.0926\n",
      "43/1088, train_loss: 0.1084\n",
      "44/1088, train_loss: 0.1053\n",
      "45/1088, train_loss: 0.1106\n",
      "46/1088, train_loss: 0.1029\n",
      "47/1088, train_loss: 0.1044\n",
      "48/1088, train_loss: 0.1028\n",
      "49/1088, train_loss: 0.1161\n",
      "50/1088, train_loss: 0.0830\n",
      "51/1088, train_loss: 0.0876\n",
      "52/1088, train_loss: 0.1057\n",
      "53/1088, train_loss: 0.0855\n",
      "54/1088, train_loss: 0.0948\n",
      "55/1088, train_loss: 0.1023\n",
      "56/1088, train_loss: 0.0906\n",
      "57/1088, train_loss: 0.0794\n",
      "58/1088, train_loss: 0.0863\n",
      "59/1088, train_loss: 0.1095\n",
      "60/1088, train_loss: 0.0803\n",
      "61/1088, train_loss: 0.1074\n",
      "62/1088, train_loss: 0.1035\n",
      "63/1088, train_loss: 0.0749\n",
      "64/1088, train_loss: 0.0799\n",
      "65/1088, train_loss: 0.0800\n",
      "66/1088, train_loss: 0.0917\n",
      "67/1088, train_loss: 0.0793\n",
      "68/1088, train_loss: 0.1052\n",
      "69/1088, train_loss: 0.0804\n",
      "70/1088, train_loss: 0.0814\n",
      "71/1088, train_loss: 0.0806\n",
      "72/1088, train_loss: 0.0806\n",
      "73/1088, train_loss: 0.0935\n",
      "74/1088, train_loss: 0.0761\n",
      "75/1088, train_loss: 0.0763\n",
      "76/1088, train_loss: 0.0862\n",
      "77/1088, train_loss: 0.0764\n",
      "78/1088, train_loss: 0.0868\n",
      "79/1088, train_loss: 0.0815\n",
      "80/1088, train_loss: 0.0694\n",
      "81/1088, train_loss: 0.0749\n",
      "82/1088, train_loss: 0.0811\n",
      "83/1088, train_loss: 0.0698\n",
      "84/1088, train_loss: 0.0710\n",
      "85/1088, train_loss: 0.0742\n",
      "86/1088, train_loss: 0.0713\n",
      "87/1088, train_loss: 0.0589\n",
      "88/1088, train_loss: 0.0618\n",
      "89/1088, train_loss: 0.0777\n",
      "90/1088, train_loss: 0.0786\n",
      "91/1088, train_loss: 0.0643\n",
      "92/1088, train_loss: 0.0599\n",
      "93/1088, train_loss: 0.0639\n",
      "94/1088, train_loss: 0.0738\n",
      "95/1088, train_loss: 0.0640\n",
      "96/1088, train_loss: 0.0624\n",
      "97/1088, train_loss: 0.0688\n",
      "98/1088, train_loss: 0.0801\n",
      "99/1088, train_loss: 0.0642\n",
      "100/1088, train_loss: 0.0653\n",
      "101/1088, train_loss: 0.0606\n",
      "102/1088, train_loss: 0.0742\n",
      "103/1088, train_loss: 0.0580\n",
      "104/1088, train_loss: 0.0723\n",
      "105/1088, train_loss: 0.0614\n",
      "106/1088, train_loss: 0.0582\n",
      "107/1088, train_loss: 0.0595\n",
      "108/1088, train_loss: 0.0512\n",
      "109/1088, train_loss: 0.0600\n",
      "110/1088, train_loss: 0.0652\n",
      "111/1088, train_loss: 0.0701\n",
      "112/1088, train_loss: 0.0703\n",
      "113/1088, train_loss: 0.0698\n",
      "114/1088, train_loss: 0.0547\n",
      "115/1088, train_loss: 0.0612\n",
      "116/1088, train_loss: 0.0732\n",
      "117/1088, train_loss: 0.0741\n",
      "118/1088, train_loss: 0.0689\n",
      "119/1088, train_loss: 0.0626\n",
      "120/1088, train_loss: 0.0651\n",
      "121/1088, train_loss: 0.0634\n",
      "122/1088, train_loss: 0.0640\n",
      "123/1088, train_loss: 0.0579\n",
      "124/1088, train_loss: 0.0595\n",
      "125/1088, train_loss: 0.0636\n",
      "126/1088, train_loss: 0.0710\n",
      "127/1088, train_loss: 0.0545\n",
      "128/1088, train_loss: 0.0541\n",
      "129/1088, train_loss: 0.0626\n",
      "130/1088, train_loss: 0.0555\n",
      "131/1088, train_loss: 0.0533\n",
      "132/1088, train_loss: 0.0589\n",
      "133/1088, train_loss: 0.0523\n",
      "134/1088, train_loss: 0.0583\n",
      "135/1088, train_loss: 0.0559\n",
      "136/1088, train_loss: 0.0544\n",
      "137/1088, train_loss: 0.0694\n",
      "138/1088, train_loss: 0.0581\n",
      "139/1088, train_loss: 0.0557\n",
      "140/1088, train_loss: 0.0530\n",
      "141/1088, train_loss: 0.0528\n",
      "142/1088, train_loss: 0.0597\n",
      "143/1088, train_loss: 0.0756\n",
      "144/1088, train_loss: 0.0501\n",
      "145/1088, train_loss: 0.0596\n",
      "146/1088, train_loss: 0.0706\n",
      "147/1088, train_loss: 0.0753\n",
      "148/1088, train_loss: 0.0504\n",
      "149/1088, train_loss: 0.0589\n",
      "150/1088, train_loss: 0.0676\n",
      "151/1088, train_loss: 0.0640\n",
      "152/1088, train_loss: 0.0549\n",
      "153/1088, train_loss: 0.0578\n",
      "154/1088, train_loss: 0.0600\n",
      "155/1088, train_loss: 0.0573\n",
      "156/1088, train_loss: 0.0568\n",
      "157/1088, train_loss: 0.0523\n",
      "158/1088, train_loss: 0.0530\n",
      "159/1088, train_loss: 0.0595\n",
      "160/1088, train_loss: 0.0545\n",
      "161/1088, train_loss: 0.0500\n",
      "162/1088, train_loss: 0.0524\n",
      "163/1088, train_loss: 0.0626\n",
      "164/1088, train_loss: 0.0531\n",
      "165/1088, train_loss: 0.0524\n",
      "166/1088, train_loss: 0.0492\n",
      "167/1088, train_loss: 0.0594\n",
      "168/1088, train_loss: 0.0786\n",
      "169/1088, train_loss: 0.0499\n",
      "170/1088, train_loss: 0.0494\n",
      "171/1088, train_loss: 0.0511\n",
      "172/1088, train_loss: 0.0520\n",
      "173/1088, train_loss: 0.0522\n",
      "174/1088, train_loss: 0.0555\n",
      "175/1088, train_loss: 0.0526\n",
      "176/1088, train_loss: 0.0535\n",
      "177/1088, train_loss: 0.0499\n",
      "178/1088, train_loss: 0.0600\n",
      "179/1088, train_loss: 0.0541\n",
      "180/1088, train_loss: 0.0574\n",
      "181/1088, train_loss: 0.0563\n",
      "182/1088, train_loss: 0.0499\n",
      "183/1088, train_loss: 0.0478\n",
      "184/1088, train_loss: 0.0534\n",
      "185/1088, train_loss: 0.0492\n",
      "186/1088, train_loss: 0.0473\n",
      "187/1088, train_loss: 0.0459\n",
      "188/1088, train_loss: 0.0503\n",
      "189/1088, train_loss: 0.0523\n",
      "190/1088, train_loss: 0.0476\n",
      "191/1088, train_loss: 0.0563\n",
      "192/1088, train_loss: 0.0537\n",
      "193/1088, train_loss: 0.0477\n",
      "194/1088, train_loss: 0.0515\n",
      "195/1088, train_loss: 0.0460\n",
      "196/1088, train_loss: 0.0499\n",
      "197/1088, train_loss: 0.0626\n",
      "198/1088, train_loss: 0.0442\n",
      "199/1088, train_loss: 0.0516\n",
      "200/1088, train_loss: 0.0499\n",
      "201/1088, train_loss: 0.0669\n",
      "202/1088, train_loss: 0.0643\n",
      "203/1088, train_loss: 0.0496\n",
      "204/1088, train_loss: 0.0574\n",
      "205/1088, train_loss: 0.0481\n",
      "206/1088, train_loss: 0.0453\n",
      "207/1088, train_loss: 0.0466\n",
      "208/1088, train_loss: 0.0447\n",
      "209/1088, train_loss: 0.0594\n",
      "210/1088, train_loss: 0.0667\n",
      "211/1088, train_loss: 0.0574\n",
      "212/1088, train_loss: 0.0465\n",
      "213/1088, train_loss: 0.0508\n",
      "214/1088, train_loss: 0.0534\n",
      "215/1088, train_loss: 0.0464\n",
      "216/1088, train_loss: 0.0488\n",
      "217/1088, train_loss: 0.0479\n",
      "218/1088, train_loss: 0.0478\n",
      "219/1088, train_loss: 0.0545\n",
      "220/1088, train_loss: 0.0592\n",
      "221/1088, train_loss: 0.0533\n",
      "222/1088, train_loss: 0.0503\n",
      "223/1088, train_loss: 0.0483\n",
      "224/1088, train_loss: 0.0458\n",
      "225/1088, train_loss: 0.0544\n",
      "226/1088, train_loss: 0.0462\n",
      "227/1088, train_loss: 0.0541\n",
      "228/1088, train_loss: 0.0515\n",
      "229/1088, train_loss: 0.0456\n",
      "230/1088, train_loss: 0.0469\n",
      "231/1088, train_loss: 0.0453\n",
      "232/1088, train_loss: 0.0495\n",
      "233/1088, train_loss: 0.0468\n",
      "234/1088, train_loss: 0.0436\n",
      "235/1088, train_loss: 0.0512\n",
      "236/1088, train_loss: 0.0496\n",
      "237/1088, train_loss: 0.0476\n",
      "238/1088, train_loss: 0.0594\n",
      "239/1088, train_loss: 0.0674\n",
      "240/1088, train_loss: 0.0868\n",
      "241/1088, train_loss: 0.0592\n",
      "242/1088, train_loss: 0.0462\n",
      "243/1088, train_loss: 0.0506\n",
      "244/1088, train_loss: 0.0466\n",
      "245/1088, train_loss: 0.0474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/1088, train_loss: 0.0459\n",
      "247/1088, train_loss: 0.0426\n",
      "248/1088, train_loss: 0.0467\n",
      "249/1088, train_loss: 0.0439\n",
      "250/1088, train_loss: 0.0427\n",
      "251/1088, train_loss: 0.0670\n",
      "252/1088, train_loss: 0.0882\n",
      "253/1088, train_loss: 0.0614\n",
      "254/1088, train_loss: 0.0396\n",
      "255/1088, train_loss: 0.0515\n",
      "256/1088, train_loss: 0.0506\n",
      "257/1088, train_loss: 0.0537\n",
      "258/1088, train_loss: 0.0477\n",
      "259/1088, train_loss: 0.0466\n",
      "260/1088, train_loss: 0.0507\n",
      "261/1088, train_loss: 0.0501\n",
      "262/1088, train_loss: 0.0559\n",
      "263/1088, train_loss: 0.0433\n",
      "264/1088, train_loss: 0.0451\n",
      "265/1088, train_loss: 0.0421\n",
      "266/1088, train_loss: 0.0592\n",
      "267/1088, train_loss: 0.0564\n",
      "268/1088, train_loss: 0.0460\n",
      "269/1088, train_loss: 0.0485\n",
      "270/1088, train_loss: 0.0429\n",
      "271/1088, train_loss: 0.0435\n",
      "272/1088, train_loss: 0.0452\n",
      "273/1088, train_loss: 0.0559\n",
      "274/1088, train_loss: 0.0513\n",
      "275/1088, train_loss: 0.0453\n",
      "276/1088, train_loss: 0.0448\n",
      "277/1088, train_loss: 0.0427\n",
      "278/1088, train_loss: 0.0454\n",
      "279/1088, train_loss: 0.0500\n",
      "280/1088, train_loss: 0.0770\n",
      "281/1088, train_loss: 0.0437\n",
      "282/1088, train_loss: 0.0666\n",
      "283/1088, train_loss: 0.0556\n",
      "284/1088, train_loss: 0.0423\n",
      "285/1088, train_loss: 0.0464\n",
      "286/1088, train_loss: 0.0451\n",
      "287/1088, train_loss: 0.0461\n",
      "288/1088, train_loss: 0.0444\n",
      "289/1088, train_loss: 0.0509\n",
      "290/1088, train_loss: 0.0447\n",
      "291/1088, train_loss: 0.0457\n",
      "292/1088, train_loss: 0.0409\n",
      "293/1088, train_loss: 0.0427\n",
      "294/1088, train_loss: 0.0439\n",
      "295/1088, train_loss: 0.0467\n",
      "296/1088, train_loss: 0.0415\n",
      "297/1088, train_loss: 0.0431\n",
      "298/1088, train_loss: 0.0418\n",
      "299/1088, train_loss: 0.0461\n",
      "300/1088, train_loss: 0.0466\n",
      "301/1088, train_loss: 0.0403\n",
      "302/1088, train_loss: 0.0430\n",
      "303/1088, train_loss: 0.0443\n",
      "304/1088, train_loss: 0.0506\n",
      "305/1088, train_loss: 0.0530\n",
      "306/1088, train_loss: 0.0512\n",
      "307/1088, train_loss: 0.0676\n",
      "308/1088, train_loss: 0.0450\n",
      "309/1088, train_loss: 0.0415\n",
      "310/1088, train_loss: 0.0410\n",
      "311/1088, train_loss: 0.0421\n",
      "312/1088, train_loss: 0.0464\n",
      "313/1088, train_loss: 0.0416\n",
      "314/1088, train_loss: 0.0416\n",
      "315/1088, train_loss: 0.0672\n",
      "316/1088, train_loss: 0.0456\n",
      "317/1088, train_loss: 0.0540\n",
      "318/1088, train_loss: 0.0514\n",
      "319/1088, train_loss: 0.0470\n",
      "320/1088, train_loss: 0.0472\n",
      "321/1088, train_loss: 0.0394\n",
      "322/1088, train_loss: 0.0496\n",
      "323/1088, train_loss: 0.0403\n",
      "324/1088, train_loss: 0.0496\n",
      "325/1088, train_loss: 0.0406\n",
      "326/1088, train_loss: 0.0441\n",
      "327/1088, train_loss: 0.0415\n",
      "328/1088, train_loss: 0.0402\n",
      "329/1088, train_loss: 0.0412\n",
      "330/1088, train_loss: 0.0472\n",
      "331/1088, train_loss: 0.0501\n",
      "332/1088, train_loss: 0.0431\n",
      "333/1088, train_loss: 0.0405\n",
      "334/1088, train_loss: 0.0500\n",
      "335/1088, train_loss: 0.0581\n",
      "336/1088, train_loss: 0.0431\n",
      "337/1088, train_loss: 0.0412\n",
      "338/1088, train_loss: 0.0457\n",
      "339/1088, train_loss: 0.0489\n",
      "340/1088, train_loss: 0.0470\n",
      "341/1088, train_loss: 0.0586\n",
      "342/1088, train_loss: 0.0430\n",
      "343/1088, train_loss: 0.0464\n",
      "344/1088, train_loss: 0.0464\n",
      "345/1088, train_loss: 0.0397\n",
      "346/1088, train_loss: 0.0861\n",
      "347/1088, train_loss: 0.0555\n",
      "348/1088, train_loss: 0.0441\n",
      "349/1088, train_loss: 0.0450\n",
      "350/1088, train_loss: 0.0421\n",
      "351/1088, train_loss: 0.0401\n",
      "352/1088, train_loss: 0.0441\n",
      "353/1088, train_loss: 0.0446\n",
      "354/1088, train_loss: 0.0422\n",
      "355/1088, train_loss: 0.0448\n",
      "356/1088, train_loss: 0.0491\n",
      "357/1088, train_loss: 0.0434\n",
      "358/1088, train_loss: 0.0402\n",
      "359/1088, train_loss: 0.0414\n",
      "360/1088, train_loss: 0.0404\n",
      "361/1088, train_loss: 0.0443\n",
      "362/1088, train_loss: 0.0434\n",
      "363/1088, train_loss: 0.0447\n",
      "364/1088, train_loss: 0.0414\n",
      "365/1088, train_loss: 0.0417\n",
      "366/1088, train_loss: 0.0526\n",
      "367/1088, train_loss: 0.0432\n",
      "368/1088, train_loss: 0.0427\n",
      "369/1088, train_loss: 0.0437\n",
      "370/1088, train_loss: 0.0422\n",
      "371/1088, train_loss: 0.0458\n",
      "372/1088, train_loss: 0.0437\n",
      "373/1088, train_loss: 0.0392\n",
      "374/1088, train_loss: 0.0515\n",
      "375/1088, train_loss: 0.0443\n",
      "376/1088, train_loss: 0.0413\n",
      "377/1088, train_loss: 0.0502\n",
      "378/1088, train_loss: 0.0451\n",
      "379/1088, train_loss: 0.0555\n",
      "380/1088, train_loss: 0.0417\n",
      "381/1088, train_loss: 0.0405\n",
      "382/1088, train_loss: 0.0412\n",
      "383/1088, train_loss: 0.0401\n",
      "384/1088, train_loss: 0.0387\n",
      "385/1088, train_loss: 0.0399\n",
      "386/1088, train_loss: 0.0392\n",
      "387/1088, train_loss: 0.0794\n",
      "388/1088, train_loss: 0.0447\n",
      "389/1088, train_loss: 0.0429\n",
      "390/1088, train_loss: 0.0453\n",
      "391/1088, train_loss: 0.0462\n",
      "392/1088, train_loss: 0.0431\n",
      "393/1088, train_loss: 0.0450\n",
      "394/1088, train_loss: 0.0432\n",
      "395/1088, train_loss: 0.0522\n",
      "396/1088, train_loss: 0.0412\n",
      "397/1088, train_loss: 0.0427\n",
      "398/1088, train_loss: 0.0401\n",
      "399/1088, train_loss: 0.0424\n",
      "400/1088, train_loss: 0.0425\n",
      "401/1088, train_loss: 0.0424\n",
      "402/1088, train_loss: 0.0409\n",
      "403/1088, train_loss: 0.0462\n",
      "404/1088, train_loss: 0.0434\n",
      "405/1088, train_loss: 0.0403\n",
      "406/1088, train_loss: 0.0413\n",
      "407/1088, train_loss: 0.0382\n",
      "408/1088, train_loss: 0.0399\n",
      "409/1088, train_loss: 0.0431\n",
      "410/1088, train_loss: 0.0435\n",
      "411/1088, train_loss: 0.0404\n",
      "412/1088, train_loss: 0.0503\n",
      "413/1088, train_loss: 0.0557\n",
      "414/1088, train_loss: 0.0413\n",
      "415/1088, train_loss: 0.0419\n",
      "416/1088, train_loss: 0.0422\n",
      "417/1088, train_loss: 0.0385\n",
      "418/1088, train_loss: 0.0378\n",
      "419/1088, train_loss: 0.0577\n",
      "420/1088, train_loss: 0.0392\n",
      "421/1088, train_loss: 0.0392\n",
      "422/1088, train_loss: 0.0372\n",
      "423/1088, train_loss: 0.0492\n",
      "424/1088, train_loss: 0.0573\n",
      "425/1088, train_loss: 0.0417\n",
      "426/1088, train_loss: 0.0386\n",
      "427/1088, train_loss: 0.0379\n",
      "428/1088, train_loss: 0.0387\n",
      "429/1088, train_loss: 0.0366\n",
      "430/1088, train_loss: 0.0407\n",
      "431/1088, train_loss: 0.0405\n",
      "432/1088, train_loss: 0.0512\n",
      "433/1088, train_loss: 0.0432\n",
      "434/1088, train_loss: 0.0410\n",
      "435/1088, train_loss: 0.0389\n",
      "436/1088, train_loss: 0.0443\n",
      "437/1088, train_loss: 0.0377\n",
      "438/1088, train_loss: 0.0408\n",
      "439/1088, train_loss: 0.0397\n",
      "440/1088, train_loss: 0.0502\n",
      "441/1088, train_loss: 0.0398\n",
      "442/1088, train_loss: 0.0398\n",
      "443/1088, train_loss: 0.0377\n",
      "444/1088, train_loss: 0.0434\n",
      "445/1088, train_loss: 0.0415\n",
      "446/1088, train_loss: 0.0439\n",
      "447/1088, train_loss: 0.0522\n",
      "448/1088, train_loss: 0.0412\n",
      "449/1088, train_loss: 0.0411\n",
      "450/1088, train_loss: 0.0388\n",
      "451/1088, train_loss: 0.0521\n",
      "452/1088, train_loss: 0.0381\n",
      "453/1088, train_loss: 0.0429\n",
      "454/1088, train_loss: 0.0401\n",
      "455/1088, train_loss: 0.0462\n",
      "456/1088, train_loss: 0.0403\n",
      "457/1088, train_loss: 0.0411\n",
      "458/1088, train_loss: 0.0447\n",
      "459/1088, train_loss: 0.0389\n",
      "460/1088, train_loss: 0.0432\n",
      "461/1088, train_loss: 0.0444\n",
      "462/1088, train_loss: 0.0417\n",
      "463/1088, train_loss: 0.0380\n",
      "464/1088, train_loss: 0.0404\n",
      "465/1088, train_loss: 0.0496\n",
      "466/1088, train_loss: 0.0456\n",
      "467/1088, train_loss: 0.0428\n",
      "468/1088, train_loss: 0.0398\n",
      "469/1088, train_loss: 0.0493\n",
      "470/1088, train_loss: 0.0399\n",
      "471/1088, train_loss: 0.0378\n",
      "472/1088, train_loss: 0.0394\n",
      "473/1088, train_loss: 0.0493\n",
      "474/1088, train_loss: 0.0419\n",
      "475/1088, train_loss: 0.0426\n",
      "476/1088, train_loss: 0.0424\n",
      "477/1088, train_loss: 0.0444\n",
      "478/1088, train_loss: 0.0518\n",
      "479/1088, train_loss: 0.0474\n",
      "480/1088, train_loss: 0.0431\n",
      "481/1088, train_loss: 0.0501\n",
      "482/1088, train_loss: 0.0537\n",
      "483/1088, train_loss: 0.0388\n",
      "484/1088, train_loss: 0.0398\n",
      "485/1088, train_loss: 0.0433\n",
      "486/1088, train_loss: 0.0401\n",
      "487/1088, train_loss: 0.0416\n",
      "488/1088, train_loss: 0.0475\n",
      "489/1088, train_loss: 0.0377\n",
      "490/1088, train_loss: 0.0471\n",
      "491/1088, train_loss: 0.0433\n",
      "492/1088, train_loss: 0.0440\n",
      "493/1088, train_loss: 0.0399\n",
      "494/1088, train_loss: 0.0403\n",
      "495/1088, train_loss: 0.0380\n",
      "496/1088, train_loss: 0.0380\n",
      "497/1088, train_loss: 0.0382\n",
      "498/1088, train_loss: 0.0395\n",
      "499/1088, train_loss: 0.0419\n",
      "500/1088, train_loss: 0.0387\n",
      "501/1088, train_loss: 0.0359\n",
      "502/1088, train_loss: 0.0400\n",
      "503/1088, train_loss: 0.0391\n",
      "504/1088, train_loss: 0.0439\n",
      "505/1088, train_loss: 0.0383\n",
      "506/1088, train_loss: 0.0497\n",
      "507/1088, train_loss: 0.0409\n",
      "508/1088, train_loss: 0.0376\n",
      "509/1088, train_loss: 0.0398\n",
      "510/1088, train_loss: 0.0385\n",
      "511/1088, train_loss: 0.0379\n",
      "512/1088, train_loss: 0.0381\n",
      "513/1088, train_loss: 0.0584\n",
      "514/1088, train_loss: 0.0414\n",
      "515/1088, train_loss: 0.0424\n",
      "516/1088, train_loss: 0.0425\n",
      "517/1088, train_loss: 0.0403\n",
      "518/1088, train_loss: 0.0394\n",
      "519/1088, train_loss: 0.0380\n",
      "520/1088, train_loss: 0.0399\n",
      "521/1088, train_loss: 0.0470\n",
      "522/1088, train_loss: 0.0431\n",
      "523/1088, train_loss: 0.0438\n",
      "524/1088, train_loss: 0.0500\n",
      "525/1088, train_loss: 0.0412\n",
      "526/1088, train_loss: 0.0375\n",
      "527/1088, train_loss: 0.0384\n",
      "528/1088, train_loss: 0.0374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529/1088, train_loss: 0.0378\n",
      "530/1088, train_loss: 0.0417\n",
      "531/1088, train_loss: 0.0455\n",
      "532/1088, train_loss: 0.0360\n",
      "533/1088, train_loss: 0.0543\n",
      "534/1088, train_loss: 0.0369\n",
      "535/1088, train_loss: 0.0525\n",
      "536/1088, train_loss: 0.0354\n",
      "537/1088, train_loss: 0.0393\n",
      "538/1088, train_loss: 0.0372\n",
      "539/1088, train_loss: 0.0396\n",
      "540/1088, train_loss: 0.0394\n",
      "541/1088, train_loss: 0.0381\n",
      "542/1088, train_loss: 0.0387\n",
      "543/1088, train_loss: 0.0399\n",
      "544/1088, train_loss: 0.0416\n",
      "545/1088, train_loss: 0.0391\n",
      "546/1088, train_loss: 0.0457\n",
      "547/1088, train_loss: 0.0475\n",
      "548/1088, train_loss: 0.0368\n",
      "549/1088, train_loss: 0.0533\n",
      "550/1088, train_loss: 0.0465\n",
      "551/1088, train_loss: 0.0393\n",
      "552/1088, train_loss: 0.0390\n",
      "553/1088, train_loss: 0.0375\n",
      "554/1088, train_loss: 0.0376\n",
      "555/1088, train_loss: 0.0379\n",
      "556/1088, train_loss: 0.0382\n",
      "557/1088, train_loss: 0.0372\n",
      "558/1088, train_loss: 0.0459\n",
      "559/1088, train_loss: 0.0431\n",
      "560/1088, train_loss: 0.0515\n",
      "561/1088, train_loss: 0.0453\n",
      "562/1088, train_loss: 0.0400\n",
      "563/1088, train_loss: 0.0438\n",
      "564/1088, train_loss: 0.0384\n",
      "565/1088, train_loss: 0.0387\n",
      "566/1088, train_loss: 0.0449\n",
      "567/1088, train_loss: 0.0378\n",
      "568/1088, train_loss: 0.0368\n",
      "569/1088, train_loss: 0.0431\n",
      "570/1088, train_loss: 0.0396\n",
      "571/1088, train_loss: 0.0524\n",
      "572/1088, train_loss: 0.0427\n",
      "573/1088, train_loss: 0.0398\n",
      "574/1088, train_loss: 0.0426\n",
      "575/1088, train_loss: 0.0445\n",
      "576/1088, train_loss: 0.0386\n",
      "577/1088, train_loss: 0.0376\n",
      "578/1088, train_loss: 0.0440\n",
      "579/1088, train_loss: 0.0387\n",
      "580/1088, train_loss: 0.0369\n",
      "581/1088, train_loss: 0.0390\n",
      "582/1088, train_loss: 0.0464\n",
      "583/1088, train_loss: 0.0373\n",
      "584/1088, train_loss: 0.0361\n",
      "585/1088, train_loss: 0.0372\n",
      "586/1088, train_loss: 0.0358\n",
      "587/1088, train_loss: 0.0378\n",
      "588/1088, train_loss: 0.0377\n",
      "589/1088, train_loss: 0.0345\n",
      "590/1088, train_loss: 0.0374\n",
      "591/1088, train_loss: 0.0640\n",
      "592/1088, train_loss: 0.0385\n",
      "593/1088, train_loss: 0.0497\n",
      "594/1088, train_loss: 0.0359\n",
      "595/1088, train_loss: 0.0381\n",
      "596/1088, train_loss: 0.0413\n",
      "597/1088, train_loss: 0.0399\n",
      "598/1088, train_loss: 0.0389\n",
      "599/1088, train_loss: 0.0395\n",
      "600/1088, train_loss: 0.0380\n",
      "601/1088, train_loss: 0.0364\n",
      "602/1088, train_loss: 0.0562\n",
      "603/1088, train_loss: 0.0390\n",
      "604/1088, train_loss: 0.0362\n",
      "605/1088, train_loss: 0.0341\n",
      "606/1088, train_loss: 0.0422\n",
      "607/1088, train_loss: 0.0424\n",
      "608/1088, train_loss: 0.0452\n",
      "609/1088, train_loss: 0.0358\n",
      "610/1088, train_loss: 0.0558\n",
      "611/1088, train_loss: 0.0439\n",
      "612/1088, train_loss: 0.0469\n",
      "613/1088, train_loss: 0.0379\n",
      "614/1088, train_loss: 0.0386\n",
      "615/1088, train_loss: 0.0368\n",
      "616/1088, train_loss: 0.0472\n",
      "617/1088, train_loss: 0.0439\n",
      "618/1088, train_loss: 0.0427\n",
      "619/1088, train_loss: 0.0396\n",
      "620/1088, train_loss: 0.0369\n",
      "621/1088, train_loss: 0.0370\n",
      "622/1088, train_loss: 0.0380\n",
      "623/1088, train_loss: 0.0357\n",
      "624/1088, train_loss: 0.0378\n",
      "625/1088, train_loss: 0.0356\n",
      "626/1088, train_loss: 0.0411\n",
      "627/1088, train_loss: 0.0392\n",
      "628/1088, train_loss: 0.0373\n",
      "629/1088, train_loss: 0.0434\n",
      "630/1088, train_loss: 0.0403\n",
      "631/1088, train_loss: 0.0379\n",
      "632/1088, train_loss: 0.0403\n",
      "633/1088, train_loss: 0.0459\n",
      "634/1088, train_loss: 0.0461\n",
      "635/1088, train_loss: 0.0394\n",
      "636/1088, train_loss: 0.0368\n",
      "637/1088, train_loss: 0.0375\n",
      "638/1088, train_loss: 0.0367\n",
      "639/1088, train_loss: 0.0405\n",
      "640/1088, train_loss: 0.0395\n",
      "641/1088, train_loss: 0.0359\n",
      "642/1088, train_loss: 0.0343\n",
      "643/1088, train_loss: 0.0379\n",
      "644/1088, train_loss: 0.0509\n",
      "645/1088, train_loss: 0.0406\n",
      "646/1088, train_loss: 0.0518\n",
      "647/1088, train_loss: 0.0357\n",
      "648/1088, train_loss: 0.0344\n",
      "649/1088, train_loss: 0.0413\n",
      "650/1088, train_loss: 0.0561\n",
      "651/1088, train_loss: 0.0682\n",
      "652/1088, train_loss: 0.0370\n",
      "653/1088, train_loss: 0.0474\n",
      "654/1088, train_loss: 0.0446\n",
      "655/1088, train_loss: 0.0393\n",
      "656/1088, train_loss: 0.0479\n",
      "657/1088, train_loss: 0.0403\n",
      "658/1088, train_loss: 0.0398\n",
      "659/1088, train_loss: 0.0363\n",
      "660/1088, train_loss: 0.0422\n",
      "661/1088, train_loss: 0.0376\n",
      "662/1088, train_loss: 0.0360\n",
      "663/1088, train_loss: 0.0356\n",
      "664/1088, train_loss: 0.0361\n",
      "665/1088, train_loss: 0.0377\n",
      "666/1088, train_loss: 0.0361\n",
      "667/1088, train_loss: 0.0360\n",
      "668/1088, train_loss: 0.0360\n",
      "669/1088, train_loss: 0.0439\n",
      "670/1088, train_loss: 0.0432\n",
      "671/1088, train_loss: 0.0451\n",
      "672/1088, train_loss: 0.0406\n",
      "673/1088, train_loss: 0.0375\n",
      "674/1088, train_loss: 0.0440\n",
      "675/1088, train_loss: 0.0472\n",
      "676/1088, train_loss: 0.0641\n",
      "677/1088, train_loss: 0.0449\n",
      "678/1088, train_loss: 0.0429\n",
      "679/1088, train_loss: 0.0409\n",
      "680/1088, train_loss: 0.0510\n",
      "681/1088, train_loss: 0.0417\n",
      "682/1088, train_loss: 0.0407\n",
      "683/1088, train_loss: 0.0444\n",
      "684/1088, train_loss: 0.0513\n",
      "685/1088, train_loss: 0.0383\n",
      "686/1088, train_loss: 0.0418\n",
      "687/1088, train_loss: 0.0421\n",
      "688/1088, train_loss: 0.0424\n",
      "689/1088, train_loss: 0.0382\n",
      "690/1088, train_loss: 0.0445\n",
      "691/1088, train_loss: 0.0425\n",
      "692/1088, train_loss: 0.0384\n",
      "693/1088, train_loss: 0.0359\n",
      "694/1088, train_loss: 0.0367\n",
      "695/1088, train_loss: 0.0347\n",
      "696/1088, train_loss: 0.0365\n",
      "697/1088, train_loss: 0.0385\n",
      "698/1088, train_loss: 0.0368\n",
      "699/1088, train_loss: 0.0377\n",
      "700/1088, train_loss: 0.0372\n",
      "701/1088, train_loss: 0.0371\n",
      "702/1088, train_loss: 0.0385\n",
      "703/1088, train_loss: 0.0461\n",
      "704/1088, train_loss: 0.0371\n",
      "705/1088, train_loss: 0.0395\n",
      "706/1088, train_loss: 0.0382\n",
      "707/1088, train_loss: 0.0400\n",
      "708/1088, train_loss: 0.0344\n",
      "709/1088, train_loss: 0.0364\n",
      "710/1088, train_loss: 0.0369\n",
      "711/1088, train_loss: 0.0466\n",
      "712/1088, train_loss: 0.0363\n",
      "713/1088, train_loss: 0.0328\n",
      "714/1088, train_loss: 0.0413\n",
      "715/1088, train_loss: 0.0327\n",
      "716/1088, train_loss: 0.0341\n",
      "717/1088, train_loss: 0.0328\n",
      "718/1088, train_loss: 0.0417\n",
      "719/1088, train_loss: 0.0382\n",
      "720/1088, train_loss: 0.0740\n",
      "721/1088, train_loss: 0.0387\n",
      "722/1088, train_loss: 0.0347\n",
      "723/1088, train_loss: 0.0381\n",
      "724/1088, train_loss: 0.0386\n",
      "725/1088, train_loss: 0.0434\n",
      "726/1088, train_loss: 0.0371\n",
      "727/1088, train_loss: 0.0397\n",
      "728/1088, train_loss: 0.0421\n",
      "729/1088, train_loss: 0.0366\n",
      "730/1088, train_loss: 0.0371\n",
      "731/1088, train_loss: 0.0418\n",
      "732/1088, train_loss: 0.0364\n",
      "733/1088, train_loss: 0.0415\n",
      "734/1088, train_loss: 0.0404\n",
      "735/1088, train_loss: 0.0395\n",
      "736/1088, train_loss: 0.0409\n",
      "737/1088, train_loss: 0.0374\n",
      "738/1088, train_loss: 0.0348\n",
      "739/1088, train_loss: 0.0363\n",
      "740/1088, train_loss: 0.0382\n",
      "741/1088, train_loss: 0.0341\n",
      "742/1088, train_loss: 0.0385\n",
      "743/1088, train_loss: 0.0468\n",
      "744/1088, train_loss: 0.0369\n",
      "745/1088, train_loss: 0.0354\n",
      "746/1088, train_loss: 0.0405\n",
      "747/1088, train_loss: 0.0497\n",
      "748/1088, train_loss: 0.0358\n",
      "749/1088, train_loss: 0.0429\n",
      "750/1088, train_loss: 0.0363\n",
      "751/1088, train_loss: 0.0382\n",
      "752/1088, train_loss: 0.0360\n",
      "753/1088, train_loss: 0.0397\n",
      "754/1088, train_loss: 0.0365\n",
      "755/1088, train_loss: 0.0424\n",
      "756/1088, train_loss: 0.0339\n",
      "757/1088, train_loss: 0.0388\n",
      "758/1088, train_loss: 0.0341\n",
      "759/1088, train_loss: 0.0354\n",
      "760/1088, train_loss: 0.0354\n",
      "761/1088, train_loss: 0.0386\n",
      "762/1088, train_loss: 0.0508\n",
      "763/1088, train_loss: 0.0368\n",
      "764/1088, train_loss: 0.0355\n",
      "765/1088, train_loss: 0.0359\n",
      "766/1088, train_loss: 0.0378\n",
      "767/1088, train_loss: 0.0393\n",
      "768/1088, train_loss: 0.0362\n",
      "769/1088, train_loss: 0.0381\n",
      "770/1088, train_loss: 0.0354\n",
      "771/1088, train_loss: 0.0349\n",
      "772/1088, train_loss: 0.0370\n",
      "773/1088, train_loss: 0.0375\n",
      "774/1088, train_loss: 0.0348\n",
      "775/1088, train_loss: 0.0357\n",
      "776/1088, train_loss: 0.0388\n",
      "777/1088, train_loss: 0.0342\n",
      "778/1088, train_loss: 0.0442\n",
      "779/1088, train_loss: 0.0334\n",
      "780/1088, train_loss: 0.0362\n",
      "781/1088, train_loss: 0.0325\n",
      "782/1088, train_loss: 0.0374\n",
      "783/1088, train_loss: 0.0418\n",
      "784/1088, train_loss: 0.0349\n",
      "785/1088, train_loss: 0.0397\n",
      "786/1088, train_loss: 0.0345\n",
      "787/1088, train_loss: 0.0337\n",
      "788/1088, train_loss: 0.0413\n",
      "789/1088, train_loss: 0.0397\n",
      "790/1088, train_loss: 0.0353\n",
      "791/1088, train_loss: 0.0388\n",
      "792/1088, train_loss: 0.0399\n",
      "793/1088, train_loss: 0.0353\n",
      "794/1088, train_loss: 0.0348\n",
      "795/1088, train_loss: 0.0440\n",
      "796/1088, train_loss: 0.0376\n",
      "797/1088, train_loss: 0.0397\n",
      "798/1088, train_loss: 0.0364\n",
      "799/1088, train_loss: 0.0412\n",
      "800/1088, train_loss: 0.0355\n",
      "801/1088, train_loss: 0.0356\n",
      "802/1088, train_loss: 0.0363\n",
      "803/1088, train_loss: 0.0430\n",
      "804/1088, train_loss: 0.0370\n",
      "805/1088, train_loss: 0.0350\n",
      "806/1088, train_loss: 0.0361\n",
      "807/1088, train_loss: 0.0387\n",
      "808/1088, train_loss: 0.0352\n",
      "809/1088, train_loss: 0.0437\n",
      "810/1088, train_loss: 0.0345\n",
      "811/1088, train_loss: 0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "812/1088, train_loss: 0.0344\n",
      "813/1088, train_loss: 0.0433\n",
      "814/1088, train_loss: 0.0363\n",
      "815/1088, train_loss: 0.0438\n",
      "816/1088, train_loss: 0.0349\n",
      "817/1088, train_loss: 0.0393\n",
      "818/1088, train_loss: 0.0369\n",
      "819/1088, train_loss: 0.0458\n",
      "820/1088, train_loss: 0.0361\n",
      "821/1088, train_loss: 0.0424\n",
      "822/1088, train_loss: 0.0342\n",
      "823/1088, train_loss: 0.0345\n",
      "824/1088, train_loss: 0.0341\n",
      "825/1088, train_loss: 0.0359\n",
      "826/1088, train_loss: 0.0359\n",
      "827/1088, train_loss: 0.0345\n",
      "828/1088, train_loss: 0.0336\n",
      "829/1088, train_loss: 0.0393\n",
      "830/1088, train_loss: 0.0435\n",
      "831/1088, train_loss: 0.0331\n",
      "832/1088, train_loss: 0.0373\n",
      "833/1088, train_loss: 0.0394\n",
      "834/1088, train_loss: 0.0360\n",
      "835/1088, train_loss: 0.0429\n",
      "836/1088, train_loss: 0.0359\n",
      "837/1088, train_loss: 0.0350\n",
      "838/1088, train_loss: 0.0335\n",
      "839/1088, train_loss: 0.0453\n",
      "840/1088, train_loss: 0.0440\n",
      "841/1088, train_loss: 0.0352\n",
      "842/1088, train_loss: 0.0366\n",
      "843/1088, train_loss: 0.0390\n",
      "844/1088, train_loss: 0.0368\n",
      "845/1088, train_loss: 0.0348\n",
      "846/1088, train_loss: 0.0345\n",
      "847/1088, train_loss: 0.0344\n",
      "848/1088, train_loss: 0.0413\n",
      "849/1088, train_loss: 0.0389\n",
      "850/1088, train_loss: 0.0654\n",
      "851/1088, train_loss: 0.0398\n",
      "852/1088, train_loss: 0.0408\n",
      "853/1088, train_loss: 0.0346\n",
      "854/1088, train_loss: 0.0349\n",
      "855/1088, train_loss: 0.0334\n",
      "856/1088, train_loss: 0.0341\n",
      "857/1088, train_loss: 0.0347\n",
      "858/1088, train_loss: 0.0336\n",
      "859/1088, train_loss: 0.0330\n",
      "860/1088, train_loss: 0.0347\n",
      "861/1088, train_loss: 0.0373\n",
      "862/1088, train_loss: 0.0361\n",
      "863/1088, train_loss: 0.0349\n",
      "864/1088, train_loss: 0.0352\n",
      "865/1088, train_loss: 0.0405\n",
      "866/1088, train_loss: 0.0406\n",
      "867/1088, train_loss: 0.0388\n",
      "868/1088, train_loss: 0.0445\n",
      "869/1088, train_loss: 0.0357\n",
      "870/1088, train_loss: 0.0355\n",
      "871/1088, train_loss: 0.0363\n",
      "872/1088, train_loss: 0.0354\n",
      "873/1088, train_loss: 0.0382\n",
      "874/1088, train_loss: 0.0443\n",
      "875/1088, train_loss: 0.0393\n",
      "876/1088, train_loss: 0.0330\n",
      "877/1088, train_loss: 0.0389\n",
      "878/1088, train_loss: 0.0374\n",
      "879/1088, train_loss: 0.0670\n",
      "880/1088, train_loss: 0.0366\n",
      "881/1088, train_loss: 0.0358\n",
      "882/1088, train_loss: 0.0435\n",
      "883/1088, train_loss: 0.0381\n",
      "884/1088, train_loss: 0.0377\n",
      "885/1088, train_loss: 0.0391\n",
      "886/1088, train_loss: 0.0347\n",
      "887/1088, train_loss: 0.0351\n",
      "888/1088, train_loss: 0.0389\n",
      "889/1088, train_loss: 0.0353\n",
      "890/1088, train_loss: 0.0350\n",
      "891/1088, train_loss: 0.0342\n",
      "892/1088, train_loss: 0.0369\n",
      "893/1088, train_loss: 0.0406\n",
      "894/1088, train_loss: 0.0396\n",
      "895/1088, train_loss: 0.0387\n",
      "896/1088, train_loss: 0.0346\n",
      "897/1088, train_loss: 0.0421\n",
      "898/1088, train_loss: 0.0348\n",
      "899/1088, train_loss: 0.0375\n",
      "900/1088, train_loss: 0.0432\n",
      "901/1088, train_loss: 0.0345\n",
      "902/1088, train_loss: 0.0359\n",
      "903/1088, train_loss: 0.0360\n",
      "904/1088, train_loss: 0.0404\n",
      "905/1088, train_loss: 0.0368\n",
      "906/1088, train_loss: 0.0364\n",
      "907/1088, train_loss: 0.0351\n",
      "908/1088, train_loss: 0.0342\n",
      "909/1088, train_loss: 0.0330\n",
      "910/1088, train_loss: 0.0334\n",
      "911/1088, train_loss: 0.0351\n",
      "912/1088, train_loss: 0.0511\n",
      "913/1088, train_loss: 0.0332\n",
      "914/1088, train_loss: 0.0347\n",
      "915/1088, train_loss: 0.0343\n",
      "916/1088, train_loss: 0.0378\n",
      "917/1088, train_loss: 0.0361\n",
      "918/1088, train_loss: 0.0325\n",
      "919/1088, train_loss: 0.0363\n",
      "920/1088, train_loss: 0.0368\n",
      "921/1088, train_loss: 0.0348\n",
      "922/1088, train_loss: 0.0349\n",
      "923/1088, train_loss: 0.0338\n",
      "924/1088, train_loss: 0.0352\n",
      "925/1088, train_loss: 0.0362\n",
      "926/1088, train_loss: 0.0365\n",
      "927/1088, train_loss: 0.0394\n",
      "928/1088, train_loss: 0.0330\n",
      "929/1088, train_loss: 0.0346\n",
      "930/1088, train_loss: 0.0436\n",
      "931/1088, train_loss: 0.0343\n",
      "932/1088, train_loss: 0.0333\n",
      "933/1088, train_loss: 0.0374\n",
      "934/1088, train_loss: 0.0348\n",
      "935/1088, train_loss: 0.0396\n",
      "936/1088, train_loss: 0.0359\n",
      "937/1088, train_loss: 0.0330\n",
      "938/1088, train_loss: 0.0398\n",
      "939/1088, train_loss: 0.0349\n",
      "940/1088, train_loss: 0.0360\n",
      "941/1088, train_loss: 0.0327\n",
      "942/1088, train_loss: 0.0459\n",
      "943/1088, train_loss: 0.0377\n",
      "944/1088, train_loss: 0.0360\n",
      "945/1088, train_loss: 0.0343\n",
      "946/1088, train_loss: 0.0355\n",
      "947/1088, train_loss: 0.0418\n",
      "948/1088, train_loss: 0.0373\n",
      "949/1088, train_loss: 0.0496\n",
      "950/1088, train_loss: 0.0349\n",
      "951/1088, train_loss: 0.0347\n",
      "952/1088, train_loss: 0.0348\n",
      "953/1088, train_loss: 0.0349\n",
      "954/1088, train_loss: 0.0430\n",
      "955/1088, train_loss: 0.0335\n",
      "956/1088, train_loss: 0.0570\n",
      "957/1088, train_loss: 0.0398\n",
      "958/1088, train_loss: 0.0352\n",
      "959/1088, train_loss: 0.0353\n",
      "960/1088, train_loss: 0.0327\n",
      "961/1088, train_loss: 0.0332\n",
      "962/1088, train_loss: 0.0348\n",
      "963/1088, train_loss: 0.0507\n",
      "964/1088, train_loss: 0.0461\n",
      "965/1088, train_loss: 0.0327\n",
      "966/1088, train_loss: 0.0322\n",
      "967/1088, train_loss: 0.0363\n",
      "968/1088, train_loss: 0.0450\n",
      "969/1088, train_loss: 0.0323\n",
      "970/1088, train_loss: 0.0375\n",
      "971/1088, train_loss: 0.0335\n",
      "972/1088, train_loss: 0.0410\n",
      "973/1088, train_loss: 0.0351\n",
      "974/1088, train_loss: 0.0323\n",
      "975/1088, train_loss: 0.0370\n",
      "976/1088, train_loss: 0.0372\n",
      "977/1088, train_loss: 0.0401\n",
      "978/1088, train_loss: 0.0363\n",
      "979/1088, train_loss: 0.0426\n",
      "980/1088, train_loss: 0.0359\n",
      "981/1088, train_loss: 0.0346\n",
      "982/1088, train_loss: 0.0351\n",
      "983/1088, train_loss: 0.0360\n",
      "984/1088, train_loss: 0.0345\n",
      "985/1088, train_loss: 0.0359\n",
      "986/1088, train_loss: 0.0342\n",
      "987/1088, train_loss: 0.0352\n",
      "988/1088, train_loss: 0.0350\n",
      "989/1088, train_loss: 0.0342\n",
      "990/1088, train_loss: 0.0389\n",
      "991/1088, train_loss: 0.0356\n",
      "992/1088, train_loss: 0.0368\n",
      "993/1088, train_loss: 0.0364\n",
      "994/1088, train_loss: 0.0356\n",
      "995/1088, train_loss: 0.0349\n",
      "996/1088, train_loss: 0.0352\n",
      "997/1088, train_loss: 0.0340\n",
      "998/1088, train_loss: 0.0347\n",
      "999/1088, train_loss: 0.0374\n",
      "1000/1088, train_loss: 0.0365\n",
      "1001/1088, train_loss: 0.0432\n",
      "1002/1088, train_loss: 0.0364\n",
      "1003/1088, train_loss: 0.0473\n",
      "1004/1088, train_loss: 0.0374\n",
      "1005/1088, train_loss: 0.0365\n",
      "1006/1088, train_loss: 0.0368\n",
      "1007/1088, train_loss: 0.0362\n",
      "1008/1088, train_loss: 0.0391\n",
      "1009/1088, train_loss: 0.0392\n",
      "1010/1088, train_loss: 0.0363\n",
      "1011/1088, train_loss: 0.0366\n",
      "1012/1088, train_loss: 0.0354\n",
      "1013/1088, train_loss: 0.0356\n",
      "1014/1088, train_loss: 0.0371\n",
      "1015/1088, train_loss: 0.0367\n",
      "1016/1088, train_loss: 0.0326\n",
      "1017/1088, train_loss: 0.0304\n",
      "1018/1088, train_loss: 0.0450\n",
      "1019/1088, train_loss: 0.0356\n",
      "1020/1088, train_loss: 0.0335\n",
      "1021/1088, train_loss: 0.0462\n",
      "1022/1088, train_loss: 0.0397\n",
      "1023/1088, train_loss: 0.0405\n",
      "1024/1088, train_loss: 0.0353\n",
      "1025/1088, train_loss: 0.0354\n",
      "1026/1088, train_loss: 0.0357\n",
      "1027/1088, train_loss: 0.0385\n",
      "1028/1088, train_loss: 0.0366\n",
      "1029/1088, train_loss: 0.0349\n",
      "1030/1088, train_loss: 0.0368\n",
      "1031/1088, train_loss: 0.0365\n",
      "1032/1088, train_loss: 0.0341\n",
      "1033/1088, train_loss: 0.0343\n",
      "1034/1088, train_loss: 0.0344\n",
      "1035/1088, train_loss: 0.0340\n",
      "1036/1088, train_loss: 0.0336\n",
      "1037/1088, train_loss: 0.0333\n",
      "1038/1088, train_loss: 0.0375\n",
      "1039/1088, train_loss: 0.0342\n",
      "1040/1088, train_loss: 0.0371\n",
      "1041/1088, train_loss: 0.0524\n",
      "1042/1088, train_loss: 0.0433\n",
      "1043/1088, train_loss: 0.0335\n",
      "1044/1088, train_loss: 0.0352\n",
      "1045/1088, train_loss: 0.0321\n",
      "1046/1088, train_loss: 0.0497\n",
      "1047/1088, train_loss: 0.0359\n",
      "1048/1088, train_loss: 0.0386\n",
      "1049/1088, train_loss: 0.0508\n",
      "1050/1088, train_loss: 0.0402\n",
      "1051/1088, train_loss: 0.0436\n",
      "1052/1088, train_loss: 0.0352\n",
      "1053/1088, train_loss: 0.0361\n",
      "1054/1088, train_loss: 0.0400\n",
      "1055/1088, train_loss: 0.0396\n",
      "1056/1088, train_loss: 0.0378\n",
      "1057/1088, train_loss: 0.0401\n",
      "1058/1088, train_loss: 0.0351\n",
      "1059/1088, train_loss: 0.0337\n",
      "1060/1088, train_loss: 0.0337\n",
      "1061/1088, train_loss: 0.0347\n",
      "1062/1088, train_loss: 0.0347\n",
      "1063/1088, train_loss: 0.0334\n",
      "1064/1088, train_loss: 0.0411\n",
      "1065/1088, train_loss: 0.0346\n",
      "1066/1088, train_loss: 0.0337\n",
      "1067/1088, train_loss: 0.0373\n",
      "1068/1088, train_loss: 0.0420\n",
      "1069/1088, train_loss: 0.0339\n",
      "1070/1088, train_loss: 0.0329\n",
      "1071/1088, train_loss: 0.0407\n",
      "1072/1088, train_loss: 0.0364\n",
      "1073/1088, train_loss: 0.0381\n",
      "1074/1088, train_loss: 0.0347\n",
      "1075/1088, train_loss: 0.0441\n",
      "1076/1088, train_loss: 0.0330\n",
      "1077/1088, train_loss: 0.0374\n",
      "1078/1088, train_loss: 0.0405\n",
      "1079/1088, train_loss: 0.0464\n",
      "1080/1088, train_loss: 0.0404\n",
      "1081/1088, train_loss: 0.0409\n",
      "1082/1088, train_loss: 0.0557\n",
      "1083/1088, train_loss: 0.0501\n",
      "1084/1088, train_loss: 0.0386\n",
      "1085/1088, train_loss: 0.0399\n",
      "1086/1088, train_loss: 0.0355\n",
      "1087/1088, train_loss: 0.0366\n",
      "1088/1088, train_loss: 0.0369\n",
      "1089/1088, train_loss: 0.0354\n",
      "epoch 1 average loss: 0.0517, train_dice: 0.9526\n",
      "epoch 1 average loss: 0.0517\n",
      "--------------------------------------------------\n",
      "epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1088, train_loss: 0.0397\n",
      "2/1088, train_loss: 0.0373\n",
      "3/1088, train_loss: 0.0352\n",
      "4/1088, train_loss: 0.0369\n",
      "5/1088, train_loss: 0.0336\n",
      "6/1088, train_loss: 0.0329\n",
      "7/1088, train_loss: 0.0346\n",
      "8/1088, train_loss: 0.0327\n",
      "9/1088, train_loss: 0.0317\n",
      "10/1088, train_loss: 0.0315\n",
      "11/1088, train_loss: 0.0403\n",
      "12/1088, train_loss: 0.0396\n",
      "13/1088, train_loss: 0.0339\n",
      "14/1088, train_loss: 0.0343\n",
      "15/1088, train_loss: 0.0462\n",
      "16/1088, train_loss: 0.0380\n",
      "17/1088, train_loss: 0.0353\n",
      "18/1088, train_loss: 0.0359\n",
      "19/1088, train_loss: 0.0389\n",
      "20/1088, train_loss: 0.0375\n",
      "21/1088, train_loss: 0.0373\n",
      "22/1088, train_loss: 0.0350\n",
      "23/1088, train_loss: 0.0355\n",
      "24/1088, train_loss: 0.0415\n",
      "25/1088, train_loss: 0.0344\n",
      "26/1088, train_loss: 0.0346\n",
      "27/1088, train_loss: 0.0335\n",
      "28/1088, train_loss: 0.0355\n",
      "29/1088, train_loss: 0.0315\n",
      "30/1088, train_loss: 0.0331\n",
      "31/1088, train_loss: 0.0364\n",
      "32/1088, train_loss: 0.0469\n",
      "33/1088, train_loss: 0.0528\n",
      "34/1088, train_loss: 0.0464\n",
      "35/1088, train_loss: 0.0356\n",
      "36/1088, train_loss: 0.0363\n",
      "37/1088, train_loss: 0.0344\n",
      "38/1088, train_loss: 0.0353\n",
      "39/1088, train_loss: 0.0351\n",
      "40/1088, train_loss: 0.0335\n",
      "41/1088, train_loss: 0.0340\n",
      "42/1088, train_loss: 0.0493\n",
      "43/1088, train_loss: 0.0390\n",
      "44/1088, train_loss: 0.0334\n",
      "45/1088, train_loss: 0.0479\n",
      "46/1088, train_loss: 0.0355\n",
      "47/1088, train_loss: 0.0484\n",
      "48/1088, train_loss: 0.0435\n",
      "49/1088, train_loss: 0.0413\n",
      "50/1088, train_loss: 0.0434\n",
      "51/1088, train_loss: 0.0363\n",
      "52/1088, train_loss: 0.0363\n",
      "53/1088, train_loss: 0.0356\n",
      "54/1088, train_loss: 0.0389\n",
      "55/1088, train_loss: 0.0393\n",
      "56/1088, train_loss: 0.0338\n",
      "57/1088, train_loss: 0.0390\n",
      "58/1088, train_loss: 0.0335\n",
      "59/1088, train_loss: 0.0368\n",
      "60/1088, train_loss: 0.0349\n",
      "61/1088, train_loss: 0.0350\n",
      "62/1088, train_loss: 0.0368\n",
      "63/1088, train_loss: 0.0359\n",
      "64/1088, train_loss: 0.0348\n",
      "65/1088, train_loss: 0.0383\n",
      "66/1088, train_loss: 0.0376\n",
      "67/1088, train_loss: 0.0444\n",
      "68/1088, train_loss: 0.0380\n",
      "69/1088, train_loss: 0.0425\n",
      "70/1088, train_loss: 0.0342\n",
      "71/1088, train_loss: 0.0354\n",
      "72/1088, train_loss: 0.0371\n",
      "73/1088, train_loss: 0.0357\n",
      "74/1088, train_loss: 0.0338\n",
      "75/1088, train_loss: 0.0355\n",
      "76/1088, train_loss: 0.0357\n",
      "77/1088, train_loss: 0.0340\n",
      "78/1088, train_loss: 0.0353\n",
      "79/1088, train_loss: 0.0449\n",
      "80/1088, train_loss: 0.0337\n",
      "81/1088, train_loss: 0.0387\n",
      "82/1088, train_loss: 0.0337\n",
      "83/1088, train_loss: 0.0363\n",
      "84/1088, train_loss: 0.0352\n",
      "85/1088, train_loss: 0.0362\n",
      "86/1088, train_loss: 0.0404\n",
      "87/1088, train_loss: 0.0338\n",
      "88/1088, train_loss: 0.0357\n",
      "89/1088, train_loss: 0.0359\n",
      "90/1088, train_loss: 0.0357\n",
      "91/1088, train_loss: 0.0358\n",
      "92/1088, train_loss: 0.0357\n",
      "93/1088, train_loss: 0.0410\n",
      "94/1088, train_loss: 0.0337\n",
      "95/1088, train_loss: 0.0343\n",
      "96/1088, train_loss: 0.0435\n",
      "97/1088, train_loss: 0.0350\n",
      "98/1088, train_loss: 0.0338\n",
      "99/1088, train_loss: 0.0327\n",
      "100/1088, train_loss: 0.0350\n",
      "101/1088, train_loss: 0.0420\n",
      "102/1088, train_loss: 0.0342\n",
      "103/1088, train_loss: 0.0319\n",
      "104/1088, train_loss: 0.0394\n",
      "105/1088, train_loss: 0.0400\n",
      "106/1088, train_loss: 0.0352\n",
      "107/1088, train_loss: 0.0376\n",
      "108/1088, train_loss: 0.0410\n",
      "109/1088, train_loss: 0.0367\n",
      "110/1088, train_loss: 0.0335\n",
      "111/1088, train_loss: 0.0338\n",
      "112/1088, train_loss: 0.0525\n",
      "113/1088, train_loss: 0.0394\n",
      "114/1088, train_loss: 0.0336\n",
      "115/1088, train_loss: 0.0440\n",
      "116/1088, train_loss: 0.0368\n",
      "117/1088, train_loss: 0.0425\n",
      "118/1088, train_loss: 0.0364\n",
      "119/1088, train_loss: 0.0376\n",
      "120/1088, train_loss: 0.0370\n",
      "121/1088, train_loss: 0.0350\n",
      "122/1088, train_loss: 0.0407\n",
      "123/1088, train_loss: 0.0351\n",
      "124/1088, train_loss: 0.0352\n",
      "125/1088, train_loss: 0.0420\n",
      "126/1088, train_loss: 0.0360\n",
      "127/1088, train_loss: 0.0347\n",
      "128/1088, train_loss: 0.0386\n",
      "129/1088, train_loss: 0.0348\n",
      "130/1088, train_loss: 0.0525\n",
      "131/1088, train_loss: 0.0374\n",
      "132/1088, train_loss: 0.0341\n",
      "133/1088, train_loss: 0.0348\n",
      "134/1088, train_loss: 0.0378\n",
      "135/1088, train_loss: 0.0327\n",
      "136/1088, train_loss: 0.0347\n",
      "137/1088, train_loss: 0.0328\n",
      "138/1088, train_loss: 0.0336\n",
      "139/1088, train_loss: 0.0346\n",
      "140/1088, train_loss: 0.0343\n",
      "141/1088, train_loss: 0.0409\n",
      "142/1088, train_loss: 0.0403\n",
      "143/1088, train_loss: 0.0363\n",
      "144/1088, train_loss: 0.0314\n",
      "145/1088, train_loss: 0.0382\n",
      "146/1088, train_loss: 0.0388\n",
      "147/1088, train_loss: 0.0385\n",
      "148/1088, train_loss: 0.0395\n",
      "149/1088, train_loss: 0.0351\n",
      "150/1088, train_loss: 0.0354\n",
      "151/1088, train_loss: 0.0344\n",
      "152/1088, train_loss: 0.0364\n",
      "153/1088, train_loss: 0.0365\n",
      "154/1088, train_loss: 0.0370\n",
      "155/1088, train_loss: 0.0392\n",
      "156/1088, train_loss: 0.0391\n",
      "157/1088, train_loss: 0.0484\n",
      "158/1088, train_loss: 0.0358\n",
      "159/1088, train_loss: 0.0390\n",
      "160/1088, train_loss: 0.0342\n",
      "161/1088, train_loss: 0.0328\n",
      "162/1088, train_loss: 0.0425\n",
      "163/1088, train_loss: 0.0350\n",
      "164/1088, train_loss: 0.0339\n",
      "165/1088, train_loss: 0.0417\n",
      "166/1088, train_loss: 0.0360\n",
      "167/1088, train_loss: 0.0351\n",
      "168/1088, train_loss: 0.0368\n",
      "169/1088, train_loss: 0.0324\n",
      "170/1088, train_loss: 0.0325\n",
      "171/1088, train_loss: 0.0330\n",
      "172/1088, train_loss: 0.0356\n",
      "173/1088, train_loss: 0.0350\n",
      "174/1088, train_loss: 0.0540\n",
      "175/1088, train_loss: 0.0335\n",
      "176/1088, train_loss: 0.0459\n",
      "177/1088, train_loss: 0.0564\n",
      "178/1088, train_loss: 0.0334\n",
      "179/1088, train_loss: 0.0377\n",
      "180/1088, train_loss: 0.0325\n",
      "181/1088, train_loss: 0.0394\n",
      "182/1088, train_loss: 0.0398\n",
      "183/1088, train_loss: 0.0355\n",
      "184/1088, train_loss: 0.0348\n",
      "185/1088, train_loss: 0.0423\n",
      "186/1088, train_loss: 0.0495\n",
      "187/1088, train_loss: 0.0342\n",
      "188/1088, train_loss: 0.0387\n",
      "189/1088, train_loss: 0.0366\n",
      "190/1088, train_loss: 0.0357\n",
      "191/1088, train_loss: 0.0333\n",
      "192/1088, train_loss: 0.0332\n",
      "193/1088, train_loss: 0.0321\n",
      "194/1088, train_loss: 0.0337\n",
      "195/1088, train_loss: 0.0338\n",
      "196/1088, train_loss: 0.0362\n",
      "197/1088, train_loss: 0.0328\n",
      "198/1088, train_loss: 0.0342\n",
      "199/1088, train_loss: 0.0357\n",
      "200/1088, train_loss: 0.0458\n",
      "201/1088, train_loss: 0.0368\n",
      "202/1088, train_loss: 0.0332\n",
      "203/1088, train_loss: 0.0372\n",
      "204/1088, train_loss: 0.0354\n",
      "205/1088, train_loss: 0.0342\n",
      "206/1088, train_loss: 0.0349\n",
      "207/1088, train_loss: 0.0497\n",
      "208/1088, train_loss: 0.0334\n",
      "209/1088, train_loss: 0.0362\n",
      "210/1088, train_loss: 0.0351\n",
      "211/1088, train_loss: 0.0401\n",
      "212/1088, train_loss: 0.0335\n",
      "213/1088, train_loss: 0.0416\n",
      "214/1088, train_loss: 0.0324\n",
      "215/1088, train_loss: 0.0355\n",
      "216/1088, train_loss: 0.0393\n",
      "217/1088, train_loss: 0.0358\n",
      "218/1088, train_loss: 0.0374\n",
      "219/1088, train_loss: 0.0363\n",
      "220/1088, train_loss: 0.0364\n",
      "221/1088, train_loss: 0.0361\n",
      "222/1088, train_loss: 0.0365\n",
      "223/1088, train_loss: 0.0372\n",
      "224/1088, train_loss: 0.0377\n",
      "225/1088, train_loss: 0.0386\n",
      "226/1088, train_loss: 0.0347\n",
      "227/1088, train_loss: 0.0389\n",
      "228/1088, train_loss: 0.0355\n",
      "229/1088, train_loss: 0.0396\n",
      "230/1088, train_loss: 0.0367\n",
      "231/1088, train_loss: 0.0484\n",
      "232/1088, train_loss: 0.0356\n",
      "233/1088, train_loss: 0.0350\n",
      "234/1088, train_loss: 0.0368\n",
      "235/1088, train_loss: 0.0376\n",
      "236/1088, train_loss: 0.0374\n",
      "237/1088, train_loss: 0.0364\n",
      "238/1088, train_loss: 0.0383\n",
      "239/1088, train_loss: 0.0385\n",
      "240/1088, train_loss: 0.0359\n",
      "241/1088, train_loss: 0.0355\n",
      "242/1088, train_loss: 0.0363\n",
      "243/1088, train_loss: 0.0348\n",
      "244/1088, train_loss: 0.0360\n",
      "245/1088, train_loss: 0.0413\n",
      "246/1088, train_loss: 0.0358\n",
      "247/1088, train_loss: 0.0359\n",
      "248/1088, train_loss: 0.0360\n",
      "249/1088, train_loss: 0.0426\n",
      "250/1088, train_loss: 0.0385\n",
      "251/1088, train_loss: 0.0450\n",
      "252/1088, train_loss: 0.0350\n",
      "253/1088, train_loss: 0.0381\n",
      "254/1088, train_loss: 0.0339\n",
      "255/1088, train_loss: 0.0334\n",
      "256/1088, train_loss: 0.0324\n",
      "257/1088, train_loss: 0.0335\n",
      "258/1088, train_loss: 0.0379\n",
      "259/1088, train_loss: 0.0324\n",
      "260/1088, train_loss: 0.0355\n",
      "261/1088, train_loss: 0.0381\n",
      "262/1088, train_loss: 0.0390\n",
      "263/1088, train_loss: 0.0338\n",
      "264/1088, train_loss: 0.0346\n",
      "265/1088, train_loss: 0.0494\n",
      "266/1088, train_loss: 0.0385\n",
      "267/1088, train_loss: 0.0374\n",
      "268/1088, train_loss: 0.0349\n",
      "269/1088, train_loss: 0.0382\n",
      "270/1088, train_loss: 0.0361\n",
      "271/1088, train_loss: 0.0355\n",
      "272/1088, train_loss: 0.0383\n",
      "273/1088, train_loss: 0.0373\n",
      "274/1088, train_loss: 0.0353\n",
      "275/1088, train_loss: 0.0352\n",
      "276/1088, train_loss: 0.0380\n",
      "277/1088, train_loss: 0.0376\n",
      "278/1088, train_loss: 0.0355\n",
      "279/1088, train_loss: 0.0407\n",
      "280/1088, train_loss: 0.0360\n",
      "281/1088, train_loss: 0.0371\n",
      "282/1088, train_loss: 0.0354\n",
      "283/1088, train_loss: 0.0331\n",
      "284/1088, train_loss: 0.0325\n",
      "285/1088, train_loss: 0.0346\n",
      "286/1088, train_loss: 0.0318\n",
      "287/1088, train_loss: 0.0387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/1088, train_loss: 0.0326\n",
      "289/1088, train_loss: 0.0375\n",
      "290/1088, train_loss: 0.0331\n",
      "291/1088, train_loss: 0.0332\n",
      "292/1088, train_loss: 0.0353\n",
      "293/1088, train_loss: 0.0339\n",
      "294/1088, train_loss: 0.0440\n",
      "295/1088, train_loss: 0.0333\n",
      "296/1088, train_loss: 0.0397\n",
      "297/1088, train_loss: 0.0475\n",
      "298/1088, train_loss: 0.0368\n",
      "299/1088, train_loss: 0.0366\n",
      "300/1088, train_loss: 0.0384\n",
      "301/1088, train_loss: 0.0348\n",
      "302/1088, train_loss: 0.0336\n",
      "303/1088, train_loss: 0.0341\n",
      "304/1088, train_loss: 0.0341\n",
      "305/1088, train_loss: 0.0326\n",
      "306/1088, train_loss: 0.0316\n",
      "307/1088, train_loss: 0.0351\n",
      "308/1088, train_loss: 0.0366\n",
      "309/1088, train_loss: 0.0334\n",
      "310/1088, train_loss: 0.0439\n",
      "311/1088, train_loss: 0.0505\n",
      "312/1088, train_loss: 0.0372\n",
      "313/1088, train_loss: 0.0369\n",
      "314/1088, train_loss: 0.0367\n",
      "315/1088, train_loss: 0.0361\n",
      "316/1088, train_loss: 0.0516\n",
      "317/1088, train_loss: 0.0341\n",
      "318/1088, train_loss: 0.0347\n",
      "319/1088, train_loss: 0.0352\n",
      "320/1088, train_loss: 0.0345\n",
      "321/1088, train_loss: 0.0322\n",
      "322/1088, train_loss: 0.0352\n",
      "323/1088, train_loss: 0.0334\n",
      "324/1088, train_loss: 0.0360\n",
      "325/1088, train_loss: 0.0394\n",
      "326/1088, train_loss: 0.0331\n",
      "327/1088, train_loss: 0.0353\n",
      "328/1088, train_loss: 0.0345\n",
      "329/1088, train_loss: 0.0371\n",
      "330/1088, train_loss: 0.0352\n",
      "331/1088, train_loss: 0.0370\n",
      "332/1088, train_loss: 0.0388\n",
      "333/1088, train_loss: 0.0345\n",
      "334/1088, train_loss: 0.0344\n",
      "335/1088, train_loss: 0.0342\n",
      "336/1088, train_loss: 0.0363\n",
      "337/1088, train_loss: 0.0348\n",
      "338/1088, train_loss: 0.0355\n",
      "339/1088, train_loss: 0.0337\n",
      "340/1088, train_loss: 0.0400\n",
      "341/1088, train_loss: 0.0376\n",
      "342/1088, train_loss: 0.0358\n",
      "343/1088, train_loss: 0.0332\n",
      "344/1088, train_loss: 0.0336\n",
      "345/1088, train_loss: 0.0354\n",
      "346/1088, train_loss: 0.0348\n",
      "347/1088, train_loss: 0.0355\n",
      "348/1088, train_loss: 0.0313\n",
      "349/1088, train_loss: 0.0476\n",
      "350/1088, train_loss: 0.0405\n",
      "351/1088, train_loss: 0.0372\n",
      "352/1088, train_loss: 0.0339\n",
      "353/1088, train_loss: 0.0342\n",
      "354/1088, train_loss: 0.0324\n",
      "355/1088, train_loss: 0.0334\n",
      "356/1088, train_loss: 0.0327\n",
      "357/1088, train_loss: 0.0352\n",
      "358/1088, train_loss: 0.0377\n",
      "359/1088, train_loss: 0.0314\n",
      "360/1088, train_loss: 0.0329\n",
      "361/1088, train_loss: 0.0315\n",
      "362/1088, train_loss: 0.0333\n",
      "363/1088, train_loss: 0.0324\n",
      "364/1088, train_loss: 0.0402\n",
      "365/1088, train_loss: 0.0356\n",
      "366/1088, train_loss: 0.0347\n",
      "367/1088, train_loss: 0.0324\n",
      "368/1088, train_loss: 0.0345\n",
      "369/1088, train_loss: 0.0345\n",
      "370/1088, train_loss: 0.0358\n",
      "371/1088, train_loss: 0.0334\n",
      "372/1088, train_loss: 0.0307\n",
      "373/1088, train_loss: 0.0336\n",
      "374/1088, train_loss: 0.0332\n",
      "375/1088, train_loss: 0.0362\n",
      "376/1088, train_loss: 0.0400\n",
      "377/1088, train_loss: 0.0359\n",
      "378/1088, train_loss: 0.0344\n",
      "379/1088, train_loss: 0.0330\n",
      "380/1088, train_loss: 0.0351\n",
      "381/1088, train_loss: 0.0483\n",
      "382/1088, train_loss: 0.0497\n",
      "383/1088, train_loss: 0.0352\n",
      "384/1088, train_loss: 0.0335\n",
      "385/1088, train_loss: 0.0338\n",
      "386/1088, train_loss: 0.0346\n",
      "387/1088, train_loss: 0.0335\n",
      "388/1088, train_loss: 0.0305\n",
      "389/1088, train_loss: 0.0366\n",
      "390/1088, train_loss: 0.0337\n",
      "391/1088, train_loss: 0.0330\n",
      "392/1088, train_loss: 0.0339\n",
      "393/1088, train_loss: 0.0331\n",
      "394/1088, train_loss: 0.0347\n",
      "395/1088, train_loss: 0.0312\n",
      "396/1088, train_loss: 0.0304\n",
      "397/1088, train_loss: 0.0348\n",
      "398/1088, train_loss: 0.0332\n",
      "399/1088, train_loss: 0.0335\n",
      "400/1088, train_loss: 0.0362\n",
      "401/1088, train_loss: 0.0325\n",
      "402/1088, train_loss: 0.0365\n",
      "403/1088, train_loss: 0.0321\n",
      "404/1088, train_loss: 0.0336\n",
      "405/1088, train_loss: 0.0348\n",
      "406/1088, train_loss: 0.0342\n",
      "407/1088, train_loss: 0.0426\n",
      "408/1088, train_loss: 0.0339\n",
      "409/1088, train_loss: 0.0350\n",
      "410/1088, train_loss: 0.0359\n",
      "411/1088, train_loss: 0.0336\n",
      "412/1088, train_loss: 0.0335\n",
      "413/1088, train_loss: 0.0329\n",
      "414/1088, train_loss: 0.0331\n",
      "415/1088, train_loss: 0.0327\n",
      "416/1088, train_loss: 0.0347\n",
      "417/1088, train_loss: 0.0339\n",
      "418/1088, train_loss: 0.0396\n",
      "419/1088, train_loss: 0.0337\n",
      "420/1088, train_loss: 0.0345\n",
      "421/1088, train_loss: 0.0325\n",
      "422/1088, train_loss: 0.0383\n",
      "423/1088, train_loss: 0.0348\n",
      "424/1088, train_loss: 0.0335\n",
      "425/1088, train_loss: 0.0359\n",
      "426/1088, train_loss: 0.0332\n",
      "427/1088, train_loss: 0.0398\n",
      "428/1088, train_loss: 0.0316\n",
      "429/1088, train_loss: 0.0323\n",
      "430/1088, train_loss: 0.0374\n",
      "431/1088, train_loss: 0.0372\n",
      "432/1088, train_loss: 0.0339\n",
      "433/1088, train_loss: 0.0299\n",
      "434/1088, train_loss: 0.0303\n",
      "435/1088, train_loss: 0.0371\n",
      "436/1088, train_loss: 0.0344\n",
      "437/1088, train_loss: 0.0373\n",
      "438/1088, train_loss: 0.0323\n",
      "439/1088, train_loss: 0.0337\n",
      "440/1088, train_loss: 0.0362\n",
      "441/1088, train_loss: 0.0327\n",
      "442/1088, train_loss: 0.0319\n",
      "443/1088, train_loss: 0.0343\n",
      "444/1088, train_loss: 0.0342\n",
      "445/1088, train_loss: 0.0327\n",
      "446/1088, train_loss: 0.0349\n",
      "447/1088, train_loss: 0.0339\n",
      "448/1088, train_loss: 0.0370\n",
      "449/1088, train_loss: 0.0346\n",
      "450/1088, train_loss: 0.0329\n",
      "451/1088, train_loss: 0.0307\n",
      "452/1088, train_loss: 0.0315\n",
      "453/1088, train_loss: 0.0421\n",
      "454/1088, train_loss: 0.0299\n",
      "455/1088, train_loss: 0.0335\n",
      "456/1088, train_loss: 0.0443\n",
      "457/1088, train_loss: 0.0461\n",
      "458/1088, train_loss: 0.0341\n",
      "459/1088, train_loss: 0.0374\n",
      "460/1088, train_loss: 0.0328\n",
      "461/1088, train_loss: 0.0446\n",
      "462/1088, train_loss: 0.0355\n",
      "463/1088, train_loss: 0.0337\n",
      "464/1088, train_loss: 0.0326\n",
      "465/1088, train_loss: 0.0350\n",
      "466/1088, train_loss: 0.0363\n",
      "467/1088, train_loss: 0.0319\n",
      "468/1088, train_loss: 0.0318\n",
      "469/1088, train_loss: 0.0308\n",
      "470/1088, train_loss: 0.0387\n",
      "471/1088, train_loss: 0.0351\n",
      "472/1088, train_loss: 0.0318\n",
      "473/1088, train_loss: 0.0480\n",
      "474/1088, train_loss: 0.0375\n",
      "475/1088, train_loss: 0.0319\n",
      "476/1088, train_loss: 0.0341\n",
      "477/1088, train_loss: 0.0366\n",
      "478/1088, train_loss: 0.0327\n",
      "479/1088, train_loss: 0.0330\n",
      "480/1088, train_loss: 0.0332\n",
      "481/1088, train_loss: 0.0315\n",
      "482/1088, train_loss: 0.0380\n",
      "483/1088, train_loss: 0.0365\n",
      "484/1088, train_loss: 0.0336\n",
      "485/1088, train_loss: 0.0319\n",
      "486/1088, train_loss: 0.0365\n",
      "487/1088, train_loss: 0.0339\n",
      "488/1088, train_loss: 0.0347\n",
      "489/1088, train_loss: 0.0330\n",
      "490/1088, train_loss: 0.0313\n",
      "491/1088, train_loss: 0.0361\n",
      "492/1088, train_loss: 0.0364\n",
      "493/1088, train_loss: 0.0370\n",
      "494/1088, train_loss: 0.0416\n",
      "495/1088, train_loss: 0.0355\n",
      "496/1088, train_loss: 0.0311\n",
      "497/1088, train_loss: 0.0324\n",
      "498/1088, train_loss: 0.0324\n",
      "499/1088, train_loss: 0.0393\n",
      "500/1088, train_loss: 0.0344\n",
      "501/1088, train_loss: 0.0341\n",
      "502/1088, train_loss: 0.0343\n",
      "503/1088, train_loss: 0.0377\n",
      "504/1088, train_loss: 0.0338\n",
      "505/1088, train_loss: 0.0341\n",
      "506/1088, train_loss: 0.0339\n",
      "507/1088, train_loss: 0.0356\n",
      "508/1088, train_loss: 0.0318\n",
      "509/1088, train_loss: 0.0332\n",
      "510/1088, train_loss: 0.0327\n",
      "511/1088, train_loss: 0.0348\n",
      "512/1088, train_loss: 0.0326\n",
      "513/1088, train_loss: 0.0360\n",
      "514/1088, train_loss: 0.0459\n",
      "515/1088, train_loss: 0.0372\n",
      "516/1088, train_loss: 0.0343\n",
      "517/1088, train_loss: 0.0317\n",
      "518/1088, train_loss: 0.0468\n",
      "519/1088, train_loss: 0.0319\n",
      "520/1088, train_loss: 0.0304\n",
      "521/1088, train_loss: 0.0381\n",
      "522/1088, train_loss: 0.0291\n",
      "523/1088, train_loss: 0.0338\n",
      "524/1088, train_loss: 0.0361\n",
      "525/1088, train_loss: 0.0336\n",
      "526/1088, train_loss: 0.0313\n",
      "527/1088, train_loss: 0.0398\n",
      "528/1088, train_loss: 0.0326\n",
      "529/1088, train_loss: 0.0342\n",
      "530/1088, train_loss: 0.0358\n",
      "531/1088, train_loss: 0.0345\n",
      "532/1088, train_loss: 0.0316\n",
      "533/1088, train_loss: 0.0322\n",
      "534/1088, train_loss: 0.0352\n",
      "535/1088, train_loss: 0.0298\n",
      "536/1088, train_loss: 0.0329\n",
      "537/1088, train_loss: 0.0327\n",
      "538/1088, train_loss: 0.0311\n",
      "539/1088, train_loss: 0.0339\n",
      "540/1088, train_loss: 0.0316\n",
      "541/1088, train_loss: 0.0331\n",
      "542/1088, train_loss: 0.0329\n",
      "543/1088, train_loss: 0.0368\n",
      "544/1088, train_loss: 0.0355\n",
      "545/1088, train_loss: 0.0392\n",
      "546/1088, train_loss: 0.0347\n",
      "547/1088, train_loss: 0.0357\n",
      "548/1088, train_loss: 0.0315\n",
      "549/1088, train_loss: 0.0316\n",
      "550/1088, train_loss: 0.0312\n",
      "551/1088, train_loss: 0.0301\n",
      "552/1088, train_loss: 0.0338\n",
      "553/1088, train_loss: 0.0324\n",
      "554/1088, train_loss: 0.0344\n",
      "555/1088, train_loss: 0.0381\n",
      "556/1088, train_loss: 0.0322\n",
      "557/1088, train_loss: 0.0383\n",
      "558/1088, train_loss: 0.0309\n",
      "559/1088, train_loss: 0.0359\n",
      "560/1088, train_loss: 0.0321\n",
      "561/1088, train_loss: 0.0322\n",
      "562/1088, train_loss: 0.0336\n",
      "563/1088, train_loss: 0.0309\n",
      "564/1088, train_loss: 0.0319\n",
      "565/1088, train_loss: 0.0425\n",
      "566/1088, train_loss: 0.0327\n",
      "567/1088, train_loss: 0.0396\n",
      "568/1088, train_loss: 0.0341\n",
      "569/1088, train_loss: 0.0327\n",
      "570/1088, train_loss: 0.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/1088, train_loss: 0.0321\n",
      "572/1088, train_loss: 0.0319\n",
      "573/1088, train_loss: 0.0319\n",
      "574/1088, train_loss: 0.0328\n",
      "575/1088, train_loss: 0.0316\n",
      "576/1088, train_loss: 0.0328\n",
      "577/1088, train_loss: 0.0361\n",
      "578/1088, train_loss: 0.0327\n",
      "579/1088, train_loss: 0.0366\n",
      "580/1088, train_loss: 0.0369\n",
      "581/1088, train_loss: 0.0323\n",
      "582/1088, train_loss: 0.0338\n",
      "583/1088, train_loss: 0.0350\n",
      "584/1088, train_loss: 0.0335\n",
      "585/1088, train_loss: 0.0317\n",
      "586/1088, train_loss: 0.0311\n",
      "587/1088, train_loss: 0.0361\n",
      "588/1088, train_loss: 0.0323\n",
      "589/1088, train_loss: 0.0347\n",
      "590/1088, train_loss: 0.0341\n",
      "591/1088, train_loss: 0.0358\n",
      "592/1088, train_loss: 0.0326\n",
      "593/1088, train_loss: 0.0335\n",
      "594/1088, train_loss: 0.0323\n",
      "595/1088, train_loss: 0.0330\n",
      "596/1088, train_loss: 0.0341\n",
      "597/1088, train_loss: 0.0338\n",
      "598/1088, train_loss: 0.0391\n",
      "599/1088, train_loss: 0.0319\n",
      "600/1088, train_loss: 0.0320\n",
      "601/1088, train_loss: 0.0315\n",
      "602/1088, train_loss: 0.0299\n",
      "603/1088, train_loss: 0.0357\n",
      "604/1088, train_loss: 0.0365\n",
      "605/1088, train_loss: 0.0308\n",
      "606/1088, train_loss: 0.0325\n",
      "607/1088, train_loss: 0.0322\n",
      "608/1088, train_loss: 0.0311\n",
      "609/1088, train_loss: 0.0329\n",
      "610/1088, train_loss: 0.0334\n",
      "611/1088, train_loss: 0.0324\n",
      "612/1088, train_loss: 0.0405\n",
      "613/1088, train_loss: 0.0397\n",
      "614/1088, train_loss: 0.0350\n",
      "615/1088, train_loss: 0.0348\n",
      "616/1088, train_loss: 0.0352\n",
      "617/1088, train_loss: 0.0372\n",
      "618/1088, train_loss: 0.0446\n",
      "619/1088, train_loss: 0.0387\n",
      "620/1088, train_loss: 0.0368\n",
      "621/1088, train_loss: 0.0339\n",
      "622/1088, train_loss: 0.0329\n",
      "623/1088, train_loss: 0.0371\n",
      "624/1088, train_loss: 0.0337\n",
      "625/1088, train_loss: 0.0359\n",
      "626/1088, train_loss: 0.0355\n",
      "627/1088, train_loss: 0.0346\n",
      "628/1088, train_loss: 0.0326\n",
      "629/1088, train_loss: 0.0327\n",
      "630/1088, train_loss: 0.0460\n",
      "631/1088, train_loss: 0.0355\n",
      "632/1088, train_loss: 0.0460\n",
      "633/1088, train_loss: 0.0338\n",
      "634/1088, train_loss: 0.0428\n",
      "635/1088, train_loss: 0.0336\n",
      "636/1088, train_loss: 0.0341\n",
      "637/1088, train_loss: 0.0332\n",
      "638/1088, train_loss: 0.0337\n",
      "639/1088, train_loss: 0.0336\n",
      "640/1088, train_loss: 0.0340\n",
      "641/1088, train_loss: 0.0322\n",
      "642/1088, train_loss: 0.0331\n",
      "643/1088, train_loss: 0.0320\n",
      "644/1088, train_loss: 0.0328\n",
      "645/1088, train_loss: 0.0353\n",
      "646/1088, train_loss: 0.0330\n",
      "647/1088, train_loss: 0.0449\n",
      "648/1088, train_loss: 0.0388\n",
      "649/1088, train_loss: 0.0330\n",
      "650/1088, train_loss: 0.0368\n",
      "651/1088, train_loss: 0.0316\n",
      "652/1088, train_loss: 0.0335\n",
      "653/1088, train_loss: 0.0344\n",
      "654/1088, train_loss: 0.0323\n",
      "655/1088, train_loss: 0.0323\n",
      "656/1088, train_loss: 0.0332\n",
      "657/1088, train_loss: 0.0363\n",
      "658/1088, train_loss: 0.0326\n",
      "659/1088, train_loss: 0.0326\n",
      "660/1088, train_loss: 0.0331\n",
      "661/1088, train_loss: 0.0322\n",
      "662/1088, train_loss: 0.0398\n",
      "663/1088, train_loss: 0.0368\n",
      "664/1088, train_loss: 0.0314\n",
      "665/1088, train_loss: 0.0585\n",
      "666/1088, train_loss: 0.0325\n",
      "667/1088, train_loss: 0.0335\n",
      "668/1088, train_loss: 0.0329\n",
      "669/1088, train_loss: 0.0397\n",
      "670/1088, train_loss: 0.0368\n",
      "671/1088, train_loss: 0.0326\n",
      "672/1088, train_loss: 0.0387\n",
      "673/1088, train_loss: 0.0312\n",
      "674/1088, train_loss: 0.0326\n",
      "675/1088, train_loss: 0.0341\n",
      "676/1088, train_loss: 0.0409\n",
      "677/1088, train_loss: 0.0316\n",
      "678/1088, train_loss: 0.0361\n",
      "679/1088, train_loss: 0.0350\n",
      "680/1088, train_loss: 0.0323\n",
      "681/1088, train_loss: 0.0305\n",
      "682/1088, train_loss: 0.0304\n",
      "683/1088, train_loss: 0.0332\n",
      "684/1088, train_loss: 0.0323\n",
      "685/1088, train_loss: 0.0283\n",
      "686/1088, train_loss: 0.0354\n",
      "687/1088, train_loss: 0.0372\n",
      "688/1088, train_loss: 0.0349\n",
      "689/1088, train_loss: 0.0358\n",
      "690/1088, train_loss: 0.0381\n",
      "691/1088, train_loss: 0.0411\n",
      "692/1088, train_loss: 0.0365\n",
      "693/1088, train_loss: 0.0372\n",
      "694/1088, train_loss: 0.0355\n",
      "695/1088, train_loss: 0.0391\n",
      "696/1088, train_loss: 0.0332\n",
      "697/1088, train_loss: 0.0352\n",
      "698/1088, train_loss: 0.0363\n",
      "699/1088, train_loss: 0.0370\n",
      "700/1088, train_loss: 0.0335\n",
      "701/1088, train_loss: 0.0337\n",
      "702/1088, train_loss: 0.0325\n",
      "703/1088, train_loss: 0.0329\n",
      "704/1088, train_loss: 0.0366\n",
      "705/1088, train_loss: 0.0300\n",
      "706/1088, train_loss: 0.0301\n",
      "707/1088, train_loss: 0.0341\n",
      "708/1088, train_loss: 0.0336\n",
      "709/1088, train_loss: 0.0399\n",
      "710/1088, train_loss: 0.0318\n",
      "711/1088, train_loss: 0.0314\n",
      "712/1088, train_loss: 0.0350\n",
      "713/1088, train_loss: 0.0442\n",
      "714/1088, train_loss: 0.0336\n",
      "715/1088, train_loss: 0.0374\n",
      "716/1088, train_loss: 0.0320\n",
      "717/1088, train_loss: 0.0323\n",
      "718/1088, train_loss: 0.0345\n",
      "719/1088, train_loss: 0.0323\n",
      "720/1088, train_loss: 0.0383\n",
      "721/1088, train_loss: 0.0342\n",
      "722/1088, train_loss: 0.0354\n",
      "723/1088, train_loss: 0.0365\n",
      "724/1088, train_loss: 0.0339\n",
      "725/1088, train_loss: 0.0327\n",
      "726/1088, train_loss: 0.0315\n",
      "727/1088, train_loss: 0.0327\n",
      "728/1088, train_loss: 0.0348\n",
      "729/1088, train_loss: 0.0387\n",
      "730/1088, train_loss: 0.0365\n",
      "731/1088, train_loss: 0.0343\n",
      "732/1088, train_loss: 0.0355\n",
      "733/1088, train_loss: 0.0325\n",
      "734/1088, train_loss: 0.0323\n",
      "735/1088, train_loss: 0.0323\n",
      "736/1088, train_loss: 0.0353\n",
      "737/1088, train_loss: 0.0497\n",
      "738/1088, train_loss: 0.0345\n",
      "739/1088, train_loss: 0.0331\n",
      "740/1088, train_loss: 0.0329\n",
      "741/1088, train_loss: 0.0333\n",
      "742/1088, train_loss: 0.0311\n",
      "743/1088, train_loss: 0.0363\n",
      "744/1088, train_loss: 0.0355\n",
      "745/1088, train_loss: 0.0332\n",
      "746/1088, train_loss: 0.0316\n",
      "747/1088, train_loss: 0.0335\n",
      "748/1088, train_loss: 0.0337\n",
      "749/1088, train_loss: 0.0317\n",
      "750/1088, train_loss: 0.0318\n",
      "751/1088, train_loss: 0.0346\n",
      "752/1088, train_loss: 0.0300\n",
      "753/1088, train_loss: 0.0308\n",
      "754/1088, train_loss: 0.0355\n",
      "755/1088, train_loss: 0.0326\n",
      "756/1088, train_loss: 0.0358\n",
      "757/1088, train_loss: 0.0322\n",
      "758/1088, train_loss: 0.0346\n",
      "759/1088, train_loss: 0.0377\n",
      "760/1088, train_loss: 0.0319\n",
      "761/1088, train_loss: 0.0332\n",
      "762/1088, train_loss: 0.0330\n",
      "763/1088, train_loss: 0.0338\n",
      "764/1088, train_loss: 0.0315\n",
      "765/1088, train_loss: 0.0326\n",
      "766/1088, train_loss: 0.0338\n",
      "767/1088, train_loss: 0.0334\n",
      "768/1088, train_loss: 0.0378\n",
      "769/1088, train_loss: 0.0440\n",
      "770/1088, train_loss: 0.0344\n",
      "771/1088, train_loss: 0.0387\n",
      "772/1088, train_loss: 0.0347\n",
      "773/1088, train_loss: 0.0375\n",
      "774/1088, train_loss: 0.0348\n",
      "775/1088, train_loss: 0.0406\n",
      "776/1088, train_loss: 0.0354\n",
      "777/1088, train_loss: 0.0336\n",
      "778/1088, train_loss: 0.0325\n",
      "779/1088, train_loss: 0.0344\n",
      "780/1088, train_loss: 0.0324\n",
      "781/1088, train_loss: 0.0337\n",
      "782/1088, train_loss: 0.0355\n",
      "783/1088, train_loss: 0.0367\n",
      "784/1088, train_loss: 0.0383\n",
      "785/1088, train_loss: 0.0346\n",
      "786/1088, train_loss: 0.0403\n",
      "787/1088, train_loss: 0.0344\n",
      "788/1088, train_loss: 0.0408\n",
      "789/1088, train_loss: 0.0347\n",
      "790/1088, train_loss: 0.0352\n",
      "791/1088, train_loss: 0.0354\n",
      "792/1088, train_loss: 0.0340\n",
      "793/1088, train_loss: 0.0360\n",
      "794/1088, train_loss: 0.0419\n",
      "795/1088, train_loss: 0.0347\n",
      "796/1088, train_loss: 0.0353\n",
      "797/1088, train_loss: 0.0364\n",
      "798/1088, train_loss: 0.0366\n",
      "799/1088, train_loss: 0.0354\n",
      "800/1088, train_loss: 0.0335\n",
      "801/1088, train_loss: 0.0369\n",
      "802/1088, train_loss: 0.0369\n",
      "803/1088, train_loss: 0.0384\n",
      "804/1088, train_loss: 0.0333\n",
      "805/1088, train_loss: 0.0309\n",
      "806/1088, train_loss: 0.0373\n",
      "807/1088, train_loss: 0.0334\n",
      "808/1088, train_loss: 0.0337\n",
      "809/1088, train_loss: 0.0308\n",
      "810/1088, train_loss: 0.0312\n",
      "811/1088, train_loss: 0.0382\n",
      "812/1088, train_loss: 0.0316\n",
      "813/1088, train_loss: 0.0324\n",
      "814/1088, train_loss: 0.0299\n",
      "815/1088, train_loss: 0.0328\n",
      "816/1088, train_loss: 0.0320\n",
      "817/1088, train_loss: 0.0338\n",
      "818/1088, train_loss: 0.0344\n",
      "819/1088, train_loss: 0.0308\n",
      "820/1088, train_loss: 0.0324\n",
      "821/1088, train_loss: 0.0303\n",
      "822/1088, train_loss: 0.0344\n",
      "823/1088, train_loss: 0.0333\n",
      "824/1088, train_loss: 0.0322\n",
      "825/1088, train_loss: 0.0406\n",
      "826/1088, train_loss: 0.0380\n",
      "827/1088, train_loss: 0.0321\n",
      "828/1088, train_loss: 0.0320\n",
      "829/1088, train_loss: 0.0342\n",
      "830/1088, train_loss: 0.0312\n",
      "831/1088, train_loss: 0.0324\n",
      "832/1088, train_loss: 0.0392\n",
      "833/1088, train_loss: 0.0345\n",
      "834/1088, train_loss: 0.0320\n",
      "835/1088, train_loss: 0.0319\n",
      "836/1088, train_loss: 0.0388\n",
      "837/1088, train_loss: 0.0335\n",
      "838/1088, train_loss: 0.0390\n",
      "839/1088, train_loss: 0.0313\n",
      "840/1088, train_loss: 0.0388\n",
      "841/1088, train_loss: 0.0333\n",
      "842/1088, train_loss: 0.0372\n",
      "843/1088, train_loss: 0.0484\n",
      "844/1088, train_loss: 0.0333\n",
      "845/1088, train_loss: 0.0342\n",
      "846/1088, train_loss: 0.0431\n",
      "847/1088, train_loss: 0.0345\n",
      "848/1088, train_loss: 0.0378\n",
      "849/1088, train_loss: 0.0314\n",
      "850/1088, train_loss: 0.0312\n",
      "851/1088, train_loss: 0.0354\n",
      "852/1088, train_loss: 0.0338\n",
      "853/1088, train_loss: 0.0491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "854/1088, train_loss: 0.0361\n",
      "855/1088, train_loss: 0.0554\n",
      "856/1088, train_loss: 0.0365\n",
      "857/1088, train_loss: 0.0416\n",
      "858/1088, train_loss: 0.0362\n",
      "859/1088, train_loss: 0.0372\n",
      "860/1088, train_loss: 0.0417\n",
      "861/1088, train_loss: 0.0365\n",
      "862/1088, train_loss: 0.0379\n",
      "863/1088, train_loss: 0.0353\n",
      "864/1088, train_loss: 0.0351\n",
      "865/1088, train_loss: 0.0460\n",
      "866/1088, train_loss: 0.0385\n",
      "867/1088, train_loss: 0.0523\n",
      "868/1088, train_loss: 0.0356\n",
      "869/1088, train_loss: 0.0506\n",
      "870/1088, train_loss: 0.0358\n",
      "871/1088, train_loss: 0.0372\n",
      "872/1088, train_loss: 0.0347\n",
      "873/1088, train_loss: 0.0329\n",
      "874/1088, train_loss: 0.0322\n",
      "875/1088, train_loss: 0.0320\n",
      "876/1088, train_loss: 0.0325\n",
      "877/1088, train_loss: 0.0369\n",
      "878/1088, train_loss: 0.0308\n",
      "879/1088, train_loss: 0.0296\n",
      "880/1088, train_loss: 0.0321\n",
      "881/1088, train_loss: 0.0321\n",
      "882/1088, train_loss: 0.0422\n",
      "883/1088, train_loss: 0.0326\n",
      "884/1088, train_loss: 0.0392\n",
      "885/1088, train_loss: 0.0353\n",
      "886/1088, train_loss: 0.0340\n",
      "887/1088, train_loss: 0.0322\n",
      "888/1088, train_loss: 0.0334\n",
      "889/1088, train_loss: 0.0347\n",
      "890/1088, train_loss: 0.0421\n",
      "891/1088, train_loss: 0.0329\n",
      "892/1088, train_loss: 0.0415\n",
      "893/1088, train_loss: 0.0372\n",
      "894/1088, train_loss: 0.0335\n",
      "895/1088, train_loss: 0.0414\n",
      "896/1088, train_loss: 0.0358\n",
      "897/1088, train_loss: 0.0373\n",
      "898/1088, train_loss: 0.0338\n",
      "899/1088, train_loss: 0.0335\n",
      "900/1088, train_loss: 0.0392\n",
      "901/1088, train_loss: 0.0350\n",
      "902/1088, train_loss: 0.0336\n",
      "903/1088, train_loss: 0.0356\n",
      "904/1088, train_loss: 0.0346\n",
      "905/1088, train_loss: 0.0362\n",
      "906/1088, train_loss: 0.0331\n",
      "907/1088, train_loss: 0.0346\n",
      "908/1088, train_loss: 0.0359\n",
      "909/1088, train_loss: 0.0348\n",
      "910/1088, train_loss: 0.0322\n",
      "911/1088, train_loss: 0.0323\n",
      "912/1088, train_loss: 0.0331\n",
      "913/1088, train_loss: 0.0362\n",
      "914/1088, train_loss: 0.0394\n",
      "915/1088, train_loss: 0.0343\n",
      "916/1088, train_loss: 0.0381\n",
      "917/1088, train_loss: 0.0374\n",
      "918/1088, train_loss: 0.0386\n",
      "919/1088, train_loss: 0.0378\n",
      "920/1088, train_loss: 0.0331\n",
      "921/1088, train_loss: 0.0368\n",
      "922/1088, train_loss: 0.0348\n",
      "923/1088, train_loss: 0.0336\n",
      "924/1088, train_loss: 0.0483\n",
      "925/1088, train_loss: 0.0338\n",
      "926/1088, train_loss: 0.0344\n",
      "927/1088, train_loss: 0.0407\n",
      "928/1088, train_loss: 0.0329\n",
      "929/1088, train_loss: 0.0365\n",
      "930/1088, train_loss: 0.0331\n",
      "931/1088, train_loss: 0.0587\n",
      "932/1088, train_loss: 0.0346\n",
      "933/1088, train_loss: 0.0330\n",
      "934/1088, train_loss: 0.0323\n",
      "935/1088, train_loss: 0.0350\n",
      "936/1088, train_loss: 0.0326\n",
      "937/1088, train_loss: 0.0313\n",
      "938/1088, train_loss: 0.0464\n",
      "939/1088, train_loss: 0.0317\n",
      "940/1088, train_loss: 0.0337\n",
      "941/1088, train_loss: 0.0358\n",
      "942/1088, train_loss: 0.0355\n",
      "943/1088, train_loss: 0.0322\n",
      "944/1088, train_loss: 0.0429\n",
      "945/1088, train_loss: 0.0328\n",
      "946/1088, train_loss: 0.0339\n",
      "947/1088, train_loss: 0.0364\n",
      "948/1088, train_loss: 0.0300\n",
      "949/1088, train_loss: 0.0331\n",
      "950/1088, train_loss: 0.0317\n",
      "951/1088, train_loss: 0.0317\n",
      "952/1088, train_loss: 0.0332\n",
      "953/1088, train_loss: 0.0296\n",
      "954/1088, train_loss: 0.0341\n",
      "955/1088, train_loss: 0.0378\n",
      "956/1088, train_loss: 0.0337\n",
      "957/1088, train_loss: 0.0368\n",
      "958/1088, train_loss: 0.0311\n",
      "959/1088, train_loss: 0.0381\n",
      "960/1088, train_loss: 0.0308\n",
      "961/1088, train_loss: 0.0361\n",
      "962/1088, train_loss: 0.0330\n",
      "963/1088, train_loss: 0.0331\n",
      "964/1088, train_loss: 0.0315\n",
      "965/1088, train_loss: 0.0337\n",
      "966/1088, train_loss: 0.0334\n",
      "967/1088, train_loss: 0.0322\n",
      "968/1088, train_loss: 0.0348\n",
      "969/1088, train_loss: 0.0352\n",
      "970/1088, train_loss: 0.0313\n",
      "971/1088, train_loss: 0.0336\n",
      "972/1088, train_loss: 0.0329\n",
      "973/1088, train_loss: 0.0312\n",
      "974/1088, train_loss: 0.0328\n",
      "975/1088, train_loss: 0.0302\n",
      "976/1088, train_loss: 0.0387\n",
      "977/1088, train_loss: 0.0359\n",
      "978/1088, train_loss: 0.0364\n",
      "979/1088, train_loss: 0.0353\n",
      "980/1088, train_loss: 0.0328\n",
      "981/1088, train_loss: 0.0324\n",
      "982/1088, train_loss: 0.0315\n",
      "983/1088, train_loss: 0.0311\n",
      "984/1088, train_loss: 0.0332\n",
      "985/1088, train_loss: 0.0314\n",
      "986/1088, train_loss: 0.0374\n",
      "987/1088, train_loss: 0.0363\n",
      "988/1088, train_loss: 0.0356\n",
      "989/1088, train_loss: 0.0322\n",
      "990/1088, train_loss: 0.0345\n",
      "991/1088, train_loss: 0.0322\n",
      "992/1088, train_loss: 0.0329\n",
      "993/1088, train_loss: 0.0387\n",
      "994/1088, train_loss: 0.0345\n",
      "995/1088, train_loss: 0.0334\n",
      "996/1088, train_loss: 0.0331\n",
      "997/1088, train_loss: 0.0325\n",
      "998/1088, train_loss: 0.0344\n",
      "999/1088, train_loss: 0.0395\n",
      "1000/1088, train_loss: 0.0326\n",
      "1001/1088, train_loss: 0.0363\n",
      "1002/1088, train_loss: 0.0312\n",
      "1003/1088, train_loss: 0.0312\n",
      "1004/1088, train_loss: 0.0302\n",
      "1005/1088, train_loss: 0.0343\n",
      "1006/1088, train_loss: 0.0383\n",
      "1007/1088, train_loss: 0.0302\n",
      "1008/1088, train_loss: 0.0317\n",
      "1009/1088, train_loss: 0.0424\n",
      "1010/1088, train_loss: 0.0333\n",
      "1011/1088, train_loss: 0.0318\n",
      "1012/1088, train_loss: 0.0323\n",
      "1013/1088, train_loss: 0.0325\n",
      "1014/1088, train_loss: 0.0359\n",
      "1015/1088, train_loss: 0.0311\n",
      "1016/1088, train_loss: 0.0322\n",
      "1017/1088, train_loss: 0.0334\n",
      "1018/1088, train_loss: 0.0331\n",
      "1019/1088, train_loss: 0.0350\n",
      "1020/1088, train_loss: 0.0361\n",
      "1021/1088, train_loss: 0.0306\n",
      "1022/1088, train_loss: 0.0314\n",
      "1023/1088, train_loss: 0.0322\n",
      "1024/1088, train_loss: 0.0319\n",
      "1025/1088, train_loss: 0.0319\n",
      "1026/1088, train_loss: 0.0309\n",
      "1027/1088, train_loss: 0.0353\n",
      "1028/1088, train_loss: 0.0317\n",
      "1029/1088, train_loss: 0.0306\n",
      "1030/1088, train_loss: 0.0340\n",
      "1031/1088, train_loss: 0.0443\n",
      "1032/1088, train_loss: 0.0327\n",
      "1033/1088, train_loss: 0.0328\n",
      "1034/1088, train_loss: 0.0391\n",
      "1035/1088, train_loss: 0.0405\n",
      "1036/1088, train_loss: 0.0362\n",
      "1037/1088, train_loss: 0.0347\n",
      "1038/1088, train_loss: 0.0311\n",
      "1039/1088, train_loss: 0.0312\n",
      "1040/1088, train_loss: 0.0335\n",
      "1041/1088, train_loss: 0.0303\n",
      "1042/1088, train_loss: 0.0330\n",
      "1043/1088, train_loss: 0.0318\n",
      "1044/1088, train_loss: 0.0317\n",
      "1045/1088, train_loss: 0.0324\n",
      "1046/1088, train_loss: 0.0330\n",
      "1047/1088, train_loss: 0.0336\n",
      "1048/1088, train_loss: 0.0357\n",
      "1049/1088, train_loss: 0.0311\n",
      "1050/1088, train_loss: 0.0340\n",
      "1051/1088, train_loss: 0.0326\n",
      "1052/1088, train_loss: 0.0326\n",
      "1053/1088, train_loss: 0.0337\n",
      "1054/1088, train_loss: 0.0308\n",
      "1055/1088, train_loss: 0.0330\n",
      "1056/1088, train_loss: 0.0364\n",
      "1057/1088, train_loss: 0.0357\n",
      "1058/1088, train_loss: 0.0375\n",
      "1059/1088, train_loss: 0.0327\n",
      "1060/1088, train_loss: 0.0318\n",
      "1061/1088, train_loss: 0.0303\n",
      "1062/1088, train_loss: 0.0372\n",
      "1063/1088, train_loss: 0.0344\n",
      "1064/1088, train_loss: 0.0377\n",
      "1065/1088, train_loss: 0.0323\n",
      "1066/1088, train_loss: 0.0364\n",
      "1067/1088, train_loss: 0.0336\n",
      "1068/1088, train_loss: 0.0327\n",
      "1069/1088, train_loss: 0.0306\n",
      "1070/1088, train_loss: 0.0321\n",
      "1071/1088, train_loss: 0.0293\n",
      "1072/1088, train_loss: 0.0319\n",
      "1073/1088, train_loss: 0.0359\n",
      "1074/1088, train_loss: 0.0319\n",
      "1075/1088, train_loss: 0.0322\n",
      "1076/1088, train_loss: 0.0357\n",
      "1077/1088, train_loss: 0.0338\n",
      "1078/1088, train_loss: 0.0314\n",
      "1079/1088, train_loss: 0.0335\n",
      "1080/1088, train_loss: 0.0427\n",
      "1081/1088, train_loss: 0.0324\n",
      "1082/1088, train_loss: 0.0330\n",
      "1083/1088, train_loss: 0.0383\n",
      "1084/1088, train_loss: 0.0346\n",
      "1085/1088, train_loss: 0.0322\n",
      "1086/1088, train_loss: 0.0311\n",
      "1087/1088, train_loss: 0.0335\n",
      "1088/1088, train_loss: 0.0302\n",
      "1089/1088, train_loss: 0.0319\n",
      "epoch 2 average loss: 0.0355, train_dice: 0.9648\n",
      "epoch 2 average loss: 0.0355\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.9655 best mean dice: 0.9655 at epoch 2\n",
      "--------------------------------------------------\n",
      "epoch 3/50\n",
      "1/1088, train_loss: 0.0318\n",
      "2/1088, train_loss: 0.0318\n",
      "3/1088, train_loss: 0.0313\n",
      "4/1088, train_loss: 0.0393\n",
      "5/1088, train_loss: 0.0310\n",
      "6/1088, train_loss: 0.0356\n",
      "7/1088, train_loss: 0.0321\n",
      "8/1088, train_loss: 0.0308\n",
      "9/1088, train_loss: 0.0308\n",
      "10/1088, train_loss: 0.0325\n",
      "11/1088, train_loss: 0.0343\n",
      "12/1088, train_loss: 0.0319\n",
      "13/1088, train_loss: 0.0318\n",
      "14/1088, train_loss: 0.0340\n",
      "15/1088, train_loss: 0.0300\n",
      "16/1088, train_loss: 0.0412\n",
      "17/1088, train_loss: 0.0320\n",
      "18/1088, train_loss: 0.0319\n",
      "19/1088, train_loss: 0.0320\n",
      "20/1088, train_loss: 0.0324\n",
      "21/1088, train_loss: 0.0352\n",
      "22/1088, train_loss: 0.0354\n",
      "23/1088, train_loss: 0.0307\n",
      "24/1088, train_loss: 0.0334\n",
      "25/1088, train_loss: 0.0355\n",
      "26/1088, train_loss: 0.0345\n",
      "27/1088, train_loss: 0.0316\n",
      "28/1088, train_loss: 0.0342\n",
      "29/1088, train_loss: 0.0340\n",
      "30/1088, train_loss: 0.0334\n",
      "31/1088, train_loss: 0.0317\n",
      "32/1088, train_loss: 0.0331\n",
      "33/1088, train_loss: 0.0320\n",
      "34/1088, train_loss: 0.0367\n",
      "35/1088, train_loss: 0.0382\n",
      "36/1088, train_loss: 0.0342\n",
      "37/1088, train_loss: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/1088, train_loss: 0.0326\n",
      "39/1088, train_loss: 0.0358\n",
      "40/1088, train_loss: 0.0302\n",
      "41/1088, train_loss: 0.0305\n",
      "42/1088, train_loss: 0.0299\n",
      "43/1088, train_loss: 0.0307\n",
      "44/1088, train_loss: 0.0374\n",
      "45/1088, train_loss: 0.0302\n",
      "46/1088, train_loss: 0.0310\n",
      "47/1088, train_loss: 0.0338\n",
      "48/1088, train_loss: 0.0314\n",
      "49/1088, train_loss: 0.0297\n",
      "50/1088, train_loss: 0.0360\n",
      "51/1088, train_loss: 0.0307\n",
      "52/1088, train_loss: 0.0304\n",
      "53/1088, train_loss: 0.0380\n",
      "54/1088, train_loss: 0.0337\n",
      "55/1088, train_loss: 0.0296\n",
      "56/1088, train_loss: 0.0323\n",
      "57/1088, train_loss: 0.0339\n",
      "58/1088, train_loss: 0.0307\n",
      "59/1088, train_loss: 0.0336\n",
      "60/1088, train_loss: 0.0330\n",
      "61/1088, train_loss: 0.0455\n",
      "62/1088, train_loss: 0.0303\n",
      "63/1088, train_loss: 0.0352\n",
      "64/1088, train_loss: 0.0334\n",
      "65/1088, train_loss: 0.0310\n",
      "66/1088, train_loss: 0.0299\n",
      "67/1088, train_loss: 0.0320\n",
      "68/1088, train_loss: 0.0326\n",
      "69/1088, train_loss: 0.0409\n",
      "70/1088, train_loss: 0.0322\n",
      "71/1088, train_loss: 0.0324\n",
      "72/1088, train_loss: 0.0295\n",
      "73/1088, train_loss: 0.0348\n",
      "74/1088, train_loss: 0.0406\n",
      "75/1088, train_loss: 0.0321\n",
      "76/1088, train_loss: 0.0342\n",
      "77/1088, train_loss: 0.0352\n",
      "78/1088, train_loss: 0.0324\n",
      "79/1088, train_loss: 0.0320\n",
      "80/1088, train_loss: 0.0309\n",
      "81/1088, train_loss: 0.0347\n",
      "82/1088, train_loss: 0.0311\n",
      "83/1088, train_loss: 0.0297\n",
      "84/1088, train_loss: 0.0308\n",
      "85/1088, train_loss: 0.0304\n",
      "86/1088, train_loss: 0.0304\n",
      "87/1088, train_loss: 0.0298\n",
      "88/1088, train_loss: 0.0456\n",
      "89/1088, train_loss: 0.0366\n",
      "90/1088, train_loss: 0.0330\n",
      "91/1088, train_loss: 0.0316\n",
      "92/1088, train_loss: 0.0390\n",
      "93/1088, train_loss: 0.0365\n",
      "94/1088, train_loss: 0.0317\n",
      "95/1088, train_loss: 0.0309\n",
      "96/1088, train_loss: 0.0331\n",
      "97/1088, train_loss: 0.0306\n",
      "98/1088, train_loss: 0.0349\n",
      "99/1088, train_loss: 0.0355\n",
      "100/1088, train_loss: 0.0352\n",
      "101/1088, train_loss: 0.0387\n",
      "102/1088, train_loss: 0.0314\n",
      "103/1088, train_loss: 0.0351\n",
      "104/1088, train_loss: 0.0332\n",
      "105/1088, train_loss: 0.0312\n",
      "106/1088, train_loss: 0.0326\n",
      "107/1088, train_loss: 0.0370\n",
      "108/1088, train_loss: 0.0332\n",
      "109/1088, train_loss: 0.0316\n",
      "110/1088, train_loss: 0.0326\n",
      "111/1088, train_loss: 0.0416\n",
      "112/1088, train_loss: 0.0303\n",
      "113/1088, train_loss: 0.0330\n",
      "114/1088, train_loss: 0.0311\n",
      "115/1088, train_loss: 0.0320\n",
      "116/1088, train_loss: 0.0367\n",
      "117/1088, train_loss: 0.0305\n",
      "118/1088, train_loss: 0.0325\n",
      "119/1088, train_loss: 0.0328\n",
      "120/1088, train_loss: 0.0361\n",
      "121/1088, train_loss: 0.0323\n",
      "122/1088, train_loss: 0.0320\n",
      "123/1088, train_loss: 0.0349\n",
      "124/1088, train_loss: 0.0335\n",
      "125/1088, train_loss: 0.0324\n",
      "126/1088, train_loss: 0.0311\n",
      "127/1088, train_loss: 0.0329\n",
      "128/1088, train_loss: 0.0321\n",
      "129/1088, train_loss: 0.0310\n",
      "130/1088, train_loss: 0.0380\n",
      "131/1088, train_loss: 0.0298\n",
      "132/1088, train_loss: 0.0333\n",
      "133/1088, train_loss: 0.0317\n",
      "134/1088, train_loss: 0.0305\n",
      "135/1088, train_loss: 0.0325\n",
      "136/1088, train_loss: 0.0305\n",
      "137/1088, train_loss: 0.0320\n",
      "138/1088, train_loss: 0.0320\n",
      "139/1088, train_loss: 0.0327\n",
      "140/1088, train_loss: 0.0290\n",
      "141/1088, train_loss: 0.0308\n",
      "142/1088, train_loss: 0.0459\n",
      "143/1088, train_loss: 0.0307\n",
      "144/1088, train_loss: 0.0382\n",
      "145/1088, train_loss: 0.0401\n",
      "146/1088, train_loss: 0.0438\n",
      "147/1088, train_loss: 0.0295\n",
      "148/1088, train_loss: 0.0322\n",
      "149/1088, train_loss: 0.0299\n",
      "150/1088, train_loss: 0.0346\n",
      "151/1088, train_loss: 0.0312\n",
      "152/1088, train_loss: 0.0300\n",
      "153/1088, train_loss: 0.0310\n",
      "154/1088, train_loss: 0.0322\n",
      "155/1088, train_loss: 0.0341\n",
      "156/1088, train_loss: 0.0340\n",
      "157/1088, train_loss: 0.0334\n",
      "158/1088, train_loss: 0.0315\n",
      "159/1088, train_loss: 0.0305\n",
      "160/1088, train_loss: 0.0335\n",
      "161/1088, train_loss: 0.0369\n",
      "162/1088, train_loss: 0.0320\n",
      "163/1088, train_loss: 0.0333\n",
      "164/1088, train_loss: 0.0297\n",
      "165/1088, train_loss: 0.0312\n",
      "166/1088, train_loss: 0.0312\n",
      "167/1088, train_loss: 0.0312\n",
      "168/1088, train_loss: 0.0323\n",
      "169/1088, train_loss: 0.0329\n",
      "170/1088, train_loss: 0.0304\n",
      "171/1088, train_loss: 0.0306\n",
      "172/1088, train_loss: 0.0310\n",
      "173/1088, train_loss: 0.0359\n",
      "174/1088, train_loss: 0.0372\n",
      "175/1088, train_loss: 0.0303\n",
      "176/1088, train_loss: 0.0344\n",
      "177/1088, train_loss: 0.0315\n",
      "178/1088, train_loss: 0.0320\n",
      "179/1088, train_loss: 0.0447\n",
      "180/1088, train_loss: 0.0314\n",
      "181/1088, train_loss: 0.0325\n",
      "182/1088, train_loss: 0.0328\n",
      "183/1088, train_loss: 0.0382\n",
      "184/1088, train_loss: 0.0305\n",
      "185/1088, train_loss: 0.0301\n",
      "186/1088, train_loss: 0.0361\n",
      "187/1088, train_loss: 0.0315\n",
      "188/1088, train_loss: 0.0366\n",
      "189/1088, train_loss: 0.0344\n",
      "190/1088, train_loss: 0.0327\n",
      "191/1088, train_loss: 0.0317\n",
      "192/1088, train_loss: 0.0321\n",
      "193/1088, train_loss: 0.0336\n",
      "194/1088, train_loss: 0.0334\n",
      "195/1088, train_loss: 0.0329\n",
      "196/1088, train_loss: 0.0322\n",
      "197/1088, train_loss: 0.0306\n",
      "198/1088, train_loss: 0.0312\n",
      "199/1088, train_loss: 0.0311\n",
      "200/1088, train_loss: 0.0352\n",
      "201/1088, train_loss: 0.0321\n",
      "202/1088, train_loss: 0.0345\n",
      "203/1088, train_loss: 0.0336\n",
      "204/1088, train_loss: 0.0321\n",
      "205/1088, train_loss: 0.0315\n",
      "206/1088, train_loss: 0.0366\n",
      "207/1088, train_loss: 0.0328\n",
      "208/1088, train_loss: 0.0338\n",
      "209/1088, train_loss: 0.0319\n",
      "210/1088, train_loss: 0.0318\n",
      "211/1088, train_loss: 0.0360\n",
      "212/1088, train_loss: 0.0323\n",
      "213/1088, train_loss: 0.0295\n",
      "214/1088, train_loss: 0.0330\n",
      "215/1088, train_loss: 0.0297\n",
      "216/1088, train_loss: 0.0289\n",
      "217/1088, train_loss: 0.0407\n",
      "218/1088, train_loss: 0.0313\n",
      "219/1088, train_loss: 0.0322\n",
      "220/1088, train_loss: 0.0345\n",
      "221/1088, train_loss: 0.0305\n",
      "222/1088, train_loss: 0.0299\n",
      "223/1088, train_loss: 0.0336\n",
      "224/1088, train_loss: 0.0340\n",
      "225/1088, train_loss: 0.0342\n",
      "226/1088, train_loss: 0.0331\n",
      "227/1088, train_loss: 0.0322\n",
      "228/1088, train_loss: 0.0324\n",
      "229/1088, train_loss: 0.0323\n",
      "230/1088, train_loss: 0.0313\n",
      "231/1088, train_loss: 0.0334\n",
      "232/1088, train_loss: 0.0423\n",
      "233/1088, train_loss: 0.0320\n",
      "234/1088, train_loss: 0.0302\n",
      "235/1088, train_loss: 0.0310\n",
      "236/1088, train_loss: 0.0348\n",
      "237/1088, train_loss: 0.0337\n",
      "238/1088, train_loss: 0.0326\n",
      "239/1088, train_loss: 0.0351\n",
      "240/1088, train_loss: 0.0298\n",
      "241/1088, train_loss: 0.0325\n",
      "242/1088, train_loss: 0.0324\n",
      "243/1088, train_loss: 0.0342\n",
      "244/1088, train_loss: 0.0324\n",
      "245/1088, train_loss: 0.0325\n",
      "246/1088, train_loss: 0.0369\n",
      "247/1088, train_loss: 0.0340\n",
      "248/1088, train_loss: 0.0358\n",
      "249/1088, train_loss: 0.0409\n",
      "250/1088, train_loss: 0.0351\n",
      "251/1088, train_loss: 0.0468\n",
      "252/1088, train_loss: 0.0373\n",
      "253/1088, train_loss: 0.0354\n",
      "254/1088, train_loss: 0.0339\n",
      "255/1088, train_loss: 0.0363\n",
      "256/1088, train_loss: 0.0321\n",
      "257/1088, train_loss: 0.0314\n",
      "258/1088, train_loss: 0.0317\n",
      "259/1088, train_loss: 0.0302\n",
      "260/1088, train_loss: 0.0293\n",
      "261/1088, train_loss: 0.0315\n",
      "262/1088, train_loss: 0.0350\n",
      "263/1088, train_loss: 0.0447\n",
      "264/1088, train_loss: 0.0375\n",
      "265/1088, train_loss: 0.0333\n",
      "266/1088, train_loss: 0.0339\n",
      "267/1088, train_loss: 0.0323\n",
      "268/1088, train_loss: 0.0355\n",
      "269/1088, train_loss: 0.0337\n",
      "270/1088, train_loss: 0.0342\n",
      "271/1088, train_loss: 0.0302\n",
      "272/1088, train_loss: 0.0311\n",
      "273/1088, train_loss: 0.0344\n",
      "274/1088, train_loss: 0.0337\n",
      "275/1088, train_loss: 0.0324\n",
      "276/1088, train_loss: 0.0307\n",
      "277/1088, train_loss: 0.0313\n",
      "278/1088, train_loss: 0.0311\n",
      "279/1088, train_loss: 0.0340\n",
      "280/1088, train_loss: 0.0318\n",
      "281/1088, train_loss: 0.0330\n",
      "282/1088, train_loss: 0.0326\n",
      "283/1088, train_loss: 0.0320\n",
      "284/1088, train_loss: 0.0334\n",
      "285/1088, train_loss: 0.0325\n",
      "286/1088, train_loss: 0.0389\n",
      "287/1088, train_loss: 0.0304\n",
      "288/1088, train_loss: 0.0335\n",
      "289/1088, train_loss: 0.0355\n",
      "290/1088, train_loss: 0.0319\n",
      "291/1088, train_loss: 0.0328\n",
      "292/1088, train_loss: 0.0306\n",
      "293/1088, train_loss: 0.0336\n",
      "294/1088, train_loss: 0.0305\n",
      "295/1088, train_loss: 0.0292\n",
      "296/1088, train_loss: 0.0310\n",
      "297/1088, train_loss: 0.0326\n",
      "298/1088, train_loss: 0.0338\n",
      "299/1088, train_loss: 0.0290\n",
      "300/1088, train_loss: 0.0384\n",
      "301/1088, train_loss: 0.0352\n",
      "302/1088, train_loss: 0.0343\n",
      "303/1088, train_loss: 0.0339\n",
      "304/1088, train_loss: 0.0347\n",
      "305/1088, train_loss: 0.0345\n",
      "306/1088, train_loss: 0.0375\n",
      "307/1088, train_loss: 0.0349\n",
      "308/1088, train_loss: 0.0349\n",
      "309/1088, train_loss: 0.0317\n",
      "310/1088, train_loss: 0.0323\n",
      "311/1088, train_loss: 0.0306\n",
      "312/1088, train_loss: 0.0316\n",
      "313/1088, train_loss: 0.0313\n",
      "314/1088, train_loss: 0.0342\n",
      "315/1088, train_loss: 0.0314\n",
      "316/1088, train_loss: 0.0317\n",
      "317/1088, train_loss: 0.0333\n",
      "318/1088, train_loss: 0.0296\n",
      "319/1088, train_loss: 0.0319\n",
      "320/1088, train_loss: 0.0287\n",
      "321/1088, train_loss: 0.0411\n",
      "322/1088, train_loss: 0.0452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323/1088, train_loss: 0.0290\n",
      "324/1088, train_loss: 0.0353\n",
      "325/1088, train_loss: 0.0382\n",
      "326/1088, train_loss: 0.0306\n",
      "327/1088, train_loss: 0.0331\n",
      "328/1088, train_loss: 0.0353\n",
      "329/1088, train_loss: 0.0371\n",
      "330/1088, train_loss: 0.0318\n",
      "331/1088, train_loss: 0.0382\n",
      "332/1088, train_loss: 0.0328\n",
      "333/1088, train_loss: 0.0336\n",
      "334/1088, train_loss: 0.0318\n",
      "335/1088, train_loss: 0.0318\n",
      "336/1088, train_loss: 0.0297\n",
      "337/1088, train_loss: 0.0363\n",
      "338/1088, train_loss: 0.0333\n",
      "339/1088, train_loss: 0.0355\n",
      "340/1088, train_loss: 0.0300\n",
      "341/1088, train_loss: 0.0343\n",
      "342/1088, train_loss: 0.0331\n",
      "343/1088, train_loss: 0.0297\n",
      "344/1088, train_loss: 0.0300\n",
      "345/1088, train_loss: 0.0314\n",
      "346/1088, train_loss: 0.0310\n",
      "347/1088, train_loss: 0.0327\n",
      "348/1088, train_loss: 0.0303\n",
      "349/1088, train_loss: 0.0301\n",
      "350/1088, train_loss: 0.0423\n",
      "351/1088, train_loss: 0.0322\n",
      "352/1088, train_loss: 0.0328\n",
      "353/1088, train_loss: 0.0325\n",
      "354/1088, train_loss: 0.0338\n",
      "355/1088, train_loss: 0.0329\n",
      "356/1088, train_loss: 0.0352\n",
      "357/1088, train_loss: 0.0349\n",
      "358/1088, train_loss: 0.0353\n",
      "359/1088, train_loss: 0.0316\n",
      "360/1088, train_loss: 0.0305\n",
      "361/1088, train_loss: 0.0408\n",
      "362/1088, train_loss: 0.0304\n",
      "363/1088, train_loss: 0.0376\n",
      "364/1088, train_loss: 0.0319\n",
      "365/1088, train_loss: 0.0317\n",
      "366/1088, train_loss: 0.0295\n",
      "367/1088, train_loss: 0.0288\n",
      "368/1088, train_loss: 0.0406\n",
      "369/1088, train_loss: 0.0297\n",
      "370/1088, train_loss: 0.0332\n",
      "371/1088, train_loss: 0.0357\n",
      "372/1088, train_loss: 0.0290\n",
      "373/1088, train_loss: 0.0318\n",
      "374/1088, train_loss: 0.0333\n",
      "375/1088, train_loss: 0.0315\n",
      "376/1088, train_loss: 0.0311\n",
      "377/1088, train_loss: 0.0321\n",
      "378/1088, train_loss: 0.0322\n",
      "379/1088, train_loss: 0.0315\n",
      "380/1088, train_loss: 0.0302\n",
      "381/1088, train_loss: 0.0324\n",
      "382/1088, train_loss: 0.0314\n",
      "383/1088, train_loss: 0.0311\n",
      "384/1088, train_loss: 0.0333\n",
      "385/1088, train_loss: 0.0313\n",
      "386/1088, train_loss: 0.0353\n",
      "387/1088, train_loss: 0.0339\n",
      "388/1088, train_loss: 0.0351\n",
      "389/1088, train_loss: 0.0311\n",
      "390/1088, train_loss: 0.0311\n",
      "391/1088, train_loss: 0.0319\n",
      "392/1088, train_loss: 0.0345\n",
      "393/1088, train_loss: 0.0317\n",
      "394/1088, train_loss: 0.0347\n",
      "395/1088, train_loss: 0.0336\n",
      "396/1088, train_loss: 0.0346\n",
      "397/1088, train_loss: 0.0326\n",
      "398/1088, train_loss: 0.0323\n",
      "399/1088, train_loss: 0.0321\n",
      "400/1088, train_loss: 0.0319\n",
      "401/1088, train_loss: 0.0306\n",
      "402/1088, train_loss: 0.0353\n",
      "403/1088, train_loss: 0.0304\n",
      "404/1088, train_loss: 0.0338\n",
      "405/1088, train_loss: 0.0297\n",
      "406/1088, train_loss: 0.0326\n",
      "407/1088, train_loss: 0.0342\n",
      "408/1088, train_loss: 0.0342\n",
      "409/1088, train_loss: 0.0312\n",
      "410/1088, train_loss: 0.0350\n",
      "411/1088, train_loss: 0.0304\n",
      "412/1088, train_loss: 0.0324\n",
      "413/1088, train_loss: 0.0285\n",
      "414/1088, train_loss: 0.0299\n",
      "415/1088, train_loss: 0.0298\n",
      "416/1088, train_loss: 0.0369\n",
      "417/1088, train_loss: 0.0319\n",
      "418/1088, train_loss: 0.0337\n",
      "419/1088, train_loss: 0.0342\n",
      "420/1088, train_loss: 0.0335\n",
      "421/1088, train_loss: 0.0368\n",
      "422/1088, train_loss: 0.0342\n",
      "423/1088, train_loss: 0.0327\n",
      "424/1088, train_loss: 0.0322\n",
      "425/1088, train_loss: 0.0351\n",
      "426/1088, train_loss: 0.0327\n",
      "427/1088, train_loss: 0.0316\n",
      "428/1088, train_loss: 0.0352\n",
      "429/1088, train_loss: 0.0338\n",
      "430/1088, train_loss: 0.0321\n",
      "431/1088, train_loss: 0.0333\n",
      "432/1088, train_loss: 0.0328\n",
      "433/1088, train_loss: 0.0304\n",
      "434/1088, train_loss: 0.0306\n",
      "435/1088, train_loss: 0.0302\n",
      "436/1088, train_loss: 0.0347\n",
      "437/1088, train_loss: 0.0313\n",
      "438/1088, train_loss: 0.0363\n",
      "439/1088, train_loss: 0.0323\n",
      "440/1088, train_loss: 0.0304\n",
      "441/1088, train_loss: 0.0319\n",
      "442/1088, train_loss: 0.0299\n",
      "443/1088, train_loss: 0.0369\n",
      "444/1088, train_loss: 0.0302\n",
      "445/1088, train_loss: 0.0320\n",
      "446/1088, train_loss: 0.0294\n",
      "447/1088, train_loss: 0.0416\n",
      "448/1088, train_loss: 0.0381\n",
      "449/1088, train_loss: 0.0292\n",
      "450/1088, train_loss: 0.0407\n",
      "451/1088, train_loss: 0.0302\n",
      "452/1088, train_loss: 0.0306\n",
      "453/1088, train_loss: 0.0304\n",
      "454/1088, train_loss: 0.0331\n",
      "455/1088, train_loss: 0.0314\n",
      "456/1088, train_loss: 0.0359\n",
      "457/1088, train_loss: 0.0337\n",
      "458/1088, train_loss: 0.0357\n",
      "459/1088, train_loss: 0.0344\n",
      "460/1088, train_loss: 0.0307\n",
      "461/1088, train_loss: 0.0337\n",
      "462/1088, train_loss: 0.0321\n",
      "463/1088, train_loss: 0.0325\n",
      "464/1088, train_loss: 0.0343\n",
      "465/1088, train_loss: 0.0322\n",
      "466/1088, train_loss: 0.0310\n",
      "467/1088, train_loss: 0.0309\n",
      "468/1088, train_loss: 0.0308\n",
      "469/1088, train_loss: 0.0334\n",
      "470/1088, train_loss: 0.0331\n",
      "471/1088, train_loss: 0.0315\n",
      "472/1088, train_loss: 0.0381\n",
      "473/1088, train_loss: 0.0364\n",
      "474/1088, train_loss: 0.0373\n",
      "475/1088, train_loss: 0.0295\n",
      "476/1088, train_loss: 0.0307\n",
      "477/1088, train_loss: 0.0324\n",
      "478/1088, train_loss: 0.0315\n",
      "479/1088, train_loss: 0.0369\n",
      "480/1088, train_loss: 0.0355\n",
      "481/1088, train_loss: 0.0296\n",
      "482/1088, train_loss: 0.0325\n",
      "483/1088, train_loss: 0.0327\n",
      "484/1088, train_loss: 0.0313\n",
      "485/1088, train_loss: 0.0339\n",
      "486/1088, train_loss: 0.0319\n",
      "487/1088, train_loss: 0.0340\n",
      "488/1088, train_loss: 0.0339\n",
      "489/1088, train_loss: 0.0343\n",
      "490/1088, train_loss: 0.0326\n",
      "491/1088, train_loss: 0.0317\n",
      "492/1088, train_loss: 0.0333\n",
      "493/1088, train_loss: 0.0298\n",
      "494/1088, train_loss: 0.0314\n",
      "495/1088, train_loss: 0.0319\n",
      "496/1088, train_loss: 0.0304\n",
      "497/1088, train_loss: 0.0391\n",
      "498/1088, train_loss: 0.0308\n",
      "499/1088, train_loss: 0.0354\n",
      "500/1088, train_loss: 0.0276\n",
      "501/1088, train_loss: 0.0325\n",
      "502/1088, train_loss: 0.0345\n",
      "503/1088, train_loss: 0.0315\n",
      "504/1088, train_loss: 0.0304\n",
      "505/1088, train_loss: 0.0345\n",
      "506/1088, train_loss: 0.0318\n",
      "507/1088, train_loss: 0.0312\n",
      "508/1088, train_loss: 0.0313\n",
      "509/1088, train_loss: 0.0309\n",
      "510/1088, train_loss: 0.0293\n",
      "511/1088, train_loss: 0.0354\n",
      "512/1088, train_loss: 0.0313\n",
      "513/1088, train_loss: 0.0309\n",
      "514/1088, train_loss: 0.0320\n",
      "515/1088, train_loss: 0.0306\n",
      "516/1088, train_loss: 0.0304\n",
      "517/1088, train_loss: 0.0336\n",
      "518/1088, train_loss: 0.0318\n",
      "519/1088, train_loss: 0.0336\n",
      "520/1088, train_loss: 0.0318\n",
      "521/1088, train_loss: 0.0317\n",
      "522/1088, train_loss: 0.0317\n",
      "523/1088, train_loss: 0.0301\n",
      "524/1088, train_loss: 0.0322\n",
      "525/1088, train_loss: 0.0315\n",
      "526/1088, train_loss: 0.0292\n",
      "527/1088, train_loss: 0.0316\n",
      "528/1088, train_loss: 0.0311\n",
      "529/1088, train_loss: 0.0292\n",
      "530/1088, train_loss: 0.0330\n",
      "531/1088, train_loss: 0.0304\n",
      "532/1088, train_loss: 0.0288\n",
      "533/1088, train_loss: 0.0346\n",
      "534/1088, train_loss: 0.0303\n",
      "535/1088, train_loss: 0.0318\n",
      "536/1088, train_loss: 0.0331\n",
      "537/1088, train_loss: 0.0307\n",
      "538/1088, train_loss: 0.0296\n",
      "539/1088, train_loss: 0.0357\n",
      "540/1088, train_loss: 0.0341\n",
      "541/1088, train_loss: 0.0326\n",
      "542/1088, train_loss: 0.0305\n",
      "543/1088, train_loss: 0.0342\n",
      "544/1088, train_loss: 0.0319\n",
      "545/1088, train_loss: 0.0326\n",
      "546/1088, train_loss: 0.0327\n",
      "547/1088, train_loss: 0.0325\n",
      "548/1088, train_loss: 0.0314\n",
      "549/1088, train_loss: 0.0362\n",
      "550/1088, train_loss: 0.0312\n",
      "551/1088, train_loss: 0.0323\n",
      "552/1088, train_loss: 0.0327\n",
      "553/1088, train_loss: 0.0323\n",
      "554/1088, train_loss: 0.0333\n",
      "555/1088, train_loss: 0.0321\n",
      "556/1088, train_loss: 0.0316\n",
      "557/1088, train_loss: 0.0304\n",
      "558/1088, train_loss: 0.0271\n",
      "559/1088, train_loss: 0.0314\n",
      "560/1088, train_loss: 0.0322\n",
      "561/1088, train_loss: 0.0281\n",
      "562/1088, train_loss: 0.0427\n",
      "563/1088, train_loss: 0.0340\n",
      "564/1088, train_loss: 0.0358\n",
      "565/1088, train_loss: 0.0298\n",
      "566/1088, train_loss: 0.0346\n",
      "567/1088, train_loss: 0.0324\n",
      "568/1088, train_loss: 0.0350\n",
      "569/1088, train_loss: 0.0343\n",
      "570/1088, train_loss: 0.0316\n",
      "571/1088, train_loss: 0.0339\n",
      "572/1088, train_loss: 0.0328\n",
      "573/1088, train_loss: 0.0313\n",
      "574/1088, train_loss: 0.0315\n",
      "575/1088, train_loss: 0.0310\n",
      "576/1088, train_loss: 0.0314\n",
      "577/1088, train_loss: 0.0419\n",
      "578/1088, train_loss: 0.0312\n",
      "579/1088, train_loss: 0.0312\n",
      "580/1088, train_loss: 0.0309\n",
      "581/1088, train_loss: 0.0321\n",
      "582/1088, train_loss: 0.0366\n",
      "583/1088, train_loss: 0.0336\n",
      "584/1088, train_loss: 0.0305\n",
      "585/1088, train_loss: 0.0338\n",
      "586/1088, train_loss: 0.0311\n",
      "587/1088, train_loss: 0.0318\n",
      "588/1088, train_loss: 0.0346\n",
      "589/1088, train_loss: 0.0343\n",
      "590/1088, train_loss: 0.0321\n",
      "591/1088, train_loss: 0.0339\n",
      "592/1088, train_loss: 0.0331\n",
      "593/1088, train_loss: 0.0330\n",
      "594/1088, train_loss: 0.0307\n",
      "595/1088, train_loss: 0.0306\n",
      "596/1088, train_loss: 0.0300\n",
      "597/1088, train_loss: 0.0322\n",
      "598/1088, train_loss: 0.0291\n",
      "599/1088, train_loss: 0.0340\n",
      "600/1088, train_loss: 0.0288\n",
      "601/1088, train_loss: 0.0335\n",
      "602/1088, train_loss: 0.0373\n",
      "603/1088, train_loss: 0.0338\n",
      "604/1088, train_loss: 0.0331\n",
      "605/1088, train_loss: 0.0324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606/1088, train_loss: 0.0352\n",
      "607/1088, train_loss: 0.0330\n",
      "608/1088, train_loss: 0.0308\n",
      "609/1088, train_loss: 0.0321\n",
      "610/1088, train_loss: 0.0332\n",
      "611/1088, train_loss: 0.0310\n",
      "612/1088, train_loss: 0.0311\n",
      "613/1088, train_loss: 0.0402\n",
      "614/1088, train_loss: 0.0299\n",
      "615/1088, train_loss: 0.0351\n",
      "616/1088, train_loss: 0.0307\n",
      "617/1088, train_loss: 0.0333\n",
      "618/1088, train_loss: 0.0302\n",
      "619/1088, train_loss: 0.0311\n",
      "620/1088, train_loss: 0.0373\n",
      "621/1088, train_loss: 0.0328\n",
      "622/1088, train_loss: 0.0315\n",
      "623/1088, train_loss: 0.0307\n",
      "624/1088, train_loss: 0.0318\n",
      "625/1088, train_loss: 0.0297\n",
      "626/1088, train_loss: 0.0331\n",
      "627/1088, train_loss: 0.0316\n",
      "628/1088, train_loss: 0.0295\n",
      "629/1088, train_loss: 0.0296\n",
      "630/1088, train_loss: 0.0365\n",
      "631/1088, train_loss: 0.0323\n",
      "632/1088, train_loss: 0.0340\n",
      "633/1088, train_loss: 0.0375\n",
      "634/1088, train_loss: 0.0307\n",
      "635/1088, train_loss: 0.0310\n",
      "636/1088, train_loss: 0.0310\n",
      "637/1088, train_loss: 0.0334\n",
      "638/1088, train_loss: 0.0317\n",
      "639/1088, train_loss: 0.0307\n",
      "640/1088, train_loss: 0.0303\n",
      "641/1088, train_loss: 0.0331\n",
      "642/1088, train_loss: 0.0324\n",
      "643/1088, train_loss: 0.0318\n",
      "644/1088, train_loss: 0.0308\n",
      "645/1088, train_loss: 0.0338\n",
      "646/1088, train_loss: 0.0296\n",
      "647/1088, train_loss: 0.0301\n",
      "648/1088, train_loss: 0.0343\n",
      "649/1088, train_loss: 0.0363\n",
      "650/1088, train_loss: 0.0331\n",
      "651/1088, train_loss: 0.0328\n",
      "652/1088, train_loss: 0.0319\n",
      "653/1088, train_loss: 0.0315\n",
      "654/1088, train_loss: 0.0313\n",
      "655/1088, train_loss: 0.0308\n",
      "656/1088, train_loss: 0.0329\n",
      "657/1088, train_loss: 0.0310\n",
      "658/1088, train_loss: 0.0351\n",
      "659/1088, train_loss: 0.0339\n",
      "660/1088, train_loss: 0.0314\n",
      "661/1088, train_loss: 0.0314\n",
      "662/1088, train_loss: 0.0288\n",
      "663/1088, train_loss: 0.0320\n",
      "664/1088, train_loss: 0.0331\n",
      "665/1088, train_loss: 0.0387\n",
      "666/1088, train_loss: 0.0360\n",
      "667/1088, train_loss: 0.0320\n",
      "668/1088, train_loss: 0.0332\n",
      "669/1088, train_loss: 0.0309\n",
      "670/1088, train_loss: 0.0325\n",
      "671/1088, train_loss: 0.0323\n",
      "672/1088, train_loss: 0.0300\n",
      "673/1088, train_loss: 0.0317\n",
      "674/1088, train_loss: 0.0293\n",
      "675/1088, train_loss: 0.0363\n",
      "676/1088, train_loss: 0.0351\n",
      "677/1088, train_loss: 0.0389\n",
      "678/1088, train_loss: 0.0326\n",
      "679/1088, train_loss: 0.0332\n",
      "680/1088, train_loss: 0.0320\n",
      "681/1088, train_loss: 0.0324\n",
      "682/1088, train_loss: 0.0335\n",
      "683/1088, train_loss: 0.0309\n",
      "684/1088, train_loss: 0.0301\n",
      "685/1088, train_loss: 0.0311\n",
      "686/1088, train_loss: 0.0338\n",
      "687/1088, train_loss: 0.0321\n",
      "688/1088, train_loss: 0.0353\n",
      "689/1088, train_loss: 0.0379\n",
      "690/1088, train_loss: 0.0319\n",
      "691/1088, train_loss: 0.0376\n",
      "692/1088, train_loss: 0.0334\n",
      "693/1088, train_loss: 0.0309\n",
      "694/1088, train_loss: 0.0315\n",
      "695/1088, train_loss: 0.0296\n",
      "696/1088, train_loss: 0.0304\n",
      "697/1088, train_loss: 0.0314\n",
      "698/1088, train_loss: 0.0332\n",
      "699/1088, train_loss: 0.0342\n",
      "700/1088, train_loss: 0.0316\n",
      "701/1088, train_loss: 0.0321\n",
      "702/1088, train_loss: 0.0344\n",
      "703/1088, train_loss: 0.0313\n",
      "704/1088, train_loss: 0.0318\n",
      "705/1088, train_loss: 0.0311\n",
      "706/1088, train_loss: 0.0307\n",
      "707/1088, train_loss: 0.0304\n",
      "708/1088, train_loss: 0.0334\n",
      "709/1088, train_loss: 0.0331\n",
      "710/1088, train_loss: 0.0300\n",
      "711/1088, train_loss: 0.0301\n",
      "712/1088, train_loss: 0.0315\n",
      "713/1088, train_loss: 0.0351\n",
      "714/1088, train_loss: 0.0291\n",
      "715/1088, train_loss: 0.0312\n",
      "716/1088, train_loss: 0.0297\n",
      "717/1088, train_loss: 0.0308\n",
      "718/1088, train_loss: 0.0315\n",
      "719/1088, train_loss: 0.0310\n",
      "720/1088, train_loss: 0.0336\n",
      "721/1088, train_loss: 0.0347\n",
      "722/1088, train_loss: 0.0315\n",
      "723/1088, train_loss: 0.0326\n",
      "724/1088, train_loss: 0.0348\n",
      "725/1088, train_loss: 0.0307\n",
      "726/1088, train_loss: 0.0315\n",
      "727/1088, train_loss: 0.0321\n",
      "728/1088, train_loss: 0.0328\n",
      "729/1088, train_loss: 0.0285\n",
      "730/1088, train_loss: 0.0370\n",
      "731/1088, train_loss: 0.0331\n",
      "732/1088, train_loss: 0.0310\n",
      "733/1088, train_loss: 0.0341\n",
      "734/1088, train_loss: 0.0323\n",
      "735/1088, train_loss: 0.0313\n",
      "736/1088, train_loss: 0.0321\n",
      "737/1088, train_loss: 0.0318\n",
      "738/1088, train_loss: 0.0306\n",
      "739/1088, train_loss: 0.0324\n",
      "740/1088, train_loss: 0.0344\n",
      "741/1088, train_loss: 0.0302\n",
      "742/1088, train_loss: 0.0349\n",
      "743/1088, train_loss: 0.0301\n",
      "744/1088, train_loss: 0.0287\n",
      "745/1088, train_loss: 0.0384\n",
      "746/1088, train_loss: 0.0349\n",
      "747/1088, train_loss: 0.0350\n",
      "748/1088, train_loss: 0.0307\n",
      "749/1088, train_loss: 0.0308\n",
      "750/1088, train_loss: 0.0309\n",
      "751/1088, train_loss: 0.0327\n",
      "752/1088, train_loss: 0.0324\n",
      "753/1088, train_loss: 0.0319\n",
      "754/1088, train_loss: 0.0316\n",
      "755/1088, train_loss: 0.0319\n",
      "756/1088, train_loss: 0.0399\n",
      "757/1088, train_loss: 0.0326\n",
      "758/1088, train_loss: 0.0307\n",
      "759/1088, train_loss: 0.0381\n",
      "760/1088, train_loss: 0.0315\n",
      "761/1088, train_loss: 0.0318\n",
      "762/1088, train_loss: 0.0314\n",
      "763/1088, train_loss: 0.0316\n",
      "764/1088, train_loss: 0.0298\n",
      "765/1088, train_loss: 0.0361\n",
      "766/1088, train_loss: 0.0374\n",
      "767/1088, train_loss: 0.0303\n",
      "768/1088, train_loss: 0.0293\n",
      "769/1088, train_loss: 0.0341\n",
      "770/1088, train_loss: 0.0302\n",
      "771/1088, train_loss: 0.0292\n",
      "772/1088, train_loss: 0.0329\n",
      "773/1088, train_loss: 0.0363\n",
      "774/1088, train_loss: 0.0302\n",
      "775/1088, train_loss: 0.0335\n",
      "776/1088, train_loss: 0.0308\n",
      "777/1088, train_loss: 0.0291\n",
      "778/1088, train_loss: 0.0335\n",
      "779/1088, train_loss: 0.0302\n",
      "780/1088, train_loss: 0.0313\n",
      "781/1088, train_loss: 0.0285\n",
      "782/1088, train_loss: 0.0334\n",
      "783/1088, train_loss: 0.0300\n",
      "784/1088, train_loss: 0.0321\n",
      "785/1088, train_loss: 0.0307\n",
      "786/1088, train_loss: 0.0346\n",
      "787/1088, train_loss: 0.0323\n",
      "788/1088, train_loss: 0.0339\n",
      "789/1088, train_loss: 0.0320\n",
      "790/1088, train_loss: 0.0314\n",
      "791/1088, train_loss: 0.0309\n",
      "792/1088, train_loss: 0.0333\n",
      "793/1088, train_loss: 0.0329\n",
      "794/1088, train_loss: 0.0354\n",
      "795/1088, train_loss: 0.0309\n",
      "796/1088, train_loss: 0.0323\n",
      "797/1088, train_loss: 0.0321\n",
      "798/1088, train_loss: 0.0301\n",
      "799/1088, train_loss: 0.0302\n",
      "800/1088, train_loss: 0.0317\n",
      "801/1088, train_loss: 0.0286\n",
      "802/1088, train_loss: 0.0295\n",
      "803/1088, train_loss: 0.0336\n",
      "804/1088, train_loss: 0.0332\n",
      "805/1088, train_loss: 0.0326\n",
      "806/1088, train_loss: 0.0319\n",
      "807/1088, train_loss: 0.0355\n",
      "808/1088, train_loss: 0.0357\n",
      "809/1088, train_loss: 0.0357\n",
      "810/1088, train_loss: 0.0310\n",
      "811/1088, train_loss: 0.0320\n",
      "812/1088, train_loss: 0.0321\n",
      "813/1088, train_loss: 0.0308\n",
      "814/1088, train_loss: 0.0328\n",
      "815/1088, train_loss: 0.0332\n",
      "816/1088, train_loss: 0.0342\n",
      "817/1088, train_loss: 0.0313\n",
      "818/1088, train_loss: 0.0358\n",
      "819/1088, train_loss: 0.0316\n",
      "820/1088, train_loss: 0.0340\n",
      "821/1088, train_loss: 0.0345\n",
      "822/1088, train_loss: 0.0317\n",
      "823/1088, train_loss: 0.0319\n",
      "824/1088, train_loss: 0.0317\n",
      "825/1088, train_loss: 0.0340\n",
      "826/1088, train_loss: 0.0291\n",
      "827/1088, train_loss: 0.0310\n",
      "828/1088, train_loss: 0.0299\n",
      "829/1088, train_loss: 0.0329\n",
      "830/1088, train_loss: 0.0327\n",
      "831/1088, train_loss: 0.0310\n",
      "832/1088, train_loss: 0.0333\n",
      "833/1088, train_loss: 0.0302\n",
      "834/1088, train_loss: 0.0544\n",
      "835/1088, train_loss: 0.0312\n",
      "836/1088, train_loss: 0.0337\n",
      "837/1088, train_loss: 0.0347\n",
      "838/1088, train_loss: 0.0321\n",
      "839/1088, train_loss: 0.0318\n",
      "840/1088, train_loss: 0.0326\n",
      "841/1088, train_loss: 0.0341\n",
      "842/1088, train_loss: 0.0318\n",
      "843/1088, train_loss: 0.0323\n",
      "844/1088, train_loss: 0.0313\n",
      "845/1088, train_loss: 0.0329\n",
      "846/1088, train_loss: 0.0305\n",
      "847/1088, train_loss: 0.0315\n",
      "848/1088, train_loss: 0.0308\n",
      "849/1088, train_loss: 0.0287\n",
      "850/1088, train_loss: 0.0420\n",
      "851/1088, train_loss: 0.0338\n",
      "852/1088, train_loss: 0.0293\n",
      "853/1088, train_loss: 0.0316\n",
      "854/1088, train_loss: 0.0300\n",
      "855/1088, train_loss: 0.0363\n",
      "856/1088, train_loss: 0.0332\n",
      "857/1088, train_loss: 0.0320\n",
      "858/1088, train_loss: 0.0341\n",
      "859/1088, train_loss: 0.0331\n",
      "860/1088, train_loss: 0.0312\n",
      "861/1088, train_loss: 0.0291\n",
      "862/1088, train_loss: 0.0316\n",
      "863/1088, train_loss: 0.0284\n",
      "864/1088, train_loss: 0.0343\n",
      "865/1088, train_loss: 0.0305\n",
      "866/1088, train_loss: 0.0308\n",
      "867/1088, train_loss: 0.0293\n",
      "868/1088, train_loss: 0.0330\n",
      "869/1088, train_loss: 0.0363\n",
      "870/1088, train_loss: 0.0312\n",
      "871/1088, train_loss: 0.0305\n",
      "872/1088, train_loss: 0.0305\n",
      "873/1088, train_loss: 0.0305\n",
      "874/1088, train_loss: 0.0326\n",
      "875/1088, train_loss: 0.0319\n",
      "876/1088, train_loss: 0.0325\n",
      "877/1088, train_loss: 0.0313\n",
      "878/1088, train_loss: 0.0324\n",
      "879/1088, train_loss: 0.0320\n",
      "880/1088, train_loss: 0.0328\n",
      "881/1088, train_loss: 0.0337\n",
      "882/1088, train_loss: 0.0340\n",
      "883/1088, train_loss: 0.0327\n",
      "884/1088, train_loss: 0.0314\n",
      "885/1088, train_loss: 0.0305\n",
      "886/1088, train_loss: 0.0350\n",
      "887/1088, train_loss: 0.0312\n",
      "888/1088, train_loss: 0.0283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/1088, train_loss: 0.0304\n",
      "890/1088, train_loss: 0.0298\n",
      "891/1088, train_loss: 0.0321\n",
      "892/1088, train_loss: 0.0338\n",
      "893/1088, train_loss: 0.0332\n",
      "894/1088, train_loss: 0.0302\n",
      "895/1088, train_loss: 0.0306\n",
      "896/1088, train_loss: 0.0319\n",
      "897/1088, train_loss: 0.0313\n",
      "898/1088, train_loss: 0.0340\n",
      "899/1088, train_loss: 0.0347\n",
      "900/1088, train_loss: 0.0325\n",
      "901/1088, train_loss: 0.0338\n",
      "902/1088, train_loss: 0.0307\n",
      "903/1088, train_loss: 0.0311\n",
      "904/1088, train_loss: 0.0316\n",
      "905/1088, train_loss: 0.0301\n",
      "906/1088, train_loss: 0.0302\n",
      "907/1088, train_loss: 0.0343\n",
      "908/1088, train_loss: 0.0315\n",
      "909/1088, train_loss: 0.0327\n",
      "910/1088, train_loss: 0.0324\n",
      "911/1088, train_loss: 0.0314\n",
      "912/1088, train_loss: 0.0314\n",
      "913/1088, train_loss: 0.0311\n",
      "914/1088, train_loss: 0.0300\n",
      "915/1088, train_loss: 0.0304\n",
      "916/1088, train_loss: 0.0362\n",
      "917/1088, train_loss: 0.0302\n",
      "918/1088, train_loss: 0.0324\n",
      "919/1088, train_loss: 0.0322\n",
      "920/1088, train_loss: 0.0313\n",
      "921/1088, train_loss: 0.0335\n",
      "922/1088, train_loss: 0.0328\n",
      "923/1088, train_loss: 0.0313\n",
      "924/1088, train_loss: 0.0361\n",
      "925/1088, train_loss: 0.0296\n",
      "926/1088, train_loss: 0.0305\n",
      "927/1088, train_loss: 0.0305\n",
      "928/1088, train_loss: 0.0315\n",
      "929/1088, train_loss: 0.0308\n",
      "930/1088, train_loss: 0.0324\n",
      "931/1088, train_loss: 0.0291\n",
      "932/1088, train_loss: 0.0309\n",
      "933/1088, train_loss: 0.0314\n",
      "934/1088, train_loss: 0.0302\n",
      "935/1088, train_loss: 0.0419\n",
      "936/1088, train_loss: 0.0306\n",
      "937/1088, train_loss: 0.0356\n",
      "938/1088, train_loss: 0.0322\n",
      "939/1088, train_loss: 0.0313\n",
      "940/1088, train_loss: 0.0292\n",
      "941/1088, train_loss: 0.0305\n",
      "942/1088, train_loss: 0.0321\n",
      "943/1088, train_loss: 0.0309\n",
      "944/1088, train_loss: 0.0317\n",
      "945/1088, train_loss: 0.0347\n",
      "946/1088, train_loss: 0.0322\n",
      "947/1088, train_loss: 0.0344\n",
      "948/1088, train_loss: 0.0349\n",
      "949/1088, train_loss: 0.0313\n",
      "950/1088, train_loss: 0.0309\n",
      "951/1088, train_loss: 0.0309\n",
      "952/1088, train_loss: 0.0309\n",
      "953/1088, train_loss: 0.0344\n",
      "954/1088, train_loss: 0.0330\n",
      "955/1088, train_loss: 0.0348\n",
      "956/1088, train_loss: 0.0324\n",
      "957/1088, train_loss: 0.0321\n",
      "958/1088, train_loss: 0.0342\n",
      "959/1088, train_loss: 0.0323\n",
      "960/1088, train_loss: 0.0342\n",
      "961/1088, train_loss: 0.0329\n",
      "962/1088, train_loss: 0.0322\n",
      "963/1088, train_loss: 0.0300\n",
      "964/1088, train_loss: 0.0313\n",
      "965/1088, train_loss: 0.0308\n",
      "966/1088, train_loss: 0.0303\n",
      "967/1088, train_loss: 0.0294\n",
      "968/1088, train_loss: 0.0291\n",
      "969/1088, train_loss: 0.0295\n",
      "970/1088, train_loss: 0.0302\n",
      "971/1088, train_loss: 0.0382\n",
      "972/1088, train_loss: 0.0291\n",
      "973/1088, train_loss: 0.0317\n",
      "974/1088, train_loss: 0.0300\n",
      "975/1088, train_loss: 0.0333\n",
      "976/1088, train_loss: 0.0318\n",
      "977/1088, train_loss: 0.0392\n",
      "978/1088, train_loss: 0.0306\n",
      "979/1088, train_loss: 0.0319\n",
      "980/1088, train_loss: 0.0322\n",
      "981/1088, train_loss: 0.0303\n",
      "982/1088, train_loss: 0.0314\n",
      "983/1088, train_loss: 0.0331\n",
      "984/1088, train_loss: 0.0296\n",
      "985/1088, train_loss: 0.0288\n",
      "986/1088, train_loss: 0.0297\n",
      "987/1088, train_loss: 0.0372\n",
      "988/1088, train_loss: 0.0496\n",
      "989/1088, train_loss: 0.0327\n",
      "990/1088, train_loss: 0.0284\n",
      "991/1088, train_loss: 0.0371\n",
      "992/1088, train_loss: 0.0339\n",
      "993/1088, train_loss: 0.0314\n",
      "994/1088, train_loss: 0.0321\n",
      "995/1088, train_loss: 0.0309\n",
      "996/1088, train_loss: 0.0308\n",
      "997/1088, train_loss: 0.0332\n",
      "998/1088, train_loss: 0.0305\n",
      "999/1088, train_loss: 0.0303\n",
      "1000/1088, train_loss: 0.0307\n",
      "1001/1088, train_loss: 0.0343\n",
      "1002/1088, train_loss: 0.0400\n",
      "1003/1088, train_loss: 0.0301\n",
      "1004/1088, train_loss: 0.0297\n",
      "1005/1088, train_loss: 0.0296\n",
      "1006/1088, train_loss: 0.0379\n",
      "1007/1088, train_loss: 0.0301\n",
      "1008/1088, train_loss: 0.0310\n",
      "1009/1088, train_loss: 0.0339\n",
      "1010/1088, train_loss: 0.0316\n",
      "1011/1088, train_loss: 0.0300\n",
      "1012/1088, train_loss: 0.0340\n",
      "1013/1088, train_loss: 0.0322\n",
      "1014/1088, train_loss: 0.0337\n",
      "1015/1088, train_loss: 0.0359\n",
      "1016/1088, train_loss: 0.0377\n",
      "1017/1088, train_loss: 0.0352\n",
      "1018/1088, train_loss: 0.0321\n",
      "1019/1088, train_loss: 0.0313\n",
      "1020/1088, train_loss: 0.0301\n",
      "1021/1088, train_loss: 0.0320\n",
      "1022/1088, train_loss: 0.0313\n",
      "1023/1088, train_loss: 0.0301\n",
      "1024/1088, train_loss: 0.0408\n",
      "1025/1088, train_loss: 0.0313\n",
      "1026/1088, train_loss: 0.0288\n",
      "1027/1088, train_loss: 0.0308\n",
      "1028/1088, train_loss: 0.0350\n",
      "1029/1088, train_loss: 0.0296\n",
      "1030/1088, train_loss: 0.0362\n",
      "1031/1088, train_loss: 0.0334\n",
      "1032/1088, train_loss: 0.0318\n",
      "1033/1088, train_loss: 0.0325\n",
      "1034/1088, train_loss: 0.0329\n",
      "1035/1088, train_loss: 0.0337\n",
      "1036/1088, train_loss: 0.0343\n",
      "1037/1088, train_loss: 0.0353\n",
      "1038/1088, train_loss: 0.0317\n",
      "1039/1088, train_loss: 0.0349\n",
      "1040/1088, train_loss: 0.0323\n",
      "1041/1088, train_loss: 0.0296\n",
      "1042/1088, train_loss: 0.0328\n",
      "1043/1088, train_loss: 0.0322\n",
      "1044/1088, train_loss: 0.0311\n",
      "1045/1088, train_loss: 0.0344\n",
      "1046/1088, train_loss: 0.0314\n",
      "1047/1088, train_loss: 0.0309\n",
      "1048/1088, train_loss: 0.0335\n",
      "1049/1088, train_loss: 0.0351\n",
      "1050/1088, train_loss: 0.0364\n",
      "1051/1088, train_loss: 0.0353\n",
      "1052/1088, train_loss: 0.0348\n",
      "1053/1088, train_loss: 0.0322\n",
      "1054/1088, train_loss: 0.0411\n",
      "1055/1088, train_loss: 0.0342\n",
      "1056/1088, train_loss: 0.0356\n",
      "1057/1088, train_loss: 0.0324\n",
      "1058/1088, train_loss: 0.0422\n",
      "1059/1088, train_loss: 0.0328\n",
      "1060/1088, train_loss: 0.0344\n",
      "1061/1088, train_loss: 0.0336\n",
      "1062/1088, train_loss: 0.0319\n",
      "1063/1088, train_loss: 0.0352\n",
      "1064/1088, train_loss: 0.0316\n",
      "1065/1088, train_loss: 0.0294\n",
      "1066/1088, train_loss: 0.0294\n",
      "1067/1088, train_loss: 0.0348\n",
      "1068/1088, train_loss: 0.0335\n",
      "1069/1088, train_loss: 0.0315\n",
      "1070/1088, train_loss: 0.0294\n",
      "1071/1088, train_loss: 0.0351\n",
      "1072/1088, train_loss: 0.0327\n",
      "1073/1088, train_loss: 0.0409\n",
      "1074/1088, train_loss: 0.0355\n",
      "1075/1088, train_loss: 0.0310\n",
      "1076/1088, train_loss: 0.0317\n",
      "1077/1088, train_loss: 0.0306\n",
      "1078/1088, train_loss: 0.0310\n",
      "1079/1088, train_loss: 0.0313\n",
      "1080/1088, train_loss: 0.0336\n",
      "1081/1088, train_loss: 0.0313\n",
      "1082/1088, train_loss: 0.0315\n",
      "1083/1088, train_loss: 0.0312\n",
      "1084/1088, train_loss: 0.0309\n",
      "1085/1088, train_loss: 0.0325\n",
      "1086/1088, train_loss: 0.0305\n",
      "1087/1088, train_loss: 0.0315\n",
      "1088/1088, train_loss: 0.0326\n",
      "1089/1088, train_loss: 0.0337\n",
      "epoch 3 average loss: 0.0328, train_dice: 0.9674\n",
      "epoch 3 average loss: 0.0328\n",
      "--------------------------------------------------\n",
      "epoch 4/50\n",
      "1/1088, train_loss: 0.0330\n",
      "2/1088, train_loss: 0.0345\n",
      "3/1088, train_loss: 0.0325\n",
      "4/1088, train_loss: 0.0324\n",
      "5/1088, train_loss: 0.0329\n",
      "6/1088, train_loss: 0.0326\n",
      "7/1088, train_loss: 0.0318\n",
      "8/1088, train_loss: 0.0334\n",
      "9/1088, train_loss: 0.0292\n",
      "10/1088, train_loss: 0.0363\n",
      "11/1088, train_loss: 0.0318\n",
      "12/1088, train_loss: 0.0357\n",
      "13/1088, train_loss: 0.0319\n",
      "14/1088, train_loss: 0.0396\n",
      "15/1088, train_loss: 0.0300\n",
      "16/1088, train_loss: 0.0340\n",
      "17/1088, train_loss: 0.0303\n",
      "18/1088, train_loss: 0.0453\n",
      "19/1088, train_loss: 0.0326\n",
      "20/1088, train_loss: 0.0384\n",
      "21/1088, train_loss: 0.0324\n",
      "22/1088, train_loss: 0.0324\n",
      "23/1088, train_loss: 0.0319\n",
      "24/1088, train_loss: 0.0321\n",
      "25/1088, train_loss: 0.0308\n",
      "26/1088, train_loss: 0.0334\n",
      "27/1088, train_loss: 0.0417\n",
      "28/1088, train_loss: 0.0310\n",
      "29/1088, train_loss: 0.0310\n",
      "30/1088, train_loss: 0.0312\n",
      "31/1088, train_loss: 0.0328\n",
      "32/1088, train_loss: 0.0337\n",
      "33/1088, train_loss: 0.0365\n",
      "34/1088, train_loss: 0.0387\n",
      "35/1088, train_loss: 0.0361\n",
      "36/1088, train_loss: 0.0312\n",
      "37/1088, train_loss: 0.0317\n",
      "38/1088, train_loss: 0.0306\n",
      "39/1088, train_loss: 0.0320\n",
      "40/1088, train_loss: 0.0317\n",
      "41/1088, train_loss: 0.0306\n",
      "42/1088, train_loss: 0.0290\n",
      "43/1088, train_loss: 0.0456\n",
      "44/1088, train_loss: 0.0346\n",
      "45/1088, train_loss: 0.0316\n",
      "46/1088, train_loss: 0.0312\n",
      "47/1088, train_loss: 0.0303\n",
      "48/1088, train_loss: 0.0331\n",
      "49/1088, train_loss: 0.0337\n",
      "50/1088, train_loss: 0.0318\n",
      "51/1088, train_loss: 0.0330\n",
      "52/1088, train_loss: 0.0321\n",
      "53/1088, train_loss: 0.0317\n",
      "54/1088, train_loss: 0.0349\n",
      "55/1088, train_loss: 0.0324\n",
      "56/1088, train_loss: 0.0377\n",
      "57/1088, train_loss: 0.0340\n",
      "58/1088, train_loss: 0.0357\n",
      "59/1088, train_loss: 0.0354\n",
      "60/1088, train_loss: 0.0321\n",
      "61/1088, train_loss: 0.0458\n",
      "62/1088, train_loss: 0.0362\n",
      "63/1088, train_loss: 0.0317\n",
      "64/1088, train_loss: 0.0307\n",
      "65/1088, train_loss: 0.0304\n",
      "66/1088, train_loss: 0.0318\n",
      "67/1088, train_loss: 0.0313\n",
      "68/1088, train_loss: 0.0379\n",
      "69/1088, train_loss: 0.0440\n",
      "70/1088, train_loss: 0.0394\n",
      "71/1088, train_loss: 0.0319\n",
      "72/1088, train_loss: 0.0413\n",
      "73/1088, train_loss: 0.0320\n",
      "74/1088, train_loss: 0.0375\n",
      "75/1088, train_loss: 0.0394\n",
      "76/1088, train_loss: 0.0324\n",
      "77/1088, train_loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/1088, train_loss: 0.0318\n",
      "79/1088, train_loss: 0.0316\n",
      "80/1088, train_loss: 0.0301\n",
      "81/1088, train_loss: 0.0349\n",
      "82/1088, train_loss: 0.0332\n",
      "83/1088, train_loss: 0.0386\n",
      "84/1088, train_loss: 0.0360\n",
      "85/1088, train_loss: 0.0329\n",
      "86/1088, train_loss: 0.0341\n",
      "87/1088, train_loss: 0.0351\n",
      "88/1088, train_loss: 0.0312\n",
      "89/1088, train_loss: 0.0347\n",
      "90/1088, train_loss: 0.0328\n",
      "91/1088, train_loss: 0.0300\n",
      "92/1088, train_loss: 0.0298\n",
      "93/1088, train_loss: 0.0324\n",
      "94/1088, train_loss: 0.0319\n",
      "95/1088, train_loss: 0.0306\n",
      "96/1088, train_loss: 0.0296\n",
      "97/1088, train_loss: 0.0313\n",
      "98/1088, train_loss: 0.0315\n",
      "99/1088, train_loss: 0.0311\n",
      "100/1088, train_loss: 0.0413\n",
      "101/1088, train_loss: 0.0335\n",
      "102/1088, train_loss: 0.0320\n",
      "103/1088, train_loss: 0.0301\n",
      "104/1088, train_loss: 0.0309\n",
      "105/1088, train_loss: 0.0316\n",
      "106/1088, train_loss: 0.0309\n",
      "107/1088, train_loss: 0.0338\n",
      "108/1088, train_loss: 0.0323\n",
      "109/1088, train_loss: 0.0338\n",
      "110/1088, train_loss: 0.0316\n",
      "111/1088, train_loss: 0.0312\n",
      "112/1088, train_loss: 0.0315\n",
      "113/1088, train_loss: 0.0345\n",
      "114/1088, train_loss: 0.0313\n",
      "115/1088, train_loss: 0.0328\n",
      "116/1088, train_loss: 0.0317\n",
      "117/1088, train_loss: 0.0319\n",
      "118/1088, train_loss: 0.0362\n",
      "119/1088, train_loss: 0.0301\n",
      "120/1088, train_loss: 0.0315\n",
      "121/1088, train_loss: 0.0380\n",
      "122/1088, train_loss: 0.0320\n",
      "123/1088, train_loss: 0.0284\n",
      "124/1088, train_loss: 0.0317\n",
      "125/1088, train_loss: 0.0306\n",
      "126/1088, train_loss: 0.0396\n",
      "127/1088, train_loss: 0.0323\n",
      "128/1088, train_loss: 0.0328\n",
      "129/1088, train_loss: 0.0335\n",
      "130/1088, train_loss: 0.0325\n",
      "131/1088, train_loss: 0.0318\n",
      "132/1088, train_loss: 0.0321\n",
      "133/1088, train_loss: 0.0319\n",
      "134/1088, train_loss: 0.0344\n",
      "135/1088, train_loss: 0.0331\n",
      "136/1088, train_loss: 0.0371\n",
      "137/1088, train_loss: 0.0323\n",
      "138/1088, train_loss: 0.0347\n",
      "139/1088, train_loss: 0.0317\n",
      "140/1088, train_loss: 0.0309\n",
      "141/1088, train_loss: 0.0319\n",
      "142/1088, train_loss: 0.0343\n",
      "143/1088, train_loss: 0.0306\n",
      "144/1088, train_loss: 0.0314\n",
      "145/1088, train_loss: 0.0342\n",
      "146/1088, train_loss: 0.0332\n",
      "147/1088, train_loss: 0.0273\n",
      "148/1088, train_loss: 0.0309\n",
      "149/1088, train_loss: 0.0301\n",
      "150/1088, train_loss: 0.0307\n",
      "151/1088, train_loss: 0.0311\n",
      "152/1088, train_loss: 0.0347\n",
      "153/1088, train_loss: 0.0320\n",
      "154/1088, train_loss: 0.0336\n",
      "155/1088, train_loss: 0.0326\n",
      "156/1088, train_loss: 0.0321\n",
      "157/1088, train_loss: 0.0342\n",
      "158/1088, train_loss: 0.0316\n",
      "159/1088, train_loss: 0.0349\n",
      "160/1088, train_loss: 0.0310\n",
      "161/1088, train_loss: 0.0324\n",
      "162/1088, train_loss: 0.0318\n",
      "163/1088, train_loss: 0.0314\n",
      "164/1088, train_loss: 0.0331\n",
      "165/1088, train_loss: 0.0340\n",
      "166/1088, train_loss: 0.0334\n",
      "167/1088, train_loss: 0.0335\n",
      "168/1088, train_loss: 0.0334\n",
      "169/1088, train_loss: 0.0361\n",
      "170/1088, train_loss: 0.0326\n",
      "171/1088, train_loss: 0.0308\n",
      "172/1088, train_loss: 0.0344\n",
      "173/1088, train_loss: 0.0389\n",
      "174/1088, train_loss: 0.0312\n",
      "175/1088, train_loss: 0.0314\n",
      "176/1088, train_loss: 0.0366\n",
      "177/1088, train_loss: 0.0325\n",
      "178/1088, train_loss: 0.0317\n",
      "179/1088, train_loss: 0.0339\n",
      "180/1088, train_loss: 0.0311\n",
      "181/1088, train_loss: 0.0314\n",
      "182/1088, train_loss: 0.0325\n",
      "183/1088, train_loss: 0.0300\n",
      "184/1088, train_loss: 0.0377\n",
      "185/1088, train_loss: 0.0303\n",
      "186/1088, train_loss: 0.0378\n",
      "187/1088, train_loss: 0.0317\n",
      "188/1088, train_loss: 0.0300\n",
      "189/1088, train_loss: 0.0347\n",
      "190/1088, train_loss: 0.0318\n",
      "191/1088, train_loss: 0.0308\n",
      "192/1088, train_loss: 0.0314\n",
      "193/1088, train_loss: 0.0331\n",
      "194/1088, train_loss: 0.0311\n",
      "195/1088, train_loss: 0.0344\n",
      "196/1088, train_loss: 0.0307\n",
      "197/1088, train_loss: 0.0310\n",
      "198/1088, train_loss: 0.0319\n",
      "199/1088, train_loss: 0.0316\n",
      "200/1088, train_loss: 0.0341\n",
      "201/1088, train_loss: 0.0330\n",
      "202/1088, train_loss: 0.0314\n",
      "203/1088, train_loss: 0.0308\n",
      "204/1088, train_loss: 0.0316\n",
      "205/1088, train_loss: 0.0318\n",
      "206/1088, train_loss: 0.0328\n",
      "207/1088, train_loss: 0.0319\n",
      "208/1088, train_loss: 0.0331\n",
      "209/1088, train_loss: 0.0322\n",
      "210/1088, train_loss: 0.0365\n",
      "211/1088, train_loss: 0.0310\n",
      "212/1088, train_loss: 0.0302\n",
      "213/1088, train_loss: 0.0315\n",
      "214/1088, train_loss: 0.0364\n",
      "215/1088, train_loss: 0.0319\n",
      "216/1088, train_loss: 0.0293\n",
      "217/1088, train_loss: 0.0305\n",
      "218/1088, train_loss: 0.0287\n",
      "219/1088, train_loss: 0.0340\n",
      "220/1088, train_loss: 0.0324\n",
      "221/1088, train_loss: 0.0383\n",
      "222/1088, train_loss: 0.0356\n",
      "223/1088, train_loss: 0.0310\n",
      "224/1088, train_loss: 0.0373\n",
      "225/1088, train_loss: 0.0309\n",
      "226/1088, train_loss: 0.0382\n",
      "227/1088, train_loss: 0.0332\n",
      "228/1088, train_loss: 0.0383\n",
      "229/1088, train_loss: 0.0384\n",
      "230/1088, train_loss: 0.0322\n",
      "231/1088, train_loss: 0.0324\n",
      "232/1088, train_loss: 0.0337\n",
      "233/1088, train_loss: 0.0297\n",
      "234/1088, train_loss: 0.0312\n",
      "235/1088, train_loss: 0.0301\n",
      "236/1088, train_loss: 0.0309\n",
      "237/1088, train_loss: 0.0305\n",
      "238/1088, train_loss: 0.0309\n",
      "239/1088, train_loss: 0.0369\n",
      "240/1088, train_loss: 0.0367\n",
      "241/1088, train_loss: 0.0303\n",
      "242/1088, train_loss: 0.0300\n",
      "243/1088, train_loss: 0.0289\n",
      "244/1088, train_loss: 0.0373\n",
      "245/1088, train_loss: 0.0321\n",
      "246/1088, train_loss: 0.0306\n",
      "247/1088, train_loss: 0.0321\n",
      "248/1088, train_loss: 0.0338\n",
      "249/1088, train_loss: 0.0324\n",
      "250/1088, train_loss: 0.0372\n",
      "251/1088, train_loss: 0.0409\n",
      "252/1088, train_loss: 0.0405\n",
      "253/1088, train_loss: 0.0345\n",
      "254/1088, train_loss: 0.0344\n",
      "255/1088, train_loss: 0.0362\n",
      "256/1088, train_loss: 0.0413\n",
      "257/1088, train_loss: 0.0327\n",
      "258/1088, train_loss: 0.0344\n",
      "259/1088, train_loss: 0.0347\n",
      "260/1088, train_loss: 0.0294\n",
      "261/1088, train_loss: 0.0295\n",
      "262/1088, train_loss: 0.0320\n",
      "263/1088, train_loss: 0.0292\n",
      "264/1088, train_loss: 0.0308\n",
      "265/1088, train_loss: 0.0317\n",
      "266/1088, train_loss: 0.0310\n",
      "267/1088, train_loss: 0.0354\n",
      "268/1088, train_loss: 0.0317\n",
      "269/1088, train_loss: 0.0320\n",
      "270/1088, train_loss: 0.0324\n",
      "271/1088, train_loss: 0.0303\n",
      "272/1088, train_loss: 0.0319\n",
      "273/1088, train_loss: 0.0336\n",
      "274/1088, train_loss: 0.0316\n",
      "275/1088, train_loss: 0.0312\n",
      "276/1088, train_loss: 0.0370\n",
      "277/1088, train_loss: 0.0306\n",
      "278/1088, train_loss: 0.0290\n",
      "279/1088, train_loss: 0.0289\n",
      "280/1088, train_loss: 0.0326\n",
      "281/1088, train_loss: 0.0348\n",
      "282/1088, train_loss: 0.0312\n",
      "283/1088, train_loss: 0.0300\n",
      "284/1088, train_loss: 0.0305\n",
      "285/1088, train_loss: 0.0313\n",
      "286/1088, train_loss: 0.0328\n",
      "287/1088, train_loss: 0.0297\n",
      "288/1088, train_loss: 0.0321\n",
      "289/1088, train_loss: 0.0318\n",
      "290/1088, train_loss: 0.0302\n",
      "291/1088, train_loss: 0.0305\n",
      "292/1088, train_loss: 0.0313\n",
      "293/1088, train_loss: 0.0326\n",
      "294/1088, train_loss: 0.0304\n",
      "295/1088, train_loss: 0.0304\n",
      "296/1088, train_loss: 0.0297\n",
      "297/1088, train_loss: 0.0324\n",
      "298/1088, train_loss: 0.0318\n",
      "299/1088, train_loss: 0.0351\n",
      "300/1088, train_loss: 0.0296\n",
      "301/1088, train_loss: 0.0324\n",
      "302/1088, train_loss: 0.0336\n",
      "303/1088, train_loss: 0.0380\n",
      "304/1088, train_loss: 0.0296\n",
      "305/1088, train_loss: 0.0332\n",
      "306/1088, train_loss: 0.0295\n",
      "307/1088, train_loss: 0.0334\n",
      "308/1088, train_loss: 0.0339\n",
      "309/1088, train_loss: 0.0324\n",
      "310/1088, train_loss: 0.0338\n",
      "311/1088, train_loss: 0.0323\n",
      "312/1088, train_loss: 0.0297\n",
      "313/1088, train_loss: 0.0311\n",
      "314/1088, train_loss: 0.0301\n",
      "315/1088, train_loss: 0.0284\n",
      "316/1088, train_loss: 0.0362\n",
      "317/1088, train_loss: 0.0313\n",
      "318/1088, train_loss: 0.0304\n",
      "319/1088, train_loss: 0.0308\n",
      "320/1088, train_loss: 0.0331\n",
      "321/1088, train_loss: 0.0320\n",
      "322/1088, train_loss: 0.0325\n",
      "323/1088, train_loss: 0.0307\n",
      "324/1088, train_loss: 0.0302\n",
      "325/1088, train_loss: 0.0299\n",
      "326/1088, train_loss: 0.0325\n",
      "327/1088, train_loss: 0.0307\n",
      "328/1088, train_loss: 0.0301\n",
      "329/1088, train_loss: 0.0311\n",
      "330/1088, train_loss: 0.0315\n",
      "331/1088, train_loss: 0.0316\n",
      "332/1088, train_loss: 0.0326\n",
      "333/1088, train_loss: 0.0311\n",
      "334/1088, train_loss: 0.0302\n",
      "335/1088, train_loss: 0.0290\n",
      "336/1088, train_loss: 0.0309\n",
      "337/1088, train_loss: 0.0308\n",
      "338/1088, train_loss: 0.0308\n",
      "339/1088, train_loss: 0.0374\n",
      "340/1088, train_loss: 0.0302\n",
      "341/1088, train_loss: 0.0324\n",
      "342/1088, train_loss: 0.0360\n",
      "343/1088, train_loss: 0.0290\n",
      "344/1088, train_loss: 0.0318\n",
      "345/1088, train_loss: 0.0320\n",
      "346/1088, train_loss: 0.0307\n",
      "347/1088, train_loss: 0.0314\n",
      "348/1088, train_loss: 0.0328\n",
      "349/1088, train_loss: 0.0308\n",
      "350/1088, train_loss: 0.0316\n",
      "351/1088, train_loss: 0.0310\n",
      "352/1088, train_loss: 0.0341\n",
      "353/1088, train_loss: 0.0325\n",
      "354/1088, train_loss: 0.0343\n",
      "355/1088, train_loss: 0.0316\n",
      "356/1088, train_loss: 0.0368\n",
      "357/1088, train_loss: 0.0348\n",
      "358/1088, train_loss: 0.0294\n",
      "359/1088, train_loss: 0.0313\n",
      "360/1088, train_loss: 0.0333\n",
      "361/1088, train_loss: 0.0325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362/1088, train_loss: 0.0298\n",
      "363/1088, train_loss: 0.0322\n",
      "364/1088, train_loss: 0.0333\n",
      "365/1088, train_loss: 0.0342\n",
      "366/1088, train_loss: 0.0300\n",
      "367/1088, train_loss: 0.0304\n",
      "368/1088, train_loss: 0.0306\n",
      "369/1088, train_loss: 0.0301\n",
      "370/1088, train_loss: 0.0319\n",
      "371/1088, train_loss: 0.0313\n",
      "372/1088, train_loss: 0.0285\n",
      "373/1088, train_loss: 0.0338\n",
      "374/1088, train_loss: 0.0308\n",
      "375/1088, train_loss: 0.0334\n",
      "376/1088, train_loss: 0.0290\n",
      "377/1088, train_loss: 0.0350\n",
      "378/1088, train_loss: 0.0329\n",
      "379/1088, train_loss: 0.0341\n",
      "380/1088, train_loss: 0.0339\n",
      "381/1088, train_loss: 0.0301\n",
      "382/1088, train_loss: 0.0305\n",
      "383/1088, train_loss: 0.0317\n",
      "384/1088, train_loss: 0.0346\n",
      "385/1088, train_loss: 0.0323\n",
      "386/1088, train_loss: 0.0321\n",
      "387/1088, train_loss: 0.0322\n",
      "388/1088, train_loss: 0.0355\n",
      "389/1088, train_loss: 0.0319\n",
      "390/1088, train_loss: 0.0347\n",
      "391/1088, train_loss: 0.0328\n",
      "392/1088, train_loss: 0.0295\n",
      "393/1088, train_loss: 0.0290\n",
      "394/1088, train_loss: 0.0316\n",
      "395/1088, train_loss: 0.0306\n",
      "396/1088, train_loss: 0.0316\n",
      "397/1088, train_loss: 0.0359\n",
      "398/1088, train_loss: 0.0314\n",
      "399/1088, train_loss: 0.0290\n",
      "400/1088, train_loss: 0.0313\n",
      "401/1088, train_loss: 0.0295\n",
      "402/1088, train_loss: 0.0299\n",
      "403/1088, train_loss: 0.0317\n",
      "404/1088, train_loss: 0.0291\n",
      "405/1088, train_loss: 0.0439\n",
      "406/1088, train_loss: 0.0306\n",
      "407/1088, train_loss: 0.0399\n",
      "408/1088, train_loss: 0.0317\n",
      "409/1088, train_loss: 0.0325\n",
      "410/1088, train_loss: 0.0330\n",
      "411/1088, train_loss: 0.0339\n",
      "412/1088, train_loss: 0.0318\n",
      "413/1088, train_loss: 0.0309\n",
      "414/1088, train_loss: 0.0355\n",
      "415/1088, train_loss: 0.0343\n",
      "416/1088, train_loss: 0.0351\n",
      "417/1088, train_loss: 0.0322\n",
      "418/1088, train_loss: 0.0327\n",
      "419/1088, train_loss: 0.0319\n",
      "420/1088, train_loss: 0.0380\n",
      "421/1088, train_loss: 0.0321\n",
      "422/1088, train_loss: 0.0301\n",
      "423/1088, train_loss: 0.0334\n",
      "424/1088, train_loss: 0.0332\n",
      "425/1088, train_loss: 0.0306\n",
      "426/1088, train_loss: 0.0300\n",
      "427/1088, train_loss: 0.0344\n",
      "428/1088, train_loss: 0.0293\n",
      "429/1088, train_loss: 0.0318\n",
      "430/1088, train_loss: 0.0317\n",
      "431/1088, train_loss: 0.0311\n",
      "432/1088, train_loss: 0.0304\n",
      "433/1088, train_loss: 0.0304\n",
      "434/1088, train_loss: 0.0321\n",
      "435/1088, train_loss: 0.0450\n",
      "436/1088, train_loss: 0.0304\n",
      "437/1088, train_loss: 0.0274\n",
      "438/1088, train_loss: 0.0320\n",
      "439/1088, train_loss: 0.0334\n",
      "440/1088, train_loss: 0.0313\n",
      "441/1088, train_loss: 0.0342\n",
      "442/1088, train_loss: 0.0309\n",
      "443/1088, train_loss: 0.0299\n",
      "444/1088, train_loss: 0.0346\n",
      "445/1088, train_loss: 0.0328\n",
      "446/1088, train_loss: 0.0323\n",
      "447/1088, train_loss: 0.0324\n",
      "448/1088, train_loss: 0.0346\n",
      "449/1088, train_loss: 0.0346\n",
      "450/1088, train_loss: 0.0324\n",
      "451/1088, train_loss: 0.0317\n",
      "452/1088, train_loss: 0.0329\n",
      "453/1088, train_loss: 0.0302\n",
      "454/1088, train_loss: 0.0404\n",
      "455/1088, train_loss: 0.0323\n",
      "456/1088, train_loss: 0.0320\n",
      "457/1088, train_loss: 0.0301\n",
      "458/1088, train_loss: 0.0401\n",
      "459/1088, train_loss: 0.0362\n",
      "460/1088, train_loss: 0.0310\n",
      "461/1088, train_loss: 0.0323\n",
      "462/1088, train_loss: 0.0303\n",
      "463/1088, train_loss: 0.0295\n",
      "464/1088, train_loss: 0.0317\n",
      "465/1088, train_loss: 0.0320\n",
      "466/1088, train_loss: 0.0299\n",
      "467/1088, train_loss: 0.0314\n",
      "468/1088, train_loss: 0.0326\n",
      "469/1088, train_loss: 0.0307\n",
      "470/1088, train_loss: 0.0329\n",
      "471/1088, train_loss: 0.0355\n",
      "472/1088, train_loss: 0.0287\n",
      "473/1088, train_loss: 0.0284\n",
      "474/1088, train_loss: 0.0296\n",
      "475/1088, train_loss: 0.0290\n",
      "476/1088, train_loss: 0.0304\n",
      "477/1088, train_loss: 0.0288\n",
      "478/1088, train_loss: 0.0303\n",
      "479/1088, train_loss: 0.0316\n",
      "480/1088, train_loss: 0.0292\n",
      "481/1088, train_loss: 0.0312\n",
      "482/1088, train_loss: 0.0302\n",
      "483/1088, train_loss: 0.0313\n",
      "484/1088, train_loss: 0.0310\n",
      "485/1088, train_loss: 0.0284\n",
      "486/1088, train_loss: 0.0295\n",
      "487/1088, train_loss: 0.0311\n",
      "488/1088, train_loss: 0.0324\n",
      "489/1088, train_loss: 0.0316\n",
      "490/1088, train_loss: 0.0319\n",
      "491/1088, train_loss: 0.0294\n",
      "492/1088, train_loss: 0.0324\n",
      "493/1088, train_loss: 0.0359\n",
      "494/1088, train_loss: 0.0315\n",
      "495/1088, train_loss: 0.0278\n",
      "496/1088, train_loss: 0.0338\n",
      "497/1088, train_loss: 0.0315\n",
      "498/1088, train_loss: 0.0321\n",
      "499/1088, train_loss: 0.0338\n",
      "500/1088, train_loss: 0.0295\n",
      "501/1088, train_loss: 0.0295\n",
      "502/1088, train_loss: 0.0310\n",
      "503/1088, train_loss: 0.0337\n",
      "504/1088, train_loss: 0.0306\n",
      "505/1088, train_loss: 0.0318\n",
      "506/1088, train_loss: 0.0345\n",
      "507/1088, train_loss: 0.0302\n",
      "508/1088, train_loss: 0.0287\n",
      "509/1088, train_loss: 0.0310\n",
      "510/1088, train_loss: 0.0309\n",
      "511/1088, train_loss: 0.0329\n",
      "512/1088, train_loss: 0.0368\n",
      "513/1088, train_loss: 0.0329\n",
      "514/1088, train_loss: 0.0330\n",
      "515/1088, train_loss: 0.0332\n",
      "516/1088, train_loss: 0.0325\n",
      "517/1088, train_loss: 0.0327\n",
      "518/1088, train_loss: 0.0294\n",
      "519/1088, train_loss: 0.0369\n",
      "520/1088, train_loss: 0.0297\n",
      "521/1088, train_loss: 0.0304\n",
      "522/1088, train_loss: 0.0317\n",
      "523/1088, train_loss: 0.0349\n",
      "524/1088, train_loss: 0.0342\n",
      "525/1088, train_loss: 0.0308\n",
      "526/1088, train_loss: 0.0315\n",
      "527/1088, train_loss: 0.0310\n",
      "528/1088, train_loss: 0.0309\n",
      "529/1088, train_loss: 0.0307\n",
      "530/1088, train_loss: 0.0310\n",
      "531/1088, train_loss: 0.0303\n",
      "532/1088, train_loss: 0.0326\n",
      "533/1088, train_loss: 0.0318\n",
      "534/1088, train_loss: 0.0323\n",
      "535/1088, train_loss: 0.0296\n",
      "536/1088, train_loss: 0.0302\n",
      "537/1088, train_loss: 0.0315\n",
      "538/1088, train_loss: 0.0292\n",
      "539/1088, train_loss: 0.0320\n",
      "540/1088, train_loss: 0.0300\n",
      "541/1088, train_loss: 0.0311\n",
      "542/1088, train_loss: 0.0299\n",
      "543/1088, train_loss: 0.0316\n",
      "544/1088, train_loss: 0.0304\n",
      "545/1088, train_loss: 0.0314\n",
      "546/1088, train_loss: 0.0337\n",
      "547/1088, train_loss: 0.0312\n",
      "548/1088, train_loss: 0.0336\n",
      "549/1088, train_loss: 0.0296\n",
      "550/1088, train_loss: 0.0326\n",
      "551/1088, train_loss: 0.0308\n",
      "552/1088, train_loss: 0.0384\n",
      "553/1088, train_loss: 0.0326\n",
      "554/1088, train_loss: 0.0308\n",
      "555/1088, train_loss: 0.0312\n",
      "556/1088, train_loss: 0.0318\n",
      "557/1088, train_loss: 0.0325\n",
      "558/1088, train_loss: 0.0348\n",
      "559/1088, train_loss: 0.0297\n",
      "560/1088, train_loss: 0.0291\n",
      "561/1088, train_loss: 0.0329\n",
      "562/1088, train_loss: 0.0309\n",
      "563/1088, train_loss: 0.0303\n",
      "564/1088, train_loss: 0.0328\n",
      "565/1088, train_loss: 0.0318\n",
      "566/1088, train_loss: 0.0347\n",
      "567/1088, train_loss: 0.0336\n",
      "568/1088, train_loss: 0.0326\n",
      "569/1088, train_loss: 0.0321\n",
      "570/1088, train_loss: 0.0343\n",
      "571/1088, train_loss: 0.0347\n",
      "572/1088, train_loss: 0.0321\n",
      "573/1088, train_loss: 0.0337\n",
      "574/1088, train_loss: 0.0369\n",
      "575/1088, train_loss: 0.0338\n",
      "576/1088, train_loss: 0.0334\n",
      "577/1088, train_loss: 0.0310\n",
      "578/1088, train_loss: 0.0323\n",
      "579/1088, train_loss: 0.0299\n",
      "580/1088, train_loss: 0.0308\n",
      "581/1088, train_loss: 0.0289\n",
      "582/1088, train_loss: 0.0308\n",
      "583/1088, train_loss: 0.0288\n",
      "584/1088, train_loss: 0.0290\n",
      "585/1088, train_loss: 0.0332\n",
      "586/1088, train_loss: 0.0305\n",
      "587/1088, train_loss: 0.0293\n",
      "588/1088, train_loss: 0.0297\n",
      "589/1088, train_loss: 0.0310\n",
      "590/1088, train_loss: 0.0297\n",
      "591/1088, train_loss: 0.0278\n",
      "592/1088, train_loss: 0.0343\n",
      "593/1088, train_loss: 0.0295\n",
      "594/1088, train_loss: 0.0283\n",
      "595/1088, train_loss: 0.0312\n",
      "596/1088, train_loss: 0.0298\n",
      "597/1088, train_loss: 0.0338\n",
      "598/1088, train_loss: 0.0291\n",
      "599/1088, train_loss: 0.0306\n",
      "600/1088, train_loss: 0.0314\n",
      "601/1088, train_loss: 0.0318\n",
      "602/1088, train_loss: 0.0292\n",
      "603/1088, train_loss: 0.0321\n",
      "604/1088, train_loss: 0.0319\n",
      "605/1088, train_loss: 0.0306\n",
      "606/1088, train_loss: 0.0346\n",
      "607/1088, train_loss: 0.0306\n",
      "608/1088, train_loss: 0.0299\n",
      "609/1088, train_loss: 0.0336\n",
      "610/1088, train_loss: 0.0301\n",
      "611/1088, train_loss: 0.0319\n",
      "612/1088, train_loss: 0.0355\n",
      "613/1088, train_loss: 0.0298\n",
      "614/1088, train_loss: 0.0311\n",
      "615/1088, train_loss: 0.0300\n",
      "616/1088, train_loss: 0.0305\n",
      "617/1088, train_loss: 0.0312\n",
      "618/1088, train_loss: 0.0299\n",
      "619/1088, train_loss: 0.0307\n",
      "620/1088, train_loss: 0.0311\n",
      "621/1088, train_loss: 0.0341\n",
      "622/1088, train_loss: 0.0307\n",
      "623/1088, train_loss: 0.0313\n",
      "624/1088, train_loss: 0.0313\n",
      "625/1088, train_loss: 0.0302\n",
      "626/1088, train_loss: 0.0339\n",
      "627/1088, train_loss: 0.0326\n",
      "628/1088, train_loss: 0.0279\n",
      "629/1088, train_loss: 0.0333\n",
      "630/1088, train_loss: 0.0292\n",
      "631/1088, train_loss: 0.0306\n",
      "632/1088, train_loss: 0.0316\n",
      "633/1088, train_loss: 0.0315\n",
      "634/1088, train_loss: 0.0303\n",
      "635/1088, train_loss: 0.0305\n",
      "636/1088, train_loss: 0.0304\n",
      "637/1088, train_loss: 0.0295\n",
      "638/1088, train_loss: 0.0304\n",
      "639/1088, train_loss: 0.0293\n",
      "640/1088, train_loss: 0.0322\n",
      "641/1088, train_loss: 0.0319\n",
      "642/1088, train_loss: 0.0306\n",
      "643/1088, train_loss: 0.0327\n",
      "644/1088, train_loss: 0.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/1088, train_loss: 0.0307\n",
      "646/1088, train_loss: 0.0315\n",
      "647/1088, train_loss: 0.0288\n",
      "648/1088, train_loss: 0.0417\n",
      "649/1088, train_loss: 0.0336\n",
      "650/1088, train_loss: 0.0371\n",
      "651/1088, train_loss: 0.0312\n",
      "652/1088, train_loss: 0.0291\n",
      "653/1088, train_loss: 0.0326\n",
      "654/1088, train_loss: 0.0351\n",
      "655/1088, train_loss: 0.0304\n",
      "656/1088, train_loss: 0.0288\n",
      "657/1088, train_loss: 0.0312\n",
      "658/1088, train_loss: 0.0306\n",
      "659/1088, train_loss: 0.0310\n",
      "660/1088, train_loss: 0.0300\n",
      "661/1088, train_loss: 0.0299\n",
      "662/1088, train_loss: 0.0305\n",
      "663/1088, train_loss: 0.0319\n",
      "664/1088, train_loss: 0.0299\n",
      "665/1088, train_loss: 0.0326\n",
      "666/1088, train_loss: 0.0321\n",
      "667/1088, train_loss: 0.0310\n",
      "668/1088, train_loss: 0.0332\n",
      "669/1088, train_loss: 0.0327\n",
      "670/1088, train_loss: 0.0326\n",
      "671/1088, train_loss: 0.0328\n",
      "672/1088, train_loss: 0.0289\n",
      "673/1088, train_loss: 0.0294\n",
      "674/1088, train_loss: 0.0327\n",
      "675/1088, train_loss: 0.0299\n",
      "676/1088, train_loss: 0.0330\n",
      "677/1088, train_loss: 0.0333\n",
      "678/1088, train_loss: 0.0297\n",
      "679/1088, train_loss: 0.0288\n",
      "680/1088, train_loss: 0.0312\n",
      "681/1088, train_loss: 0.0295\n",
      "682/1088, train_loss: 0.0293\n",
      "683/1088, train_loss: 0.0343\n",
      "684/1088, train_loss: 0.0336\n",
      "685/1088, train_loss: 0.0340\n",
      "686/1088, train_loss: 0.0336\n",
      "687/1088, train_loss: 0.0361\n",
      "688/1088, train_loss: 0.0317\n",
      "689/1088, train_loss: 0.0328\n",
      "690/1088, train_loss: 0.0345\n",
      "691/1088, train_loss: 0.0322\n",
      "692/1088, train_loss: 0.0302\n",
      "693/1088, train_loss: 0.0316\n",
      "694/1088, train_loss: 0.0306\n",
      "695/1088, train_loss: 0.0298\n",
      "696/1088, train_loss: 0.0300\n",
      "697/1088, train_loss: 0.0299\n",
      "698/1088, train_loss: 0.0352\n",
      "699/1088, train_loss: 0.0283\n",
      "700/1088, train_loss: 0.0297\n",
      "701/1088, train_loss: 0.0288\n",
      "702/1088, train_loss: 0.0294\n",
      "703/1088, train_loss: 0.0313\n",
      "704/1088, train_loss: 0.0315\n",
      "705/1088, train_loss: 0.0312\n",
      "706/1088, train_loss: 0.0357\n",
      "707/1088, train_loss: 0.0327\n",
      "708/1088, train_loss: 0.0313\n",
      "709/1088, train_loss: 0.0324\n",
      "710/1088, train_loss: 0.0326\n",
      "711/1088, train_loss: 0.0334\n",
      "712/1088, train_loss: 0.0343\n",
      "713/1088, train_loss: 0.0315\n",
      "714/1088, train_loss: 0.0328\n",
      "715/1088, train_loss: 0.0309\n",
      "716/1088, train_loss: 0.0307\n",
      "717/1088, train_loss: 0.0313\n",
      "718/1088, train_loss: 0.0297\n",
      "719/1088, train_loss: 0.0319\n",
      "720/1088, train_loss: 0.0324\n",
      "721/1088, train_loss: 0.0302\n",
      "722/1088, train_loss: 0.0299\n",
      "723/1088, train_loss: 0.0293\n",
      "724/1088, train_loss: 0.0326\n",
      "725/1088, train_loss: 0.0324\n",
      "726/1088, train_loss: 0.0302\n",
      "727/1088, train_loss: 0.0308\n",
      "728/1088, train_loss: 0.0349\n",
      "729/1088, train_loss: 0.0308\n",
      "730/1088, train_loss: 0.0325\n",
      "731/1088, train_loss: 0.0359\n",
      "732/1088, train_loss: 0.0291\n",
      "733/1088, train_loss: 0.0438\n",
      "734/1088, train_loss: 0.0316\n",
      "735/1088, train_loss: 0.0279\n",
      "736/1088, train_loss: 0.0297\n",
      "737/1088, train_loss: 0.0294\n",
      "738/1088, train_loss: 0.0312\n",
      "739/1088, train_loss: 0.0413\n",
      "740/1088, train_loss: 0.0301\n",
      "741/1088, train_loss: 0.0290\n",
      "742/1088, train_loss: 0.0301\n",
      "743/1088, train_loss: 0.0297\n",
      "744/1088, train_loss: 0.0323\n",
      "745/1088, train_loss: 0.0306\n",
      "746/1088, train_loss: 0.0338\n",
      "747/1088, train_loss: 0.0301\n",
      "748/1088, train_loss: 0.0300\n",
      "749/1088, train_loss: 0.0343\n",
      "750/1088, train_loss: 0.0295\n",
      "751/1088, train_loss: 0.0315\n",
      "752/1088, train_loss: 0.0345\n",
      "753/1088, train_loss: 0.0274\n",
      "754/1088, train_loss: 0.0324\n",
      "755/1088, train_loss: 0.0341\n",
      "756/1088, train_loss: 0.0307\n",
      "757/1088, train_loss: 0.0278\n",
      "758/1088, train_loss: 0.0309\n",
      "759/1088, train_loss: 0.0312\n",
      "760/1088, train_loss: 0.0283\n",
      "761/1088, train_loss: 0.0313\n",
      "762/1088, train_loss: 0.0325\n",
      "763/1088, train_loss: 0.0306\n",
      "764/1088, train_loss: 0.0319\n",
      "765/1088, train_loss: 0.0321\n",
      "766/1088, train_loss: 0.0274\n",
      "767/1088, train_loss: 0.0294\n",
      "768/1088, train_loss: 0.0302\n",
      "769/1088, train_loss: 0.0315\n",
      "770/1088, train_loss: 0.0316\n",
      "771/1088, train_loss: 0.0301\n",
      "772/1088, train_loss: 0.0301\n",
      "773/1088, train_loss: 0.0317\n",
      "774/1088, train_loss: 0.0300\n",
      "775/1088, train_loss: 0.0299\n",
      "776/1088, train_loss: 0.0293\n",
      "777/1088, train_loss: 0.0312\n",
      "778/1088, train_loss: 0.0288\n",
      "779/1088, train_loss: 0.0332\n",
      "780/1088, train_loss: 0.0300\n",
      "781/1088, train_loss: 0.0322\n",
      "782/1088, train_loss: 0.0295\n",
      "783/1088, train_loss: 0.0293\n",
      "784/1088, train_loss: 0.0340\n",
      "785/1088, train_loss: 0.0341\n",
      "786/1088, train_loss: 0.0303\n",
      "787/1088, train_loss: 0.0272\n",
      "788/1088, train_loss: 0.0372\n",
      "789/1088, train_loss: 0.0310\n",
      "790/1088, train_loss: 0.0314\n",
      "791/1088, train_loss: 0.0329\n",
      "792/1088, train_loss: 0.0294\n",
      "793/1088, train_loss: 0.0306\n",
      "794/1088, train_loss: 0.0274\n",
      "795/1088, train_loss: 0.0305\n",
      "796/1088, train_loss: 0.0303\n",
      "797/1088, train_loss: 0.0288\n",
      "798/1088, train_loss: 0.0299\n",
      "799/1088, train_loss: 0.0289\n",
      "800/1088, train_loss: 0.0280\n",
      "801/1088, train_loss: 0.0342\n",
      "802/1088, train_loss: 0.0324\n",
      "803/1088, train_loss: 0.0324\n",
      "804/1088, train_loss: 0.0330\n",
      "805/1088, train_loss: 0.0311\n",
      "806/1088, train_loss: 0.0307\n",
      "807/1088, train_loss: 0.0316\n",
      "808/1088, train_loss: 0.0292\n",
      "809/1088, train_loss: 0.0320\n",
      "810/1088, train_loss: 0.0419\n",
      "811/1088, train_loss: 0.0296\n",
      "812/1088, train_loss: 0.0317\n",
      "813/1088, train_loss: 0.0296\n",
      "814/1088, train_loss: 0.0312\n",
      "815/1088, train_loss: 0.0315\n",
      "816/1088, train_loss: 0.0314\n",
      "817/1088, train_loss: 0.0290\n",
      "818/1088, train_loss: 0.0333\n",
      "819/1088, train_loss: 0.0319\n",
      "820/1088, train_loss: 0.0322\n",
      "821/1088, train_loss: 0.0321\n",
      "822/1088, train_loss: 0.0312\n",
      "823/1088, train_loss: 0.0306\n",
      "824/1088, train_loss: 0.0304\n",
      "825/1088, train_loss: 0.0334\n",
      "826/1088, train_loss: 0.0311\n",
      "827/1088, train_loss: 0.0311\n",
      "828/1088, train_loss: 0.0380\n",
      "829/1088, train_loss: 0.0282\n",
      "830/1088, train_loss: 0.0292\n",
      "831/1088, train_loss: 0.0342\n",
      "832/1088, train_loss: 0.0359\n",
      "833/1088, train_loss: 0.0327\n",
      "834/1088, train_loss: 0.0304\n",
      "835/1088, train_loss: 0.0278\n",
      "836/1088, train_loss: 0.0369\n",
      "837/1088, train_loss: 0.0342\n",
      "838/1088, train_loss: 0.0308\n",
      "839/1088, train_loss: 0.0303\n",
      "840/1088, train_loss: 0.0297\n",
      "841/1088, train_loss: 0.0303\n",
      "842/1088, train_loss: 0.0330\n",
      "843/1088, train_loss: 0.0294\n",
      "844/1088, train_loss: 0.0332\n",
      "845/1088, train_loss: 0.0354\n",
      "846/1088, train_loss: 0.0316\n",
      "847/1088, train_loss: 0.0366\n",
      "848/1088, train_loss: 0.0316\n",
      "849/1088, train_loss: 0.0329\n",
      "850/1088, train_loss: 0.0312\n",
      "851/1088, train_loss: 0.0358\n",
      "852/1088, train_loss: 0.0361\n",
      "853/1088, train_loss: 0.0314\n",
      "854/1088, train_loss: 0.0297\n",
      "855/1088, train_loss: 0.0283\n",
      "856/1088, train_loss: 0.0316\n",
      "857/1088, train_loss: 0.0349\n",
      "858/1088, train_loss: 0.0332\n",
      "859/1088, train_loss: 0.0317\n",
      "860/1088, train_loss: 0.0314\n",
      "861/1088, train_loss: 0.0327\n",
      "862/1088, train_loss: 0.0298\n",
      "863/1088, train_loss: 0.0307\n",
      "864/1088, train_loss: 0.0301\n",
      "865/1088, train_loss: 0.0292\n",
      "866/1088, train_loss: 0.0319\n",
      "867/1088, train_loss: 0.0310\n",
      "868/1088, train_loss: 0.0310\n",
      "869/1088, train_loss: 0.0307\n",
      "870/1088, train_loss: 0.0319\n",
      "871/1088, train_loss: 0.0322\n",
      "872/1088, train_loss: 0.0298\n",
      "873/1088, train_loss: 0.0316\n",
      "874/1088, train_loss: 0.0300\n",
      "875/1088, train_loss: 0.0304\n",
      "876/1088, train_loss: 0.0281\n",
      "877/1088, train_loss: 0.0294\n",
      "878/1088, train_loss: 0.0430\n",
      "879/1088, train_loss: 0.0321\n",
      "880/1088, train_loss: 0.0286\n",
      "881/1088, train_loss: 0.0295\n",
      "882/1088, train_loss: 0.0312\n",
      "883/1088, train_loss: 0.0286\n",
      "884/1088, train_loss: 0.0296\n",
      "885/1088, train_loss: 0.0304\n",
      "886/1088, train_loss: 0.0305\n",
      "887/1088, train_loss: 0.0311\n",
      "888/1088, train_loss: 0.0294\n",
      "889/1088, train_loss: 0.0306\n",
      "890/1088, train_loss: 0.0298\n",
      "891/1088, train_loss: 0.0314\n",
      "892/1088, train_loss: 0.0300\n",
      "893/1088, train_loss: 0.0300\n",
      "894/1088, train_loss: 0.0310\n",
      "895/1088, train_loss: 0.0278\n",
      "896/1088, train_loss: 0.0287\n",
      "897/1088, train_loss: 0.0296\n",
      "898/1088, train_loss: 0.0283\n",
      "899/1088, train_loss: 0.0318\n",
      "900/1088, train_loss: 0.0294\n",
      "901/1088, train_loss: 0.0301\n",
      "902/1088, train_loss: 0.0308\n",
      "903/1088, train_loss: 0.0287\n",
      "904/1088, train_loss: 0.0316\n",
      "905/1088, train_loss: 0.0317\n",
      "906/1088, train_loss: 0.0326\n",
      "907/1088, train_loss: 0.0306\n",
      "908/1088, train_loss: 0.0317\n",
      "909/1088, train_loss: 0.0302\n",
      "910/1088, train_loss: 0.0313\n",
      "911/1088, train_loss: 0.0290\n",
      "912/1088, train_loss: 0.0295\n",
      "913/1088, train_loss: 0.0288\n",
      "914/1088, train_loss: 0.0293\n",
      "915/1088, train_loss: 0.0333\n",
      "916/1088, train_loss: 0.0303\n",
      "917/1088, train_loss: 0.0368\n",
      "918/1088, train_loss: 0.0311\n",
      "919/1088, train_loss: 0.0305\n",
      "920/1088, train_loss: 0.0308\n",
      "921/1088, train_loss: 0.0326\n",
      "922/1088, train_loss: 0.0296\n",
      "923/1088, train_loss: 0.0298\n",
      "924/1088, train_loss: 0.0296\n",
      "925/1088, train_loss: 0.0292\n",
      "926/1088, train_loss: 0.0288\n",
      "927/1088, train_loss: 0.0325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "928/1088, train_loss: 0.0352\n",
      "929/1088, train_loss: 0.0313\n",
      "930/1088, train_loss: 0.0308\n",
      "931/1088, train_loss: 0.0330\n",
      "932/1088, train_loss: 0.0295\n",
      "933/1088, train_loss: 0.0315\n",
      "934/1088, train_loss: 0.0339\n",
      "935/1088, train_loss: 0.0290\n",
      "936/1088, train_loss: 0.0334\n",
      "937/1088, train_loss: 0.0311\n",
      "938/1088, train_loss: 0.0321\n",
      "939/1088, train_loss: 0.0297\n",
      "940/1088, train_loss: 0.0310\n",
      "941/1088, train_loss: 0.0312\n",
      "942/1088, train_loss: 0.0292\n",
      "943/1088, train_loss: 0.0275\n",
      "944/1088, train_loss: 0.0302\n",
      "945/1088, train_loss: 0.0298\n",
      "946/1088, train_loss: 0.0278\n",
      "947/1088, train_loss: 0.0303\n",
      "948/1088, train_loss: 0.0346\n",
      "949/1088, train_loss: 0.0301\n",
      "950/1088, train_loss: 0.0323\n",
      "951/1088, train_loss: 0.0287\n",
      "952/1088, train_loss: 0.0343\n",
      "953/1088, train_loss: 0.0328\n",
      "954/1088, train_loss: 0.0449\n",
      "955/1088, train_loss: 0.0309\n",
      "956/1088, train_loss: 0.0271\n",
      "957/1088, train_loss: 0.0301\n",
      "958/1088, train_loss: 0.0301\n",
      "959/1088, train_loss: 0.0297\n",
      "960/1088, train_loss: 0.0280\n",
      "961/1088, train_loss: 0.0294\n",
      "962/1088, train_loss: 0.0307\n",
      "963/1088, train_loss: 0.0311\n",
      "964/1088, train_loss: 0.0286\n",
      "965/1088, train_loss: 0.0317\n",
      "966/1088, train_loss: 0.0304\n",
      "967/1088, train_loss: 0.0282\n",
      "968/1088, train_loss: 0.0326\n",
      "969/1088, train_loss: 0.0297\n",
      "970/1088, train_loss: 0.0315\n",
      "971/1088, train_loss: 0.0285\n",
      "972/1088, train_loss: 0.0294\n",
      "973/1088, train_loss: 0.0279\n",
      "974/1088, train_loss: 0.0271\n",
      "975/1088, train_loss: 0.0312\n",
      "976/1088, train_loss: 0.0293\n",
      "977/1088, train_loss: 0.0283\n",
      "978/1088, train_loss: 0.0302\n",
      "979/1088, train_loss: 0.0287\n",
      "980/1088, train_loss: 0.0296\n",
      "981/1088, train_loss: 0.0304\n",
      "982/1088, train_loss: 0.0347\n",
      "983/1088, train_loss: 0.0309\n",
      "984/1088, train_loss: 0.0287\n",
      "985/1088, train_loss: 0.0315\n",
      "986/1088, train_loss: 0.0334\n",
      "987/1088, train_loss: 0.0327\n",
      "988/1088, train_loss: 0.0321\n",
      "989/1088, train_loss: 0.0291\n",
      "990/1088, train_loss: 0.0305\n",
      "991/1088, train_loss: 0.0309\n",
      "992/1088, train_loss: 0.0296\n",
      "993/1088, train_loss: 0.0311\n",
      "994/1088, train_loss: 0.0313\n",
      "995/1088, train_loss: 0.0308\n",
      "996/1088, train_loss: 0.0312\n",
      "997/1088, train_loss: 0.0322\n",
      "998/1088, train_loss: 0.0330\n",
      "999/1088, train_loss: 0.0291\n",
      "1000/1088, train_loss: 0.0300\n",
      "1001/1088, train_loss: 0.0311\n",
      "1002/1088, train_loss: 0.0295\n",
      "1003/1088, train_loss: 0.0332\n",
      "1004/1088, train_loss: 0.0333\n",
      "1005/1088, train_loss: 0.0311\n",
      "1006/1088, train_loss: 0.0291\n",
      "1007/1088, train_loss: 0.0299\n",
      "1008/1088, train_loss: 0.0301\n",
      "1009/1088, train_loss: 0.0300\n",
      "1010/1088, train_loss: 0.0317\n",
      "1011/1088, train_loss: 0.0291\n",
      "1012/1088, train_loss: 0.0334\n",
      "1013/1088, train_loss: 0.0309\n",
      "1014/1088, train_loss: 0.0294\n",
      "1015/1088, train_loss: 0.0285\n",
      "1016/1088, train_loss: 0.0313\n",
      "1017/1088, train_loss: 0.0301\n",
      "1018/1088, train_loss: 0.0390\n",
      "1019/1088, train_loss: 0.0293\n",
      "1020/1088, train_loss: 0.0298\n",
      "1021/1088, train_loss: 0.0307\n",
      "1022/1088, train_loss: 0.0305\n",
      "1023/1088, train_loss: 0.0318\n",
      "1024/1088, train_loss: 0.0306\n",
      "1025/1088, train_loss: 0.0313\n",
      "1026/1088, train_loss: 0.0284\n",
      "1027/1088, train_loss: 0.0309\n",
      "1028/1088, train_loss: 0.0323\n",
      "1029/1088, train_loss: 0.0277\n",
      "1030/1088, train_loss: 0.0307\n",
      "1031/1088, train_loss: 0.0322\n",
      "1032/1088, train_loss: 0.0290\n",
      "1033/1088, train_loss: 0.0279\n",
      "1034/1088, train_loss: 0.0310\n",
      "1035/1088, train_loss: 0.0310\n",
      "1036/1088, train_loss: 0.0296\n",
      "1037/1088, train_loss: 0.0287\n",
      "1038/1088, train_loss: 0.0297\n",
      "1039/1088, train_loss: 0.0292\n",
      "1040/1088, train_loss: 0.0318\n",
      "1041/1088, train_loss: 0.0294\n",
      "1042/1088, train_loss: 0.0297\n",
      "1043/1088, train_loss: 0.0299\n",
      "1044/1088, train_loss: 0.0330\n",
      "1045/1088, train_loss: 0.0301\n",
      "1046/1088, train_loss: 0.0299\n",
      "1047/1088, train_loss: 0.0297\n",
      "1048/1088, train_loss: 0.0306\n",
      "1049/1088, train_loss: 0.0311\n",
      "1050/1088, train_loss: 0.0304\n",
      "1051/1088, train_loss: 0.0323\n",
      "1052/1088, train_loss: 0.0326\n",
      "1053/1088, train_loss: 0.0297\n",
      "1054/1088, train_loss: 0.0296\n",
      "1055/1088, train_loss: 0.0296\n",
      "1056/1088, train_loss: 0.0300\n",
      "1057/1088, train_loss: 0.0310\n",
      "1058/1088, train_loss: 0.0294\n",
      "1059/1088, train_loss: 0.0294\n",
      "1060/1088, train_loss: 0.0408\n",
      "1061/1088, train_loss: 0.0445\n",
      "1062/1088, train_loss: 0.0309\n",
      "1063/1088, train_loss: 0.0302\n",
      "1064/1088, train_loss: 0.0315\n",
      "1065/1088, train_loss: 0.0287\n",
      "1066/1088, train_loss: 0.0290\n",
      "1067/1088, train_loss: 0.0308\n",
      "1068/1088, train_loss: 0.0327\n",
      "1069/1088, train_loss: 0.0283\n",
      "1070/1088, train_loss: 0.0305\n",
      "1071/1088, train_loss: 0.0304\n",
      "1072/1088, train_loss: 0.0296\n",
      "1073/1088, train_loss: 0.0313\n",
      "1074/1088, train_loss: 0.0285\n",
      "1075/1088, train_loss: 0.0311\n",
      "1076/1088, train_loss: 0.0293\n",
      "1077/1088, train_loss: 0.0309\n",
      "1078/1088, train_loss: 0.0325\n",
      "1079/1088, train_loss: 0.0294\n",
      "1080/1088, train_loss: 0.0283\n",
      "1081/1088, train_loss: 0.0299\n",
      "1082/1088, train_loss: 0.0291\n",
      "1083/1088, train_loss: 0.0343\n",
      "1084/1088, train_loss: 0.0309\n",
      "1085/1088, train_loss: 0.0416\n",
      "1086/1088, train_loss: 0.0291\n",
      "1087/1088, train_loss: 0.0288\n",
      "1088/1088, train_loss: 0.0302\n",
      "1089/1088, train_loss: 0.0327\n",
      "epoch 4 average loss: 0.0319, train_dice: 0.9682\n",
      "epoch 4 average loss: 0.0319\n",
      "saved new best metric model\n",
      "current epoch: 4 current mean dice: 0.9669 best mean dice: 0.9669 at epoch 4\n",
      "--------------------------------------------------\n",
      "epoch 5/50\n",
      "1/1088, train_loss: 0.0273\n",
      "2/1088, train_loss: 0.0300\n",
      "3/1088, train_loss: 0.0280\n",
      "4/1088, train_loss: 0.0281\n",
      "5/1088, train_loss: 0.0320\n",
      "6/1088, train_loss: 0.0317\n",
      "7/1088, train_loss: 0.0284\n",
      "8/1088, train_loss: 0.0277\n",
      "9/1088, train_loss: 0.0309\n",
      "10/1088, train_loss: 0.0291\n",
      "11/1088, train_loss: 0.0308\n",
      "12/1088, train_loss: 0.0283\n",
      "13/1088, train_loss: 0.0385\n",
      "14/1088, train_loss: 0.0322\n",
      "15/1088, train_loss: 0.0314\n",
      "16/1088, train_loss: 0.0312\n",
      "17/1088, train_loss: 0.0313\n",
      "18/1088, train_loss: 0.0302\n",
      "19/1088, train_loss: 0.0318\n",
      "20/1088, train_loss: 0.0284\n",
      "21/1088, train_loss: 0.0317\n",
      "22/1088, train_loss: 0.0332\n",
      "23/1088, train_loss: 0.0279\n",
      "24/1088, train_loss: 0.0298\n",
      "25/1088, train_loss: 0.0296\n",
      "26/1088, train_loss: 0.0288\n",
      "27/1088, train_loss: 0.0299\n",
      "28/1088, train_loss: 0.0298\n",
      "29/1088, train_loss: 0.0305\n",
      "30/1088, train_loss: 0.0291\n",
      "31/1088, train_loss: 0.0292\n",
      "32/1088, train_loss: 0.0298\n",
      "33/1088, train_loss: 0.0304\n",
      "34/1088, train_loss: 0.0298\n",
      "35/1088, train_loss: 0.0270\n",
      "36/1088, train_loss: 0.0289\n",
      "37/1088, train_loss: 0.0300\n",
      "38/1088, train_loss: 0.0297\n",
      "39/1088, train_loss: 0.0308\n",
      "40/1088, train_loss: 0.0305\n",
      "41/1088, train_loss: 0.0305\n",
      "42/1088, train_loss: 0.0287\n",
      "43/1088, train_loss: 0.0334\n",
      "44/1088, train_loss: 0.0279\n",
      "45/1088, train_loss: 0.0299\n",
      "46/1088, train_loss: 0.0296\n",
      "47/1088, train_loss: 0.0295\n",
      "48/1088, train_loss: 0.0280\n",
      "49/1088, train_loss: 0.0308\n",
      "50/1088, train_loss: 0.0295\n",
      "51/1088, train_loss: 0.0334\n",
      "52/1088, train_loss: 0.0289\n",
      "53/1088, train_loss: 0.0290\n",
      "54/1088, train_loss: 0.0311\n",
      "55/1088, train_loss: 0.0310\n",
      "56/1088, train_loss: 0.0411\n",
      "57/1088, train_loss: 0.0284\n",
      "58/1088, train_loss: 0.0283\n",
      "59/1088, train_loss: 0.0306\n",
      "60/1088, train_loss: 0.0331\n",
      "61/1088, train_loss: 0.0312\n",
      "62/1088, train_loss: 0.0307\n",
      "63/1088, train_loss: 0.0301\n",
      "64/1088, train_loss: 0.0285\n",
      "65/1088, train_loss: 0.0315\n",
      "66/1088, train_loss: 0.0302\n",
      "67/1088, train_loss: 0.0292\n",
      "68/1088, train_loss: 0.0321\n",
      "69/1088, train_loss: 0.0286\n",
      "70/1088, train_loss: 0.0267\n",
      "71/1088, train_loss: 0.0310\n",
      "72/1088, train_loss: 0.0282\n",
      "73/1088, train_loss: 0.0298\n",
      "74/1088, train_loss: 0.0309\n",
      "75/1088, train_loss: 0.0292\n",
      "76/1088, train_loss: 0.0286\n",
      "77/1088, train_loss: 0.0307\n",
      "78/1088, train_loss: 0.0271\n",
      "79/1088, train_loss: 0.0285\n",
      "80/1088, train_loss: 0.0302\n",
      "81/1088, train_loss: 0.0310\n",
      "82/1088, train_loss: 0.0276\n",
      "83/1088, train_loss: 0.0292\n",
      "84/1088, train_loss: 0.0291\n",
      "85/1088, train_loss: 0.0293\n",
      "86/1088, train_loss: 0.0295\n",
      "87/1088, train_loss: 0.0286\n",
      "88/1088, train_loss: 0.0298\n",
      "89/1088, train_loss: 0.0288\n",
      "90/1088, train_loss: 0.0281\n",
      "91/1088, train_loss: 0.0328\n",
      "92/1088, train_loss: 0.0282\n",
      "93/1088, train_loss: 0.0328\n",
      "94/1088, train_loss: 0.0302\n",
      "95/1088, train_loss: 0.0290\n",
      "96/1088, train_loss: 0.0315\n",
      "97/1088, train_loss: 0.0289\n",
      "98/1088, train_loss: 0.0305\n",
      "99/1088, train_loss: 0.0288\n",
      "100/1088, train_loss: 0.0298\n",
      "101/1088, train_loss: 0.0303\n",
      "102/1088, train_loss: 0.0318\n",
      "103/1088, train_loss: 0.0275\n",
      "104/1088, train_loss: 0.0398\n",
      "105/1088, train_loss: 0.0285\n",
      "106/1088, train_loss: 0.0322\n",
      "107/1088, train_loss: 0.0271\n",
      "108/1088, train_loss: 0.0322\n",
      "109/1088, train_loss: 0.0310\n",
      "110/1088, train_loss: 0.0305\n",
      "111/1088, train_loss: 0.0317\n",
      "112/1088, train_loss: 0.0383\n",
      "113/1088, train_loss: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/1088, train_loss: 0.0320\n",
      "115/1088, train_loss: 0.0317\n",
      "116/1088, train_loss: 0.0300\n",
      "117/1088, train_loss: 0.0353\n",
      "118/1088, train_loss: 0.0305\n",
      "119/1088, train_loss: 0.0304\n",
      "120/1088, train_loss: 0.0320\n",
      "121/1088, train_loss: 0.0344\n",
      "122/1088, train_loss: 0.0291\n",
      "123/1088, train_loss: 0.0287\n",
      "124/1088, train_loss: 0.0276\n",
      "125/1088, train_loss: 0.0304\n",
      "126/1088, train_loss: 0.0294\n",
      "127/1088, train_loss: 0.0305\n",
      "128/1088, train_loss: 0.0287\n",
      "129/1088, train_loss: 0.0299\n",
      "130/1088, train_loss: 0.0312\n",
      "131/1088, train_loss: 0.0293\n",
      "132/1088, train_loss: 0.0300\n",
      "133/1088, train_loss: 0.0345\n",
      "134/1088, train_loss: 0.0317\n",
      "135/1088, train_loss: 0.0290\n",
      "136/1088, train_loss: 0.0312\n",
      "137/1088, train_loss: 0.0283\n",
      "138/1088, train_loss: 0.0279\n",
      "139/1088, train_loss: 0.0315\n",
      "140/1088, train_loss: 0.0315\n",
      "141/1088, train_loss: 0.0286\n",
      "142/1088, train_loss: 0.0309\n",
      "143/1088, train_loss: 0.0309\n",
      "144/1088, train_loss: 0.0296\n",
      "145/1088, train_loss: 0.0313\n",
      "146/1088, train_loss: 0.0289\n",
      "147/1088, train_loss: 0.0308\n",
      "148/1088, train_loss: 0.0355\n",
      "149/1088, train_loss: 0.0335\n",
      "150/1088, train_loss: 0.0301\n",
      "151/1088, train_loss: 0.0301\n",
      "152/1088, train_loss: 0.0295\n",
      "153/1088, train_loss: 0.0340\n",
      "154/1088, train_loss: 0.0315\n",
      "155/1088, train_loss: 0.0315\n",
      "156/1088, train_loss: 0.0311\n",
      "157/1088, train_loss: 0.0308\n",
      "158/1088, train_loss: 0.0310\n",
      "159/1088, train_loss: 0.0329\n",
      "160/1088, train_loss: 0.0311\n",
      "161/1088, train_loss: 0.0314\n",
      "162/1088, train_loss: 0.0334\n",
      "163/1088, train_loss: 0.0305\n",
      "164/1088, train_loss: 0.0282\n",
      "165/1088, train_loss: 0.0299\n",
      "166/1088, train_loss: 0.0298\n",
      "167/1088, train_loss: 0.0294\n",
      "168/1088, train_loss: 0.0312\n",
      "169/1088, train_loss: 0.0294\n",
      "170/1088, train_loss: 0.0293\n",
      "171/1088, train_loss: 0.0279\n",
      "172/1088, train_loss: 0.0309\n",
      "173/1088, train_loss: 0.0295\n",
      "174/1088, train_loss: 0.0293\n",
      "175/1088, train_loss: 0.0289\n",
      "176/1088, train_loss: 0.0384\n",
      "177/1088, train_loss: 0.0334\n",
      "178/1088, train_loss: 0.0306\n",
      "179/1088, train_loss: 0.0327\n",
      "180/1088, train_loss: 0.0312\n",
      "181/1088, train_loss: 0.0320\n",
      "182/1088, train_loss: 0.0321\n",
      "183/1088, train_loss: 0.0298\n",
      "184/1088, train_loss: 0.0331\n",
      "185/1088, train_loss: 0.0354\n",
      "186/1088, train_loss: 0.0301\n",
      "187/1088, train_loss: 0.0333\n",
      "188/1088, train_loss: 0.0310\n",
      "189/1088, train_loss: 0.0295\n",
      "190/1088, train_loss: 0.0327\n",
      "191/1088, train_loss: 0.0314\n",
      "192/1088, train_loss: 0.0298\n",
      "193/1088, train_loss: 0.0316\n",
      "194/1088, train_loss: 0.0296\n",
      "195/1088, train_loss: 0.0322\n",
      "196/1088, train_loss: 0.0291\n",
      "197/1088, train_loss: 0.0305\n",
      "198/1088, train_loss: 0.0304\n",
      "199/1088, train_loss: 0.0315\n",
      "200/1088, train_loss: 0.0321\n",
      "201/1088, train_loss: 0.0315\n",
      "202/1088, train_loss: 0.0296\n",
      "203/1088, train_loss: 0.0336\n",
      "204/1088, train_loss: 0.0289\n",
      "205/1088, train_loss: 0.0303\n",
      "206/1088, train_loss: 0.0288\n",
      "207/1088, train_loss: 0.0309\n",
      "208/1088, train_loss: 0.0317\n",
      "209/1088, train_loss: 0.0302\n",
      "210/1088, train_loss: 0.0313\n",
      "211/1088, train_loss: 0.0308\n",
      "212/1088, train_loss: 0.0307\n",
      "213/1088, train_loss: 0.0282\n",
      "214/1088, train_loss: 0.0298\n",
      "215/1088, train_loss: 0.0305\n",
      "216/1088, train_loss: 0.0310\n",
      "217/1088, train_loss: 0.0301\n",
      "218/1088, train_loss: 0.0298\n",
      "219/1088, train_loss: 0.0297\n",
      "220/1088, train_loss: 0.0296\n",
      "221/1088, train_loss: 0.0296\n",
      "222/1088, train_loss: 0.0303\n",
      "223/1088, train_loss: 0.0353\n",
      "224/1088, train_loss: 0.0302\n",
      "225/1088, train_loss: 0.0311\n",
      "226/1088, train_loss: 0.0309\n",
      "227/1088, train_loss: 0.0292\n",
      "228/1088, train_loss: 0.0273\n",
      "229/1088, train_loss: 0.0306\n",
      "230/1088, train_loss: 0.0299\n",
      "231/1088, train_loss: 0.0327\n",
      "232/1088, train_loss: 0.0305\n",
      "233/1088, train_loss: 0.0291\n",
      "234/1088, train_loss: 0.0321\n",
      "235/1088, train_loss: 0.0332\n",
      "236/1088, train_loss: 0.0286\n",
      "237/1088, train_loss: 0.0294\n",
      "238/1088, train_loss: 0.0309\n",
      "239/1088, train_loss: 0.0314\n",
      "240/1088, train_loss: 0.0284\n",
      "241/1088, train_loss: 0.0313\n",
      "242/1088, train_loss: 0.0309\n",
      "243/1088, train_loss: 0.0312\n",
      "244/1088, train_loss: 0.0315\n",
      "245/1088, train_loss: 0.0305\n",
      "246/1088, train_loss: 0.0294\n",
      "247/1088, train_loss: 0.0285\n",
      "248/1088, train_loss: 0.0295\n",
      "249/1088, train_loss: 0.0292\n",
      "250/1088, train_loss: 0.0336\n",
      "251/1088, train_loss: 0.0324\n",
      "252/1088, train_loss: 0.0294\n",
      "253/1088, train_loss: 0.0324\n",
      "254/1088, train_loss: 0.0318\n",
      "255/1088, train_loss: 0.0292\n",
      "256/1088, train_loss: 0.0319\n",
      "257/1088, train_loss: 0.0318\n",
      "258/1088, train_loss: 0.0336\n",
      "259/1088, train_loss: 0.0323\n",
      "260/1088, train_loss: 0.0317\n",
      "261/1088, train_loss: 0.0336\n",
      "262/1088, train_loss: 0.0313\n",
      "263/1088, train_loss: 0.0302\n",
      "264/1088, train_loss: 0.0305\n",
      "265/1088, train_loss: 0.0322\n",
      "266/1088, train_loss: 0.0307\n",
      "267/1088, train_loss: 0.0286\n",
      "268/1088, train_loss: 0.0270\n",
      "269/1088, train_loss: 0.0326\n",
      "270/1088, train_loss: 0.0289\n",
      "271/1088, train_loss: 0.0294\n",
      "272/1088, train_loss: 0.0283\n",
      "273/1088, train_loss: 0.0304\n",
      "274/1088, train_loss: 0.0442\n",
      "275/1088, train_loss: 0.0278\n",
      "276/1088, train_loss: 0.0332\n",
      "277/1088, train_loss: 0.0296\n",
      "278/1088, train_loss: 0.0305\n",
      "279/1088, train_loss: 0.0328\n",
      "280/1088, train_loss: 0.0289\n",
      "281/1088, train_loss: 0.0318\n",
      "282/1088, train_loss: 0.0281\n",
      "283/1088, train_loss: 0.0331\n",
      "284/1088, train_loss: 0.0321\n",
      "285/1088, train_loss: 0.0303\n",
      "286/1088, train_loss: 0.0308\n",
      "287/1088, train_loss: 0.0292\n",
      "288/1088, train_loss: 0.0305\n",
      "289/1088, train_loss: 0.0297\n",
      "290/1088, train_loss: 0.0302\n",
      "291/1088, train_loss: 0.0306\n",
      "292/1088, train_loss: 0.0288\n",
      "293/1088, train_loss: 0.0303\n",
      "294/1088, train_loss: 0.0293\n",
      "295/1088, train_loss: 0.0284\n",
      "296/1088, train_loss: 0.0309\n",
      "297/1088, train_loss: 0.0274\n",
      "298/1088, train_loss: 0.0306\n",
      "299/1088, train_loss: 0.0301\n",
      "300/1088, train_loss: 0.0330\n",
      "301/1088, train_loss: 0.0303\n",
      "302/1088, train_loss: 0.0303\n",
      "303/1088, train_loss: 0.0298\n",
      "304/1088, train_loss: 0.0297\n",
      "305/1088, train_loss: 0.0301\n",
      "306/1088, train_loss: 0.0313\n",
      "307/1088, train_loss: 0.0305\n",
      "308/1088, train_loss: 0.0294\n",
      "309/1088, train_loss: 0.0314\n",
      "310/1088, train_loss: 0.0308\n",
      "311/1088, train_loss: 0.0321\n",
      "312/1088, train_loss: 0.0293\n",
      "313/1088, train_loss: 0.0298\n",
      "314/1088, train_loss: 0.0301\n",
      "315/1088, train_loss: 0.0305\n",
      "316/1088, train_loss: 0.0356\n",
      "317/1088, train_loss: 0.0324\n",
      "318/1088, train_loss: 0.0287\n",
      "319/1088, train_loss: 0.0289\n",
      "320/1088, train_loss: 0.0297\n",
      "321/1088, train_loss: 0.0298\n",
      "322/1088, train_loss: 0.0303\n",
      "323/1088, train_loss: 0.0295\n",
      "324/1088, train_loss: 0.0294\n",
      "325/1088, train_loss: 0.0334\n",
      "326/1088, train_loss: 0.0281\n",
      "327/1088, train_loss: 0.0323\n",
      "328/1088, train_loss: 0.0377\n",
      "329/1088, train_loss: 0.0306\n",
      "330/1088, train_loss: 0.0331\n",
      "331/1088, train_loss: 0.0288\n",
      "332/1088, train_loss: 0.0321\n",
      "333/1088, train_loss: 0.0292\n",
      "334/1088, train_loss: 0.0315\n",
      "335/1088, train_loss: 0.0297\n",
      "336/1088, train_loss: 0.0321\n",
      "337/1088, train_loss: 0.0322\n",
      "338/1088, train_loss: 0.0322\n",
      "339/1088, train_loss: 0.0314\n",
      "340/1088, train_loss: 0.0336\n",
      "341/1088, train_loss: 0.0313\n",
      "342/1088, train_loss: 0.0309\n",
      "343/1088, train_loss: 0.0287\n",
      "344/1088, train_loss: 0.0323\n",
      "345/1088, train_loss: 0.0305\n",
      "346/1088, train_loss: 0.0304\n",
      "347/1088, train_loss: 0.0294\n",
      "348/1088, train_loss: 0.0277\n",
      "349/1088, train_loss: 0.0293\n",
      "350/1088, train_loss: 0.0295\n",
      "351/1088, train_loss: 0.0289\n",
      "352/1088, train_loss: 0.0300\n",
      "353/1088, train_loss: 0.0301\n",
      "354/1088, train_loss: 0.0292\n",
      "355/1088, train_loss: 0.0289\n",
      "356/1088, train_loss: 0.0295\n",
      "357/1088, train_loss: 0.0275\n",
      "358/1088, train_loss: 0.0304\n",
      "359/1088, train_loss: 0.0361\n",
      "360/1088, train_loss: 0.0327\n",
      "361/1088, train_loss: 0.0316\n",
      "362/1088, train_loss: 0.0349\n",
      "363/1088, train_loss: 0.0348\n",
      "364/1088, train_loss: 0.0314\n",
      "365/1088, train_loss: 0.0297\n",
      "366/1088, train_loss: 0.0327\n",
      "367/1088, train_loss: 0.0383\n",
      "368/1088, train_loss: 0.0284\n",
      "369/1088, train_loss: 0.0304\n",
      "370/1088, train_loss: 0.0326\n",
      "371/1088, train_loss: 0.0295\n",
      "372/1088, train_loss: 0.0304\n",
      "373/1088, train_loss: 0.0301\n",
      "374/1088, train_loss: 0.0307\n",
      "375/1088, train_loss: 0.0291\n",
      "376/1088, train_loss: 0.0288\n",
      "377/1088, train_loss: 0.0298\n",
      "378/1088, train_loss: 0.0306\n",
      "379/1088, train_loss: 0.0299\n",
      "380/1088, train_loss: 0.0339\n",
      "381/1088, train_loss: 0.0326\n",
      "382/1088, train_loss: 0.0291\n",
      "383/1088, train_loss: 0.0327\n",
      "384/1088, train_loss: 0.0334\n",
      "385/1088, train_loss: 0.0313\n",
      "386/1088, train_loss: 0.0284\n",
      "387/1088, train_loss: 0.0326\n",
      "388/1088, train_loss: 0.0289\n",
      "389/1088, train_loss: 0.0325\n",
      "390/1088, train_loss: 0.0302\n",
      "391/1088, train_loss: 0.0295\n",
      "392/1088, train_loss: 0.0317\n",
      "393/1088, train_loss: 0.0297\n",
      "394/1088, train_loss: 0.0309\n",
      "395/1088, train_loss: 0.0306\n",
      "396/1088, train_loss: 0.0304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/1088, train_loss: 0.0288\n",
      "398/1088, train_loss: 0.0295\n",
      "399/1088, train_loss: 0.0303\n",
      "400/1088, train_loss: 0.0316\n",
      "401/1088, train_loss: 0.0285\n",
      "402/1088, train_loss: 0.0298\n",
      "403/1088, train_loss: 0.0346\n",
      "404/1088, train_loss: 0.0308\n",
      "405/1088, train_loss: 0.0277\n",
      "406/1088, train_loss: 0.0309\n",
      "407/1088, train_loss: 0.0296\n",
      "408/1088, train_loss: 0.0316\n",
      "409/1088, train_loss: 0.0330\n",
      "410/1088, train_loss: 0.0305\n",
      "411/1088, train_loss: 0.0325\n",
      "412/1088, train_loss: 0.0313\n",
      "413/1088, train_loss: 0.0309\n",
      "414/1088, train_loss: 0.0300\n",
      "415/1088, train_loss: 0.0328\n",
      "416/1088, train_loss: 0.0319\n",
      "417/1088, train_loss: 0.0318\n",
      "418/1088, train_loss: 0.0315\n",
      "419/1088, train_loss: 0.0299\n",
      "420/1088, train_loss: 0.0296\n",
      "421/1088, train_loss: 0.0313\n",
      "422/1088, train_loss: 0.0361\n",
      "423/1088, train_loss: 0.0303\n",
      "424/1088, train_loss: 0.0295\n",
      "425/1088, train_loss: 0.0308\n",
      "426/1088, train_loss: 0.0320\n",
      "427/1088, train_loss: 0.0293\n",
      "428/1088, train_loss: 0.0317\n",
      "429/1088, train_loss: 0.0317\n",
      "430/1088, train_loss: 0.0311\n",
      "431/1088, train_loss: 0.0299\n",
      "432/1088, train_loss: 0.0324\n",
      "433/1088, train_loss: 0.0278\n",
      "434/1088, train_loss: 0.0279\n",
      "435/1088, train_loss: 0.0298\n",
      "436/1088, train_loss: 0.0320\n",
      "437/1088, train_loss: 0.0322\n",
      "438/1088, train_loss: 0.0268\n",
      "439/1088, train_loss: 0.0314\n",
      "440/1088, train_loss: 0.0321\n",
      "441/1088, train_loss: 0.0299\n",
      "442/1088, train_loss: 0.0302\n",
      "443/1088, train_loss: 0.0309\n",
      "444/1088, train_loss: 0.0284\n",
      "445/1088, train_loss: 0.0300\n",
      "446/1088, train_loss: 0.0299\n",
      "447/1088, train_loss: 0.0295\n",
      "448/1088, train_loss: 0.0337\n",
      "449/1088, train_loss: 0.0317\n",
      "450/1088, train_loss: 0.0289\n",
      "451/1088, train_loss: 0.0293\n",
      "452/1088, train_loss: 0.0274\n",
      "453/1088, train_loss: 0.0298\n",
      "454/1088, train_loss: 0.0293\n",
      "455/1088, train_loss: 0.0313\n",
      "456/1088, train_loss: 0.0302\n",
      "457/1088, train_loss: 0.0304\n",
      "458/1088, train_loss: 0.0361\n",
      "459/1088, train_loss: 0.0360\n",
      "460/1088, train_loss: 0.0286\n",
      "461/1088, train_loss: 0.0300\n",
      "462/1088, train_loss: 0.0302\n",
      "463/1088, train_loss: 0.0297\n",
      "464/1088, train_loss: 0.0316\n",
      "465/1088, train_loss: 0.0297\n",
      "466/1088, train_loss: 0.0305\n",
      "467/1088, train_loss: 0.0304\n",
      "468/1088, train_loss: 0.0287\n",
      "469/1088, train_loss: 0.0294\n",
      "470/1088, train_loss: 0.0289\n",
      "471/1088, train_loss: 0.0284\n",
      "472/1088, train_loss: 0.0302\n",
      "473/1088, train_loss: 0.0302\n",
      "474/1088, train_loss: 0.0326\n",
      "475/1088, train_loss: 0.0337\n",
      "476/1088, train_loss: 0.0286\n",
      "477/1088, train_loss: 0.0295\n",
      "478/1088, train_loss: 0.0277\n",
      "479/1088, train_loss: 0.0334\n",
      "480/1088, train_loss: 0.0309\n",
      "481/1088, train_loss: 0.0291\n",
      "482/1088, train_loss: 0.0315\n",
      "483/1088, train_loss: 0.0323\n",
      "484/1088, train_loss: 0.0299\n",
      "485/1088, train_loss: 0.0309\n",
      "486/1088, train_loss: 0.0271\n",
      "487/1088, train_loss: 0.0326\n",
      "488/1088, train_loss: 0.0283\n",
      "489/1088, train_loss: 0.0293\n",
      "490/1088, train_loss: 0.0294\n",
      "491/1088, train_loss: 0.0312\n",
      "492/1088, train_loss: 0.0291\n",
      "493/1088, train_loss: 0.0289\n",
      "494/1088, train_loss: 0.0304\n",
      "495/1088, train_loss: 0.0284\n",
      "496/1088, train_loss: 0.0308\n",
      "497/1088, train_loss: 0.0296\n",
      "498/1088, train_loss: 0.0298\n",
      "499/1088, train_loss: 0.0302\n",
      "500/1088, train_loss: 0.0322\n",
      "501/1088, train_loss: 0.0309\n",
      "502/1088, train_loss: 0.0301\n",
      "503/1088, train_loss: 0.0304\n",
      "504/1088, train_loss: 0.0287\n",
      "505/1088, train_loss: 0.0319\n",
      "506/1088, train_loss: 0.0312\n",
      "507/1088, train_loss: 0.0307\n",
      "508/1088, train_loss: 0.0327\n",
      "509/1088, train_loss: 0.0314\n",
      "510/1088, train_loss: 0.0281\n",
      "511/1088, train_loss: 0.0282\n",
      "512/1088, train_loss: 0.0281\n",
      "513/1088, train_loss: 0.0316\n",
      "514/1088, train_loss: 0.0316\n",
      "515/1088, train_loss: 0.0307\n",
      "516/1088, train_loss: 0.0294\n",
      "517/1088, train_loss: 0.0303\n",
      "518/1088, train_loss: 0.0300\n",
      "519/1088, train_loss: 0.0315\n",
      "520/1088, train_loss: 0.0328\n",
      "521/1088, train_loss: 0.0309\n",
      "522/1088, train_loss: 0.0287\n",
      "523/1088, train_loss: 0.0290\n",
      "524/1088, train_loss: 0.0293\n",
      "525/1088, train_loss: 0.0290\n",
      "526/1088, train_loss: 0.0317\n",
      "527/1088, train_loss: 0.0310\n",
      "528/1088, train_loss: 0.0294\n",
      "529/1088, train_loss: 0.0308\n",
      "530/1088, train_loss: 0.0286\n",
      "531/1088, train_loss: 0.0293\n",
      "532/1088, train_loss: 0.0303\n",
      "533/1088, train_loss: 0.0297\n",
      "534/1088, train_loss: 0.0281\n",
      "535/1088, train_loss: 0.0303\n",
      "536/1088, train_loss: 0.0290\n",
      "537/1088, train_loss: 0.0287\n",
      "538/1088, train_loss: 0.0273\n",
      "539/1088, train_loss: 0.0280\n",
      "540/1088, train_loss: 0.0283\n",
      "541/1088, train_loss: 0.0280\n",
      "542/1088, train_loss: 0.0288\n",
      "543/1088, train_loss: 0.0352\n",
      "544/1088, train_loss: 0.0313\n",
      "545/1088, train_loss: 0.0293\n",
      "546/1088, train_loss: 0.0307\n",
      "547/1088, train_loss: 0.0306\n",
      "548/1088, train_loss: 0.0302\n",
      "549/1088, train_loss: 0.0292\n",
      "550/1088, train_loss: 0.0309\n",
      "551/1088, train_loss: 0.0310\n",
      "552/1088, train_loss: 0.0286\n",
      "553/1088, train_loss: 0.0293\n",
      "554/1088, train_loss: 0.0288\n",
      "555/1088, train_loss: 0.0304\n",
      "556/1088, train_loss: 0.0297\n",
      "557/1088, train_loss: 0.0294\n",
      "558/1088, train_loss: 0.0290\n",
      "559/1088, train_loss: 0.0357\n",
      "560/1088, train_loss: 0.0290\n",
      "561/1088, train_loss: 0.0321\n",
      "562/1088, train_loss: 0.0299\n",
      "563/1088, train_loss: 0.0328\n",
      "564/1088, train_loss: 0.0295\n",
      "565/1088, train_loss: 0.0333\n",
      "566/1088, train_loss: 0.0299\n",
      "567/1088, train_loss: 0.0305\n",
      "568/1088, train_loss: 0.0305\n",
      "569/1088, train_loss: 0.0353\n",
      "570/1088, train_loss: 0.0307\n",
      "571/1088, train_loss: 0.0329\n",
      "572/1088, train_loss: 0.0298\n",
      "573/1088, train_loss: 0.0318\n",
      "574/1088, train_loss: 0.0299\n",
      "575/1088, train_loss: 0.0294\n",
      "576/1088, train_loss: 0.0294\n",
      "577/1088, train_loss: 0.0294\n",
      "578/1088, train_loss: 0.0284\n",
      "579/1088, train_loss: 0.0387\n",
      "580/1088, train_loss: 0.0298\n",
      "581/1088, train_loss: 0.0308\n",
      "582/1088, train_loss: 0.0290\n",
      "583/1088, train_loss: 0.0312\n",
      "584/1088, train_loss: 0.0323\n",
      "585/1088, train_loss: 0.0317\n",
      "586/1088, train_loss: 0.0292\n",
      "587/1088, train_loss: 0.0303\n",
      "588/1088, train_loss: 0.0346\n",
      "589/1088, train_loss: 0.0308\n",
      "590/1088, train_loss: 0.0287\n",
      "591/1088, train_loss: 0.0286\n",
      "592/1088, train_loss: 0.0328\n",
      "593/1088, train_loss: 0.0351\n",
      "594/1088, train_loss: 0.0290\n",
      "595/1088, train_loss: 0.0302\n",
      "596/1088, train_loss: 0.0317\n",
      "597/1088, train_loss: 0.0287\n",
      "598/1088, train_loss: 0.0302\n",
      "599/1088, train_loss: 0.0319\n",
      "600/1088, train_loss: 0.0320\n",
      "601/1088, train_loss: 0.0298\n",
      "602/1088, train_loss: 0.0332\n",
      "603/1088, train_loss: 0.0293\n",
      "604/1088, train_loss: 0.0282\n",
      "605/1088, train_loss: 0.0301\n",
      "606/1088, train_loss: 0.0269\n",
      "607/1088, train_loss: 0.0291\n",
      "608/1088, train_loss: 0.0293\n",
      "609/1088, train_loss: 0.0284\n",
      "610/1088, train_loss: 0.0304\n",
      "611/1088, train_loss: 0.0316\n",
      "612/1088, train_loss: 0.0298\n",
      "613/1088, train_loss: 0.0327\n",
      "614/1088, train_loss: 0.0326\n",
      "615/1088, train_loss: 0.0323\n",
      "616/1088, train_loss: 0.0299\n",
      "617/1088, train_loss: 0.0314\n",
      "618/1088, train_loss: 0.0277\n",
      "619/1088, train_loss: 0.0309\n",
      "620/1088, train_loss: 0.0300\n",
      "621/1088, train_loss: 0.0314\n",
      "622/1088, train_loss: 0.0317\n",
      "623/1088, train_loss: 0.0297\n",
      "624/1088, train_loss: 0.0307\n",
      "625/1088, train_loss: 0.0295\n",
      "626/1088, train_loss: 0.0284\n",
      "627/1088, train_loss: 0.0284\n",
      "628/1088, train_loss: 0.0259\n",
      "629/1088, train_loss: 0.0300\n",
      "630/1088, train_loss: 0.0289\n",
      "631/1088, train_loss: 0.0284\n",
      "632/1088, train_loss: 0.0302\n",
      "633/1088, train_loss: 0.0287\n",
      "634/1088, train_loss: 0.0299\n",
      "635/1088, train_loss: 0.0313\n",
      "636/1088, train_loss: 0.0305\n",
      "637/1088, train_loss: 0.0305\n",
      "638/1088, train_loss: 0.0317\n",
      "639/1088, train_loss: 0.0291\n",
      "640/1088, train_loss: 0.0331\n",
      "641/1088, train_loss: 0.0295\n",
      "642/1088, train_loss: 0.0325\n",
      "643/1088, train_loss: 0.0279\n",
      "644/1088, train_loss: 0.0286\n",
      "645/1088, train_loss: 0.0304\n",
      "646/1088, train_loss: 0.0300\n",
      "647/1088, train_loss: 0.0324\n",
      "648/1088, train_loss: 0.0319\n",
      "649/1088, train_loss: 0.0346\n",
      "650/1088, train_loss: 0.0395\n",
      "651/1088, train_loss: 0.0297\n",
      "652/1088, train_loss: 0.0294\n",
      "653/1088, train_loss: 0.0311\n",
      "654/1088, train_loss: 0.0292\n",
      "655/1088, train_loss: 0.0285\n",
      "656/1088, train_loss: 0.0295\n",
      "657/1088, train_loss: 0.0288\n",
      "658/1088, train_loss: 0.0326\n",
      "659/1088, train_loss: 0.0303\n",
      "660/1088, train_loss: 0.0322\n",
      "661/1088, train_loss: 0.0312\n",
      "662/1088, train_loss: 0.0288\n",
      "663/1088, train_loss: 0.0272\n",
      "664/1088, train_loss: 0.0275\n",
      "665/1088, train_loss: 0.0304\n",
      "666/1088, train_loss: 0.0287\n",
      "667/1088, train_loss: 0.0332\n",
      "668/1088, train_loss: 0.0316\n",
      "669/1088, train_loss: 0.0296\n",
      "670/1088, train_loss: 0.0298\n",
      "671/1088, train_loss: 0.0300\n",
      "672/1088, train_loss: 0.0286\n",
      "673/1088, train_loss: 0.0308\n",
      "674/1088, train_loss: 0.0278\n",
      "675/1088, train_loss: 0.0309\n",
      "676/1088, train_loss: 0.0277\n",
      "677/1088, train_loss: 0.0318\n",
      "678/1088, train_loss: 0.0308\n",
      "679/1088, train_loss: 0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680/1088, train_loss: 0.0302\n",
      "681/1088, train_loss: 0.0289\n",
      "682/1088, train_loss: 0.0301\n",
      "683/1088, train_loss: 0.0316\n",
      "684/1088, train_loss: 0.0312\n",
      "685/1088, train_loss: 0.0305\n",
      "686/1088, train_loss: 0.0314\n",
      "687/1088, train_loss: 0.0312\n",
      "688/1088, train_loss: 0.0335\n",
      "689/1088, train_loss: 0.0312\n",
      "690/1088, train_loss: 0.0285\n",
      "691/1088, train_loss: 0.0301\n",
      "692/1088, train_loss: 0.0305\n",
      "693/1088, train_loss: 0.0351\n",
      "694/1088, train_loss: 0.0284\n",
      "695/1088, train_loss: 0.0300\n",
      "696/1088, train_loss: 0.0315\n",
      "697/1088, train_loss: 0.0307\n",
      "698/1088, train_loss: 0.0292\n",
      "699/1088, train_loss: 0.0296\n",
      "700/1088, train_loss: 0.0304\n",
      "701/1088, train_loss: 0.0278\n",
      "702/1088, train_loss: 0.0313\n",
      "703/1088, train_loss: 0.0329\n",
      "704/1088, train_loss: 0.0298\n",
      "705/1088, train_loss: 0.0353\n",
      "706/1088, train_loss: 0.0306\n",
      "707/1088, train_loss: 0.0310\n",
      "708/1088, train_loss: 0.0301\n",
      "709/1088, train_loss: 0.0312\n",
      "710/1088, train_loss: 0.0348\n",
      "711/1088, train_loss: 0.0308\n",
      "712/1088, train_loss: 0.0343\n",
      "713/1088, train_loss: 0.0276\n",
      "714/1088, train_loss: 0.0268\n",
      "715/1088, train_loss: 0.0295\n",
      "716/1088, train_loss: 0.0323\n",
      "717/1088, train_loss: 0.0331\n",
      "718/1088, train_loss: 0.0309\n",
      "719/1088, train_loss: 0.0298\n",
      "720/1088, train_loss: 0.0310\n",
      "721/1088, train_loss: 0.0293\n",
      "722/1088, train_loss: 0.0342\n",
      "723/1088, train_loss: 0.0308\n",
      "724/1088, train_loss: 0.0306\n",
      "725/1088, train_loss: 0.0314\n",
      "726/1088, train_loss: 0.0314\n",
      "727/1088, train_loss: 0.0335\n",
      "728/1088, train_loss: 0.0352\n",
      "729/1088, train_loss: 0.0306\n",
      "730/1088, train_loss: 0.0333\n",
      "731/1088, train_loss: 0.0307\n",
      "732/1088, train_loss: 0.0308\n",
      "733/1088, train_loss: 0.0284\n",
      "734/1088, train_loss: 0.0292\n",
      "735/1088, train_loss: 0.0328\n",
      "736/1088, train_loss: 0.0294\n",
      "737/1088, train_loss: 0.0312\n",
      "738/1088, train_loss: 0.0289\n",
      "739/1088, train_loss: 0.0324\n",
      "740/1088, train_loss: 0.0317\n",
      "741/1088, train_loss: 0.0307\n",
      "742/1088, train_loss: 0.0303\n",
      "743/1088, train_loss: 0.0315\n",
      "744/1088, train_loss: 0.0334\n",
      "745/1088, train_loss: 0.0287\n",
      "746/1088, train_loss: 0.0297\n",
      "747/1088, train_loss: 0.0310\n",
      "748/1088, train_loss: 0.0309\n",
      "749/1088, train_loss: 0.0287\n",
      "750/1088, train_loss: 0.0296\n",
      "751/1088, train_loss: 0.0288\n",
      "752/1088, train_loss: 0.0305\n",
      "753/1088, train_loss: 0.0288\n",
      "754/1088, train_loss: 0.0318\n",
      "755/1088, train_loss: 0.0301\n",
      "756/1088, train_loss: 0.0295\n",
      "757/1088, train_loss: 0.0288\n",
      "758/1088, train_loss: 0.0281\n",
      "759/1088, train_loss: 0.0277\n",
      "760/1088, train_loss: 0.0303\n",
      "761/1088, train_loss: 0.0319\n",
      "762/1088, train_loss: 0.0302\n",
      "763/1088, train_loss: 0.0278\n",
      "764/1088, train_loss: 0.0270\n",
      "765/1088, train_loss: 0.0311\n",
      "766/1088, train_loss: 0.0325\n",
      "767/1088, train_loss: 0.0328\n",
      "768/1088, train_loss: 0.0305\n",
      "769/1088, train_loss: 0.0329\n",
      "770/1088, train_loss: 0.0292\n",
      "771/1088, train_loss: 0.0307\n",
      "772/1088, train_loss: 0.0304\n",
      "773/1088, train_loss: 0.0319\n",
      "774/1088, train_loss: 0.0286\n",
      "775/1088, train_loss: 0.0285\n",
      "776/1088, train_loss: 0.0300\n",
      "777/1088, train_loss: 0.0281\n",
      "778/1088, train_loss: 0.0298\n",
      "779/1088, train_loss: 0.0322\n",
      "780/1088, train_loss: 0.0394\n",
      "781/1088, train_loss: 0.0287\n",
      "782/1088, train_loss: 0.0318\n",
      "783/1088, train_loss: 0.0304\n",
      "784/1088, train_loss: 0.0329\n",
      "785/1088, train_loss: 0.0286\n",
      "786/1088, train_loss: 0.0312\n",
      "787/1088, train_loss: 0.0299\n",
      "788/1088, train_loss: 0.0321\n",
      "789/1088, train_loss: 0.0291\n",
      "790/1088, train_loss: 0.0308\n",
      "791/1088, train_loss: 0.0308\n",
      "792/1088, train_loss: 0.0307\n",
      "793/1088, train_loss: 0.0282\n",
      "794/1088, train_loss: 0.0318\n",
      "795/1088, train_loss: 0.0299\n",
      "796/1088, train_loss: 0.0356\n",
      "797/1088, train_loss: 0.0295\n",
      "798/1088, train_loss: 0.0320\n",
      "799/1088, train_loss: 0.0458\n",
      "800/1088, train_loss: 0.0306\n",
      "801/1088, train_loss: 0.0311\n",
      "802/1088, train_loss: 0.0326\n",
      "803/1088, train_loss: 0.0338\n",
      "804/1088, train_loss: 0.0319\n",
      "805/1088, train_loss: 0.0302\n",
      "806/1088, train_loss: 0.0275\n",
      "807/1088, train_loss: 0.0277\n",
      "808/1088, train_loss: 0.0284\n",
      "809/1088, train_loss: 0.0302\n",
      "810/1088, train_loss: 0.0320\n",
      "811/1088, train_loss: 0.0323\n",
      "812/1088, train_loss: 0.0334\n",
      "813/1088, train_loss: 0.0301\n",
      "814/1088, train_loss: 0.0293\n",
      "815/1088, train_loss: 0.0299\n",
      "816/1088, train_loss: 0.0308\n",
      "817/1088, train_loss: 0.0298\n",
      "818/1088, train_loss: 0.0297\n",
      "819/1088, train_loss: 0.0292\n",
      "820/1088, train_loss: 0.0319\n",
      "821/1088, train_loss: 0.0284\n",
      "822/1088, train_loss: 0.0346\n",
      "823/1088, train_loss: 0.0341\n",
      "824/1088, train_loss: 0.0277\n",
      "825/1088, train_loss: 0.0283\n",
      "826/1088, train_loss: 0.0312\n",
      "827/1088, train_loss: 0.0346\n",
      "828/1088, train_loss: 0.0283\n",
      "829/1088, train_loss: 0.0327\n",
      "830/1088, train_loss: 0.0303\n",
      "831/1088, train_loss: 0.0307\n",
      "832/1088, train_loss: 0.0317\n",
      "833/1088, train_loss: 0.0324\n",
      "834/1088, train_loss: 0.0325\n",
      "835/1088, train_loss: 0.0306\n",
      "836/1088, train_loss: 0.0303\n",
      "837/1088, train_loss: 0.0298\n",
      "838/1088, train_loss: 0.0319\n",
      "839/1088, train_loss: 0.0307\n",
      "840/1088, train_loss: 0.0291\n",
      "841/1088, train_loss: 0.0295\n",
      "842/1088, train_loss: 0.0323\n",
      "843/1088, train_loss: 0.0313\n",
      "844/1088, train_loss: 0.0328\n",
      "845/1088, train_loss: 0.0311\n",
      "846/1088, train_loss: 0.0317\n",
      "847/1088, train_loss: 0.0312\n",
      "848/1088, train_loss: 0.0296\n",
      "849/1088, train_loss: 0.0306\n",
      "850/1088, train_loss: 0.0320\n",
      "851/1088, train_loss: 0.0325\n",
      "852/1088, train_loss: 0.0280\n",
      "853/1088, train_loss: 0.0313\n",
      "854/1088, train_loss: 0.0323\n",
      "855/1088, train_loss: 0.0281\n",
      "856/1088, train_loss: 0.0297\n",
      "857/1088, train_loss: 0.0293\n",
      "858/1088, train_loss: 0.0301\n",
      "859/1088, train_loss: 0.0319\n",
      "860/1088, train_loss: 0.0279\n",
      "861/1088, train_loss: 0.0311\n",
      "862/1088, train_loss: 0.0286\n",
      "863/1088, train_loss: 0.0291\n",
      "864/1088, train_loss: 0.0306\n",
      "865/1088, train_loss: 0.0288\n",
      "866/1088, train_loss: 0.0342\n",
      "867/1088, train_loss: 0.0309\n",
      "868/1088, train_loss: 0.0307\n",
      "869/1088, train_loss: 0.0287\n",
      "870/1088, train_loss: 0.0326\n",
      "871/1088, train_loss: 0.0325\n",
      "872/1088, train_loss: 0.0284\n",
      "873/1088, train_loss: 0.0279\n",
      "874/1088, train_loss: 0.0311\n",
      "875/1088, train_loss: 0.0310\n",
      "876/1088, train_loss: 0.0306\n",
      "877/1088, train_loss: 0.0302\n",
      "878/1088, train_loss: 0.0327\n",
      "879/1088, train_loss: 0.0282\n",
      "880/1088, train_loss: 0.0294\n",
      "881/1088, train_loss: 0.0297\n",
      "882/1088, train_loss: 0.0316\n",
      "883/1088, train_loss: 0.0305\n",
      "884/1088, train_loss: 0.0333\n",
      "885/1088, train_loss: 0.0304\n",
      "886/1088, train_loss: 0.0347\n",
      "887/1088, train_loss: 0.0325\n",
      "888/1088, train_loss: 0.0304\n",
      "889/1088, train_loss: 0.0314\n",
      "890/1088, train_loss: 0.0316\n",
      "891/1088, train_loss: 0.0273\n",
      "892/1088, train_loss: 0.0295\n",
      "893/1088, train_loss: 0.0291\n",
      "894/1088, train_loss: 0.0309\n",
      "895/1088, train_loss: 0.0338\n",
      "896/1088, train_loss: 0.0281\n",
      "897/1088, train_loss: 0.0301\n",
      "898/1088, train_loss: 0.0323\n",
      "899/1088, train_loss: 0.0305\n",
      "900/1088, train_loss: 0.0294\n",
      "901/1088, train_loss: 0.0321\n",
      "902/1088, train_loss: 0.0302\n",
      "903/1088, train_loss: 0.0284\n",
      "904/1088, train_loss: 0.0321\n",
      "905/1088, train_loss: 0.0316\n",
      "906/1088, train_loss: 0.0338\n",
      "907/1088, train_loss: 0.0289\n",
      "908/1088, train_loss: 0.0364\n",
      "909/1088, train_loss: 0.0291\n",
      "910/1088, train_loss: 0.0315\n",
      "911/1088, train_loss: 0.0303\n",
      "912/1088, train_loss: 0.0309\n",
      "913/1088, train_loss: 0.0300\n",
      "914/1088, train_loss: 0.0306\n",
      "915/1088, train_loss: 0.0306\n",
      "916/1088, train_loss: 0.0303\n",
      "917/1088, train_loss: 0.0267\n",
      "918/1088, train_loss: 0.0286\n",
      "919/1088, train_loss: 0.0312\n",
      "920/1088, train_loss: 0.0316\n",
      "921/1088, train_loss: 0.0287\n",
      "922/1088, train_loss: 0.0302\n",
      "923/1088, train_loss: 0.0275\n",
      "924/1088, train_loss: 0.0288\n",
      "925/1088, train_loss: 0.0295\n",
      "926/1088, train_loss: 0.0299\n",
      "927/1088, train_loss: 0.0304\n",
      "928/1088, train_loss: 0.0313\n",
      "929/1088, train_loss: 0.0301\n",
      "930/1088, train_loss: 0.0305\n",
      "931/1088, train_loss: 0.0289\n",
      "932/1088, train_loss: 0.0310\n",
      "933/1088, train_loss: 0.0310\n",
      "934/1088, train_loss: 0.0369\n",
      "935/1088, train_loss: 0.0291\n",
      "936/1088, train_loss: 0.0330\n",
      "937/1088, train_loss: 0.0312\n",
      "938/1088, train_loss: 0.0295\n",
      "939/1088, train_loss: 0.0279\n",
      "940/1088, train_loss: 0.0291\n",
      "941/1088, train_loss: 0.0285\n",
      "942/1088, train_loss: 0.0330\n",
      "943/1088, train_loss: 0.0297\n",
      "944/1088, train_loss: 0.0310\n",
      "945/1088, train_loss: 0.0291\n",
      "946/1088, train_loss: 0.0337\n",
      "947/1088, train_loss: 0.0300\n",
      "948/1088, train_loss: 0.0320\n",
      "949/1088, train_loss: 0.0318\n",
      "950/1088, train_loss: 0.0320\n",
      "951/1088, train_loss: 0.0295\n",
      "952/1088, train_loss: 0.0322\n",
      "953/1088, train_loss: 0.0284\n",
      "954/1088, train_loss: 0.0303\n",
      "955/1088, train_loss: 0.0309\n",
      "956/1088, train_loss: 0.0280\n",
      "957/1088, train_loss: 0.0308\n",
      "958/1088, train_loss: 0.0338\n",
      "959/1088, train_loss: 0.0337\n",
      "960/1088, train_loss: 0.0324\n",
      "961/1088, train_loss: 0.0303\n",
      "962/1088, train_loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "963/1088, train_loss: 0.0298\n",
      "964/1088, train_loss: 0.0309\n",
      "965/1088, train_loss: 0.0300\n",
      "966/1088, train_loss: 0.0293\n",
      "967/1088, train_loss: 0.0287\n",
      "968/1088, train_loss: 0.0302\n",
      "969/1088, train_loss: 0.0296\n",
      "970/1088, train_loss: 0.0310\n",
      "971/1088, train_loss: 0.0298\n",
      "972/1088, train_loss: 0.0297\n",
      "973/1088, train_loss: 0.0318\n",
      "974/1088, train_loss: 0.0296\n",
      "975/1088, train_loss: 0.0290\n",
      "976/1088, train_loss: 0.0292\n",
      "977/1088, train_loss: 0.0299\n",
      "978/1088, train_loss: 0.0297\n",
      "979/1088, train_loss: 0.0310\n",
      "980/1088, train_loss: 0.0301\n",
      "981/1088, train_loss: 0.0352\n",
      "982/1088, train_loss: 0.0293\n",
      "983/1088, train_loss: 0.0268\n",
      "984/1088, train_loss: 0.0308\n",
      "985/1088, train_loss: 0.0294\n",
      "986/1088, train_loss: 0.0293\n",
      "987/1088, train_loss: 0.0314\n",
      "988/1088, train_loss: 0.0292\n",
      "989/1088, train_loss: 0.0305\n",
      "990/1088, train_loss: 0.0313\n",
      "991/1088, train_loss: 0.0311\n",
      "992/1088, train_loss: 0.0291\n",
      "993/1088, train_loss: 0.0284\n",
      "994/1088, train_loss: 0.0280\n",
      "995/1088, train_loss: 0.0291\n",
      "996/1088, train_loss: 0.0300\n",
      "997/1088, train_loss: 0.0336\n",
      "998/1088, train_loss: 0.0371\n",
      "999/1088, train_loss: 0.0278\n",
      "1000/1088, train_loss: 0.0356\n",
      "1001/1088, train_loss: 0.0309\n",
      "1002/1088, train_loss: 0.0307\n",
      "1003/1088, train_loss: 0.0308\n",
      "1004/1088, train_loss: 0.0302\n",
      "1005/1088, train_loss: 0.0311\n",
      "1006/1088, train_loss: 0.0312\n",
      "1007/1088, train_loss: 0.0309\n",
      "1008/1088, train_loss: 0.0302\n",
      "1009/1088, train_loss: 0.0271\n",
      "1010/1088, train_loss: 0.0351\n",
      "1011/1088, train_loss: 0.0305\n",
      "1012/1088, train_loss: 0.0296\n",
      "1013/1088, train_loss: 0.0271\n",
      "1014/1088, train_loss: 0.0302\n",
      "1015/1088, train_loss: 0.0289\n",
      "1016/1088, train_loss: 0.0339\n",
      "1017/1088, train_loss: 0.0312\n",
      "1018/1088, train_loss: 0.0316\n",
      "1019/1088, train_loss: 0.0316\n",
      "1020/1088, train_loss: 0.0310\n",
      "1021/1088, train_loss: 0.0299\n",
      "1022/1088, train_loss: 0.0293\n",
      "1023/1088, train_loss: 0.0278\n",
      "1024/1088, train_loss: 0.0320\n",
      "1025/1088, train_loss: 0.0357\n",
      "1026/1088, train_loss: 0.0277\n",
      "1027/1088, train_loss: 0.0280\n",
      "1028/1088, train_loss: 0.0279\n",
      "1029/1088, train_loss: 0.0290\n",
      "1030/1088, train_loss: 0.0320\n",
      "1031/1088, train_loss: 0.0290\n",
      "1032/1088, train_loss: 0.0306\n",
      "1033/1088, train_loss: 0.0302\n",
      "1034/1088, train_loss: 0.0307\n",
      "1035/1088, train_loss: 0.0300\n",
      "1036/1088, train_loss: 0.0332\n",
      "1037/1088, train_loss: 0.0338\n",
      "1038/1088, train_loss: 0.0305\n",
      "1039/1088, train_loss: 0.0300\n",
      "1040/1088, train_loss: 0.0310\n",
      "1041/1088, train_loss: 0.0292\n",
      "1042/1088, train_loss: 0.0289\n",
      "1043/1088, train_loss: 0.0279\n",
      "1044/1088, train_loss: 0.0311\n",
      "1045/1088, train_loss: 0.0308\n",
      "1046/1088, train_loss: 0.0322\n",
      "1047/1088, train_loss: 0.0294\n",
      "1048/1088, train_loss: 0.0297\n",
      "1049/1088, train_loss: 0.0299\n",
      "1050/1088, train_loss: 0.0314\n",
      "1051/1088, train_loss: 0.0286\n",
      "1052/1088, train_loss: 0.0284\n",
      "1053/1088, train_loss: 0.0281\n",
      "1054/1088, train_loss: 0.0287\n",
      "1055/1088, train_loss: 0.0274\n",
      "1056/1088, train_loss: 0.0345\n",
      "1057/1088, train_loss: 0.0274\n",
      "1058/1088, train_loss: 0.0276\n",
      "1059/1088, train_loss: 0.0301\n",
      "1060/1088, train_loss: 0.0302\n",
      "1061/1088, train_loss: 0.0342\n",
      "1062/1088, train_loss: 0.0308\n",
      "1063/1088, train_loss: 0.0292\n",
      "1064/1088, train_loss: 0.0324\n",
      "1065/1088, train_loss: 0.0289\n",
      "1066/1088, train_loss: 0.0287\n",
      "1067/1088, train_loss: 0.0281\n",
      "1068/1088, train_loss: 0.0339\n",
      "1069/1088, train_loss: 0.0293\n",
      "1070/1088, train_loss: 0.0283\n",
      "1071/1088, train_loss: 0.0342\n",
      "1072/1088, train_loss: 0.0301\n",
      "1073/1088, train_loss: 0.0316\n",
      "1074/1088, train_loss: 0.0325\n",
      "1075/1088, train_loss: 0.0350\n",
      "1076/1088, train_loss: 0.0297\n",
      "1077/1088, train_loss: 0.0304\n",
      "1078/1088, train_loss: 0.0296\n",
      "1079/1088, train_loss: 0.0306\n",
      "1080/1088, train_loss: 0.0306\n",
      "1081/1088, train_loss: 0.0331\n",
      "1082/1088, train_loss: 0.0298\n",
      "1083/1088, train_loss: 0.0300\n",
      "1084/1088, train_loss: 0.0309\n",
      "1085/1088, train_loss: 0.0319\n",
      "1086/1088, train_loss: 0.0308\n",
      "1087/1088, train_loss: 0.0276\n",
      "1088/1088, train_loss: 0.0297\n",
      "1089/1088, train_loss: 0.0333\n",
      "epoch 5 average loss: 0.0306, train_dice: 0.9695\n",
      "epoch 5 average loss: 0.0306\n",
      "--------------------------------------------------\n",
      "epoch 6/50\n",
      "1/1088, train_loss: 0.0310\n",
      "2/1088, train_loss: 0.0282\n",
      "3/1088, train_loss: 0.0320\n",
      "4/1088, train_loss: 0.0305\n",
      "5/1088, train_loss: 0.0305\n",
      "6/1088, train_loss: 0.0298\n",
      "7/1088, train_loss: 0.0276\n",
      "8/1088, train_loss: 0.0305\n",
      "9/1088, train_loss: 0.0284\n",
      "10/1088, train_loss: 0.0284\n",
      "11/1088, train_loss: 0.0305\n",
      "12/1088, train_loss: 0.0288\n",
      "13/1088, train_loss: 0.0305\n",
      "14/1088, train_loss: 0.0296\n",
      "15/1088, train_loss: 0.0311\n",
      "16/1088, train_loss: 0.0288\n",
      "17/1088, train_loss: 0.0281\n",
      "18/1088, train_loss: 0.0294\n",
      "19/1088, train_loss: 0.0275\n",
      "20/1088, train_loss: 0.0290\n",
      "21/1088, train_loss: 0.0294\n",
      "22/1088, train_loss: 0.0292\n",
      "23/1088, train_loss: 0.0286\n",
      "24/1088, train_loss: 0.0315\n",
      "25/1088, train_loss: 0.0307\n",
      "26/1088, train_loss: 0.0291\n",
      "27/1088, train_loss: 0.0307\n",
      "28/1088, train_loss: 0.0310\n",
      "29/1088, train_loss: 0.0293\n",
      "30/1088, train_loss: 0.0297\n",
      "31/1088, train_loss: 0.0351\n",
      "32/1088, train_loss: 0.0307\n",
      "33/1088, train_loss: 0.0302\n",
      "34/1088, train_loss: 0.0324\n",
      "35/1088, train_loss: 0.0344\n",
      "36/1088, train_loss: 0.0308\n",
      "37/1088, train_loss: 0.0322\n",
      "38/1088, train_loss: 0.0311\n",
      "39/1088, train_loss: 0.0278\n",
      "40/1088, train_loss: 0.0336\n",
      "41/1088, train_loss: 0.0304\n",
      "42/1088, train_loss: 0.0303\n",
      "43/1088, train_loss: 0.0295\n",
      "44/1088, train_loss: 0.0299\n",
      "45/1088, train_loss: 0.0294\n",
      "46/1088, train_loss: 0.0282\n",
      "47/1088, train_loss: 0.0270\n",
      "48/1088, train_loss: 0.0318\n",
      "49/1088, train_loss: 0.0290\n",
      "50/1088, train_loss: 0.0290\n",
      "51/1088, train_loss: 0.0297\n",
      "52/1088, train_loss: 0.0298\n",
      "53/1088, train_loss: 0.0377\n",
      "54/1088, train_loss: 0.0295\n",
      "55/1088, train_loss: 0.0316\n",
      "56/1088, train_loss: 0.0296\n",
      "57/1088, train_loss: 0.0311\n",
      "58/1088, train_loss: 0.0292\n",
      "59/1088, train_loss: 0.0295\n",
      "60/1088, train_loss: 0.0302\n",
      "61/1088, train_loss: 0.0300\n",
      "62/1088, train_loss: 0.0301\n",
      "63/1088, train_loss: 0.0349\n",
      "64/1088, train_loss: 0.0311\n",
      "65/1088, train_loss: 0.0287\n",
      "66/1088, train_loss: 0.0315\n",
      "67/1088, train_loss: 0.0300\n",
      "68/1088, train_loss: 0.0312\n",
      "69/1088, train_loss: 0.0332\n",
      "70/1088, train_loss: 0.0320\n",
      "71/1088, train_loss: 0.0309\n",
      "72/1088, train_loss: 0.0301\n",
      "73/1088, train_loss: 0.0300\n",
      "74/1088, train_loss: 0.0306\n",
      "75/1088, train_loss: 0.0316\n",
      "76/1088, train_loss: 0.0273\n",
      "77/1088, train_loss: 0.0290\n",
      "78/1088, train_loss: 0.0275\n",
      "79/1088, train_loss: 0.0318\n",
      "80/1088, train_loss: 0.0280\n",
      "81/1088, train_loss: 0.0286\n",
      "82/1088, train_loss: 0.0300\n",
      "83/1088, train_loss: 0.0305\n",
      "84/1088, train_loss: 0.0309\n",
      "85/1088, train_loss: 0.0287\n",
      "86/1088, train_loss: 0.0278\n",
      "87/1088, train_loss: 0.0340\n",
      "88/1088, train_loss: 0.0310\n",
      "89/1088, train_loss: 0.0333\n",
      "90/1088, train_loss: 0.0319\n",
      "91/1088, train_loss: 0.0305\n",
      "92/1088, train_loss: 0.0309\n",
      "93/1088, train_loss: 0.0309\n",
      "94/1088, train_loss: 0.0289\n",
      "95/1088, train_loss: 0.0317\n",
      "96/1088, train_loss: 0.0296\n",
      "97/1088, train_loss: 0.0307\n",
      "98/1088, train_loss: 0.0339\n",
      "99/1088, train_loss: 0.0323\n",
      "100/1088, train_loss: 0.0401\n",
      "101/1088, train_loss: 0.0293\n",
      "102/1088, train_loss: 0.0286\n",
      "103/1088, train_loss: 0.0287\n",
      "104/1088, train_loss: 0.0280\n",
      "105/1088, train_loss: 0.0292\n",
      "106/1088, train_loss: 0.0300\n",
      "107/1088, train_loss: 0.0288\n",
      "108/1088, train_loss: 0.0307\n",
      "109/1088, train_loss: 0.0304\n",
      "110/1088, train_loss: 0.0335\n",
      "111/1088, train_loss: 0.0308\n",
      "112/1088, train_loss: 0.0309\n",
      "113/1088, train_loss: 0.0300\n",
      "114/1088, train_loss: 0.0297\n",
      "115/1088, train_loss: 0.0291\n",
      "116/1088, train_loss: 0.0286\n",
      "117/1088, train_loss: 0.0305\n",
      "118/1088, train_loss: 0.0356\n",
      "119/1088, train_loss: 0.0298\n",
      "120/1088, train_loss: 0.0280\n",
      "121/1088, train_loss: 0.0314\n",
      "122/1088, train_loss: 0.0297\n",
      "123/1088, train_loss: 0.0316\n",
      "124/1088, train_loss: 0.0302\n",
      "125/1088, train_loss: 0.0303\n",
      "126/1088, train_loss: 0.0302\n",
      "127/1088, train_loss: 0.0293\n",
      "128/1088, train_loss: 0.0316\n",
      "129/1088, train_loss: 0.0294\n",
      "130/1088, train_loss: 0.0286\n",
      "131/1088, train_loss: 0.0302\n",
      "132/1088, train_loss: 0.0281\n",
      "133/1088, train_loss: 0.0346\n",
      "134/1088, train_loss: 0.0302\n",
      "135/1088, train_loss: 0.0306\n",
      "136/1088, train_loss: 0.0297\n",
      "137/1088, train_loss: 0.0331\n",
      "138/1088, train_loss: 0.0286\n",
      "139/1088, train_loss: 0.0329\n",
      "140/1088, train_loss: 0.0296\n",
      "141/1088, train_loss: 0.0307\n",
      "142/1088, train_loss: 0.0288\n",
      "143/1088, train_loss: 0.0294\n",
      "144/1088, train_loss: 0.0332\n",
      "145/1088, train_loss: 0.0296\n",
      "146/1088, train_loss: 0.0289\n",
      "147/1088, train_loss: 0.0329\n",
      "148/1088, train_loss: 0.0318\n",
      "149/1088, train_loss: 0.0307\n",
      "150/1088, train_loss: 0.0298\n",
      "151/1088, train_loss: 0.0312\n",
      "152/1088, train_loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/1088, train_loss: 0.0306\n",
      "154/1088, train_loss: 0.0290\n",
      "155/1088, train_loss: 0.0331\n",
      "156/1088, train_loss: 0.0310\n",
      "157/1088, train_loss: 0.0304\n",
      "158/1088, train_loss: 0.0285\n",
      "159/1088, train_loss: 0.0288\n",
      "160/1088, train_loss: 0.0293\n",
      "161/1088, train_loss: 0.0289\n",
      "162/1088, train_loss: 0.0276\n",
      "163/1088, train_loss: 0.0342\n",
      "164/1088, train_loss: 0.0287\n",
      "165/1088, train_loss: 0.0296\n",
      "166/1088, train_loss: 0.0299\n",
      "167/1088, train_loss: 0.0297\n",
      "168/1088, train_loss: 0.0299\n",
      "169/1088, train_loss: 0.0292\n",
      "170/1088, train_loss: 0.0293\n",
      "171/1088, train_loss: 0.0293\n",
      "172/1088, train_loss: 0.0274\n",
      "173/1088, train_loss: 0.0301\n",
      "174/1088, train_loss: 0.0324\n",
      "175/1088, train_loss: 0.0293\n",
      "176/1088, train_loss: 0.0291\n",
      "177/1088, train_loss: 0.0321\n",
      "178/1088, train_loss: 0.0323\n",
      "179/1088, train_loss: 0.0284\n",
      "180/1088, train_loss: 0.0317\n",
      "181/1088, train_loss: 0.0294\n",
      "182/1088, train_loss: 0.0302\n",
      "183/1088, train_loss: 0.0286\n",
      "184/1088, train_loss: 0.0288\n",
      "185/1088, train_loss: 0.0292\n",
      "186/1088, train_loss: 0.0272\n",
      "187/1088, train_loss: 0.0312\n",
      "188/1088, train_loss: 0.0299\n",
      "189/1088, train_loss: 0.0280\n",
      "190/1088, train_loss: 0.0272\n",
      "191/1088, train_loss: 0.0306\n",
      "192/1088, train_loss: 0.0316\n",
      "193/1088, train_loss: 0.0301\n",
      "194/1088, train_loss: 0.0295\n",
      "195/1088, train_loss: 0.0304\n",
      "196/1088, train_loss: 0.0314\n",
      "197/1088, train_loss: 0.0295\n",
      "198/1088, train_loss: 0.0340\n",
      "199/1088, train_loss: 0.0323\n",
      "200/1088, train_loss: 0.0279\n",
      "201/1088, train_loss: 0.0315\n",
      "202/1088, train_loss: 0.0288\n",
      "203/1088, train_loss: 0.0354\n",
      "204/1088, train_loss: 0.0289\n",
      "205/1088, train_loss: 0.0306\n",
      "206/1088, train_loss: 0.0306\n",
      "207/1088, train_loss: 0.0298\n",
      "208/1088, train_loss: 0.0308\n",
      "209/1088, train_loss: 0.0281\n",
      "210/1088, train_loss: 0.0384\n",
      "211/1088, train_loss: 0.0309\n",
      "212/1088, train_loss: 0.0321\n",
      "213/1088, train_loss: 0.0316\n",
      "214/1088, train_loss: 0.0307\n",
      "215/1088, train_loss: 0.0301\n",
      "216/1088, train_loss: 0.0321\n",
      "217/1088, train_loss: 0.0276\n",
      "218/1088, train_loss: 0.0273\n",
      "219/1088, train_loss: 0.0309\n",
      "220/1088, train_loss: 0.0286\n",
      "221/1088, train_loss: 0.0299\n",
      "222/1088, train_loss: 0.0289\n",
      "223/1088, train_loss: 0.0302\n",
      "224/1088, train_loss: 0.0293\n",
      "225/1088, train_loss: 0.0289\n",
      "226/1088, train_loss: 0.0306\n",
      "227/1088, train_loss: 0.0291\n",
      "228/1088, train_loss: 0.0313\n",
      "229/1088, train_loss: 0.0291\n",
      "230/1088, train_loss: 0.0303\n",
      "231/1088, train_loss: 0.0369\n",
      "232/1088, train_loss: 0.0320\n",
      "233/1088, train_loss: 0.0297\n",
      "234/1088, train_loss: 0.0298\n",
      "235/1088, train_loss: 0.0297\n",
      "236/1088, train_loss: 0.0267\n",
      "237/1088, train_loss: 0.0327\n",
      "238/1088, train_loss: 0.0280\n",
      "239/1088, train_loss: 0.0316\n",
      "240/1088, train_loss: 0.0295\n",
      "241/1088, train_loss: 0.0306\n",
      "242/1088, train_loss: 0.0290\n",
      "243/1088, train_loss: 0.0317\n",
      "244/1088, train_loss: 0.0305\n",
      "245/1088, train_loss: 0.0295\n",
      "246/1088, train_loss: 0.0278\n",
      "247/1088, train_loss: 0.0280\n",
      "248/1088, train_loss: 0.0285\n",
      "249/1088, train_loss: 0.0265\n",
      "250/1088, train_loss: 0.0304\n",
      "251/1088, train_loss: 0.0271\n",
      "252/1088, train_loss: 0.0274\n",
      "253/1088, train_loss: 0.0266\n",
      "254/1088, train_loss: 0.0318\n",
      "255/1088, train_loss: 0.0319\n",
      "256/1088, train_loss: 0.0325\n",
      "257/1088, train_loss: 0.0295\n",
      "258/1088, train_loss: 0.0292\n",
      "259/1088, train_loss: 0.0292\n",
      "260/1088, train_loss: 0.0315\n",
      "261/1088, train_loss: 0.0297\n",
      "262/1088, train_loss: 0.0289\n",
      "263/1088, train_loss: 0.0318\n",
      "264/1088, train_loss: 0.0327\n",
      "265/1088, train_loss: 0.0330\n",
      "266/1088, train_loss: 0.0300\n",
      "267/1088, train_loss: 0.0300\n",
      "268/1088, train_loss: 0.0320\n",
      "269/1088, train_loss: 0.0306\n",
      "270/1088, train_loss: 0.0335\n",
      "271/1088, train_loss: 0.0316\n",
      "272/1088, train_loss: 0.0292\n",
      "273/1088, train_loss: 0.0303\n",
      "274/1088, train_loss: 0.0305\n",
      "275/1088, train_loss: 0.0302\n",
      "276/1088, train_loss: 0.0328\n",
      "277/1088, train_loss: 0.0292\n",
      "278/1088, train_loss: 0.0285\n",
      "279/1088, train_loss: 0.0304\n",
      "280/1088, train_loss: 0.0312\n",
      "281/1088, train_loss: 0.0330\n",
      "282/1088, train_loss: 0.0365\n",
      "283/1088, train_loss: 0.0300\n",
      "284/1088, train_loss: 0.0304\n",
      "285/1088, train_loss: 0.0311\n",
      "286/1088, train_loss: 0.0279\n",
      "287/1088, train_loss: 0.0278\n",
      "288/1088, train_loss: 0.0295\n",
      "289/1088, train_loss: 0.0295\n",
      "290/1088, train_loss: 0.0271\n",
      "291/1088, train_loss: 0.0277\n",
      "292/1088, train_loss: 0.0305\n",
      "293/1088, train_loss: 0.0334\n",
      "294/1088, train_loss: 0.0325\n",
      "295/1088, train_loss: 0.0299\n",
      "296/1088, train_loss: 0.0289\n",
      "297/1088, train_loss: 0.0292\n",
      "298/1088, train_loss: 0.0312\n",
      "299/1088, train_loss: 0.0286\n",
      "300/1088, train_loss: 0.0267\n",
      "301/1088, train_loss: 0.0285\n",
      "302/1088, train_loss: 0.0300\n",
      "303/1088, train_loss: 0.0295\n",
      "304/1088, train_loss: 0.0285\n",
      "305/1088, train_loss: 0.0357\n",
      "306/1088, train_loss: 0.0318\n",
      "307/1088, train_loss: 0.0327\n",
      "308/1088, train_loss: 0.0289\n",
      "309/1088, train_loss: 0.0285\n",
      "310/1088, train_loss: 0.0311\n",
      "311/1088, train_loss: 0.0313\n",
      "312/1088, train_loss: 0.0296\n",
      "313/1088, train_loss: 0.0289\n",
      "314/1088, train_loss: 0.0287\n",
      "315/1088, train_loss: 0.0321\n",
      "316/1088, train_loss: 0.0310\n",
      "317/1088, train_loss: 0.0349\n",
      "318/1088, train_loss: 0.0286\n",
      "319/1088, train_loss: 0.0339\n",
      "320/1088, train_loss: 0.0309\n",
      "321/1088, train_loss: 0.0282\n",
      "322/1088, train_loss: 0.0302\n",
      "323/1088, train_loss: 0.0289\n",
      "324/1088, train_loss: 0.0282\n",
      "325/1088, train_loss: 0.0306\n",
      "326/1088, train_loss: 0.0318\n",
      "327/1088, train_loss: 0.0309\n",
      "328/1088, train_loss: 0.0284\n",
      "329/1088, train_loss: 0.0284\n",
      "330/1088, train_loss: 0.0303\n",
      "331/1088, train_loss: 0.0319\n",
      "332/1088, train_loss: 0.0369\n",
      "333/1088, train_loss: 0.0269\n",
      "334/1088, train_loss: 0.0311\n",
      "335/1088, train_loss: 0.0293\n",
      "336/1088, train_loss: 0.0287\n",
      "337/1088, train_loss: 0.0316\n",
      "338/1088, train_loss: 0.0311\n",
      "339/1088, train_loss: 0.0309\n",
      "340/1088, train_loss: 0.0300\n",
      "341/1088, train_loss: 0.0343\n",
      "342/1088, train_loss: 0.0291\n",
      "343/1088, train_loss: 0.0305\n",
      "344/1088, train_loss: 0.0292\n",
      "345/1088, train_loss: 0.0311\n",
      "346/1088, train_loss: 0.0309\n",
      "347/1088, train_loss: 0.0345\n",
      "348/1088, train_loss: 0.0297\n",
      "349/1088, train_loss: 0.0411\n",
      "350/1088, train_loss: 0.0306\n",
      "351/1088, train_loss: 0.0300\n",
      "352/1088, train_loss: 0.0311\n",
      "353/1088, train_loss: 0.0311\n",
      "354/1088, train_loss: 0.0337\n",
      "355/1088, train_loss: 0.0328\n",
      "356/1088, train_loss: 0.0295\n",
      "357/1088, train_loss: 0.0293\n",
      "358/1088, train_loss: 0.0311\n",
      "359/1088, train_loss: 0.0287\n",
      "360/1088, train_loss: 0.0300\n",
      "361/1088, train_loss: 0.0299\n",
      "362/1088, train_loss: 0.0313\n",
      "363/1088, train_loss: 0.0309\n",
      "364/1088, train_loss: 0.0312\n",
      "365/1088, train_loss: 0.0329\n",
      "366/1088, train_loss: 0.0281\n",
      "367/1088, train_loss: 0.0300\n",
      "368/1088, train_loss: 0.0281\n",
      "369/1088, train_loss: 0.0302\n",
      "370/1088, train_loss: 0.0297\n",
      "371/1088, train_loss: 0.0315\n",
      "372/1088, train_loss: 0.0288\n",
      "373/1088, train_loss: 0.0297\n",
      "374/1088, train_loss: 0.0277\n",
      "375/1088, train_loss: 0.0286\n",
      "376/1088, train_loss: 0.0310\n",
      "377/1088, train_loss: 0.0301\n",
      "378/1088, train_loss: 0.0273\n",
      "379/1088, train_loss: 0.0284\n",
      "380/1088, train_loss: 0.0287\n",
      "381/1088, train_loss: 0.0298\n",
      "382/1088, train_loss: 0.0300\n",
      "383/1088, train_loss: 0.0327\n",
      "384/1088, train_loss: 0.0306\n",
      "385/1088, train_loss: 0.0297\n",
      "386/1088, train_loss: 0.0295\n",
      "387/1088, train_loss: 0.0414\n",
      "388/1088, train_loss: 0.0310\n",
      "389/1088, train_loss: 0.0302\n",
      "390/1088, train_loss: 0.0301\n",
      "391/1088, train_loss: 0.0317\n",
      "392/1088, train_loss: 0.0273\n",
      "393/1088, train_loss: 0.0310\n",
      "394/1088, train_loss: 0.0293\n",
      "395/1088, train_loss: 0.0286\n",
      "396/1088, train_loss: 0.0277\n",
      "397/1088, train_loss: 0.0311\n",
      "398/1088, train_loss: 0.0291\n",
      "399/1088, train_loss: 0.0299\n",
      "400/1088, train_loss: 0.0301\n",
      "401/1088, train_loss: 0.0280\n",
      "402/1088, train_loss: 0.0312\n",
      "403/1088, train_loss: 0.0286\n",
      "404/1088, train_loss: 0.0322\n",
      "405/1088, train_loss: 0.0401\n",
      "406/1088, train_loss: 0.0284\n",
      "407/1088, train_loss: 0.0285\n",
      "408/1088, train_loss: 0.0324\n",
      "409/1088, train_loss: 0.0301\n",
      "410/1088, train_loss: 0.0306\n",
      "411/1088, train_loss: 0.0300\n",
      "412/1088, train_loss: 0.0299\n",
      "413/1088, train_loss: 0.0295\n",
      "414/1088, train_loss: 0.0288\n",
      "415/1088, train_loss: 0.0304\n",
      "416/1088, train_loss: 0.0312\n",
      "417/1088, train_loss: 0.0315\n",
      "418/1088, train_loss: 0.0297\n",
      "419/1088, train_loss: 0.0362\n",
      "420/1088, train_loss: 0.0293\n",
      "421/1088, train_loss: 0.0292\n",
      "422/1088, train_loss: 0.0303\n",
      "423/1088, train_loss: 0.0295\n",
      "424/1088, train_loss: 0.0312\n",
      "425/1088, train_loss: 0.0310\n",
      "426/1088, train_loss: 0.0305\n",
      "427/1088, train_loss: 0.0319\n",
      "428/1088, train_loss: 0.0292\n",
      "429/1088, train_loss: 0.0303\n",
      "430/1088, train_loss: 0.0287\n",
      "431/1088, train_loss: 0.0301\n",
      "432/1088, train_loss: 0.0300\n",
      "433/1088, train_loss: 0.0290\n",
      "434/1088, train_loss: 0.0289\n",
      "435/1088, train_loss: 0.0285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436/1088, train_loss: 0.0310\n",
      "437/1088, train_loss: 0.0287\n",
      "438/1088, train_loss: 0.0303\n",
      "439/1088, train_loss: 0.0275\n",
      "440/1088, train_loss: 0.0283\n",
      "441/1088, train_loss: 0.0300\n",
      "442/1088, train_loss: 0.0293\n",
      "443/1088, train_loss: 0.0294\n",
      "444/1088, train_loss: 0.0305\n",
      "445/1088, train_loss: 0.0297\n",
      "446/1088, train_loss: 0.0307\n",
      "447/1088, train_loss: 0.0312\n",
      "448/1088, train_loss: 0.0311\n",
      "449/1088, train_loss: 0.0296\n",
      "450/1088, train_loss: 0.0311\n",
      "451/1088, train_loss: 0.0301\n",
      "452/1088, train_loss: 0.0289\n",
      "453/1088, train_loss: 0.0285\n",
      "454/1088, train_loss: 0.0299\n",
      "455/1088, train_loss: 0.0306\n",
      "456/1088, train_loss: 0.0307\n",
      "457/1088, train_loss: 0.0276\n",
      "458/1088, train_loss: 0.0322\n",
      "459/1088, train_loss: 0.0283\n",
      "460/1088, train_loss: 0.0300\n",
      "461/1088, train_loss: 0.0298\n",
      "462/1088, train_loss: 0.0289\n",
      "463/1088, train_loss: 0.0301\n",
      "464/1088, train_loss: 0.0276\n",
      "465/1088, train_loss: 0.0303\n",
      "466/1088, train_loss: 0.0283\n",
      "467/1088, train_loss: 0.0308\n",
      "468/1088, train_loss: 0.0314\n",
      "469/1088, train_loss: 0.0273\n",
      "470/1088, train_loss: 0.0302\n",
      "471/1088, train_loss: 0.0334\n",
      "472/1088, train_loss: 0.0277\n",
      "473/1088, train_loss: 0.0323\n",
      "474/1088, train_loss: 0.0280\n",
      "475/1088, train_loss: 0.0312\n",
      "476/1088, train_loss: 0.0297\n",
      "477/1088, train_loss: 0.0285\n",
      "478/1088, train_loss: 0.0345\n",
      "479/1088, train_loss: 0.0309\n",
      "480/1088, train_loss: 0.0292\n",
      "481/1088, train_loss: 0.0322\n",
      "482/1088, train_loss: 0.0292\n",
      "483/1088, train_loss: 0.0289\n",
      "484/1088, train_loss: 0.0296\n",
      "485/1088, train_loss: 0.0306\n",
      "486/1088, train_loss: 0.0356\n",
      "487/1088, train_loss: 0.0302\n",
      "488/1088, train_loss: 0.0285\n",
      "489/1088, train_loss: 0.0342\n",
      "490/1088, train_loss: 0.0304\n",
      "491/1088, train_loss: 0.0299\n",
      "492/1088, train_loss: 0.0299\n",
      "493/1088, train_loss: 0.0315\n",
      "494/1088, train_loss: 0.0293\n",
      "495/1088, train_loss: 0.0301\n",
      "496/1088, train_loss: 0.0320\n",
      "497/1088, train_loss: 0.0329\n",
      "498/1088, train_loss: 0.0274\n",
      "499/1088, train_loss: 0.0299\n",
      "500/1088, train_loss: 0.0314\n",
      "501/1088, train_loss: 0.0309\n",
      "502/1088, train_loss: 0.0307\n",
      "503/1088, train_loss: 0.0306\n",
      "504/1088, train_loss: 0.0315\n",
      "505/1088, train_loss: 0.0298\n",
      "506/1088, train_loss: 0.0301\n",
      "507/1088, train_loss: 0.0335\n",
      "508/1088, train_loss: 0.0318\n",
      "509/1088, train_loss: 0.0333\n",
      "510/1088, train_loss: 0.0336\n",
      "511/1088, train_loss: 0.0301\n",
      "512/1088, train_loss: 0.0294\n",
      "513/1088, train_loss: 0.0279\n",
      "514/1088, train_loss: 0.0274\n",
      "515/1088, train_loss: 0.0277\n",
      "516/1088, train_loss: 0.0381\n",
      "517/1088, train_loss: 0.0309\n",
      "518/1088, train_loss: 0.0295\n",
      "519/1088, train_loss: 0.0287\n",
      "520/1088, train_loss: 0.0292\n",
      "521/1088, train_loss: 0.0274\n",
      "522/1088, train_loss: 0.0282\n",
      "523/1088, train_loss: 0.0300\n",
      "524/1088, train_loss: 0.0281\n",
      "525/1088, train_loss: 0.0318\n",
      "526/1088, train_loss: 0.0295\n",
      "527/1088, train_loss: 0.0292\n",
      "528/1088, train_loss: 0.0312\n",
      "529/1088, train_loss: 0.0282\n",
      "530/1088, train_loss: 0.0309\n",
      "531/1088, train_loss: 0.0302\n",
      "532/1088, train_loss: 0.0287\n",
      "533/1088, train_loss: 0.0310\n",
      "534/1088, train_loss: 0.0302\n",
      "535/1088, train_loss: 0.0296\n",
      "536/1088, train_loss: 0.0254\n",
      "537/1088, train_loss: 0.0307\n",
      "538/1088, train_loss: 0.0298\n",
      "539/1088, train_loss: 0.0302\n",
      "540/1088, train_loss: 0.0294\n",
      "541/1088, train_loss: 0.0301\n",
      "542/1088, train_loss: 0.0276\n",
      "543/1088, train_loss: 0.0297\n",
      "544/1088, train_loss: 0.0307\n",
      "545/1088, train_loss: 0.0317\n",
      "546/1088, train_loss: 0.0277\n",
      "547/1088, train_loss: 0.0283\n",
      "548/1088, train_loss: 0.0321\n",
      "549/1088, train_loss: 0.0281\n",
      "550/1088, train_loss: 0.0312\n",
      "551/1088, train_loss: 0.0317\n",
      "552/1088, train_loss: 0.0329\n",
      "553/1088, train_loss: 0.0280\n",
      "554/1088, train_loss: 0.0341\n",
      "555/1088, train_loss: 0.0293\n",
      "556/1088, train_loss: 0.0283\n",
      "557/1088, train_loss: 0.0295\n",
      "558/1088, train_loss: 0.0298\n",
      "559/1088, train_loss: 0.0328\n",
      "560/1088, train_loss: 0.0283\n",
      "561/1088, train_loss: 0.0312\n",
      "562/1088, train_loss: 0.0288\n",
      "563/1088, train_loss: 0.0407\n",
      "564/1088, train_loss: 0.0302\n",
      "565/1088, train_loss: 0.0290\n",
      "566/1088, train_loss: 0.0271\n",
      "567/1088, train_loss: 0.0324\n",
      "568/1088, train_loss: 0.0313\n",
      "569/1088, train_loss: 0.0279\n",
      "570/1088, train_loss: 0.0317\n",
      "571/1088, train_loss: 0.0269\n",
      "572/1088, train_loss: 0.0284\n",
      "573/1088, train_loss: 0.0283\n",
      "574/1088, train_loss: 0.0291\n",
      "575/1088, train_loss: 0.0271\n",
      "576/1088, train_loss: 0.0291\n",
      "577/1088, train_loss: 0.0277\n",
      "578/1088, train_loss: 0.0307\n",
      "579/1088, train_loss: 0.0286\n",
      "580/1088, train_loss: 0.0289\n",
      "581/1088, train_loss: 0.0287\n",
      "582/1088, train_loss: 0.0295\n",
      "583/1088, train_loss: 0.0291\n",
      "584/1088, train_loss: 0.0290\n",
      "585/1088, train_loss: 0.0274\n",
      "586/1088, train_loss: 0.0328\n",
      "587/1088, train_loss: 0.0326\n",
      "588/1088, train_loss: 0.0320\n",
      "589/1088, train_loss: 0.0296\n",
      "590/1088, train_loss: 0.0303\n",
      "591/1088, train_loss: 0.0328\n",
      "592/1088, train_loss: 0.0297\n",
      "593/1088, train_loss: 0.0336\n",
      "594/1088, train_loss: 0.0293\n",
      "595/1088, train_loss: 0.0300\n",
      "596/1088, train_loss: 0.0315\n",
      "597/1088, train_loss: 0.0282\n",
      "598/1088, train_loss: 0.0340\n",
      "599/1088, train_loss: 0.0299\n",
      "600/1088, train_loss: 0.0294\n",
      "601/1088, train_loss: 0.0283\n",
      "602/1088, train_loss: 0.0343\n",
      "603/1088, train_loss: 0.0313\n",
      "604/1088, train_loss: 0.0326\n",
      "605/1088, train_loss: 0.0302\n",
      "606/1088, train_loss: 0.0278\n",
      "607/1088, train_loss: 0.0302\n",
      "608/1088, train_loss: 0.0278\n",
      "609/1088, train_loss: 0.0282\n",
      "610/1088, train_loss: 0.0299\n",
      "611/1088, train_loss: 0.0290\n",
      "612/1088, train_loss: 0.0317\n",
      "613/1088, train_loss: 0.0288\n",
      "614/1088, train_loss: 0.0292\n",
      "615/1088, train_loss: 0.0304\n",
      "616/1088, train_loss: 0.0325\n",
      "617/1088, train_loss: 0.0275\n",
      "618/1088, train_loss: 0.0277\n",
      "619/1088, train_loss: 0.0299\n",
      "620/1088, train_loss: 0.0287\n",
      "621/1088, train_loss: 0.0315\n",
      "622/1088, train_loss: 0.0282\n",
      "623/1088, train_loss: 0.0293\n",
      "624/1088, train_loss: 0.0320\n",
      "625/1088, train_loss: 0.0298\n",
      "626/1088, train_loss: 0.0300\n",
      "627/1088, train_loss: 0.0298\n",
      "628/1088, train_loss: 0.0294\n",
      "629/1088, train_loss: 0.0302\n",
      "630/1088, train_loss: 0.0322\n",
      "631/1088, train_loss: 0.0298\n",
      "632/1088, train_loss: 0.0313\n",
      "633/1088, train_loss: 0.0280\n",
      "634/1088, train_loss: 0.0308\n",
      "635/1088, train_loss: 0.0311\n",
      "636/1088, train_loss: 0.0278\n",
      "637/1088, train_loss: 0.0291\n",
      "638/1088, train_loss: 0.0270\n",
      "639/1088, train_loss: 0.0304\n",
      "640/1088, train_loss: 0.0314\n",
      "641/1088, train_loss: 0.0290\n",
      "642/1088, train_loss: 0.0299\n",
      "643/1088, train_loss: 0.0305\n",
      "644/1088, train_loss: 0.0291\n",
      "645/1088, train_loss: 0.0316\n",
      "646/1088, train_loss: 0.0268\n",
      "647/1088, train_loss: 0.0293\n",
      "648/1088, train_loss: 0.0299\n",
      "649/1088, train_loss: 0.0301\n",
      "650/1088, train_loss: 0.0285\n",
      "651/1088, train_loss: 0.0294\n",
      "652/1088, train_loss: 0.0333\n",
      "653/1088, train_loss: 0.0303\n",
      "654/1088, train_loss: 0.0292\n",
      "655/1088, train_loss: 0.0300\n",
      "656/1088, train_loss: 0.0289\n",
      "657/1088, train_loss: 0.0285\n",
      "658/1088, train_loss: 0.0323\n",
      "659/1088, train_loss: 0.0282\n",
      "660/1088, train_loss: 0.0278\n",
      "661/1088, train_loss: 0.0298\n",
      "662/1088, train_loss: 0.0315\n",
      "663/1088, train_loss: 0.0320\n",
      "664/1088, train_loss: 0.0291\n",
      "665/1088, train_loss: 0.0280\n",
      "666/1088, train_loss: 0.0297\n",
      "667/1088, train_loss: 0.0301\n",
      "668/1088, train_loss: 0.0324\n",
      "669/1088, train_loss: 0.0287\n",
      "670/1088, train_loss: 0.0325\n",
      "671/1088, train_loss: 0.0294\n",
      "672/1088, train_loss: 0.0294\n",
      "673/1088, train_loss: 0.0299\n",
      "674/1088, train_loss: 0.0315\n",
      "675/1088, train_loss: 0.0300\n",
      "676/1088, train_loss: 0.0292\n",
      "677/1088, train_loss: 0.0291\n",
      "678/1088, train_loss: 0.0317\n",
      "679/1088, train_loss: 0.0303\n",
      "680/1088, train_loss: 0.0290\n",
      "681/1088, train_loss: 0.0299\n",
      "682/1088, train_loss: 0.0314\n",
      "683/1088, train_loss: 0.0291\n",
      "684/1088, train_loss: 0.0293\n",
      "685/1088, train_loss: 0.0303\n",
      "686/1088, train_loss: 0.0312\n",
      "687/1088, train_loss: 0.0288\n",
      "688/1088, train_loss: 0.0336\n",
      "689/1088, train_loss: 0.0304\n",
      "690/1088, train_loss: 0.0288\n",
      "691/1088, train_loss: 0.0298\n",
      "692/1088, train_loss: 0.0295\n",
      "693/1088, train_loss: 0.0293\n",
      "694/1088, train_loss: 0.0303\n",
      "695/1088, train_loss: 0.0336\n",
      "696/1088, train_loss: 0.0303\n",
      "697/1088, train_loss: 0.0296\n",
      "698/1088, train_loss: 0.0301\n",
      "699/1088, train_loss: 0.0293\n",
      "700/1088, train_loss: 0.0281\n",
      "701/1088, train_loss: 0.0309\n",
      "702/1088, train_loss: 0.0337\n",
      "703/1088, train_loss: 0.0302\n",
      "704/1088, train_loss: 0.0304\n",
      "705/1088, train_loss: 0.0305\n",
      "706/1088, train_loss: 0.0336\n",
      "707/1088, train_loss: 0.0315\n",
      "708/1088, train_loss: 0.0317\n",
      "709/1088, train_loss: 0.0314\n",
      "710/1088, train_loss: 0.0304\n",
      "711/1088, train_loss: 0.0300\n",
      "712/1088, train_loss: 0.0308\n",
      "713/1088, train_loss: 0.0300\n",
      "714/1088, train_loss: 0.0308\n",
      "715/1088, train_loss: 0.0313\n",
      "716/1088, train_loss: 0.0290\n",
      "717/1088, train_loss: 0.0291\n",
      "718/1088, train_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719/1088, train_loss: 0.0258\n",
      "720/1088, train_loss: 0.0352\n",
      "721/1088, train_loss: 0.0271\n",
      "722/1088, train_loss: 0.0323\n",
      "723/1088, train_loss: 0.0301\n",
      "724/1088, train_loss: 0.0317\n",
      "725/1088, train_loss: 0.0318\n",
      "726/1088, train_loss: 0.0305\n",
      "727/1088, train_loss: 0.0300\n",
      "728/1088, train_loss: 0.0369\n",
      "729/1088, train_loss: 0.0308\n",
      "730/1088, train_loss: 0.0294\n",
      "731/1088, train_loss: 0.0290\n",
      "732/1088, train_loss: 0.0335\n",
      "733/1088, train_loss: 0.0304\n",
      "734/1088, train_loss: 0.0311\n",
      "735/1088, train_loss: 0.0287\n",
      "736/1088, train_loss: 0.0301\n",
      "737/1088, train_loss: 0.0320\n",
      "738/1088, train_loss: 0.0280\n",
      "739/1088, train_loss: 0.0288\n",
      "740/1088, train_loss: 0.0270\n",
      "741/1088, train_loss: 0.0267\n",
      "742/1088, train_loss: 0.0295\n",
      "743/1088, train_loss: 0.0292\n",
      "744/1088, train_loss: 0.0285\n",
      "745/1088, train_loss: 0.0308\n",
      "746/1088, train_loss: 0.0292\n",
      "747/1088, train_loss: 0.0290\n",
      "748/1088, train_loss: 0.0270\n",
      "749/1088, train_loss: 0.0280\n",
      "750/1088, train_loss: 0.0290\n",
      "751/1088, train_loss: 0.0290\n",
      "752/1088, train_loss: 0.0266\n",
      "753/1088, train_loss: 0.0295\n",
      "754/1088, train_loss: 0.0302\n",
      "755/1088, train_loss: 0.0285\n",
      "756/1088, train_loss: 0.0291\n",
      "757/1088, train_loss: 0.0301\n",
      "758/1088, train_loss: 0.0281\n",
      "759/1088, train_loss: 0.0315\n",
      "760/1088, train_loss: 0.0293\n",
      "761/1088, train_loss: 0.0296\n",
      "762/1088, train_loss: 0.0304\n",
      "763/1088, train_loss: 0.0335\n",
      "764/1088, train_loss: 0.0295\n",
      "765/1088, train_loss: 0.0308\n",
      "766/1088, train_loss: 0.0303\n",
      "767/1088, train_loss: 0.0289\n",
      "768/1088, train_loss: 0.0315\n",
      "769/1088, train_loss: 0.0289\n",
      "770/1088, train_loss: 0.0280\n",
      "771/1088, train_loss: 0.0276\n",
      "772/1088, train_loss: 0.0290\n",
      "773/1088, train_loss: 0.0298\n",
      "774/1088, train_loss: 0.0291\n",
      "775/1088, train_loss: 0.0278\n",
      "776/1088, train_loss: 0.0310\n",
      "777/1088, train_loss: 0.0281\n",
      "778/1088, train_loss: 0.0356\n",
      "779/1088, train_loss: 0.0301\n",
      "780/1088, train_loss: 0.0313\n",
      "781/1088, train_loss: 0.0300\n",
      "782/1088, train_loss: 0.0293\n",
      "783/1088, train_loss: 0.0305\n",
      "784/1088, train_loss: 0.0298\n",
      "785/1088, train_loss: 0.0290\n",
      "786/1088, train_loss: 0.0295\n",
      "787/1088, train_loss: 0.0284\n",
      "788/1088, train_loss: 0.0299\n",
      "789/1088, train_loss: 0.0266\n",
      "790/1088, train_loss: 0.0310\n",
      "791/1088, train_loss: 0.0345\n",
      "792/1088, train_loss: 0.0341\n",
      "793/1088, train_loss: 0.0318\n",
      "794/1088, train_loss: 0.0378\n",
      "795/1088, train_loss: 0.0328\n",
      "796/1088, train_loss: 0.0281\n",
      "797/1088, train_loss: 0.0302\n",
      "798/1088, train_loss: 0.0291\n",
      "799/1088, train_loss: 0.0295\n",
      "800/1088, train_loss: 0.0302\n",
      "801/1088, train_loss: 0.0277\n",
      "802/1088, train_loss: 0.0300\n",
      "803/1088, train_loss: 0.0322\n",
      "804/1088, train_loss: 0.0306\n",
      "805/1088, train_loss: 0.0341\n",
      "806/1088, train_loss: 0.0300\n",
      "807/1088, train_loss: 0.0301\n",
      "808/1088, train_loss: 0.0294\n",
      "809/1088, train_loss: 0.0293\n",
      "810/1088, train_loss: 0.0301\n",
      "811/1088, train_loss: 0.0283\n",
      "812/1088, train_loss: 0.0313\n",
      "813/1088, train_loss: 0.0305\n",
      "814/1088, train_loss: 0.0315\n",
      "815/1088, train_loss: 0.0303\n",
      "816/1088, train_loss: 0.0312\n",
      "817/1088, train_loss: 0.0330\n",
      "818/1088, train_loss: 0.0298\n",
      "819/1088, train_loss: 0.0288\n",
      "820/1088, train_loss: 0.0326\n",
      "821/1088, train_loss: 0.0301\n",
      "822/1088, train_loss: 0.0299\n",
      "823/1088, train_loss: 0.0307\n",
      "824/1088, train_loss: 0.0267\n",
      "825/1088, train_loss: 0.0470\n",
      "826/1088, train_loss: 0.0280\n",
      "827/1088, train_loss: 0.0285\n",
      "828/1088, train_loss: 0.0291\n",
      "829/1088, train_loss: 0.0408\n",
      "830/1088, train_loss: 0.0306\n",
      "831/1088, train_loss: 0.0324\n",
      "832/1088, train_loss: 0.0324\n",
      "833/1088, train_loss: 0.0283\n",
      "834/1088, train_loss: 0.0286\n",
      "835/1088, train_loss: 0.0291\n",
      "836/1088, train_loss: 0.0296\n",
      "837/1088, train_loss: 0.0278\n",
      "838/1088, train_loss: 0.0301\n",
      "839/1088, train_loss: 0.0294\n",
      "840/1088, train_loss: 0.0289\n",
      "841/1088, train_loss: 0.0300\n",
      "842/1088, train_loss: 0.0280\n",
      "843/1088, train_loss: 0.0317\n",
      "844/1088, train_loss: 0.0294\n",
      "845/1088, train_loss: 0.0272\n",
      "846/1088, train_loss: 0.0297\n",
      "847/1088, train_loss: 0.0288\n",
      "848/1088, train_loss: 0.0309\n",
      "849/1088, train_loss: 0.0355\n",
      "850/1088, train_loss: 0.0291\n",
      "851/1088, train_loss: 0.0306\n",
      "852/1088, train_loss: 0.0291\n",
      "853/1088, train_loss: 0.0295\n",
      "854/1088, train_loss: 0.0277\n",
      "855/1088, train_loss: 0.0329\n",
      "856/1088, train_loss: 0.0293\n",
      "857/1088, train_loss: 0.0299\n",
      "858/1088, train_loss: 0.0293\n",
      "859/1088, train_loss: 0.0298\n",
      "860/1088, train_loss: 0.0302\n",
      "861/1088, train_loss: 0.0273\n",
      "862/1088, train_loss: 0.0323\n",
      "863/1088, train_loss: 0.0300\n",
      "864/1088, train_loss: 0.0322\n",
      "865/1088, train_loss: 0.0277\n",
      "866/1088, train_loss: 0.0303\n",
      "867/1088, train_loss: 0.0300\n",
      "868/1088, train_loss: 0.0291\n",
      "869/1088, train_loss: 0.0286\n",
      "870/1088, train_loss: 0.0334\n",
      "871/1088, train_loss: 0.0293\n",
      "872/1088, train_loss: 0.0278\n",
      "873/1088, train_loss: 0.0291\n",
      "874/1088, train_loss: 0.0300\n",
      "875/1088, train_loss: 0.0302\n",
      "876/1088, train_loss: 0.0287\n",
      "877/1088, train_loss: 0.0273\n",
      "878/1088, train_loss: 0.0288\n",
      "879/1088, train_loss: 0.0281\n",
      "880/1088, train_loss: 0.0282\n",
      "881/1088, train_loss: 0.0332\n",
      "882/1088, train_loss: 0.0285\n",
      "883/1088, train_loss: 0.0289\n",
      "884/1088, train_loss: 0.0298\n",
      "885/1088, train_loss: 0.0348\n",
      "886/1088, train_loss: 0.0311\n",
      "887/1088, train_loss: 0.0307\n",
      "888/1088, train_loss: 0.0320\n",
      "889/1088, train_loss: 0.0283\n",
      "890/1088, train_loss: 0.0309\n",
      "891/1088, train_loss: 0.0337\n",
      "892/1088, train_loss: 0.0317\n",
      "893/1088, train_loss: 0.0302\n",
      "894/1088, train_loss: 0.0290\n",
      "895/1088, train_loss: 0.0298\n",
      "896/1088, train_loss: 0.0282\n",
      "897/1088, train_loss: 0.0286\n",
      "898/1088, train_loss: 0.0304\n",
      "899/1088, train_loss: 0.0285\n",
      "900/1088, train_loss: 0.0279\n",
      "901/1088, train_loss: 0.0286\n",
      "902/1088, train_loss: 0.0346\n",
      "903/1088, train_loss: 0.0269\n",
      "904/1088, train_loss: 0.0274\n",
      "905/1088, train_loss: 0.0278\n",
      "906/1088, train_loss: 0.0278\n",
      "907/1088, train_loss: 0.0292\n",
      "908/1088, train_loss: 0.0318\n",
      "909/1088, train_loss: 0.0280\n",
      "910/1088, train_loss: 0.0323\n",
      "911/1088, train_loss: 0.0282\n",
      "912/1088, train_loss: 0.0285\n",
      "913/1088, train_loss: 0.0316\n",
      "914/1088, train_loss: 0.0296\n",
      "915/1088, train_loss: 0.0290\n",
      "916/1088, train_loss: 0.0308\n",
      "917/1088, train_loss: 0.0290\n",
      "918/1088, train_loss: 0.0307\n",
      "919/1088, train_loss: 0.0317\n",
      "920/1088, train_loss: 0.0289\n",
      "921/1088, train_loss: 0.0304\n",
      "922/1088, train_loss: 0.0294\n",
      "923/1088, train_loss: 0.0300\n",
      "924/1088, train_loss: 0.0289\n",
      "925/1088, train_loss: 0.0323\n",
      "926/1088, train_loss: 0.0304\n",
      "927/1088, train_loss: 0.0300\n",
      "928/1088, train_loss: 0.0288\n",
      "929/1088, train_loss: 0.0295\n",
      "930/1088, train_loss: 0.0305\n",
      "931/1088, train_loss: 0.0285\n",
      "932/1088, train_loss: 0.0285\n",
      "933/1088, train_loss: 0.0305\n",
      "934/1088, train_loss: 0.0311\n",
      "935/1088, train_loss: 0.0282\n",
      "936/1088, train_loss: 0.0323\n",
      "937/1088, train_loss: 0.0327\n",
      "938/1088, train_loss: 0.0329\n",
      "939/1088, train_loss: 0.0315\n",
      "940/1088, train_loss: 0.0303\n",
      "941/1088, train_loss: 0.0305\n",
      "942/1088, train_loss: 0.0302\n",
      "943/1088, train_loss: 0.0311\n",
      "944/1088, train_loss: 0.0281\n",
      "945/1088, train_loss: 0.0312\n",
      "946/1088, train_loss: 0.0287\n",
      "947/1088, train_loss: 0.0281\n",
      "948/1088, train_loss: 0.0314\n",
      "949/1088, train_loss: 0.0289\n",
      "950/1088, train_loss: 0.0310\n",
      "951/1088, train_loss: 0.0288\n",
      "952/1088, train_loss: 0.0296\n",
      "953/1088, train_loss: 0.0305\n",
      "954/1088, train_loss: 0.0300\n",
      "955/1088, train_loss: 0.0311\n",
      "956/1088, train_loss: 0.0283\n",
      "957/1088, train_loss: 0.0278\n",
      "958/1088, train_loss: 0.0303\n",
      "959/1088, train_loss: 0.0293\n",
      "960/1088, train_loss: 0.0306\n",
      "961/1088, train_loss: 0.0298\n",
      "962/1088, train_loss: 0.0310\n",
      "963/1088, train_loss: 0.0295\n",
      "964/1088, train_loss: 0.0314\n",
      "965/1088, train_loss: 0.0281\n",
      "966/1088, train_loss: 0.0295\n",
      "967/1088, train_loss: 0.0325\n",
      "968/1088, train_loss: 0.0297\n",
      "969/1088, train_loss: 0.0293\n",
      "970/1088, train_loss: 0.0283\n",
      "971/1088, train_loss: 0.0285\n",
      "972/1088, train_loss: 0.0310\n",
      "973/1088, train_loss: 0.0314\n",
      "974/1088, train_loss: 0.0287\n",
      "975/1088, train_loss: 0.0302\n",
      "976/1088, train_loss: 0.0285\n",
      "977/1088, train_loss: 0.0296\n",
      "978/1088, train_loss: 0.0309\n",
      "979/1088, train_loss: 0.0294\n",
      "980/1088, train_loss: 0.0311\n",
      "981/1088, train_loss: 0.0293\n",
      "982/1088, train_loss: 0.0292\n",
      "983/1088, train_loss: 0.0322\n",
      "984/1088, train_loss: 0.0306\n",
      "985/1088, train_loss: 0.0284\n",
      "986/1088, train_loss: 0.0281\n",
      "987/1088, train_loss: 0.0307\n",
      "988/1088, train_loss: 0.0274\n",
      "989/1088, train_loss: 0.0284\n",
      "990/1088, train_loss: 0.0276\n",
      "991/1088, train_loss: 0.0284\n",
      "992/1088, train_loss: 0.0285\n",
      "993/1088, train_loss: 0.0276\n",
      "994/1088, train_loss: 0.0265\n",
      "995/1088, train_loss: 0.0327\n",
      "996/1088, train_loss: 0.0310\n",
      "997/1088, train_loss: 0.0303\n",
      "998/1088, train_loss: 0.0294\n",
      "999/1088, train_loss: 0.0298\n",
      "1000/1088, train_loss: 0.0277\n",
      "1001/1088, train_loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002/1088, train_loss: 0.0333\n",
      "1003/1088, train_loss: 0.0269\n",
      "1004/1088, train_loss: 0.0274\n",
      "1005/1088, train_loss: 0.0278\n",
      "1006/1088, train_loss: 0.0287\n",
      "1007/1088, train_loss: 0.0278\n",
      "1008/1088, train_loss: 0.0282\n",
      "1009/1088, train_loss: 0.0313\n",
      "1010/1088, train_loss: 0.0278\n",
      "1011/1088, train_loss: 0.0274\n",
      "1012/1088, train_loss: 0.0268\n",
      "1013/1088, train_loss: 0.0295\n",
      "1014/1088, train_loss: 0.0290\n",
      "1015/1088, train_loss: 0.0298\n",
      "1016/1088, train_loss: 0.0300\n",
      "1017/1088, train_loss: 0.0288\n",
      "1018/1088, train_loss: 0.0299\n",
      "1019/1088, train_loss: 0.0306\n",
      "1020/1088, train_loss: 0.0299\n",
      "1021/1088, train_loss: 0.0295\n",
      "1022/1088, train_loss: 0.0308\n",
      "1023/1088, train_loss: 0.0292\n",
      "1024/1088, train_loss: 0.0307\n",
      "1025/1088, train_loss: 0.0274\n",
      "1026/1088, train_loss: 0.0293\n",
      "1027/1088, train_loss: 0.0292\n",
      "1028/1088, train_loss: 0.0327\n",
      "1029/1088, train_loss: 0.0303\n",
      "1030/1088, train_loss: 0.0303\n",
      "1031/1088, train_loss: 0.0341\n",
      "1032/1088, train_loss: 0.0288\n",
      "1033/1088, train_loss: 0.0316\n",
      "1034/1088, train_loss: 0.0304\n",
      "1035/1088, train_loss: 0.0310\n",
      "1036/1088, train_loss: 0.0297\n",
      "1037/1088, train_loss: 0.0304\n",
      "1038/1088, train_loss: 0.0313\n",
      "1039/1088, train_loss: 0.0322\n",
      "1040/1088, train_loss: 0.0290\n",
      "1041/1088, train_loss: 0.0269\n",
      "1042/1088, train_loss: 0.0300\n",
      "1043/1088, train_loss: 0.0304\n",
      "1044/1088, train_loss: 0.0285\n",
      "1045/1088, train_loss: 0.0299\n",
      "1046/1088, train_loss: 0.0309\n",
      "1047/1088, train_loss: 0.0281\n",
      "1048/1088, train_loss: 0.0290\n",
      "1049/1088, train_loss: 0.0287\n",
      "1050/1088, train_loss: 0.0292\n",
      "1051/1088, train_loss: 0.0279\n",
      "1052/1088, train_loss: 0.0323\n",
      "1053/1088, train_loss: 0.0291\n",
      "1054/1088, train_loss: 0.0304\n",
      "1055/1088, train_loss: 0.0307\n",
      "1056/1088, train_loss: 0.0306\n",
      "1057/1088, train_loss: 0.0281\n",
      "1058/1088, train_loss: 0.0285\n",
      "1059/1088, train_loss: 0.0278\n",
      "1060/1088, train_loss: 0.0297\n",
      "1061/1088, train_loss: 0.0320\n",
      "1062/1088, train_loss: 0.0276\n",
      "1063/1088, train_loss: 0.0301\n",
      "1064/1088, train_loss: 0.0309\n",
      "1065/1088, train_loss: 0.0283\n",
      "1066/1088, train_loss: 0.0309\n",
      "1067/1088, train_loss: 0.0291\n",
      "1068/1088, train_loss: 0.0286\n",
      "1069/1088, train_loss: 0.0286\n",
      "1070/1088, train_loss: 0.0290\n",
      "1071/1088, train_loss: 0.0298\n",
      "1072/1088, train_loss: 0.0302\n",
      "1073/1088, train_loss: 0.0292\n",
      "1074/1088, train_loss: 0.0289\n",
      "1075/1088, train_loss: 0.0307\n",
      "1076/1088, train_loss: 0.0285\n",
      "1077/1088, train_loss: 0.0292\n",
      "1078/1088, train_loss: 0.0284\n",
      "1079/1088, train_loss: 0.0295\n",
      "1080/1088, train_loss: 0.0296\n",
      "1081/1088, train_loss: 0.0290\n",
      "1082/1088, train_loss: 0.0284\n",
      "1083/1088, train_loss: 0.0286\n",
      "1084/1088, train_loss: 0.0282\n",
      "1085/1088, train_loss: 0.0308\n",
      "1086/1088, train_loss: 0.0300\n",
      "1087/1088, train_loss: 0.0287\n",
      "1088/1088, train_loss: 0.0281\n",
      "1089/1088, train_loss: 0.0276\n",
      "epoch 6 average loss: 0.0301, train_dice: 0.9700\n",
      "epoch 6 average loss: 0.0301\n",
      "saved new best metric model\n",
      "current epoch: 6 current mean dice: 0.9673 best mean dice: 0.9673 at epoch 6\n",
      "--------------------------------------------------\n",
      "epoch 7/50\n",
      "1/1088, train_loss: 0.0311\n",
      "2/1088, train_loss: 0.0269\n",
      "3/1088, train_loss: 0.0317\n",
      "4/1088, train_loss: 0.0307\n",
      "5/1088, train_loss: 0.0307\n",
      "6/1088, train_loss: 0.0298\n",
      "7/1088, train_loss: 0.0312\n",
      "8/1088, train_loss: 0.0294\n",
      "9/1088, train_loss: 0.0315\n",
      "10/1088, train_loss: 0.0301\n",
      "11/1088, train_loss: 0.0297\n",
      "12/1088, train_loss: 0.0312\n",
      "13/1088, train_loss: 0.0303\n",
      "14/1088, train_loss: 0.0303\n",
      "15/1088, train_loss: 0.0284\n",
      "16/1088, train_loss: 0.0308\n",
      "17/1088, train_loss: 0.0282\n",
      "18/1088, train_loss: 0.0294\n",
      "19/1088, train_loss: 0.0298\n",
      "20/1088, train_loss: 0.0285\n",
      "21/1088, train_loss: 0.0291\n",
      "22/1088, train_loss: 0.0279\n",
      "23/1088, train_loss: 0.0316\n",
      "24/1088, train_loss: 0.0258\n",
      "25/1088, train_loss: 0.0287\n",
      "26/1088, train_loss: 0.0305\n",
      "27/1088, train_loss: 0.0327\n",
      "28/1088, train_loss: 0.0283\n",
      "29/1088, train_loss: 0.0308\n",
      "30/1088, train_loss: 0.0281\n",
      "31/1088, train_loss: 0.0362\n",
      "32/1088, train_loss: 0.0266\n",
      "33/1088, train_loss: 0.0297\n",
      "34/1088, train_loss: 0.0285\n",
      "35/1088, train_loss: 0.0284\n",
      "36/1088, train_loss: 0.0306\n",
      "37/1088, train_loss: 0.0266\n",
      "38/1088, train_loss: 0.0289\n",
      "39/1088, train_loss: 0.0304\n",
      "40/1088, train_loss: 0.0309\n",
      "41/1088, train_loss: 0.0290\n",
      "42/1088, train_loss: 0.0295\n",
      "43/1088, train_loss: 0.0281\n",
      "44/1088, train_loss: 0.0326\n",
      "45/1088, train_loss: 0.0292\n",
      "46/1088, train_loss: 0.0298\n",
      "47/1088, train_loss: 0.0302\n",
      "48/1088, train_loss: 0.0333\n",
      "49/1088, train_loss: 0.0294\n",
      "50/1088, train_loss: 0.0293\n",
      "51/1088, train_loss: 0.0293\n",
      "52/1088, train_loss: 0.0291\n",
      "53/1088, train_loss: 0.0297\n",
      "54/1088, train_loss: 0.0292\n",
      "55/1088, train_loss: 0.0290\n",
      "56/1088, train_loss: 0.0289\n",
      "57/1088, train_loss: 0.0290\n",
      "58/1088, train_loss: 0.0275\n",
      "59/1088, train_loss: 0.0279\n",
      "60/1088, train_loss: 0.0297\n",
      "61/1088, train_loss: 0.0295\n",
      "62/1088, train_loss: 0.0303\n",
      "63/1088, train_loss: 0.0282\n",
      "64/1088, train_loss: 0.0304\n",
      "65/1088, train_loss: 0.0276\n",
      "66/1088, train_loss: 0.0299\n",
      "67/1088, train_loss: 0.0314\n",
      "68/1088, train_loss: 0.0294\n",
      "69/1088, train_loss: 0.0325\n",
      "70/1088, train_loss: 0.0319\n",
      "71/1088, train_loss: 0.0341\n",
      "72/1088, train_loss: 0.0307\n",
      "73/1088, train_loss: 0.0286\n",
      "74/1088, train_loss: 0.0272\n",
      "75/1088, train_loss: 0.0301\n",
      "76/1088, train_loss: 0.0309\n",
      "77/1088, train_loss: 0.0280\n",
      "78/1088, train_loss: 0.0289\n",
      "79/1088, train_loss: 0.0267\n",
      "80/1088, train_loss: 0.0306\n",
      "81/1088, train_loss: 0.0299\n",
      "82/1088, train_loss: 0.0309\n",
      "83/1088, train_loss: 0.0292\n",
      "84/1088, train_loss: 0.0302\n",
      "85/1088, train_loss: 0.0304\n",
      "86/1088, train_loss: 0.0291\n",
      "87/1088, train_loss: 0.0306\n",
      "88/1088, train_loss: 0.0295\n",
      "89/1088, train_loss: 0.0301\n",
      "90/1088, train_loss: 0.0295\n",
      "91/1088, train_loss: 0.0279\n",
      "92/1088, train_loss: 0.0280\n",
      "93/1088, train_loss: 0.0286\n",
      "94/1088, train_loss: 0.0278\n",
      "95/1088, train_loss: 0.0306\n",
      "96/1088, train_loss: 0.0311\n",
      "97/1088, train_loss: 0.0281\n",
      "98/1088, train_loss: 0.0272\n",
      "99/1088, train_loss: 0.0290\n",
      "100/1088, train_loss: 0.0301\n",
      "101/1088, train_loss: 0.0278\n",
      "102/1088, train_loss: 0.0309\n",
      "103/1088, train_loss: 0.0301\n",
      "104/1088, train_loss: 0.0275\n",
      "105/1088, train_loss: 0.0280\n",
      "106/1088, train_loss: 0.0296\n",
      "107/1088, train_loss: 0.0282\n",
      "108/1088, train_loss: 0.0268\n",
      "109/1088, train_loss: 0.0288\n",
      "110/1088, train_loss: 0.0301\n",
      "111/1088, train_loss: 0.0280\n",
      "112/1088, train_loss: 0.0339\n",
      "113/1088, train_loss: 0.0289\n",
      "114/1088, train_loss: 0.0282\n",
      "115/1088, train_loss: 0.0286\n",
      "116/1088, train_loss: 0.0283\n",
      "117/1088, train_loss: 0.0299\n",
      "118/1088, train_loss: 0.0307\n",
      "119/1088, train_loss: 0.0263\n",
      "120/1088, train_loss: 0.0298\n",
      "121/1088, train_loss: 0.0301\n",
      "122/1088, train_loss: 0.0319\n",
      "123/1088, train_loss: 0.0301\n",
      "124/1088, train_loss: 0.0302\n",
      "125/1088, train_loss: 0.0286\n",
      "126/1088, train_loss: 0.0303\n",
      "127/1088, train_loss: 0.0284\n",
      "128/1088, train_loss: 0.0296\n",
      "129/1088, train_loss: 0.0306\n",
      "130/1088, train_loss: 0.0284\n",
      "131/1088, train_loss: 0.0284\n",
      "132/1088, train_loss: 0.0313\n",
      "133/1088, train_loss: 0.0298\n",
      "134/1088, train_loss: 0.0308\n",
      "135/1088, train_loss: 0.0298\n",
      "136/1088, train_loss: 0.0289\n",
      "137/1088, train_loss: 0.0294\n",
      "138/1088, train_loss: 0.0294\n",
      "139/1088, train_loss: 0.0304\n",
      "140/1088, train_loss: 0.0283\n",
      "141/1088, train_loss: 0.0288\n",
      "142/1088, train_loss: 0.0280\n",
      "143/1088, train_loss: 0.0308\n",
      "144/1088, train_loss: 0.0332\n",
      "145/1088, train_loss: 0.0306\n",
      "146/1088, train_loss: 0.0271\n",
      "147/1088, train_loss: 0.0290\n",
      "148/1088, train_loss: 0.0292\n",
      "149/1088, train_loss: 0.0376\n",
      "150/1088, train_loss: 0.0299\n",
      "151/1088, train_loss: 0.0323\n",
      "152/1088, train_loss: 0.0298\n",
      "153/1088, train_loss: 0.0297\n",
      "154/1088, train_loss: 0.0314\n",
      "155/1088, train_loss: 0.0302\n",
      "156/1088, train_loss: 0.0297\n",
      "157/1088, train_loss: 0.0277\n",
      "158/1088, train_loss: 0.0297\n",
      "159/1088, train_loss: 0.0322\n",
      "160/1088, train_loss: 0.0292\n",
      "161/1088, train_loss: 0.0291\n",
      "162/1088, train_loss: 0.0277\n",
      "163/1088, train_loss: 0.0288\n",
      "164/1088, train_loss: 0.0281\n",
      "165/1088, train_loss: 0.0296\n",
      "166/1088, train_loss: 0.0270\n",
      "167/1088, train_loss: 0.0293\n",
      "168/1088, train_loss: 0.0295\n",
      "169/1088, train_loss: 0.0286\n",
      "170/1088, train_loss: 0.0295\n",
      "171/1088, train_loss: 0.0306\n",
      "172/1088, train_loss: 0.0285\n",
      "173/1088, train_loss: 0.0274\n",
      "174/1088, train_loss: 0.0289\n",
      "175/1088, train_loss: 0.0297\n",
      "176/1088, train_loss: 0.0278\n",
      "177/1088, train_loss: 0.0275\n",
      "178/1088, train_loss: 0.0283\n",
      "179/1088, train_loss: 0.0300\n",
      "180/1088, train_loss: 0.0296\n",
      "181/1088, train_loss: 0.0267\n",
      "182/1088, train_loss: 0.0279\n",
      "183/1088, train_loss: 0.0277\n",
      "184/1088, train_loss: 0.0280\n",
      "185/1088, train_loss: 0.0295\n",
      "186/1088, train_loss: 0.0279\n",
      "187/1088, train_loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/1088, train_loss: 0.0324\n",
      "189/1088, train_loss: 0.0287\n",
      "190/1088, train_loss: 0.0311\n",
      "191/1088, train_loss: 0.0281\n",
      "192/1088, train_loss: 0.0287\n",
      "193/1088, train_loss: 0.0276\n",
      "194/1088, train_loss: 0.0312\n",
      "195/1088, train_loss: 0.0283\n",
      "196/1088, train_loss: 0.0281\n",
      "197/1088, train_loss: 0.0291\n",
      "198/1088, train_loss: 0.0277\n",
      "199/1088, train_loss: 0.0296\n",
      "200/1088, train_loss: 0.0284\n",
      "201/1088, train_loss: 0.0307\n",
      "202/1088, train_loss: 0.0292\n",
      "203/1088, train_loss: 0.0324\n",
      "204/1088, train_loss: 0.0349\n",
      "205/1088, train_loss: 0.0283\n",
      "206/1088, train_loss: 0.0314\n",
      "207/1088, train_loss: 0.0296\n",
      "208/1088, train_loss: 0.0309\n",
      "209/1088, train_loss: 0.0309\n",
      "210/1088, train_loss: 0.0313\n",
      "211/1088, train_loss: 0.0302\n",
      "212/1088, train_loss: 0.0281\n",
      "213/1088, train_loss: 0.0323\n",
      "214/1088, train_loss: 0.0310\n",
      "215/1088, train_loss: 0.0302\n",
      "216/1088, train_loss: 0.0280\n",
      "217/1088, train_loss: 0.0293\n",
      "218/1088, train_loss: 0.0302\n",
      "219/1088, train_loss: 0.0303\n",
      "220/1088, train_loss: 0.0299\n",
      "221/1088, train_loss: 0.0294\n",
      "222/1088, train_loss: 0.0304\n",
      "223/1088, train_loss: 0.0273\n",
      "224/1088, train_loss: 0.0320\n",
      "225/1088, train_loss: 0.0316\n",
      "226/1088, train_loss: 0.0300\n",
      "227/1088, train_loss: 0.0309\n",
      "228/1088, train_loss: 0.0304\n",
      "229/1088, train_loss: 0.0297\n",
      "230/1088, train_loss: 0.0322\n",
      "231/1088, train_loss: 0.0290\n",
      "232/1088, train_loss: 0.0306\n",
      "233/1088, train_loss: 0.0301\n",
      "234/1088, train_loss: 0.0295\n",
      "235/1088, train_loss: 0.0307\n",
      "236/1088, train_loss: 0.0325\n",
      "237/1088, train_loss: 0.0286\n",
      "238/1088, train_loss: 0.0362\n",
      "239/1088, train_loss: 0.0280\n",
      "240/1088, train_loss: 0.0280\n",
      "241/1088, train_loss: 0.0300\n",
      "242/1088, train_loss: 0.0299\n",
      "243/1088, train_loss: 0.0298\n",
      "244/1088, train_loss: 0.0275\n",
      "245/1088, train_loss: 0.0309\n",
      "246/1088, train_loss: 0.0281\n",
      "247/1088, train_loss: 0.0312\n",
      "248/1088, train_loss: 0.0297\n",
      "249/1088, train_loss: 0.0300\n",
      "250/1088, train_loss: 0.0291\n",
      "251/1088, train_loss: 0.0297\n",
      "252/1088, train_loss: 0.0293\n",
      "253/1088, train_loss: 0.0291\n",
      "254/1088, train_loss: 0.0296\n",
      "255/1088, train_loss: 0.0290\n",
      "256/1088, train_loss: 0.0276\n",
      "257/1088, train_loss: 0.0289\n",
      "258/1088, train_loss: 0.0289\n",
      "259/1088, train_loss: 0.0282\n",
      "260/1088, train_loss: 0.0302\n",
      "261/1088, train_loss: 0.0283\n",
      "262/1088, train_loss: 0.0287\n",
      "263/1088, train_loss: 0.0262\n",
      "264/1088, train_loss: 0.0295\n",
      "265/1088, train_loss: 0.0271\n",
      "266/1088, train_loss: 0.0265\n",
      "267/1088, train_loss: 0.0304\n",
      "268/1088, train_loss: 0.0339\n",
      "269/1088, train_loss: 0.0284\n",
      "270/1088, train_loss: 0.0295\n",
      "271/1088, train_loss: 0.0309\n",
      "272/1088, train_loss: 0.0300\n",
      "273/1088, train_loss: 0.0293\n",
      "274/1088, train_loss: 0.0268\n",
      "275/1088, train_loss: 0.0300\n",
      "276/1088, train_loss: 0.0286\n",
      "277/1088, train_loss: 0.0301\n",
      "278/1088, train_loss: 0.0272\n",
      "279/1088, train_loss: 0.0271\n",
      "280/1088, train_loss: 0.0282\n",
      "281/1088, train_loss: 0.0302\n",
      "282/1088, train_loss: 0.0303\n",
      "283/1088, train_loss: 0.0311\n",
      "284/1088, train_loss: 0.0333\n",
      "285/1088, train_loss: 0.0286\n",
      "286/1088, train_loss: 0.0297\n",
      "287/1088, train_loss: 0.0316\n",
      "288/1088, train_loss: 0.0290\n",
      "289/1088, train_loss: 0.0287\n",
      "290/1088, train_loss: 0.0305\n",
      "291/1088, train_loss: 0.0309\n",
      "292/1088, train_loss: 0.0310\n",
      "293/1088, train_loss: 0.0280\n",
      "294/1088, train_loss: 0.0288\n",
      "295/1088, train_loss: 0.0330\n",
      "296/1088, train_loss: 0.0288\n",
      "297/1088, train_loss: 0.0294\n",
      "298/1088, train_loss: 0.0274\n",
      "299/1088, train_loss: 0.0293\n",
      "300/1088, train_loss: 0.0278\n",
      "301/1088, train_loss: 0.0283\n",
      "302/1088, train_loss: 0.0293\n",
      "303/1088, train_loss: 0.0297\n",
      "304/1088, train_loss: 0.0302\n",
      "305/1088, train_loss: 0.0293\n",
      "306/1088, train_loss: 0.0349\n",
      "307/1088, train_loss: 0.0291\n",
      "308/1088, train_loss: 0.0300\n",
      "309/1088, train_loss: 0.0331\n",
      "310/1088, train_loss: 0.0278\n",
      "311/1088, train_loss: 0.0311\n",
      "312/1088, train_loss: 0.0279\n",
      "313/1088, train_loss: 0.0319\n",
      "314/1088, train_loss: 0.0321\n",
      "315/1088, train_loss: 0.0299\n",
      "316/1088, train_loss: 0.0283\n",
      "317/1088, train_loss: 0.0283\n",
      "318/1088, train_loss: 0.0295\n",
      "319/1088, train_loss: 0.0298\n",
      "320/1088, train_loss: 0.0284\n",
      "321/1088, train_loss: 0.0299\n",
      "322/1088, train_loss: 0.0289\n",
      "323/1088, train_loss: 0.0314\n",
      "324/1088, train_loss: 0.0302\n",
      "325/1088, train_loss: 0.0301\n",
      "326/1088, train_loss: 0.0315\n",
      "327/1088, train_loss: 0.0310\n",
      "328/1088, train_loss: 0.0322\n",
      "329/1088, train_loss: 0.0289\n",
      "330/1088, train_loss: 0.0283\n",
      "331/1088, train_loss: 0.0292\n",
      "332/1088, train_loss: 0.0307\n",
      "333/1088, train_loss: 0.0274\n",
      "334/1088, train_loss: 0.0277\n",
      "335/1088, train_loss: 0.0289\n",
      "336/1088, train_loss: 0.0291\n",
      "337/1088, train_loss: 0.0299\n",
      "338/1088, train_loss: 0.0287\n",
      "339/1088, train_loss: 0.0300\n",
      "340/1088, train_loss: 0.0295\n",
      "341/1088, train_loss: 0.0272\n",
      "342/1088, train_loss: 0.0283\n",
      "343/1088, train_loss: 0.0291\n",
      "344/1088, train_loss: 0.0281\n",
      "345/1088, train_loss: 0.0289\n",
      "346/1088, train_loss: 0.0291\n",
      "347/1088, train_loss: 0.0300\n",
      "348/1088, train_loss: 0.0307\n",
      "349/1088, train_loss: 0.0300\n",
      "350/1088, train_loss: 0.0312\n",
      "351/1088, train_loss: 0.0302\n",
      "352/1088, train_loss: 0.0285\n",
      "353/1088, train_loss: 0.0280\n",
      "354/1088, train_loss: 0.0293\n",
      "355/1088, train_loss: 0.0284\n",
      "356/1088, train_loss: 0.0297\n",
      "357/1088, train_loss: 0.0286\n",
      "358/1088, train_loss: 0.0303\n",
      "359/1088, train_loss: 0.0326\n",
      "360/1088, train_loss: 0.0270\n",
      "361/1088, train_loss: 0.0319\n",
      "362/1088, train_loss: 0.0318\n",
      "363/1088, train_loss: 0.0301\n",
      "364/1088, train_loss: 0.0293\n",
      "365/1088, train_loss: 0.0270\n",
      "366/1088, train_loss: 0.0322\n",
      "367/1088, train_loss: 0.0391\n",
      "368/1088, train_loss: 0.0287\n",
      "369/1088, train_loss: 0.0292\n",
      "370/1088, train_loss: 0.0285\n",
      "371/1088, train_loss: 0.0307\n",
      "372/1088, train_loss: 0.0313\n",
      "373/1088, train_loss: 0.0306\n",
      "374/1088, train_loss: 0.0287\n",
      "375/1088, train_loss: 0.0262\n",
      "376/1088, train_loss: 0.0293\n",
      "377/1088, train_loss: 0.0294\n",
      "378/1088, train_loss: 0.0284\n",
      "379/1088, train_loss: 0.0285\n",
      "380/1088, train_loss: 0.0271\n",
      "381/1088, train_loss: 0.0282\n",
      "382/1088, train_loss: 0.0311\n",
      "383/1088, train_loss: 0.0287\n",
      "384/1088, train_loss: 0.0303\n",
      "385/1088, train_loss: 0.0306\n",
      "386/1088, train_loss: 0.0293\n",
      "387/1088, train_loss: 0.0290\n",
      "388/1088, train_loss: 0.0324\n",
      "389/1088, train_loss: 0.0291\n",
      "390/1088, train_loss: 0.0264\n",
      "391/1088, train_loss: 0.0301\n",
      "392/1088, train_loss: 0.0303\n",
      "393/1088, train_loss: 0.0274\n",
      "394/1088, train_loss: 0.0293\n",
      "395/1088, train_loss: 0.0279\n",
      "396/1088, train_loss: 0.0311\n",
      "397/1088, train_loss: 0.0313\n",
      "398/1088, train_loss: 0.0285\n",
      "399/1088, train_loss: 0.0311\n",
      "400/1088, train_loss: 0.0316\n",
      "401/1088, train_loss: 0.0299\n",
      "402/1088, train_loss: 0.0290\n",
      "403/1088, train_loss: 0.0309\n",
      "404/1088, train_loss: 0.0278\n",
      "405/1088, train_loss: 0.0296\n",
      "406/1088, train_loss: 0.0297\n",
      "407/1088, train_loss: 0.0313\n",
      "408/1088, train_loss: 0.0343\n",
      "409/1088, train_loss: 0.0315\n",
      "410/1088, train_loss: 0.0275\n",
      "411/1088, train_loss: 0.0309\n",
      "412/1088, train_loss: 0.0301\n",
      "413/1088, train_loss: 0.0277\n",
      "414/1088, train_loss: 0.0290\n",
      "415/1088, train_loss: 0.0314\n",
      "416/1088, train_loss: 0.0282\n",
      "417/1088, train_loss: 0.0293\n",
      "418/1088, train_loss: 0.0271\n",
      "419/1088, train_loss: 0.0306\n",
      "420/1088, train_loss: 0.0315\n",
      "421/1088, train_loss: 0.0321\n",
      "422/1088, train_loss: 0.0291\n",
      "423/1088, train_loss: 0.0282\n",
      "424/1088, train_loss: 0.0274\n",
      "425/1088, train_loss: 0.0290\n",
      "426/1088, train_loss: 0.0284\n",
      "427/1088, train_loss: 0.0313\n",
      "428/1088, train_loss: 0.0283\n",
      "429/1088, train_loss: 0.0283\n",
      "430/1088, train_loss: 0.0300\n",
      "431/1088, train_loss: 0.0303\n",
      "432/1088, train_loss: 0.0273\n",
      "433/1088, train_loss: 0.0283\n",
      "434/1088, train_loss: 0.0285\n",
      "435/1088, train_loss: 0.0264\n",
      "436/1088, train_loss: 0.0332\n",
      "437/1088, train_loss: 0.0292\n",
      "438/1088, train_loss: 0.0287\n",
      "439/1088, train_loss: 0.0291\n",
      "440/1088, train_loss: 0.0277\n",
      "441/1088, train_loss: 0.0303\n",
      "442/1088, train_loss: 0.0283\n",
      "443/1088, train_loss: 0.0301\n",
      "444/1088, train_loss: 0.0315\n",
      "445/1088, train_loss: 0.0285\n",
      "446/1088, train_loss: 0.0293\n",
      "447/1088, train_loss: 0.0309\n",
      "448/1088, train_loss: 0.0308\n",
      "449/1088, train_loss: 0.0302\n",
      "450/1088, train_loss: 0.0299\n",
      "451/1088, train_loss: 0.0289\n",
      "452/1088, train_loss: 0.0286\n",
      "453/1088, train_loss: 0.0286\n",
      "454/1088, train_loss: 0.0285\n",
      "455/1088, train_loss: 0.0289\n",
      "456/1088, train_loss: 0.0272\n",
      "457/1088, train_loss: 0.0311\n",
      "458/1088, train_loss: 0.0321\n",
      "459/1088, train_loss: 0.0317\n",
      "460/1088, train_loss: 0.0278\n",
      "461/1088, train_loss: 0.0287\n",
      "462/1088, train_loss: 0.0308\n",
      "463/1088, train_loss: 0.0278\n",
      "464/1088, train_loss: 0.0306\n",
      "465/1088, train_loss: 0.0311\n",
      "466/1088, train_loss: 0.0345\n",
      "467/1088, train_loss: 0.0320\n",
      "468/1088, train_loss: 0.0288\n",
      "469/1088, train_loss: 0.0280\n",
      "470/1088, train_loss: 0.0340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471/1088, train_loss: 0.0289\n",
      "472/1088, train_loss: 0.0308\n",
      "473/1088, train_loss: 0.0281\n",
      "474/1088, train_loss: 0.0300\n",
      "475/1088, train_loss: 0.0329\n",
      "476/1088, train_loss: 0.0297\n",
      "477/1088, train_loss: 0.0322\n",
      "478/1088, train_loss: 0.0318\n",
      "479/1088, train_loss: 0.0311\n",
      "480/1088, train_loss: 0.0285\n",
      "481/1088, train_loss: 0.0283\n",
      "482/1088, train_loss: 0.0291\n",
      "483/1088, train_loss: 0.0314\n",
      "484/1088, train_loss: 0.0326\n",
      "485/1088, train_loss: 0.0310\n",
      "486/1088, train_loss: 0.0294\n",
      "487/1088, train_loss: 0.0299\n",
      "488/1088, train_loss: 0.0285\n",
      "489/1088, train_loss: 0.0319\n",
      "490/1088, train_loss: 0.0278\n",
      "491/1088, train_loss: 0.0318\n",
      "492/1088, train_loss: 0.0291\n",
      "493/1088, train_loss: 0.0286\n",
      "494/1088, train_loss: 0.0294\n",
      "495/1088, train_loss: 0.0278\n",
      "496/1088, train_loss: 0.0305\n",
      "497/1088, train_loss: 0.0282\n",
      "498/1088, train_loss: 0.0308\n",
      "499/1088, train_loss: 0.0307\n",
      "500/1088, train_loss: 0.0296\n",
      "501/1088, train_loss: 0.0304\n",
      "502/1088, train_loss: 0.0287\n",
      "503/1088, train_loss: 0.0298\n",
      "504/1088, train_loss: 0.0288\n",
      "505/1088, train_loss: 0.0302\n",
      "506/1088, train_loss: 0.0278\n",
      "507/1088, train_loss: 0.0276\n",
      "508/1088, train_loss: 0.0264\n",
      "509/1088, train_loss: 0.0281\n",
      "510/1088, train_loss: 0.0309\n",
      "511/1088, train_loss: 0.0291\n",
      "512/1088, train_loss: 0.0291\n",
      "513/1088, train_loss: 0.0285\n",
      "514/1088, train_loss: 0.0278\n",
      "515/1088, train_loss: 0.0281\n",
      "516/1088, train_loss: 0.0276\n",
      "517/1088, train_loss: 0.0285\n",
      "518/1088, train_loss: 0.0301\n",
      "519/1088, train_loss: 0.0304\n",
      "520/1088, train_loss: 0.0303\n",
      "521/1088, train_loss: 0.0297\n",
      "522/1088, train_loss: 0.0297\n",
      "523/1088, train_loss: 0.0343\n",
      "524/1088, train_loss: 0.0318\n",
      "525/1088, train_loss: 0.0291\n",
      "526/1088, train_loss: 0.0289\n",
      "527/1088, train_loss: 0.0305\n",
      "528/1088, train_loss: 0.0274\n",
      "529/1088, train_loss: 0.0302\n",
      "530/1088, train_loss: 0.0312\n",
      "531/1088, train_loss: 0.0286\n",
      "532/1088, train_loss: 0.0289\n",
      "533/1088, train_loss: 0.0306\n",
      "534/1088, train_loss: 0.0296\n",
      "535/1088, train_loss: 0.0283\n",
      "536/1088, train_loss: 0.0302\n",
      "537/1088, train_loss: 0.0304\n",
      "538/1088, train_loss: 0.0289\n",
      "539/1088, train_loss: 0.0283\n",
      "540/1088, train_loss: 0.0303\n",
      "541/1088, train_loss: 0.0304\n",
      "542/1088, train_loss: 0.0270\n",
      "543/1088, train_loss: 0.0283\n",
      "544/1088, train_loss: 0.0288\n",
      "545/1088, train_loss: 0.0292\n",
      "546/1088, train_loss: 0.0284\n",
      "547/1088, train_loss: 0.0297\n",
      "548/1088, train_loss: 0.0282\n",
      "549/1088, train_loss: 0.0297\n",
      "550/1088, train_loss: 0.0333\n",
      "551/1088, train_loss: 0.0282\n",
      "552/1088, train_loss: 0.0300\n",
      "553/1088, train_loss: 0.0292\n",
      "554/1088, train_loss: 0.0281\n",
      "555/1088, train_loss: 0.0277\n",
      "556/1088, train_loss: 0.0277\n",
      "557/1088, train_loss: 0.0270\n",
      "558/1088, train_loss: 0.0292\n",
      "559/1088, train_loss: 0.0280\n",
      "560/1088, train_loss: 0.0316\n",
      "561/1088, train_loss: 0.0282\n",
      "562/1088, train_loss: 0.0288\n",
      "563/1088, train_loss: 0.0270\n",
      "564/1088, train_loss: 0.0260\n",
      "565/1088, train_loss: 0.0355\n",
      "566/1088, train_loss: 0.0300\n",
      "567/1088, train_loss: 0.0263\n",
      "568/1088, train_loss: 0.0308\n",
      "569/1088, train_loss: 0.0286\n",
      "570/1088, train_loss: 0.0302\n",
      "571/1088, train_loss: 0.0301\n",
      "572/1088, train_loss: 0.0300\n",
      "573/1088, train_loss: 0.0266\n",
      "574/1088, train_loss: 0.0299\n",
      "575/1088, train_loss: 0.0288\n",
      "576/1088, train_loss: 0.0298\n",
      "577/1088, train_loss: 0.0289\n",
      "578/1088, train_loss: 0.0294\n",
      "579/1088, train_loss: 0.0279\n",
      "580/1088, train_loss: 0.0291\n",
      "581/1088, train_loss: 0.0310\n",
      "582/1088, train_loss: 0.0285\n",
      "583/1088, train_loss: 0.0298\n",
      "584/1088, train_loss: 0.0287\n",
      "585/1088, train_loss: 0.0271\n",
      "586/1088, train_loss: 0.0274\n",
      "587/1088, train_loss: 0.0275\n",
      "588/1088, train_loss: 0.0288\n",
      "589/1088, train_loss: 0.0311\n",
      "590/1088, train_loss: 0.0289\n",
      "591/1088, train_loss: 0.0304\n",
      "592/1088, train_loss: 0.0285\n",
      "593/1088, train_loss: 0.0329\n",
      "594/1088, train_loss: 0.0309\n",
      "595/1088, train_loss: 0.0297\n",
      "596/1088, train_loss: 0.0307\n",
      "597/1088, train_loss: 0.0295\n",
      "598/1088, train_loss: 0.0289\n",
      "599/1088, train_loss: 0.0303\n",
      "600/1088, train_loss: 0.0273\n",
      "601/1088, train_loss: 0.0276\n",
      "602/1088, train_loss: 0.0269\n",
      "603/1088, train_loss: 0.0298\n",
      "604/1088, train_loss: 0.0291\n",
      "605/1088, train_loss: 0.0285\n",
      "606/1088, train_loss: 0.0305\n",
      "607/1088, train_loss: 0.0285\n",
      "608/1088, train_loss: 0.0276\n",
      "609/1088, train_loss: 0.0306\n",
      "610/1088, train_loss: 0.0284\n",
      "611/1088, train_loss: 0.0288\n",
      "612/1088, train_loss: 0.0315\n",
      "613/1088, train_loss: 0.0287\n",
      "614/1088, train_loss: 0.0273\n",
      "615/1088, train_loss: 0.0291\n",
      "616/1088, train_loss: 0.0308\n",
      "617/1088, train_loss: 0.0281\n",
      "618/1088, train_loss: 0.0268\n",
      "619/1088, train_loss: 0.0298\n",
      "620/1088, train_loss: 0.0312\n",
      "621/1088, train_loss: 0.0295\n",
      "622/1088, train_loss: 0.0287\n",
      "623/1088, train_loss: 0.0298\n",
      "624/1088, train_loss: 0.0293\n",
      "625/1088, train_loss: 0.0279\n",
      "626/1088, train_loss: 0.0300\n",
      "627/1088, train_loss: 0.0296\n",
      "628/1088, train_loss: 0.0300\n",
      "629/1088, train_loss: 0.0339\n",
      "630/1088, train_loss: 0.0299\n",
      "631/1088, train_loss: 0.0315\n",
      "632/1088, train_loss: 0.0297\n",
      "633/1088, train_loss: 0.0278\n",
      "634/1088, train_loss: 0.0305\n",
      "635/1088, train_loss: 0.0304\n",
      "636/1088, train_loss: 0.0288\n",
      "637/1088, train_loss: 0.0304\n",
      "638/1088, train_loss: 0.0297\n",
      "639/1088, train_loss: 0.0294\n",
      "640/1088, train_loss: 0.0294\n",
      "641/1088, train_loss: 0.0334\n",
      "642/1088, train_loss: 0.0262\n",
      "643/1088, train_loss: 0.0295\n",
      "644/1088, train_loss: 0.0314\n",
      "645/1088, train_loss: 0.0278\n",
      "646/1088, train_loss: 0.0282\n",
      "647/1088, train_loss: 0.0280\n",
      "648/1088, train_loss: 0.0302\n",
      "649/1088, train_loss: 0.0300\n",
      "650/1088, train_loss: 0.0288\n",
      "651/1088, train_loss: 0.0316\n",
      "652/1088, train_loss: 0.0292\n",
      "653/1088, train_loss: 0.0305\n",
      "654/1088, train_loss: 0.0300\n",
      "655/1088, train_loss: 0.0286\n",
      "656/1088, train_loss: 0.0291\n",
      "657/1088, train_loss: 0.0306\n",
      "658/1088, train_loss: 0.0306\n",
      "659/1088, train_loss: 0.0276\n",
      "660/1088, train_loss: 0.0270\n",
      "661/1088, train_loss: 0.0286\n",
      "662/1088, train_loss: 0.0301\n",
      "663/1088, train_loss: 0.0274\n",
      "664/1088, train_loss: 0.0308\n",
      "665/1088, train_loss: 0.0312\n",
      "666/1088, train_loss: 0.0288\n",
      "667/1088, train_loss: 0.0298\n",
      "668/1088, train_loss: 0.0300\n",
      "669/1088, train_loss: 0.0306\n",
      "670/1088, train_loss: 0.0287\n",
      "671/1088, train_loss: 0.0278\n",
      "672/1088, train_loss: 0.0306\n",
      "673/1088, train_loss: 0.0295\n",
      "674/1088, train_loss: 0.0310\n",
      "675/1088, train_loss: 0.0278\n",
      "676/1088, train_loss: 0.0287\n",
      "677/1088, train_loss: 0.0295\n",
      "678/1088, train_loss: 0.0292\n",
      "679/1088, train_loss: 0.0316\n",
      "680/1088, train_loss: 0.0316\n",
      "681/1088, train_loss: 0.0361\n",
      "682/1088, train_loss: 0.0286\n",
      "683/1088, train_loss: 0.0302\n",
      "684/1088, train_loss: 0.0299\n",
      "685/1088, train_loss: 0.0313\n",
      "686/1088, train_loss: 0.0296\n",
      "687/1088, train_loss: 0.0297\n",
      "688/1088, train_loss: 0.0291\n",
      "689/1088, train_loss: 0.0302\n",
      "690/1088, train_loss: 0.0268\n",
      "691/1088, train_loss: 0.0282\n",
      "692/1088, train_loss: 0.0277\n",
      "693/1088, train_loss: 0.0284\n",
      "694/1088, train_loss: 0.0293\n",
      "695/1088, train_loss: 0.0329\n",
      "696/1088, train_loss: 0.0264\n",
      "697/1088, train_loss: 0.0290\n",
      "698/1088, train_loss: 0.0284\n",
      "699/1088, train_loss: 0.0273\n",
      "700/1088, train_loss: 0.0315\n",
      "701/1088, train_loss: 0.0301\n",
      "702/1088, train_loss: 0.0288\n",
      "703/1088, train_loss: 0.0268\n",
      "704/1088, train_loss: 0.0331\n",
      "705/1088, train_loss: 0.0307\n",
      "706/1088, train_loss: 0.0273\n",
      "707/1088, train_loss: 0.0327\n",
      "708/1088, train_loss: 0.0290\n",
      "709/1088, train_loss: 0.0292\n",
      "710/1088, train_loss: 0.0290\n",
      "711/1088, train_loss: 0.0291\n",
      "712/1088, train_loss: 0.0305\n",
      "713/1088, train_loss: 0.0274\n",
      "714/1088, train_loss: 0.0293\n",
      "715/1088, train_loss: 0.0274\n",
      "716/1088, train_loss: 0.0303\n",
      "717/1088, train_loss: 0.0301\n",
      "718/1088, train_loss: 0.0288\n",
      "719/1088, train_loss: 0.0295\n",
      "720/1088, train_loss: 0.0288\n",
      "721/1088, train_loss: 0.0313\n",
      "722/1088, train_loss: 0.0291\n",
      "723/1088, train_loss: 0.0314\n",
      "724/1088, train_loss: 0.0274\n",
      "725/1088, train_loss: 0.0294\n",
      "726/1088, train_loss: 0.0306\n",
      "727/1088, train_loss: 0.0292\n",
      "728/1088, train_loss: 0.0307\n",
      "729/1088, train_loss: 0.0296\n",
      "730/1088, train_loss: 0.0288\n",
      "731/1088, train_loss: 0.0307\n",
      "732/1088, train_loss: 0.0302\n",
      "733/1088, train_loss: 0.0312\n",
      "734/1088, train_loss: 0.0309\n",
      "735/1088, train_loss: 0.0292\n",
      "736/1088, train_loss: 0.0281\n",
      "737/1088, train_loss: 0.0309\n",
      "738/1088, train_loss: 0.0295\n",
      "739/1088, train_loss: 0.0284\n",
      "740/1088, train_loss: 0.0280\n",
      "741/1088, train_loss: 0.0278\n",
      "742/1088, train_loss: 0.0302\n",
      "743/1088, train_loss: 0.0276\n",
      "744/1088, train_loss: 0.0317\n",
      "745/1088, train_loss: 0.0290\n",
      "746/1088, train_loss: 0.0262\n",
      "747/1088, train_loss: 0.0306\n",
      "748/1088, train_loss: 0.0301\n",
      "749/1088, train_loss: 0.0314\n",
      "750/1088, train_loss: 0.0311\n",
      "751/1088, train_loss: 0.0292\n",
      "752/1088, train_loss: 0.0300\n",
      "753/1088, train_loss: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754/1088, train_loss: 0.0309\n",
      "755/1088, train_loss: 0.0271\n",
      "756/1088, train_loss: 0.0314\n",
      "757/1088, train_loss: 0.0274\n",
      "758/1088, train_loss: 0.0250\n",
      "759/1088, train_loss: 0.0292\n",
      "760/1088, train_loss: 0.0281\n",
      "761/1088, train_loss: 0.0292\n",
      "762/1088, train_loss: 0.0303\n",
      "763/1088, train_loss: 0.0323\n",
      "764/1088, train_loss: 0.0308\n",
      "765/1088, train_loss: 0.0290\n",
      "766/1088, train_loss: 0.0300\n",
      "767/1088, train_loss: 0.0268\n",
      "768/1088, train_loss: 0.0280\n",
      "769/1088, train_loss: 0.0312\n",
      "770/1088, train_loss: 0.0290\n",
      "771/1088, train_loss: 0.0262\n",
      "772/1088, train_loss: 0.0309\n",
      "773/1088, train_loss: 0.0364\n",
      "774/1088, train_loss: 0.0296\n",
      "775/1088, train_loss: 0.0303\n",
      "776/1088, train_loss: 0.0298\n",
      "777/1088, train_loss: 0.0299\n",
      "778/1088, train_loss: 0.0288\n",
      "779/1088, train_loss: 0.0283\n",
      "780/1088, train_loss: 0.0286\n",
      "781/1088, train_loss: 0.0307\n",
      "782/1088, train_loss: 0.0302\n",
      "783/1088, train_loss: 0.0289\n",
      "784/1088, train_loss: 0.0302\n",
      "785/1088, train_loss: 0.0297\n",
      "786/1088, train_loss: 0.0301\n",
      "787/1088, train_loss: 0.0337\n",
      "788/1088, train_loss: 0.0292\n",
      "789/1088, train_loss: 0.0323\n",
      "790/1088, train_loss: 0.0299\n",
      "791/1088, train_loss: 0.0308\n",
      "792/1088, train_loss: 0.0302\n",
      "793/1088, train_loss: 0.0273\n",
      "794/1088, train_loss: 0.0275\n",
      "795/1088, train_loss: 0.0295\n",
      "796/1088, train_loss: 0.0309\n",
      "797/1088, train_loss: 0.0297\n",
      "798/1088, train_loss: 0.0280\n",
      "799/1088, train_loss: 0.0268\n",
      "800/1088, train_loss: 0.0285\n",
      "801/1088, train_loss: 0.0272\n",
      "802/1088, train_loss: 0.0287\n",
      "803/1088, train_loss: 0.0338\n",
      "804/1088, train_loss: 0.0298\n",
      "805/1088, train_loss: 0.0306\n",
      "806/1088, train_loss: 0.0299\n",
      "807/1088, train_loss: 0.0277\n",
      "808/1088, train_loss: 0.0290\n",
      "809/1088, train_loss: 0.0289\n",
      "810/1088, train_loss: 0.0281\n",
      "811/1088, train_loss: 0.0297\n",
      "812/1088, train_loss: 0.0296\n",
      "813/1088, train_loss: 0.0306\n",
      "814/1088, train_loss: 0.0294\n",
      "815/1088, train_loss: 0.0292\n",
      "816/1088, train_loss: 0.0327\n",
      "817/1088, train_loss: 0.0291\n",
      "818/1088, train_loss: 0.0297\n",
      "819/1088, train_loss: 0.0293\n",
      "820/1088, train_loss: 0.0288\n",
      "821/1088, train_loss: 0.0288\n",
      "822/1088, train_loss: 0.0301\n",
      "823/1088, train_loss: 0.0286\n",
      "824/1088, train_loss: 0.0281\n",
      "825/1088, train_loss: 0.0301\n",
      "826/1088, train_loss: 0.0294\n",
      "827/1088, train_loss: 0.0288\n",
      "828/1088, train_loss: 0.0275\n",
      "829/1088, train_loss: 0.0295\n",
      "830/1088, train_loss: 0.0298\n",
      "831/1088, train_loss: 0.0295\n",
      "832/1088, train_loss: 0.0280\n",
      "833/1088, train_loss: 0.0268\n",
      "834/1088, train_loss: 0.0283\n",
      "835/1088, train_loss: 0.0274\n",
      "836/1088, train_loss: 0.0285\n",
      "837/1088, train_loss: 0.0401\n",
      "838/1088, train_loss: 0.0305\n",
      "839/1088, train_loss: 0.0273\n",
      "840/1088, train_loss: 0.0295\n",
      "841/1088, train_loss: 0.0273\n",
      "842/1088, train_loss: 0.0305\n",
      "843/1088, train_loss: 0.0285\n",
      "844/1088, train_loss: 0.0311\n",
      "845/1088, train_loss: 0.0329\n",
      "846/1088, train_loss: 0.0295\n",
      "847/1088, train_loss: 0.0300\n",
      "848/1088, train_loss: 0.0310\n",
      "849/1088, train_loss: 0.0281\n",
      "850/1088, train_loss: 0.0332\n",
      "851/1088, train_loss: 0.0300\n",
      "852/1088, train_loss: 0.0294\n",
      "853/1088, train_loss: 0.0293\n",
      "854/1088, train_loss: 0.0296\n",
      "855/1088, train_loss: 0.0305\n",
      "856/1088, train_loss: 0.0300\n",
      "857/1088, train_loss: 0.0276\n",
      "858/1088, train_loss: 0.0340\n",
      "859/1088, train_loss: 0.0289\n",
      "860/1088, train_loss: 0.0293\n",
      "861/1088, train_loss: 0.0284\n",
      "862/1088, train_loss: 0.0290\n",
      "863/1088, train_loss: 0.0314\n",
      "864/1088, train_loss: 0.0287\n",
      "865/1088, train_loss: 0.0280\n",
      "866/1088, train_loss: 0.0290\n",
      "867/1088, train_loss: 0.0258\n",
      "868/1088, train_loss: 0.0294\n",
      "869/1088, train_loss: 0.0299\n",
      "870/1088, train_loss: 0.0311\n",
      "871/1088, train_loss: 0.0283\n",
      "872/1088, train_loss: 0.0274\n",
      "873/1088, train_loss: 0.0285\n",
      "874/1088, train_loss: 0.0295\n",
      "875/1088, train_loss: 0.0296\n",
      "876/1088, train_loss: 0.0265\n",
      "877/1088, train_loss: 0.0308\n",
      "878/1088, train_loss: 0.0287\n",
      "879/1088, train_loss: 0.0281\n",
      "880/1088, train_loss: 0.0295\n",
      "881/1088, train_loss: 0.0307\n",
      "882/1088, train_loss: 0.0282\n",
      "883/1088, train_loss: 0.0303\n",
      "884/1088, train_loss: 0.0286\n",
      "885/1088, train_loss: 0.0275\n",
      "886/1088, train_loss: 0.0289\n",
      "887/1088, train_loss: 0.0287\n",
      "888/1088, train_loss: 0.0294\n",
      "889/1088, train_loss: 0.0273\n",
      "890/1088, train_loss: 0.0272\n",
      "891/1088, train_loss: 0.0309\n",
      "892/1088, train_loss: 0.0288\n",
      "893/1088, train_loss: 0.0297\n",
      "894/1088, train_loss: 0.0298\n",
      "895/1088, train_loss: 0.0288\n",
      "896/1088, train_loss: 0.0278\n",
      "897/1088, train_loss: 0.0300\n",
      "898/1088, train_loss: 0.0286\n",
      "899/1088, train_loss: 0.0291\n",
      "900/1088, train_loss: 0.0274\n",
      "901/1088, train_loss: 0.0311\n",
      "902/1088, train_loss: 0.0280\n",
      "903/1088, train_loss: 0.0284\n",
      "904/1088, train_loss: 0.0310\n",
      "905/1088, train_loss: 0.0277\n",
      "906/1088, train_loss: 0.0312\n",
      "907/1088, train_loss: 0.0296\n",
      "908/1088, train_loss: 0.0285\n",
      "909/1088, train_loss: 0.0301\n",
      "910/1088, train_loss: 0.0285\n",
      "911/1088, train_loss: 0.0300\n",
      "912/1088, train_loss: 0.0293\n",
      "913/1088, train_loss: 0.0279\n",
      "914/1088, train_loss: 0.0311\n",
      "915/1088, train_loss: 0.0296\n",
      "916/1088, train_loss: 0.0272\n",
      "917/1088, train_loss: 0.0283\n",
      "918/1088, train_loss: 0.0258\n",
      "919/1088, train_loss: 0.0286\n",
      "920/1088, train_loss: 0.0280\n",
      "921/1088, train_loss: 0.0275\n",
      "922/1088, train_loss: 0.0294\n",
      "923/1088, train_loss: 0.0310\n",
      "924/1088, train_loss: 0.0276\n",
      "925/1088, train_loss: 0.0299\n",
      "926/1088, train_loss: 0.0272\n",
      "927/1088, train_loss: 0.0296\n",
      "928/1088, train_loss: 0.0306\n",
      "929/1088, train_loss: 0.0273\n",
      "930/1088, train_loss: 0.0295\n",
      "931/1088, train_loss: 0.0279\n",
      "932/1088, train_loss: 0.0294\n",
      "933/1088, train_loss: 0.0283\n",
      "934/1088, train_loss: 0.0288\n",
      "935/1088, train_loss: 0.0277\n",
      "936/1088, train_loss: 0.0316\n",
      "937/1088, train_loss: 0.0312\n",
      "938/1088, train_loss: 0.0293\n",
      "939/1088, train_loss: 0.0308\n",
      "940/1088, train_loss: 0.0296\n",
      "941/1088, train_loss: 0.0282\n",
      "942/1088, train_loss: 0.0273\n",
      "943/1088, train_loss: 0.0294\n",
      "944/1088, train_loss: 0.0293\n",
      "945/1088, train_loss: 0.0305\n",
      "946/1088, train_loss: 0.0279\n",
      "947/1088, train_loss: 0.0301\n",
      "948/1088, train_loss: 0.0284\n",
      "949/1088, train_loss: 0.0311\n",
      "950/1088, train_loss: 0.0268\n",
      "951/1088, train_loss: 0.0276\n",
      "952/1088, train_loss: 0.0270\n",
      "953/1088, train_loss: 0.0321\n",
      "954/1088, train_loss: 0.0271\n",
      "955/1088, train_loss: 0.0276\n",
      "956/1088, train_loss: 0.0273\n",
      "957/1088, train_loss: 0.0316\n",
      "958/1088, train_loss: 0.0285\n",
      "959/1088, train_loss: 0.0297\n",
      "960/1088, train_loss: 0.0301\n",
      "961/1088, train_loss: 0.0280\n",
      "962/1088, train_loss: 0.0293\n",
      "963/1088, train_loss: 0.0301\n",
      "964/1088, train_loss: 0.0276\n",
      "965/1088, train_loss: 0.0290\n",
      "966/1088, train_loss: 0.0283\n",
      "967/1088, train_loss: 0.0301\n",
      "968/1088, train_loss: 0.0317\n",
      "969/1088, train_loss: 0.0269\n",
      "970/1088, train_loss: 0.0287\n",
      "971/1088, train_loss: 0.0301\n",
      "972/1088, train_loss: 0.0320\n",
      "973/1088, train_loss: 0.0295\n",
      "974/1088, train_loss: 0.0286\n",
      "975/1088, train_loss: 0.0302\n",
      "976/1088, train_loss: 0.0312\n",
      "977/1088, train_loss: 0.0291\n",
      "978/1088, train_loss: 0.0326\n",
      "979/1088, train_loss: 0.0297\n",
      "980/1088, train_loss: 0.0297\n",
      "981/1088, train_loss: 0.0287\n",
      "982/1088, train_loss: 0.0296\n",
      "983/1088, train_loss: 0.0319\n",
      "984/1088, train_loss: 0.0285\n",
      "985/1088, train_loss: 0.0316\n",
      "986/1088, train_loss: 0.0284\n",
      "987/1088, train_loss: 0.0288\n",
      "988/1088, train_loss: 0.0300\n",
      "989/1088, train_loss: 0.0284\n",
      "990/1088, train_loss: 0.0302\n",
      "991/1088, train_loss: 0.0287\n",
      "992/1088, train_loss: 0.0291\n",
      "993/1088, train_loss: 0.0308\n",
      "994/1088, train_loss: 0.0279\n",
      "995/1088, train_loss: 0.0297\n",
      "996/1088, train_loss: 0.0280\n",
      "997/1088, train_loss: 0.0307\n",
      "998/1088, train_loss: 0.0275\n",
      "999/1088, train_loss: 0.0291\n",
      "1000/1088, train_loss: 0.0274\n",
      "1001/1088, train_loss: 0.0300\n",
      "1002/1088, train_loss: 0.0277\n",
      "1003/1088, train_loss: 0.0296\n",
      "1004/1088, train_loss: 0.0267\n",
      "1005/1088, train_loss: 0.0271\n",
      "1006/1088, train_loss: 0.0302\n",
      "1007/1088, train_loss: 0.0263\n",
      "1008/1088, train_loss: 0.0295\n",
      "1009/1088, train_loss: 0.0296\n",
      "1010/1088, train_loss: 0.0313\n",
      "1011/1088, train_loss: 0.0292\n",
      "1012/1088, train_loss: 0.0280\n",
      "1013/1088, train_loss: 0.0285\n",
      "1014/1088, train_loss: 0.0279\n",
      "1015/1088, train_loss: 0.0309\n",
      "1016/1088, train_loss: 0.0296\n",
      "1017/1088, train_loss: 0.0311\n",
      "1018/1088, train_loss: 0.0300\n",
      "1019/1088, train_loss: 0.0296\n",
      "1020/1088, train_loss: 0.0278\n",
      "1021/1088, train_loss: 0.0289\n",
      "1022/1088, train_loss: 0.0295\n",
      "1023/1088, train_loss: 0.0278\n",
      "1024/1088, train_loss: 0.0292\n",
      "1025/1088, train_loss: 0.0351\n",
      "1026/1088, train_loss: 0.0323\n",
      "1027/1088, train_loss: 0.0319\n",
      "1028/1088, train_loss: 0.0296\n",
      "1029/1088, train_loss: 0.0290\n",
      "1030/1088, train_loss: 0.0283\n",
      "1031/1088, train_loss: 0.0295\n",
      "1032/1088, train_loss: 0.0297\n",
      "1033/1088, train_loss: 0.0287\n",
      "1034/1088, train_loss: 0.0374\n",
      "1035/1088, train_loss: 0.0289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036/1088, train_loss: 0.0327\n",
      "1037/1088, train_loss: 0.0286\n",
      "1038/1088, train_loss: 0.0295\n",
      "1039/1088, train_loss: 0.0297\n",
      "1040/1088, train_loss: 0.0305\n",
      "1041/1088, train_loss: 0.0319\n",
      "1042/1088, train_loss: 0.0305\n",
      "1043/1088, train_loss: 0.0280\n",
      "1044/1088, train_loss: 0.0314\n",
      "1045/1088, train_loss: 0.0296\n",
      "1046/1088, train_loss: 0.0272\n",
      "1047/1088, train_loss: 0.0334\n",
      "1048/1088, train_loss: 0.0311\n",
      "1049/1088, train_loss: 0.0305\n",
      "1050/1088, train_loss: 0.0296\n",
      "1051/1088, train_loss: 0.0293\n",
      "1052/1088, train_loss: 0.0286\n",
      "1053/1088, train_loss: 0.0289\n",
      "1054/1088, train_loss: 0.0309\n",
      "1055/1088, train_loss: 0.0299\n",
      "1056/1088, train_loss: 0.0294\n",
      "1057/1088, train_loss: 0.0306\n",
      "1058/1088, train_loss: 0.0275\n",
      "1059/1088, train_loss: 0.0294\n",
      "1060/1088, train_loss: 0.0281\n",
      "1061/1088, train_loss: 0.0295\n",
      "1062/1088, train_loss: 0.0304\n",
      "1063/1088, train_loss: 0.0271\n",
      "1064/1088, train_loss: 0.0285\n",
      "1065/1088, train_loss: 0.0288\n",
      "1066/1088, train_loss: 0.0291\n",
      "1067/1088, train_loss: 0.0262\n",
      "1068/1088, train_loss: 0.0294\n",
      "1069/1088, train_loss: 0.0318\n",
      "1070/1088, train_loss: 0.0279\n",
      "1071/1088, train_loss: 0.0269\n",
      "1072/1088, train_loss: 0.0305\n",
      "1073/1088, train_loss: 0.0300\n",
      "1074/1088, train_loss: 0.0297\n",
      "1075/1088, train_loss: 0.0277\n",
      "1076/1088, train_loss: 0.0297\n",
      "1077/1088, train_loss: 0.0281\n",
      "1078/1088, train_loss: 0.0302\n",
      "1079/1088, train_loss: 0.0289\n",
      "1080/1088, train_loss: 0.0284\n",
      "1081/1088, train_loss: 0.0270\n",
      "1082/1088, train_loss: 0.0295\n",
      "1083/1088, train_loss: 0.0283\n",
      "1084/1088, train_loss: 0.0287\n",
      "1085/1088, train_loss: 0.0283\n",
      "1086/1088, train_loss: 0.0286\n",
      "1087/1088, train_loss: 0.0273\n",
      "1088/1088, train_loss: 0.0304\n",
      "1089/1088, train_loss: 0.0283\n",
      "epoch 7 average loss: 0.0295, train_dice: 0.9706\n",
      "epoch 7 average loss: 0.0295\n",
      "--------------------------------------------------\n",
      "epoch 8/50\n",
      "1/1088, train_loss: 0.0284\n",
      "2/1088, train_loss: 0.0311\n",
      "3/1088, train_loss: 0.0297\n",
      "4/1088, train_loss: 0.0290\n",
      "5/1088, train_loss: 0.0283\n",
      "6/1088, train_loss: 0.0307\n",
      "7/1088, train_loss: 0.0296\n",
      "8/1088, train_loss: 0.0287\n",
      "9/1088, train_loss: 0.0283\n",
      "10/1088, train_loss: 0.0273\n",
      "11/1088, train_loss: 0.0284\n",
      "12/1088, train_loss: 0.0301\n",
      "13/1088, train_loss: 0.0244\n",
      "14/1088, train_loss: 0.0276\n",
      "15/1088, train_loss: 0.0287\n",
      "16/1088, train_loss: 0.0260\n",
      "17/1088, train_loss: 0.0261\n",
      "18/1088, train_loss: 0.0285\n",
      "19/1088, train_loss: 0.0305\n",
      "20/1088, train_loss: 0.0257\n",
      "21/1088, train_loss: 0.0299\n",
      "22/1088, train_loss: 0.0288\n",
      "23/1088, train_loss: 0.0329\n",
      "24/1088, train_loss: 0.0300\n",
      "25/1088, train_loss: 0.0289\n",
      "26/1088, train_loss: 0.0283\n",
      "27/1088, train_loss: 0.0285\n",
      "28/1088, train_loss: 0.0289\n",
      "29/1088, train_loss: 0.0298\n",
      "30/1088, train_loss: 0.0285\n",
      "31/1088, train_loss: 0.0284\n",
      "32/1088, train_loss: 0.0306\n",
      "33/1088, train_loss: 0.0280\n",
      "34/1088, train_loss: 0.0304\n",
      "35/1088, train_loss: 0.0285\n",
      "36/1088, train_loss: 0.0283\n",
      "37/1088, train_loss: 0.0289\n",
      "38/1088, train_loss: 0.0289\n",
      "39/1088, train_loss: 0.0273\n",
      "40/1088, train_loss: 0.0274\n",
      "41/1088, train_loss: 0.0309\n",
      "42/1088, train_loss: 0.0298\n",
      "43/1088, train_loss: 0.0321\n",
      "44/1088, train_loss: 0.0301\n",
      "45/1088, train_loss: 0.0279\n",
      "46/1088, train_loss: 0.0297\n",
      "47/1088, train_loss: 0.0299\n",
      "48/1088, train_loss: 0.0303\n",
      "49/1088, train_loss: 0.0319\n",
      "50/1088, train_loss: 0.0304\n",
      "51/1088, train_loss: 0.0285\n",
      "52/1088, train_loss: 0.0290\n",
      "53/1088, train_loss: 0.0303\n",
      "54/1088, train_loss: 0.0304\n",
      "55/1088, train_loss: 0.0314\n",
      "56/1088, train_loss: 0.0295\n",
      "57/1088, train_loss: 0.0298\n",
      "58/1088, train_loss: 0.0354\n",
      "59/1088, train_loss: 0.0296\n",
      "60/1088, train_loss: 0.0285\n",
      "61/1088, train_loss: 0.0303\n",
      "62/1088, train_loss: 0.0297\n",
      "63/1088, train_loss: 0.0328\n",
      "64/1088, train_loss: 0.0292\n",
      "65/1088, train_loss: 0.0276\n",
      "66/1088, train_loss: 0.0320\n",
      "67/1088, train_loss: 0.0304\n",
      "68/1088, train_loss: 0.0293\n",
      "69/1088, train_loss: 0.0315\n",
      "70/1088, train_loss: 0.0290\n",
      "71/1088, train_loss: 0.0283\n",
      "72/1088, train_loss: 0.0283\n",
      "73/1088, train_loss: 0.0292\n",
      "74/1088, train_loss: 0.0281\n",
      "75/1088, train_loss: 0.0299\n",
      "76/1088, train_loss: 0.0263\n",
      "77/1088, train_loss: 0.0286\n",
      "78/1088, train_loss: 0.0284\n",
      "79/1088, train_loss: 0.0290\n",
      "80/1088, train_loss: 0.0279\n",
      "81/1088, train_loss: 0.0354\n",
      "82/1088, train_loss: 0.0291\n",
      "83/1088, train_loss: 0.0292\n",
      "84/1088, train_loss: 0.0302\n",
      "85/1088, train_loss: 0.0320\n",
      "86/1088, train_loss: 0.0302\n",
      "87/1088, train_loss: 0.0282\n",
      "88/1088, train_loss: 0.0280\n",
      "89/1088, train_loss: 0.0291\n",
      "90/1088, train_loss: 0.0282\n",
      "91/1088, train_loss: 0.0282\n",
      "92/1088, train_loss: 0.0280\n",
      "93/1088, train_loss: 0.0286\n",
      "94/1088, train_loss: 0.0283\n",
      "95/1088, train_loss: 0.0273\n",
      "96/1088, train_loss: 0.0282\n",
      "97/1088, train_loss: 0.0262\n",
      "98/1088, train_loss: 0.0298\n",
      "99/1088, train_loss: 0.0286\n",
      "100/1088, train_loss: 0.0291\n",
      "101/1088, train_loss: 0.0301\n",
      "102/1088, train_loss: 0.0303\n",
      "103/1088, train_loss: 0.0301\n",
      "104/1088, train_loss: 0.0298\n",
      "105/1088, train_loss: 0.0285\n",
      "106/1088, train_loss: 0.0302\n",
      "107/1088, train_loss: 0.0279\n",
      "108/1088, train_loss: 0.0270\n",
      "109/1088, train_loss: 0.0266\n",
      "110/1088, train_loss: 0.0337\n",
      "111/1088, train_loss: 0.0340\n",
      "112/1088, train_loss: 0.0278\n",
      "113/1088, train_loss: 0.0329\n",
      "114/1088, train_loss: 0.0383\n",
      "115/1088, train_loss: 0.0271\n",
      "116/1088, train_loss: 0.0262\n",
      "117/1088, train_loss: 0.0344\n",
      "118/1088, train_loss: 0.0291\n",
      "119/1088, train_loss: 0.0308\n",
      "120/1088, train_loss: 0.0271\n",
      "121/1088, train_loss: 0.0278\n",
      "122/1088, train_loss: 0.0265\n",
      "123/1088, train_loss: 0.0313\n",
      "124/1088, train_loss: 0.0295\n",
      "125/1088, train_loss: 0.0283\n",
      "126/1088, train_loss: 0.0296\n",
      "127/1088, train_loss: 0.0281\n",
      "128/1088, train_loss: 0.0288\n",
      "129/1088, train_loss: 0.0298\n",
      "130/1088, train_loss: 0.0303\n",
      "131/1088, train_loss: 0.0284\n",
      "132/1088, train_loss: 0.0299\n",
      "133/1088, train_loss: 0.0300\n",
      "134/1088, train_loss: 0.0292\n",
      "135/1088, train_loss: 0.0281\n",
      "136/1088, train_loss: 0.0294\n",
      "137/1088, train_loss: 0.0325\n",
      "138/1088, train_loss: 0.0285\n",
      "139/1088, train_loss: 0.0266\n",
      "140/1088, train_loss: 0.0288\n",
      "141/1088, train_loss: 0.0284\n",
      "142/1088, train_loss: 0.0321\n",
      "143/1088, train_loss: 0.0299\n",
      "144/1088, train_loss: 0.0281\n",
      "145/1088, train_loss: 0.0278\n",
      "146/1088, train_loss: 0.0299\n",
      "147/1088, train_loss: 0.0278\n",
      "148/1088, train_loss: 0.0290\n",
      "149/1088, train_loss: 0.0340\n",
      "150/1088, train_loss: 0.0290\n",
      "151/1088, train_loss: 0.0274\n",
      "152/1088, train_loss: 0.0363\n",
      "153/1088, train_loss: 0.0269\n",
      "154/1088, train_loss: 0.0315\n",
      "155/1088, train_loss: 0.0268\n",
      "156/1088, train_loss: 0.0304\n",
      "157/1088, train_loss: 0.0288\n",
      "158/1088, train_loss: 0.0271\n",
      "159/1088, train_loss: 0.0270\n",
      "160/1088, train_loss: 0.0296\n",
      "161/1088, train_loss: 0.0263\n",
      "162/1088, train_loss: 0.0295\n",
      "163/1088, train_loss: 0.0295\n",
      "164/1088, train_loss: 0.0309\n",
      "165/1088, train_loss: 0.0287\n",
      "166/1088, train_loss: 0.0369\n",
      "167/1088, train_loss: 0.0283\n",
      "168/1088, train_loss: 0.0270\n",
      "169/1088, train_loss: 0.0290\n",
      "170/1088, train_loss: 0.0279\n",
      "171/1088, train_loss: 0.0272\n",
      "172/1088, train_loss: 0.0276\n",
      "173/1088, train_loss: 0.0290\n",
      "174/1088, train_loss: 0.0359\n",
      "175/1088, train_loss: 0.0310\n",
      "176/1088, train_loss: 0.0270\n",
      "177/1088, train_loss: 0.0300\n",
      "178/1088, train_loss: 0.0293\n",
      "179/1088, train_loss: 0.0285\n",
      "180/1088, train_loss: 0.0299\n",
      "181/1088, train_loss: 0.0277\n",
      "182/1088, train_loss: 0.0277\n",
      "183/1088, train_loss: 0.0271\n",
      "184/1088, train_loss: 0.0275\n",
      "185/1088, train_loss: 0.0319\n",
      "186/1088, train_loss: 0.0270\n",
      "187/1088, train_loss: 0.0315\n",
      "188/1088, train_loss: 0.0298\n",
      "189/1088, train_loss: 0.0292\n",
      "190/1088, train_loss: 0.0284\n",
      "191/1088, train_loss: 0.0275\n",
      "192/1088, train_loss: 0.0278\n",
      "193/1088, train_loss: 0.0298\n",
      "194/1088, train_loss: 0.0309\n",
      "195/1088, train_loss: 0.0277\n",
      "196/1088, train_loss: 0.0253\n",
      "197/1088, train_loss: 0.0298\n",
      "198/1088, train_loss: 0.0287\n",
      "199/1088, train_loss: 0.0297\n",
      "200/1088, train_loss: 0.0281\n",
      "201/1088, train_loss: 0.0282\n",
      "202/1088, train_loss: 0.0284\n",
      "203/1088, train_loss: 0.0298\n",
      "204/1088, train_loss: 0.0314\n",
      "205/1088, train_loss: 0.0306\n",
      "206/1088, train_loss: 0.0291\n",
      "207/1088, train_loss: 0.0291\n",
      "208/1088, train_loss: 0.0298\n",
      "209/1088, train_loss: 0.0283\n",
      "210/1088, train_loss: 0.0274\n",
      "211/1088, train_loss: 0.0289\n",
      "212/1088, train_loss: 0.0359\n",
      "213/1088, train_loss: 0.0293\n",
      "214/1088, train_loss: 0.0307\n",
      "215/1088, train_loss: 0.0276\n",
      "216/1088, train_loss: 0.0286\n",
      "217/1088, train_loss: 0.0276\n",
      "218/1088, train_loss: 0.0292\n",
      "219/1088, train_loss: 0.0264\n",
      "220/1088, train_loss: 0.0287\n",
      "221/1088, train_loss: 0.0284\n",
      "222/1088, train_loss: 0.0288\n",
      "223/1088, train_loss: 0.0283\n",
      "224/1088, train_loss: 0.0299\n",
      "225/1088, train_loss: 0.0262\n",
      "226/1088, train_loss: 0.0330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/1088, train_loss: 0.0270\n",
      "228/1088, train_loss: 0.0328\n",
      "229/1088, train_loss: 0.0273\n",
      "230/1088, train_loss: 0.0297\n",
      "231/1088, train_loss: 0.0314\n",
      "232/1088, train_loss: 0.0293\n",
      "233/1088, train_loss: 0.0294\n",
      "234/1088, train_loss: 0.0305\n",
      "235/1088, train_loss: 0.0305\n",
      "236/1088, train_loss: 0.0277\n",
      "237/1088, train_loss: 0.0279\n",
      "238/1088, train_loss: 0.0283\n",
      "239/1088, train_loss: 0.0276\n",
      "240/1088, train_loss: 0.0310\n",
      "241/1088, train_loss: 0.0293\n",
      "242/1088, train_loss: 0.0271\n",
      "243/1088, train_loss: 0.0279\n",
      "244/1088, train_loss: 0.0299\n",
      "245/1088, train_loss: 0.0283\n",
      "246/1088, train_loss: 0.0297\n",
      "247/1088, train_loss: 0.0296\n",
      "248/1088, train_loss: 0.0305\n",
      "249/1088, train_loss: 0.0273\n",
      "250/1088, train_loss: 0.0308\n",
      "251/1088, train_loss: 0.0332\n",
      "252/1088, train_loss: 0.0314\n",
      "253/1088, train_loss: 0.0307\n",
      "254/1088, train_loss: 0.0300\n",
      "255/1088, train_loss: 0.0301\n",
      "256/1088, train_loss: 0.0276\n",
      "257/1088, train_loss: 0.0299\n",
      "258/1088, train_loss: 0.0293\n",
      "259/1088, train_loss: 0.0288\n",
      "260/1088, train_loss: 0.0299\n",
      "261/1088, train_loss: 0.0298\n",
      "262/1088, train_loss: 0.0270\n",
      "263/1088, train_loss: 0.0290\n",
      "264/1088, train_loss: 0.0305\n",
      "265/1088, train_loss: 0.0272\n",
      "266/1088, train_loss: 0.0274\n",
      "267/1088, train_loss: 0.0345\n",
      "268/1088, train_loss: 0.0294\n",
      "269/1088, train_loss: 0.0316\n",
      "270/1088, train_loss: 0.0303\n",
      "271/1088, train_loss: 0.0301\n",
      "272/1088, train_loss: 0.0314\n",
      "273/1088, train_loss: 0.0299\n",
      "274/1088, train_loss: 0.0307\n",
      "275/1088, train_loss: 0.0292\n",
      "276/1088, train_loss: 0.0288\n",
      "277/1088, train_loss: 0.0297\n",
      "278/1088, train_loss: 0.0287\n",
      "279/1088, train_loss: 0.0329\n",
      "280/1088, train_loss: 0.0277\n",
      "281/1088, train_loss: 0.0299\n",
      "282/1088, train_loss: 0.0278\n",
      "283/1088, train_loss: 0.0288\n",
      "284/1088, train_loss: 0.0312\n",
      "285/1088, train_loss: 0.0287\n",
      "286/1088, train_loss: 0.0283\n",
      "287/1088, train_loss: 0.0300\n",
      "288/1088, train_loss: 0.0307\n",
      "289/1088, train_loss: 0.0287\n",
      "290/1088, train_loss: 0.0294\n",
      "291/1088, train_loss: 0.0297\n",
      "292/1088, train_loss: 0.0294\n",
      "293/1088, train_loss: 0.0298\n",
      "294/1088, train_loss: 0.0287\n",
      "295/1088, train_loss: 0.0300\n",
      "296/1088, train_loss: 0.0349\n",
      "297/1088, train_loss: 0.0281\n",
      "298/1088, train_loss: 0.0294\n",
      "299/1088, train_loss: 0.0274\n",
      "300/1088, train_loss: 0.0279\n",
      "301/1088, train_loss: 0.0341\n",
      "302/1088, train_loss: 0.0278\n",
      "303/1088, train_loss: 0.0283\n",
      "304/1088, train_loss: 0.0290\n",
      "305/1088, train_loss: 0.0287\n",
      "306/1088, train_loss: 0.0290\n",
      "307/1088, train_loss: 0.0281\n",
      "308/1088, train_loss: 0.0294\n",
      "309/1088, train_loss: 0.0332\n",
      "310/1088, train_loss: 0.0301\n",
      "311/1088, train_loss: 0.0280\n",
      "312/1088, train_loss: 0.0306\n",
      "313/1088, train_loss: 0.0257\n",
      "314/1088, train_loss: 0.0306\n",
      "315/1088, train_loss: 0.0301\n",
      "316/1088, train_loss: 0.0311\n",
      "317/1088, train_loss: 0.0311\n",
      "318/1088, train_loss: 0.0294\n",
      "319/1088, train_loss: 0.0286\n",
      "320/1088, train_loss: 0.0283\n",
      "321/1088, train_loss: 0.0310\n",
      "322/1088, train_loss: 0.0352\n",
      "323/1088, train_loss: 0.0299\n",
      "324/1088, train_loss: 0.0295\n",
      "325/1088, train_loss: 0.0286\n",
      "326/1088, train_loss: 0.0293\n",
      "327/1088, train_loss: 0.0296\n",
      "328/1088, train_loss: 0.0309\n",
      "329/1088, train_loss: 0.0282\n",
      "330/1088, train_loss: 0.0299\n",
      "331/1088, train_loss: 0.0310\n",
      "332/1088, train_loss: 0.0308\n",
      "333/1088, train_loss: 0.0325\n",
      "334/1088, train_loss: 0.0304\n",
      "335/1088, train_loss: 0.0287\n",
      "336/1088, train_loss: 0.0302\n",
      "337/1088, train_loss: 0.0285\n",
      "338/1088, train_loss: 0.0306\n",
      "339/1088, train_loss: 0.0309\n",
      "340/1088, train_loss: 0.0322\n",
      "341/1088, train_loss: 0.0288\n",
      "342/1088, train_loss: 0.0296\n",
      "343/1088, train_loss: 0.0299\n",
      "344/1088, train_loss: 0.0276\n",
      "345/1088, train_loss: 0.0297\n",
      "346/1088, train_loss: 0.0273\n",
      "347/1088, train_loss: 0.0298\n",
      "348/1088, train_loss: 0.0281\n",
      "349/1088, train_loss: 0.0281\n",
      "350/1088, train_loss: 0.0285\n",
      "351/1088, train_loss: 0.0325\n",
      "352/1088, train_loss: 0.0267\n",
      "353/1088, train_loss: 0.0305\n",
      "354/1088, train_loss: 0.0309\n",
      "355/1088, train_loss: 0.0297\n",
      "356/1088, train_loss: 0.0323\n",
      "357/1088, train_loss: 0.0291\n",
      "358/1088, train_loss: 0.0315\n",
      "359/1088, train_loss: 0.0313\n",
      "360/1088, train_loss: 0.0288\n",
      "361/1088, train_loss: 0.0301\n",
      "362/1088, train_loss: 0.0325\n",
      "363/1088, train_loss: 0.0281\n",
      "364/1088, train_loss: 0.0304\n",
      "365/1088, train_loss: 0.0288\n",
      "366/1088, train_loss: 0.0281\n",
      "367/1088, train_loss: 0.0298\n",
      "368/1088, train_loss: 0.0336\n",
      "369/1088, train_loss: 0.0317\n",
      "370/1088, train_loss: 0.0273\n",
      "371/1088, train_loss: 0.0323\n",
      "372/1088, train_loss: 0.0296\n",
      "373/1088, train_loss: 0.0333\n",
      "374/1088, train_loss: 0.0318\n",
      "375/1088, train_loss: 0.0305\n",
      "376/1088, train_loss: 0.0289\n",
      "377/1088, train_loss: 0.0293\n",
      "378/1088, train_loss: 0.0277\n",
      "379/1088, train_loss: 0.0285\n",
      "380/1088, train_loss: 0.0274\n",
      "381/1088, train_loss: 0.0306\n",
      "382/1088, train_loss: 0.0297\n",
      "383/1088, train_loss: 0.0329\n",
      "384/1088, train_loss: 0.0288\n",
      "385/1088, train_loss: 0.0300\n",
      "386/1088, train_loss: 0.0279\n",
      "387/1088, train_loss: 0.0325\n",
      "388/1088, train_loss: 0.0309\n",
      "389/1088, train_loss: 0.0263\n",
      "390/1088, train_loss: 0.0347\n",
      "391/1088, train_loss: 0.0280\n",
      "392/1088, train_loss: 0.0303\n",
      "393/1088, train_loss: 0.0287\n",
      "394/1088, train_loss: 0.0297\n",
      "395/1088, train_loss: 0.0277\n",
      "396/1088, train_loss: 0.0295\n",
      "397/1088, train_loss: 0.0294\n",
      "398/1088, train_loss: 0.0295\n",
      "399/1088, train_loss: 0.0296\n",
      "400/1088, train_loss: 0.0294\n",
      "401/1088, train_loss: 0.0280\n",
      "402/1088, train_loss: 0.0270\n",
      "403/1088, train_loss: 0.0269\n",
      "404/1088, train_loss: 0.0315\n",
      "405/1088, train_loss: 0.0264\n",
      "406/1088, train_loss: 0.0304\n",
      "407/1088, train_loss: 0.0288\n",
      "408/1088, train_loss: 0.0293\n",
      "409/1088, train_loss: 0.0268\n",
      "410/1088, train_loss: 0.0305\n",
      "411/1088, train_loss: 0.0292\n",
      "412/1088, train_loss: 0.0287\n",
      "413/1088, train_loss: 0.0284\n",
      "414/1088, train_loss: 0.0296\n",
      "415/1088, train_loss: 0.0298\n",
      "416/1088, train_loss: 0.0303\n",
      "417/1088, train_loss: 0.0286\n",
      "418/1088, train_loss: 0.0291\n",
      "419/1088, train_loss: 0.0287\n",
      "420/1088, train_loss: 0.0292\n",
      "421/1088, train_loss: 0.0295\n",
      "422/1088, train_loss: 0.0274\n",
      "423/1088, train_loss: 0.0268\n",
      "424/1088, train_loss: 0.0290\n",
      "425/1088, train_loss: 0.0298\n",
      "426/1088, train_loss: 0.0321\n",
      "427/1088, train_loss: 0.0284\n",
      "428/1088, train_loss: 0.0286\n",
      "429/1088, train_loss: 0.0287\n",
      "430/1088, train_loss: 0.0280\n",
      "431/1088, train_loss: 0.0315\n",
      "432/1088, train_loss: 0.0287\n",
      "433/1088, train_loss: 0.0288\n",
      "434/1088, train_loss: 0.0293\n",
      "435/1088, train_loss: 0.0287\n",
      "436/1088, train_loss: 0.0298\n",
      "437/1088, train_loss: 0.0283\n",
      "438/1088, train_loss: 0.0289\n",
      "439/1088, train_loss: 0.0288\n",
      "440/1088, train_loss: 0.0292\n",
      "441/1088, train_loss: 0.0281\n",
      "442/1088, train_loss: 0.0294\n",
      "443/1088, train_loss: 0.0285\n",
      "444/1088, train_loss: 0.0283\n",
      "445/1088, train_loss: 0.0303\n",
      "446/1088, train_loss: 0.0287\n",
      "447/1088, train_loss: 0.0321\n",
      "448/1088, train_loss: 0.0296\n",
      "449/1088, train_loss: 0.0269\n",
      "450/1088, train_loss: 0.0302\n",
      "451/1088, train_loss: 0.0310\n",
      "452/1088, train_loss: 0.0293\n",
      "453/1088, train_loss: 0.0323\n",
      "454/1088, train_loss: 0.0285\n",
      "455/1088, train_loss: 0.0271\n",
      "456/1088, train_loss: 0.0284\n",
      "457/1088, train_loss: 0.0319\n",
      "458/1088, train_loss: 0.0291\n",
      "459/1088, train_loss: 0.0294\n",
      "460/1088, train_loss: 0.0262\n",
      "461/1088, train_loss: 0.0275\n",
      "462/1088, train_loss: 0.0287\n",
      "463/1088, train_loss: 0.0271\n",
      "464/1088, train_loss: 0.0312\n",
      "465/1088, train_loss: 0.0301\n",
      "466/1088, train_loss: 0.0282\n",
      "467/1088, train_loss: 0.0297\n",
      "468/1088, train_loss: 0.0268\n",
      "469/1088, train_loss: 0.0281\n",
      "470/1088, train_loss: 0.0288\n",
      "471/1088, train_loss: 0.0273\n",
      "472/1088, train_loss: 0.0279\n",
      "473/1088, train_loss: 0.0292\n",
      "474/1088, train_loss: 0.0280\n",
      "475/1088, train_loss: 0.0267\n",
      "476/1088, train_loss: 0.0286\n",
      "477/1088, train_loss: 0.0260\n",
      "478/1088, train_loss: 0.0267\n",
      "479/1088, train_loss: 0.0293\n",
      "480/1088, train_loss: 0.0281\n",
      "481/1088, train_loss: 0.0300\n",
      "482/1088, train_loss: 0.0274\n",
      "483/1088, train_loss: 0.0274\n",
      "484/1088, train_loss: 0.0323\n",
      "485/1088, train_loss: 0.0310\n",
      "486/1088, train_loss: 0.0284\n",
      "487/1088, train_loss: 0.0292\n",
      "488/1088, train_loss: 0.0292\n",
      "489/1088, train_loss: 0.0315\n",
      "490/1088, train_loss: 0.0283\n",
      "491/1088, train_loss: 0.0290\n",
      "492/1088, train_loss: 0.0275\n",
      "493/1088, train_loss: 0.0267\n",
      "494/1088, train_loss: 0.0303\n",
      "495/1088, train_loss: 0.0310\n",
      "496/1088, train_loss: 0.0270\n",
      "497/1088, train_loss: 0.0286\n",
      "498/1088, train_loss: 0.0300\n",
      "499/1088, train_loss: 0.0280\n",
      "500/1088, train_loss: 0.0354\n",
      "501/1088, train_loss: 0.0301\n",
      "502/1088, train_loss: 0.0299\n",
      "503/1088, train_loss: 0.0294\n",
      "504/1088, train_loss: 0.0277\n",
      "505/1088, train_loss: 0.0290\n",
      "506/1088, train_loss: 0.0293\n",
      "507/1088, train_loss: 0.0317\n",
      "508/1088, train_loss: 0.0281\n",
      "509/1088, train_loss: 0.0287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/1088, train_loss: 0.0288\n",
      "511/1088, train_loss: 0.0286\n",
      "512/1088, train_loss: 0.0327\n",
      "513/1088, train_loss: 0.0301\n",
      "514/1088, train_loss: 0.0279\n",
      "515/1088, train_loss: 0.0300\n",
      "516/1088, train_loss: 0.0293\n",
      "517/1088, train_loss: 0.0278\n",
      "518/1088, train_loss: 0.0296\n",
      "519/1088, train_loss: 0.0276\n",
      "520/1088, train_loss: 0.0279\n",
      "521/1088, train_loss: 0.0284\n",
      "522/1088, train_loss: 0.0305\n",
      "523/1088, train_loss: 0.0276\n",
      "524/1088, train_loss: 0.0286\n",
      "525/1088, train_loss: 0.0291\n",
      "526/1088, train_loss: 0.0281\n",
      "527/1088, train_loss: 0.0282\n",
      "528/1088, train_loss: 0.0277\n",
      "529/1088, train_loss: 0.0272\n",
      "530/1088, train_loss: 0.0288\n",
      "531/1088, train_loss: 0.0281\n",
      "532/1088, train_loss: 0.0274\n",
      "533/1088, train_loss: 0.0288\n",
      "534/1088, train_loss: 0.0333\n",
      "535/1088, train_loss: 0.0280\n",
      "536/1088, train_loss: 0.0291\n",
      "537/1088, train_loss: 0.0268\n",
      "538/1088, train_loss: 0.0287\n",
      "539/1088, train_loss: 0.0315\n",
      "540/1088, train_loss: 0.0307\n",
      "541/1088, train_loss: 0.0294\n",
      "542/1088, train_loss: 0.0316\n",
      "543/1088, train_loss: 0.0304\n",
      "544/1088, train_loss: 0.0324\n",
      "545/1088, train_loss: 0.0305\n",
      "546/1088, train_loss: 0.0286\n",
      "547/1088, train_loss: 0.0309\n",
      "548/1088, train_loss: 0.0288\n",
      "549/1088, train_loss: 0.0296\n",
      "550/1088, train_loss: 0.0289\n",
      "551/1088, train_loss: 0.0283\n",
      "552/1088, train_loss: 0.0286\n",
      "553/1088, train_loss: 0.0278\n",
      "554/1088, train_loss: 0.0291\n",
      "555/1088, train_loss: 0.0303\n",
      "556/1088, train_loss: 0.0272\n",
      "557/1088, train_loss: 0.0273\n",
      "558/1088, train_loss: 0.0269\n",
      "559/1088, train_loss: 0.0276\n",
      "560/1088, train_loss: 0.0280\n",
      "561/1088, train_loss: 0.0279\n",
      "562/1088, train_loss: 0.0280\n",
      "563/1088, train_loss: 0.0291\n",
      "564/1088, train_loss: 0.0291\n",
      "565/1088, train_loss: 0.0310\n",
      "566/1088, train_loss: 0.0311\n",
      "567/1088, train_loss: 0.0297\n",
      "568/1088, train_loss: 0.0307\n",
      "569/1088, train_loss: 0.0296\n",
      "570/1088, train_loss: 0.0290\n",
      "571/1088, train_loss: 0.0291\n",
      "572/1088, train_loss: 0.0332\n",
      "573/1088, train_loss: 0.0380\n",
      "574/1088, train_loss: 0.0307\n",
      "575/1088, train_loss: 0.0279\n",
      "576/1088, train_loss: 0.0290\n",
      "577/1088, train_loss: 0.0278\n",
      "578/1088, train_loss: 0.0292\n",
      "579/1088, train_loss: 0.0276\n",
      "580/1088, train_loss: 0.0279\n",
      "581/1088, train_loss: 0.0293\n",
      "582/1088, train_loss: 0.0271\n",
      "583/1088, train_loss: 0.0276\n",
      "584/1088, train_loss: 0.0292\n",
      "585/1088, train_loss: 0.0306\n",
      "586/1088, train_loss: 0.0305\n",
      "587/1088, train_loss: 0.0279\n",
      "588/1088, train_loss: 0.0287\n",
      "589/1088, train_loss: 0.0279\n",
      "590/1088, train_loss: 0.0330\n",
      "591/1088, train_loss: 0.0312\n",
      "592/1088, train_loss: 0.0271\n",
      "593/1088, train_loss: 0.0286\n",
      "594/1088, train_loss: 0.0328\n",
      "595/1088, train_loss: 0.0276\n",
      "596/1088, train_loss: 0.0259\n",
      "597/1088, train_loss: 0.0261\n",
      "598/1088, train_loss: 0.0305\n",
      "599/1088, train_loss: 0.0311\n",
      "600/1088, train_loss: 0.0267\n",
      "601/1088, train_loss: 0.0270\n",
      "602/1088, train_loss: 0.0281\n",
      "603/1088, train_loss: 0.0283\n",
      "604/1088, train_loss: 0.0305\n",
      "605/1088, train_loss: 0.0294\n",
      "606/1088, train_loss: 0.0284\n",
      "607/1088, train_loss: 0.0290\n",
      "608/1088, train_loss: 0.0308\n",
      "609/1088, train_loss: 0.0279\n",
      "610/1088, train_loss: 0.0348\n",
      "611/1088, train_loss: 0.0298\n",
      "612/1088, train_loss: 0.0266\n",
      "613/1088, train_loss: 0.0260\n",
      "614/1088, train_loss: 0.0270\n",
      "615/1088, train_loss: 0.0317\n",
      "616/1088, train_loss: 0.0291\n",
      "617/1088, train_loss: 0.0301\n",
      "618/1088, train_loss: 0.0293\n",
      "619/1088, train_loss: 0.0297\n",
      "620/1088, train_loss: 0.0274\n",
      "621/1088, train_loss: 0.0305\n",
      "622/1088, train_loss: 0.0300\n",
      "623/1088, train_loss: 0.0330\n",
      "624/1088, train_loss: 0.0285\n",
      "625/1088, train_loss: 0.0280\n",
      "626/1088, train_loss: 0.0298\n",
      "627/1088, train_loss: 0.0321\n",
      "628/1088, train_loss: 0.0303\n",
      "629/1088, train_loss: 0.0290\n",
      "630/1088, train_loss: 0.0274\n",
      "631/1088, train_loss: 0.0300\n",
      "632/1088, train_loss: 0.0290\n",
      "633/1088, train_loss: 0.0279\n",
      "634/1088, train_loss: 0.0278\n",
      "635/1088, train_loss: 0.0258\n",
      "636/1088, train_loss: 0.0280\n",
      "637/1088, train_loss: 0.0289\n",
      "638/1088, train_loss: 0.0290\n",
      "639/1088, train_loss: 0.0278\n",
      "640/1088, train_loss: 0.0302\n",
      "641/1088, train_loss: 0.0275\n",
      "642/1088, train_loss: 0.0336\n",
      "643/1088, train_loss: 0.0290\n",
      "644/1088, train_loss: 0.0271\n",
      "645/1088, train_loss: 0.0277\n",
      "646/1088, train_loss: 0.0275\n",
      "647/1088, train_loss: 0.0285\n",
      "648/1088, train_loss: 0.0278\n",
      "649/1088, train_loss: 0.0314\n",
      "650/1088, train_loss: 0.0274\n",
      "651/1088, train_loss: 0.0283\n",
      "652/1088, train_loss: 0.0288\n",
      "653/1088, train_loss: 0.0293\n",
      "654/1088, train_loss: 0.0266\n",
      "655/1088, train_loss: 0.0285\n",
      "656/1088, train_loss: 0.0305\n",
      "657/1088, train_loss: 0.0307\n",
      "658/1088, train_loss: 0.0275\n",
      "659/1088, train_loss: 0.0300\n",
      "660/1088, train_loss: 0.0291\n",
      "661/1088, train_loss: 0.0293\n",
      "662/1088, train_loss: 0.0326\n",
      "663/1088, train_loss: 0.0302\n",
      "664/1088, train_loss: 0.0282\n",
      "665/1088, train_loss: 0.0299\n",
      "666/1088, train_loss: 0.0281\n",
      "667/1088, train_loss: 0.0303\n",
      "668/1088, train_loss: 0.0286\n",
      "669/1088, train_loss: 0.0276\n",
      "670/1088, train_loss: 0.0292\n",
      "671/1088, train_loss: 0.0294\n",
      "672/1088, train_loss: 0.0333\n",
      "673/1088, train_loss: 0.0293\n",
      "674/1088, train_loss: 0.0303\n",
      "675/1088, train_loss: 0.0297\n",
      "676/1088, train_loss: 0.0291\n",
      "677/1088, train_loss: 0.0274\n",
      "678/1088, train_loss: 0.0300\n",
      "679/1088, train_loss: 0.0306\n",
      "680/1088, train_loss: 0.0324\n",
      "681/1088, train_loss: 0.0281\n",
      "682/1088, train_loss: 0.0270\n",
      "683/1088, train_loss: 0.0279\n",
      "684/1088, train_loss: 0.0297\n",
      "685/1088, train_loss: 0.0290\n",
      "686/1088, train_loss: 0.0270\n",
      "687/1088, train_loss: 0.0295\n",
      "688/1088, train_loss: 0.0278\n",
      "689/1088, train_loss: 0.0317\n",
      "690/1088, train_loss: 0.0305\n",
      "691/1088, train_loss: 0.0291\n",
      "692/1088, train_loss: 0.0290\n",
      "693/1088, train_loss: 0.0306\n",
      "694/1088, train_loss: 0.0295\n",
      "695/1088, train_loss: 0.0296\n",
      "696/1088, train_loss: 0.0288\n",
      "697/1088, train_loss: 0.0284\n",
      "698/1088, train_loss: 0.0281\n",
      "699/1088, train_loss: 0.0288\n",
      "700/1088, train_loss: 0.0279\n",
      "701/1088, train_loss: 0.0274\n",
      "702/1088, train_loss: 0.0307\n",
      "703/1088, train_loss: 0.0286\n",
      "704/1088, train_loss: 0.0306\n",
      "705/1088, train_loss: 0.0283\n",
      "706/1088, train_loss: 0.0296\n",
      "707/1088, train_loss: 0.0311\n",
      "708/1088, train_loss: 0.0276\n",
      "709/1088, train_loss: 0.0290\n",
      "710/1088, train_loss: 0.0273\n",
      "711/1088, train_loss: 0.0284\n",
      "712/1088, train_loss: 0.0276\n",
      "713/1088, train_loss: 0.0289\n",
      "714/1088, train_loss: 0.0321\n",
      "715/1088, train_loss: 0.0299\n",
      "716/1088, train_loss: 0.0270\n",
      "717/1088, train_loss: 0.0344\n",
      "718/1088, train_loss: 0.0253\n",
      "719/1088, train_loss: 0.0293\n",
      "720/1088, train_loss: 0.0298\n",
      "721/1088, train_loss: 0.0295\n",
      "722/1088, train_loss: 0.0276\n",
      "723/1088, train_loss: 0.0283\n",
      "724/1088, train_loss: 0.0348\n",
      "725/1088, train_loss: 0.0260\n",
      "726/1088, train_loss: 0.0264\n",
      "727/1088, train_loss: 0.0307\n",
      "728/1088, train_loss: 0.0286\n",
      "729/1088, train_loss: 0.0277\n",
      "730/1088, train_loss: 0.0300\n",
      "731/1088, train_loss: 0.0273\n",
      "732/1088, train_loss: 0.0287\n",
      "733/1088, train_loss: 0.0281\n",
      "734/1088, train_loss: 0.0287\n",
      "735/1088, train_loss: 0.0287\n",
      "736/1088, train_loss: 0.0256\n",
      "737/1088, train_loss: 0.0287\n",
      "738/1088, train_loss: 0.0287\n",
      "739/1088, train_loss: 0.0297\n",
      "740/1088, train_loss: 0.0289\n",
      "741/1088, train_loss: 0.0280\n",
      "742/1088, train_loss: 0.0284\n",
      "743/1088, train_loss: 0.0263\n",
      "744/1088, train_loss: 0.0276\n",
      "745/1088, train_loss: 0.0266\n",
      "746/1088, train_loss: 0.0282\n",
      "747/1088, train_loss: 0.0274\n",
      "748/1088, train_loss: 0.0293\n",
      "749/1088, train_loss: 0.0284\n",
      "750/1088, train_loss: 0.0303\n",
      "751/1088, train_loss: 0.0288\n",
      "752/1088, train_loss: 0.0293\n",
      "753/1088, train_loss: 0.0295\n",
      "754/1088, train_loss: 0.0273\n",
      "755/1088, train_loss: 0.0254\n",
      "756/1088, train_loss: 0.0285\n",
      "757/1088, train_loss: 0.0278\n",
      "758/1088, train_loss: 0.0293\n",
      "759/1088, train_loss: 0.0296\n",
      "760/1088, train_loss: 0.0277\n",
      "761/1088, train_loss: 0.0286\n",
      "762/1088, train_loss: 0.0267\n",
      "763/1088, train_loss: 0.0275\n",
      "764/1088, train_loss: 0.0287\n",
      "765/1088, train_loss: 0.0286\n",
      "766/1088, train_loss: 0.0289\n",
      "767/1088, train_loss: 0.0275\n",
      "768/1088, train_loss: 0.0292\n",
      "769/1088, train_loss: 0.0285\n",
      "770/1088, train_loss: 0.0292\n",
      "771/1088, train_loss: 0.0284\n",
      "772/1088, train_loss: 0.0281\n",
      "773/1088, train_loss: 0.0276\n",
      "774/1088, train_loss: 0.0292\n",
      "775/1088, train_loss: 0.0283\n",
      "776/1088, train_loss: 0.0302\n",
      "777/1088, train_loss: 0.0281\n",
      "778/1088, train_loss: 0.0273\n",
      "779/1088, train_loss: 0.0296\n",
      "780/1088, train_loss: 0.0279\n",
      "781/1088, train_loss: 0.0266\n",
      "782/1088, train_loss: 0.0286\n",
      "783/1088, train_loss: 0.0294\n",
      "784/1088, train_loss: 0.0270\n",
      "785/1088, train_loss: 0.0257\n",
      "786/1088, train_loss: 0.0320\n",
      "787/1088, train_loss: 0.0311\n",
      "788/1088, train_loss: 0.0285\n",
      "789/1088, train_loss: 0.0290\n",
      "790/1088, train_loss: 0.0259\n",
      "791/1088, train_loss: 0.0294\n",
      "792/1088, train_loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "793/1088, train_loss: 0.0298\n",
      "794/1088, train_loss: 0.0300\n",
      "795/1088, train_loss: 0.0284\n",
      "796/1088, train_loss: 0.0309\n",
      "797/1088, train_loss: 0.0285\n",
      "798/1088, train_loss: 0.0281\n",
      "799/1088, train_loss: 0.0298\n",
      "800/1088, train_loss: 0.0308\n",
      "801/1088, train_loss: 0.0316\n",
      "802/1088, train_loss: 0.0274\n",
      "803/1088, train_loss: 0.0317\n",
      "804/1088, train_loss: 0.0332\n",
      "805/1088, train_loss: 0.0280\n",
      "806/1088, train_loss: 0.0289\n",
      "807/1088, train_loss: 0.0284\n",
      "808/1088, train_loss: 0.0291\n",
      "809/1088, train_loss: 0.0274\n",
      "810/1088, train_loss: 0.0287\n",
      "811/1088, train_loss: 0.0294\n",
      "812/1088, train_loss: 0.0280\n",
      "813/1088, train_loss: 0.0280\n",
      "814/1088, train_loss: 0.0270\n",
      "815/1088, train_loss: 0.0285\n",
      "816/1088, train_loss: 0.0281\n",
      "817/1088, train_loss: 0.0327\n",
      "818/1088, train_loss: 0.0288\n",
      "819/1088, train_loss: 0.0305\n",
      "820/1088, train_loss: 0.0255\n",
      "821/1088, train_loss: 0.0304\n",
      "822/1088, train_loss: 0.0281\n",
      "823/1088, train_loss: 0.0286\n",
      "824/1088, train_loss: 0.0296\n",
      "825/1088, train_loss: 0.0275\n",
      "826/1088, train_loss: 0.0305\n",
      "827/1088, train_loss: 0.0303\n",
      "828/1088, train_loss: 0.0287\n",
      "829/1088, train_loss: 0.0288\n",
      "830/1088, train_loss: 0.0287\n",
      "831/1088, train_loss: 0.0282\n",
      "832/1088, train_loss: 0.0289\n",
      "833/1088, train_loss: 0.0271\n",
      "834/1088, train_loss: 0.0304\n",
      "835/1088, train_loss: 0.0272\n",
      "836/1088, train_loss: 0.0290\n",
      "837/1088, train_loss: 0.0285\n",
      "838/1088, train_loss: 0.0288\n",
      "839/1088, train_loss: 0.0279\n",
      "840/1088, train_loss: 0.0300\n",
      "841/1088, train_loss: 0.0295\n",
      "842/1088, train_loss: 0.0295\n",
      "843/1088, train_loss: 0.0276\n",
      "844/1088, train_loss: 0.0281\n",
      "845/1088, train_loss: 0.0277\n",
      "846/1088, train_loss: 0.0293\n",
      "847/1088, train_loss: 0.0287\n",
      "848/1088, train_loss: 0.0295\n",
      "849/1088, train_loss: 0.0294\n",
      "850/1088, train_loss: 0.0311\n",
      "851/1088, train_loss: 0.0282\n",
      "852/1088, train_loss: 0.0294\n",
      "853/1088, train_loss: 0.0326\n",
      "854/1088, train_loss: 0.0292\n",
      "855/1088, train_loss: 0.0307\n",
      "856/1088, train_loss: 0.0308\n",
      "857/1088, train_loss: 0.0275\n",
      "858/1088, train_loss: 0.0283\n",
      "859/1088, train_loss: 0.0288\n",
      "860/1088, train_loss: 0.0289\n",
      "861/1088, train_loss: 0.0292\n",
      "862/1088, train_loss: 0.0289\n",
      "863/1088, train_loss: 0.0302\n",
      "864/1088, train_loss: 0.0288\n",
      "865/1088, train_loss: 0.0295\n",
      "866/1088, train_loss: 0.0280\n",
      "867/1088, train_loss: 0.0279\n",
      "868/1088, train_loss: 0.0287\n",
      "869/1088, train_loss: 0.0318\n",
      "870/1088, train_loss: 0.0299\n",
      "871/1088, train_loss: 0.0288\n",
      "872/1088, train_loss: 0.0389\n",
      "873/1088, train_loss: 0.0281\n",
      "874/1088, train_loss: 0.0273\n",
      "875/1088, train_loss: 0.0295\n",
      "876/1088, train_loss: 0.0303\n",
      "877/1088, train_loss: 0.0280\n",
      "878/1088, train_loss: 0.0286\n",
      "879/1088, train_loss: 0.0291\n",
      "880/1088, train_loss: 0.0297\n",
      "881/1088, train_loss: 0.0315\n",
      "882/1088, train_loss: 0.0345\n",
      "883/1088, train_loss: 0.0294\n",
      "884/1088, train_loss: 0.0277\n",
      "885/1088, train_loss: 0.0304\n",
      "886/1088, train_loss: 0.0313\n",
      "887/1088, train_loss: 0.0296\n",
      "888/1088, train_loss: 0.0280\n",
      "889/1088, train_loss: 0.0285\n",
      "890/1088, train_loss: 0.0284\n",
      "891/1088, train_loss: 0.0293\n",
      "892/1088, train_loss: 0.0293\n",
      "893/1088, train_loss: 0.0315\n",
      "894/1088, train_loss: 0.0282\n",
      "895/1088, train_loss: 0.0304\n",
      "896/1088, train_loss: 0.0298\n",
      "897/1088, train_loss: 0.0308\n",
      "898/1088, train_loss: 0.0279\n",
      "899/1088, train_loss: 0.0289\n",
      "900/1088, train_loss: 0.0276\n",
      "901/1088, train_loss: 0.0294\n",
      "902/1088, train_loss: 0.0295\n",
      "903/1088, train_loss: 0.0298\n",
      "904/1088, train_loss: 0.0285\n",
      "905/1088, train_loss: 0.0286\n",
      "906/1088, train_loss: 0.0258\n",
      "907/1088, train_loss: 0.0301\n",
      "908/1088, train_loss: 0.0283\n",
      "909/1088, train_loss: 0.0245\n",
      "910/1088, train_loss: 0.0261\n",
      "911/1088, train_loss: 0.0275\n",
      "912/1088, train_loss: 0.0284\n",
      "913/1088, train_loss: 0.0303\n",
      "914/1088, train_loss: 0.0321\n",
      "915/1088, train_loss: 0.0292\n",
      "916/1088, train_loss: 0.0267\n",
      "917/1088, train_loss: 0.0281\n",
      "918/1088, train_loss: 0.0306\n",
      "919/1088, train_loss: 0.0299\n",
      "920/1088, train_loss: 0.0287\n",
      "921/1088, train_loss: 0.0271\n",
      "922/1088, train_loss: 0.0288\n",
      "923/1088, train_loss: 0.0299\n",
      "924/1088, train_loss: 0.0284\n",
      "925/1088, train_loss: 0.0314\n",
      "926/1088, train_loss: 0.0290\n",
      "927/1088, train_loss: 0.0294\n",
      "928/1088, train_loss: 0.0310\n",
      "929/1088, train_loss: 0.0297\n",
      "930/1088, train_loss: 0.0288\n",
      "931/1088, train_loss: 0.0288\n",
      "932/1088, train_loss: 0.0277\n",
      "933/1088, train_loss: 0.0264\n",
      "934/1088, train_loss: 0.0286\n",
      "935/1088, train_loss: 0.0271\n",
      "936/1088, train_loss: 0.0299\n",
      "937/1088, train_loss: 0.0277\n",
      "938/1088, train_loss: 0.0299\n",
      "939/1088, train_loss: 0.0293\n",
      "940/1088, train_loss: 0.0267\n",
      "941/1088, train_loss: 0.0293\n",
      "942/1088, train_loss: 0.0311\n",
      "943/1088, train_loss: 0.0286\n",
      "944/1088, train_loss: 0.0299\n",
      "945/1088, train_loss: 0.0266\n",
      "946/1088, train_loss: 0.0273\n",
      "947/1088, train_loss: 0.0297\n",
      "948/1088, train_loss: 0.0305\n",
      "949/1088, train_loss: 0.0292\n",
      "950/1088, train_loss: 0.0263\n",
      "951/1088, train_loss: 0.0390\n",
      "952/1088, train_loss: 0.0273\n",
      "953/1088, train_loss: 0.0271\n",
      "954/1088, train_loss: 0.0308\n",
      "955/1088, train_loss: 0.0286\n",
      "956/1088, train_loss: 0.0277\n",
      "957/1088, train_loss: 0.0285\n",
      "958/1088, train_loss: 0.0305\n",
      "959/1088, train_loss: 0.0269\n",
      "960/1088, train_loss: 0.0271\n",
      "961/1088, train_loss: 0.0271\n",
      "962/1088, train_loss: 0.0271\n",
      "963/1088, train_loss: 0.0294\n",
      "964/1088, train_loss: 0.0293\n",
      "965/1088, train_loss: 0.0315\n",
      "966/1088, train_loss: 0.0291\n",
      "967/1088, train_loss: 0.0298\n",
      "968/1088, train_loss: 0.0298\n",
      "969/1088, train_loss: 0.0304\n",
      "970/1088, train_loss: 0.0288\n",
      "971/1088, train_loss: 0.0314\n",
      "972/1088, train_loss: 0.0312\n",
      "973/1088, train_loss: 0.0301\n",
      "974/1088, train_loss: 0.0321\n",
      "975/1088, train_loss: 0.0314\n",
      "976/1088, train_loss: 0.0293\n",
      "977/1088, train_loss: 0.0295\n",
      "978/1088, train_loss: 0.0277\n",
      "979/1088, train_loss: 0.0307\n",
      "980/1088, train_loss: 0.0302\n",
      "981/1088, train_loss: 0.0307\n",
      "982/1088, train_loss: 0.0303\n",
      "983/1088, train_loss: 0.0267\n",
      "984/1088, train_loss: 0.0298\n",
      "985/1088, train_loss: 0.0322\n",
      "986/1088, train_loss: 0.0305\n",
      "987/1088, train_loss: 0.0261\n",
      "988/1088, train_loss: 0.0288\n",
      "989/1088, train_loss: 0.0297\n",
      "990/1088, train_loss: 0.0287\n",
      "991/1088, train_loss: 0.0299\n",
      "992/1088, train_loss: 0.0287\n",
      "993/1088, train_loss: 0.0282\n",
      "994/1088, train_loss: 0.0261\n",
      "995/1088, train_loss: 0.0283\n",
      "996/1088, train_loss: 0.0314\n",
      "997/1088, train_loss: 0.0281\n",
      "998/1088, train_loss: 0.0323\n",
      "999/1088, train_loss: 0.0311\n",
      "1000/1088, train_loss: 0.0345\n",
      "1001/1088, train_loss: 0.0318\n",
      "1002/1088, train_loss: 0.0304\n",
      "1003/1088, train_loss: 0.0289\n",
      "1004/1088, train_loss: 0.0279\n",
      "1005/1088, train_loss: 0.0302\n",
      "1006/1088, train_loss: 0.0315\n",
      "1007/1088, train_loss: 0.0289\n",
      "1008/1088, train_loss: 0.0313\n",
      "1009/1088, train_loss: 0.0260\n",
      "1010/1088, train_loss: 0.0243\n",
      "1011/1088, train_loss: 0.0290\n",
      "1012/1088, train_loss: 0.0288\n",
      "1013/1088, train_loss: 0.0286\n",
      "1014/1088, train_loss: 0.0289\n",
      "1015/1088, train_loss: 0.0307\n",
      "1016/1088, train_loss: 0.0290\n",
      "1017/1088, train_loss: 0.0271\n",
      "1018/1088, train_loss: 0.0284\n",
      "1019/1088, train_loss: 0.0265\n",
      "1020/1088, train_loss: 0.0294\n",
      "1021/1088, train_loss: 0.0278\n",
      "1022/1088, train_loss: 0.0297\n",
      "1023/1088, train_loss: 0.0271\n",
      "1024/1088, train_loss: 0.0281\n",
      "1025/1088, train_loss: 0.0276\n",
      "1026/1088, train_loss: 0.0315\n",
      "1027/1088, train_loss: 0.0267\n",
      "1028/1088, train_loss: 0.0281\n",
      "1029/1088, train_loss: 0.0293\n",
      "1030/1088, train_loss: 0.0292\n",
      "1031/1088, train_loss: 0.0266\n",
      "1032/1088, train_loss: 0.0291\n",
      "1033/1088, train_loss: 0.0318\n",
      "1034/1088, train_loss: 0.0286\n",
      "1035/1088, train_loss: 0.0292\n",
      "1036/1088, train_loss: 0.0286\n",
      "1037/1088, train_loss: 0.0334\n",
      "1038/1088, train_loss: 0.0305\n",
      "1039/1088, train_loss: 0.0274\n",
      "1040/1088, train_loss: 0.0281\n",
      "1041/1088, train_loss: 0.0275\n",
      "1042/1088, train_loss: 0.0295\n",
      "1043/1088, train_loss: 0.0289\n",
      "1044/1088, train_loss: 0.0295\n",
      "1045/1088, train_loss: 0.0270\n",
      "1046/1088, train_loss: 0.0278\n",
      "1047/1088, train_loss: 0.0274\n",
      "1048/1088, train_loss: 0.0314\n",
      "1049/1088, train_loss: 0.0278\n",
      "1050/1088, train_loss: 0.0300\n",
      "1051/1088, train_loss: 0.0315\n",
      "1052/1088, train_loss: 0.0289\n",
      "1053/1088, train_loss: 0.0291\n",
      "1054/1088, train_loss: 0.0275\n",
      "1055/1088, train_loss: 0.0293\n",
      "1056/1088, train_loss: 0.0279\n",
      "1057/1088, train_loss: 0.0271\n",
      "1058/1088, train_loss: 0.0339\n",
      "1059/1088, train_loss: 0.0297\n",
      "1060/1088, train_loss: 0.0293\n",
      "1061/1088, train_loss: 0.0269\n",
      "1062/1088, train_loss: 0.0256\n",
      "1063/1088, train_loss: 0.0275\n",
      "1064/1088, train_loss: 0.0295\n",
      "1065/1088, train_loss: 0.0283\n",
      "1066/1088, train_loss: 0.0325\n",
      "1067/1088, train_loss: 0.0296\n",
      "1068/1088, train_loss: 0.0274\n",
      "1069/1088, train_loss: 0.0277\n",
      "1070/1088, train_loss: 0.0285\n",
      "1071/1088, train_loss: 0.0281\n",
      "1072/1088, train_loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1073/1088, train_loss: 0.0283\n",
      "1074/1088, train_loss: 0.0278\n",
      "1075/1088, train_loss: 0.0300\n",
      "1076/1088, train_loss: 0.0284\n",
      "1077/1088, train_loss: 0.0288\n",
      "1078/1088, train_loss: 0.0269\n",
      "1079/1088, train_loss: 0.0299\n",
      "1080/1088, train_loss: 0.0276\n",
      "1081/1088, train_loss: 0.0305\n",
      "1082/1088, train_loss: 0.0281\n",
      "1083/1088, train_loss: 0.0302\n",
      "1084/1088, train_loss: 0.0268\n",
      "1085/1088, train_loss: 0.0309\n",
      "1086/1088, train_loss: 0.0275\n",
      "1087/1088, train_loss: 0.0296\n",
      "1088/1088, train_loss: 0.0287\n",
      "1089/1088, train_loss: 0.0284\n",
      "epoch 8 average loss: 0.0292, train_dice: 0.9709\n",
      "epoch 8 average loss: 0.0292\n",
      "saved new best metric model\n",
      "current epoch: 8 current mean dice: 0.9703 best mean dice: 0.9703 at epoch 8\n",
      "--------------------------------------------------\n",
      "epoch 9/50\n",
      "1/1088, train_loss: 0.0325\n",
      "2/1088, train_loss: 0.0293\n",
      "3/1088, train_loss: 0.0287\n",
      "4/1088, train_loss: 0.0290\n",
      "5/1088, train_loss: 0.0297\n",
      "6/1088, train_loss: 0.0273\n",
      "7/1088, train_loss: 0.0286\n",
      "8/1088, train_loss: 0.0283\n",
      "9/1088, train_loss: 0.0293\n",
      "10/1088, train_loss: 0.0285\n",
      "11/1088, train_loss: 0.0276\n",
      "12/1088, train_loss: 0.0296\n",
      "13/1088, train_loss: 0.0293\n",
      "14/1088, train_loss: 0.0279\n",
      "15/1088, train_loss: 0.0291\n",
      "16/1088, train_loss: 0.0258\n",
      "17/1088, train_loss: 0.0327\n",
      "18/1088, train_loss: 0.0283\n",
      "19/1088, train_loss: 0.0287\n",
      "20/1088, train_loss: 0.0300\n",
      "21/1088, train_loss: 0.0273\n",
      "22/1088, train_loss: 0.0254\n",
      "23/1088, train_loss: 0.0288\n",
      "24/1088, train_loss: 0.0261\n",
      "25/1088, train_loss: 0.0279\n",
      "26/1088, train_loss: 0.0280\n",
      "27/1088, train_loss: 0.0288\n",
      "28/1088, train_loss: 0.0268\n",
      "29/1088, train_loss: 0.0263\n",
      "30/1088, train_loss: 0.0276\n",
      "31/1088, train_loss: 0.0293\n",
      "32/1088, train_loss: 0.0272\n",
      "33/1088, train_loss: 0.0316\n",
      "34/1088, train_loss: 0.0283\n",
      "35/1088, train_loss: 0.0327\n",
      "36/1088, train_loss: 0.0274\n",
      "37/1088, train_loss: 0.0297\n",
      "38/1088, train_loss: 0.0282\n",
      "39/1088, train_loss: 0.0295\n",
      "40/1088, train_loss: 0.0266\n",
      "41/1088, train_loss: 0.0343\n",
      "42/1088, train_loss: 0.0303\n",
      "43/1088, train_loss: 0.0274\n",
      "44/1088, train_loss: 0.0284\n",
      "45/1088, train_loss: 0.0288\n",
      "46/1088, train_loss: 0.0286\n",
      "47/1088, train_loss: 0.0300\n",
      "48/1088, train_loss: 0.0298\n",
      "49/1088, train_loss: 0.0291\n",
      "50/1088, train_loss: 0.0283\n",
      "51/1088, train_loss: 0.0287\n",
      "52/1088, train_loss: 0.0285\n",
      "53/1088, train_loss: 0.0338\n",
      "54/1088, train_loss: 0.0298\n",
      "55/1088, train_loss: 0.0283\n",
      "56/1088, train_loss: 0.0304\n",
      "57/1088, train_loss: 0.0294\n",
      "58/1088, train_loss: 0.0306\n",
      "59/1088, train_loss: 0.0289\n",
      "60/1088, train_loss: 0.0289\n",
      "61/1088, train_loss: 0.0279\n",
      "62/1088, train_loss: 0.0287\n",
      "63/1088, train_loss: 0.0280\n",
      "64/1088, train_loss: 0.0297\n",
      "65/1088, train_loss: 0.0285\n",
      "66/1088, train_loss: 0.0265\n",
      "67/1088, train_loss: 0.0264\n",
      "68/1088, train_loss: 0.0279\n",
      "69/1088, train_loss: 0.0286\n",
      "70/1088, train_loss: 0.0288\n",
      "71/1088, train_loss: 0.0280\n",
      "72/1088, train_loss: 0.0294\n",
      "73/1088, train_loss: 0.0287\n",
      "74/1088, train_loss: 0.0278\n",
      "75/1088, train_loss: 0.0288\n",
      "76/1088, train_loss: 0.0296\n",
      "77/1088, train_loss: 0.0269\n",
      "78/1088, train_loss: 0.0291\n",
      "79/1088, train_loss: 0.0297\n",
      "80/1088, train_loss: 0.0268\n",
      "81/1088, train_loss: 0.0278\n",
      "82/1088, train_loss: 0.0261\n",
      "83/1088, train_loss: 0.0285\n",
      "84/1088, train_loss: 0.0276\n",
      "85/1088, train_loss: 0.0293\n",
      "86/1088, train_loss: 0.0290\n",
      "87/1088, train_loss: 0.0295\n",
      "88/1088, train_loss: 0.0276\n",
      "89/1088, train_loss: 0.0309\n",
      "90/1088, train_loss: 0.0259\n",
      "91/1088, train_loss: 0.0265\n",
      "92/1088, train_loss: 0.0300\n",
      "93/1088, train_loss: 0.0290\n",
      "94/1088, train_loss: 0.0278\n",
      "95/1088, train_loss: 0.0290\n",
      "96/1088, train_loss: 0.0288\n",
      "97/1088, train_loss: 0.0302\n",
      "98/1088, train_loss: 0.0281\n",
      "99/1088, train_loss: 0.0280\n",
      "100/1088, train_loss: 0.0314\n",
      "101/1088, train_loss: 0.0267\n",
      "102/1088, train_loss: 0.0292\n",
      "103/1088, train_loss: 0.0278\n",
      "104/1088, train_loss: 0.0285\n",
      "105/1088, train_loss: 0.0278\n",
      "106/1088, train_loss: 0.0291\n",
      "107/1088, train_loss: 0.0285\n",
      "108/1088, train_loss: 0.0319\n",
      "109/1088, train_loss: 0.0288\n",
      "110/1088, train_loss: 0.0284\n",
      "111/1088, train_loss: 0.0291\n",
      "112/1088, train_loss: 0.0267\n",
      "113/1088, train_loss: 0.0284\n",
      "114/1088, train_loss: 0.0280\n",
      "115/1088, train_loss: 0.0257\n",
      "116/1088, train_loss: 0.0274\n",
      "117/1088, train_loss: 0.0271\n",
      "118/1088, train_loss: 0.0287\n",
      "119/1088, train_loss: 0.0290\n",
      "120/1088, train_loss: 0.0322\n",
      "121/1088, train_loss: 0.0276\n",
      "122/1088, train_loss: 0.0280\n",
      "123/1088, train_loss: 0.0275\n",
      "124/1088, train_loss: 0.0272\n",
      "125/1088, train_loss: 0.0287\n",
      "126/1088, train_loss: 0.0267\n",
      "127/1088, train_loss: 0.0275\n",
      "128/1088, train_loss: 0.0273\n",
      "129/1088, train_loss: 0.0300\n",
      "130/1088, train_loss: 0.0266\n",
      "131/1088, train_loss: 0.0269\n",
      "132/1088, train_loss: 0.0366\n",
      "133/1088, train_loss: 0.0333\n",
      "134/1088, train_loss: 0.0323\n",
      "135/1088, train_loss: 0.0278\n",
      "136/1088, train_loss: 0.0267\n",
      "137/1088, train_loss: 0.0286\n",
      "138/1088, train_loss: 0.0277\n",
      "139/1088, train_loss: 0.0293\n",
      "140/1088, train_loss: 0.0280\n",
      "141/1088, train_loss: 0.0276\n",
      "142/1088, train_loss: 0.0289\n",
      "143/1088, train_loss: 0.0284\n",
      "144/1088, train_loss: 0.0284\n",
      "145/1088, train_loss: 0.0296\n",
      "146/1088, train_loss: 0.0261\n",
      "147/1088, train_loss: 0.0278\n",
      "148/1088, train_loss: 0.0280\n",
      "149/1088, train_loss: 0.0287\n",
      "150/1088, train_loss: 0.0269\n",
      "151/1088, train_loss: 0.0325\n",
      "152/1088, train_loss: 0.0271\n",
      "153/1088, train_loss: 0.0276\n",
      "154/1088, train_loss: 0.0290\n",
      "155/1088, train_loss: 0.0303\n",
      "156/1088, train_loss: 0.0289\n",
      "157/1088, train_loss: 0.0275\n",
      "158/1088, train_loss: 0.0288\n",
      "159/1088, train_loss: 0.0281\n",
      "160/1088, train_loss: 0.0270\n",
      "161/1088, train_loss: 0.0281\n",
      "162/1088, train_loss: 0.0311\n",
      "163/1088, train_loss: 0.0326\n",
      "164/1088, train_loss: 0.0289\n",
      "165/1088, train_loss: 0.0293\n",
      "166/1088, train_loss: 0.0309\n",
      "167/1088, train_loss: 0.0287\n",
      "168/1088, train_loss: 0.0294\n",
      "169/1088, train_loss: 0.0294\n",
      "170/1088, train_loss: 0.0286\n",
      "171/1088, train_loss: 0.0291\n",
      "172/1088, train_loss: 0.0282\n",
      "173/1088, train_loss: 0.0292\n",
      "174/1088, train_loss: 0.0268\n",
      "175/1088, train_loss: 0.0273\n",
      "176/1088, train_loss: 0.0344\n",
      "177/1088, train_loss: 0.0282\n",
      "178/1088, train_loss: 0.0278\n",
      "179/1088, train_loss: 0.0286\n",
      "180/1088, train_loss: 0.0293\n",
      "181/1088, train_loss: 0.0304\n",
      "182/1088, train_loss: 0.0321\n",
      "183/1088, train_loss: 0.0296\n",
      "184/1088, train_loss: 0.0284\n",
      "185/1088, train_loss: 0.0285\n",
      "186/1088, train_loss: 0.0289\n",
      "187/1088, train_loss: 0.0295\n",
      "188/1088, train_loss: 0.0284\n",
      "189/1088, train_loss: 0.0290\n",
      "190/1088, train_loss: 0.0307\n",
      "191/1088, train_loss: 0.0287\n",
      "192/1088, train_loss: 0.0289\n",
      "193/1088, train_loss: 0.0297\n",
      "194/1088, train_loss: 0.0309\n",
      "195/1088, train_loss: 0.0277\n",
      "196/1088, train_loss: 0.0328\n",
      "197/1088, train_loss: 0.0303\n",
      "198/1088, train_loss: 0.0286\n",
      "199/1088, train_loss: 0.0290\n",
      "200/1088, train_loss: 0.0289\n",
      "201/1088, train_loss: 0.0302\n",
      "202/1088, train_loss: 0.0296\n",
      "203/1088, train_loss: 0.0312\n",
      "204/1088, train_loss: 0.0284\n",
      "205/1088, train_loss: 0.0291\n",
      "206/1088, train_loss: 0.0290\n",
      "207/1088, train_loss: 0.0286\n",
      "208/1088, train_loss: 0.0283\n",
      "209/1088, train_loss: 0.0275\n",
      "210/1088, train_loss: 0.0280\n",
      "211/1088, train_loss: 0.0288\n",
      "212/1088, train_loss: 0.0309\n",
      "213/1088, train_loss: 0.0283\n",
      "214/1088, train_loss: 0.0282\n",
      "215/1088, train_loss: 0.0352\n",
      "216/1088, train_loss: 0.0326\n",
      "217/1088, train_loss: 0.0290\n",
      "218/1088, train_loss: 0.0263\n",
      "219/1088, train_loss: 0.0298\n",
      "220/1088, train_loss: 0.0309\n",
      "221/1088, train_loss: 0.0302\n",
      "222/1088, train_loss: 0.0268\n",
      "223/1088, train_loss: 0.0289\n",
      "224/1088, train_loss: 0.0264\n",
      "225/1088, train_loss: 0.0294\n",
      "226/1088, train_loss: 0.0276\n",
      "227/1088, train_loss: 0.0274\n",
      "228/1088, train_loss: 0.0270\n",
      "229/1088, train_loss: 0.0295\n",
      "230/1088, train_loss: 0.0313\n",
      "231/1088, train_loss: 0.0291\n",
      "232/1088, train_loss: 0.0310\n",
      "233/1088, train_loss: 0.0272\n",
      "234/1088, train_loss: 0.0275\n",
      "235/1088, train_loss: 0.0285\n",
      "236/1088, train_loss: 0.0277\n",
      "237/1088, train_loss: 0.0289\n",
      "238/1088, train_loss: 0.0286\n",
      "239/1088, train_loss: 0.0265\n",
      "240/1088, train_loss: 0.0279\n",
      "241/1088, train_loss: 0.0311\n",
      "242/1088, train_loss: 0.0331\n",
      "243/1088, train_loss: 0.0297\n",
      "244/1088, train_loss: 0.0310\n",
      "245/1088, train_loss: 0.0284\n",
      "246/1088, train_loss: 0.0280\n",
      "247/1088, train_loss: 0.0291\n",
      "248/1088, train_loss: 0.0275\n",
      "249/1088, train_loss: 0.0265\n",
      "250/1088, train_loss: 0.0315\n",
      "251/1088, train_loss: 0.0323\n",
      "252/1088, train_loss: 0.0293\n",
      "253/1088, train_loss: 0.0302\n",
      "254/1088, train_loss: 0.0279\n",
      "255/1088, train_loss: 0.0308\n",
      "256/1088, train_loss: 0.0278\n",
      "257/1088, train_loss: 0.0291\n",
      "258/1088, train_loss: 0.0307\n",
      "259/1088, train_loss: 0.0286\n",
      "260/1088, train_loss: 0.0293\n",
      "261/1088, train_loss: 0.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/1088, train_loss: 0.0299\n",
      "263/1088, train_loss: 0.0282\n",
      "264/1088, train_loss: 0.0292\n",
      "265/1088, train_loss: 0.0283\n",
      "266/1088, train_loss: 0.0277\n",
      "267/1088, train_loss: 0.0281\n",
      "268/1088, train_loss: 0.0282\n",
      "269/1088, train_loss: 0.0284\n",
      "270/1088, train_loss: 0.0261\n",
      "271/1088, train_loss: 0.0266\n",
      "272/1088, train_loss: 0.0293\n",
      "273/1088, train_loss: 0.0313\n",
      "274/1088, train_loss: 0.0292\n",
      "275/1088, train_loss: 0.0332\n",
      "276/1088, train_loss: 0.0299\n",
      "277/1088, train_loss: 0.0339\n",
      "278/1088, train_loss: 0.0311\n",
      "279/1088, train_loss: 0.0304\n",
      "280/1088, train_loss: 0.0321\n",
      "281/1088, train_loss: 0.0300\n",
      "282/1088, train_loss: 0.0309\n",
      "283/1088, train_loss: 0.0296\n",
      "284/1088, train_loss: 0.0309\n",
      "285/1088, train_loss: 0.0295\n",
      "286/1088, train_loss: 0.0272\n",
      "287/1088, train_loss: 0.0280\n",
      "288/1088, train_loss: 0.0277\n",
      "289/1088, train_loss: 0.0289\n",
      "290/1088, train_loss: 0.0337\n",
      "291/1088, train_loss: 0.0274\n",
      "292/1088, train_loss: 0.0288\n",
      "293/1088, train_loss: 0.0301\n",
      "294/1088, train_loss: 0.0265\n",
      "295/1088, train_loss: 0.0276\n",
      "296/1088, train_loss: 0.0285\n",
      "297/1088, train_loss: 0.0282\n",
      "298/1088, train_loss: 0.0288\n",
      "299/1088, train_loss: 0.0292\n",
      "300/1088, train_loss: 0.0284\n",
      "301/1088, train_loss: 0.0285\n",
      "302/1088, train_loss: 0.0316\n",
      "303/1088, train_loss: 0.0285\n",
      "304/1088, train_loss: 0.0290\n",
      "305/1088, train_loss: 0.0284\n",
      "306/1088, train_loss: 0.0298\n",
      "307/1088, train_loss: 0.0264\n",
      "308/1088, train_loss: 0.0294\n",
      "309/1088, train_loss: 0.0272\n",
      "310/1088, train_loss: 0.0309\n",
      "311/1088, train_loss: 0.0297\n",
      "312/1088, train_loss: 0.0300\n",
      "313/1088, train_loss: 0.0341\n",
      "314/1088, train_loss: 0.0276\n",
      "315/1088, train_loss: 0.0294\n",
      "316/1088, train_loss: 0.0288\n",
      "317/1088, train_loss: 0.0297\n",
      "318/1088, train_loss: 0.0288\n",
      "319/1088, train_loss: 0.0300\n",
      "320/1088, train_loss: 0.0268\n",
      "321/1088, train_loss: 0.0287\n",
      "322/1088, train_loss: 0.0287\n",
      "323/1088, train_loss: 0.0283\n",
      "324/1088, train_loss: 0.0286\n",
      "325/1088, train_loss: 0.0284\n",
      "326/1088, train_loss: 0.0282\n",
      "327/1088, train_loss: 0.0308\n",
      "328/1088, train_loss: 0.0283\n",
      "329/1088, train_loss: 0.0277\n",
      "330/1088, train_loss: 0.0290\n",
      "331/1088, train_loss: 0.0281\n",
      "332/1088, train_loss: 0.0279\n",
      "333/1088, train_loss: 0.0279\n",
      "334/1088, train_loss: 0.0282\n",
      "335/1088, train_loss: 0.0294\n",
      "336/1088, train_loss: 0.0295\n",
      "337/1088, train_loss: 0.0340\n",
      "338/1088, train_loss: 0.0281\n",
      "339/1088, train_loss: 0.0303\n",
      "340/1088, train_loss: 0.0291\n",
      "341/1088, train_loss: 0.0296\n",
      "342/1088, train_loss: 0.0260\n",
      "343/1088, train_loss: 0.0287\n",
      "344/1088, train_loss: 0.0270\n",
      "345/1088, train_loss: 0.0292\n",
      "346/1088, train_loss: 0.0268\n",
      "347/1088, train_loss: 0.0270\n",
      "348/1088, train_loss: 0.0283\n",
      "349/1088, train_loss: 0.0261\n",
      "350/1088, train_loss: 0.0274\n",
      "351/1088, train_loss: 0.0291\n",
      "352/1088, train_loss: 0.0286\n",
      "353/1088, train_loss: 0.0286\n",
      "354/1088, train_loss: 0.0278\n",
      "355/1088, train_loss: 0.0408\n",
      "356/1088, train_loss: 0.0278\n",
      "357/1088, train_loss: 0.0288\n",
      "358/1088, train_loss: 0.0266\n",
      "359/1088, train_loss: 0.0291\n",
      "360/1088, train_loss: 0.0290\n",
      "361/1088, train_loss: 0.0286\n",
      "362/1088, train_loss: 0.0286\n",
      "363/1088, train_loss: 0.0292\n",
      "364/1088, train_loss: 0.0276\n",
      "365/1088, train_loss: 0.0273\n",
      "366/1088, train_loss: 0.0268\n",
      "367/1088, train_loss: 0.0263\n",
      "368/1088, train_loss: 0.0320\n",
      "369/1088, train_loss: 0.0272\n",
      "370/1088, train_loss: 0.0288\n",
      "371/1088, train_loss: 0.0294\n",
      "372/1088, train_loss: 0.0358\n",
      "373/1088, train_loss: 0.0298\n",
      "374/1088, train_loss: 0.0315\n",
      "375/1088, train_loss: 0.0255\n",
      "376/1088, train_loss: 0.0269\n",
      "377/1088, train_loss: 0.0280\n",
      "378/1088, train_loss: 0.0291\n",
      "379/1088, train_loss: 0.0304\n",
      "380/1088, train_loss: 0.0308\n",
      "381/1088, train_loss: 0.0267\n",
      "382/1088, train_loss: 0.0293\n",
      "383/1088, train_loss: 0.0281\n",
      "384/1088, train_loss: 0.0283\n",
      "385/1088, train_loss: 0.0293\n",
      "386/1088, train_loss: 0.0273\n",
      "387/1088, train_loss: 0.0276\n",
      "388/1088, train_loss: 0.0319\n",
      "389/1088, train_loss: 0.0278\n",
      "390/1088, train_loss: 0.0290\n",
      "391/1088, train_loss: 0.0296\n",
      "392/1088, train_loss: 0.0288\n",
      "393/1088, train_loss: 0.0293\n",
      "394/1088, train_loss: 0.0285\n",
      "395/1088, train_loss: 0.0277\n",
      "396/1088, train_loss: 0.0276\n",
      "397/1088, train_loss: 0.0318\n",
      "398/1088, train_loss: 0.0273\n",
      "399/1088, train_loss: 0.0290\n",
      "400/1088, train_loss: 0.0279\n",
      "401/1088, train_loss: 0.0265\n",
      "402/1088, train_loss: 0.0274\n",
      "403/1088, train_loss: 0.0281\n",
      "404/1088, train_loss: 0.0284\n",
      "405/1088, train_loss: 0.0277\n",
      "406/1088, train_loss: 0.0311\n",
      "407/1088, train_loss: 0.0283\n",
      "408/1088, train_loss: 0.0278\n",
      "409/1088, train_loss: 0.0275\n",
      "410/1088, train_loss: 0.0281\n",
      "411/1088, train_loss: 0.0305\n",
      "412/1088, train_loss: 0.0294\n",
      "413/1088, train_loss: 0.0276\n",
      "414/1088, train_loss: 0.0291\n",
      "415/1088, train_loss: 0.0303\n",
      "416/1088, train_loss: 0.0272\n",
      "417/1088, train_loss: 0.0300\n",
      "418/1088, train_loss: 0.0280\n",
      "419/1088, train_loss: 0.0297\n",
      "420/1088, train_loss: 0.0299\n",
      "421/1088, train_loss: 0.0304\n",
      "422/1088, train_loss: 0.0298\n",
      "423/1088, train_loss: 0.0299\n",
      "424/1088, train_loss: 0.0288\n",
      "425/1088, train_loss: 0.0273\n",
      "426/1088, train_loss: 0.0272\n",
      "427/1088, train_loss: 0.0278\n",
      "428/1088, train_loss: 0.0312\n",
      "429/1088, train_loss: 0.0278\n",
      "430/1088, train_loss: 0.0323\n",
      "431/1088, train_loss: 0.0264\n",
      "432/1088, train_loss: 0.0274\n",
      "433/1088, train_loss: 0.0266\n",
      "434/1088, train_loss: 0.0283\n",
      "435/1088, train_loss: 0.0279\n",
      "436/1088, train_loss: 0.0307\n",
      "437/1088, train_loss: 0.0302\n",
      "438/1088, train_loss: 0.0275\n",
      "439/1088, train_loss: 0.0305\n",
      "440/1088, train_loss: 0.0304\n",
      "441/1088, train_loss: 0.0314\n",
      "442/1088, train_loss: 0.0293\n",
      "443/1088, train_loss: 0.0289\n",
      "444/1088, train_loss: 0.0273\n",
      "445/1088, train_loss: 0.0311\n",
      "446/1088, train_loss: 0.0335\n",
      "447/1088, train_loss: 0.0328\n",
      "448/1088, train_loss: 0.0300\n",
      "449/1088, train_loss: 0.0273\n",
      "450/1088, train_loss: 0.0301\n",
      "451/1088, train_loss: 0.0388\n",
      "452/1088, train_loss: 0.0318\n",
      "453/1088, train_loss: 0.0305\n",
      "454/1088, train_loss: 0.0239\n",
      "455/1088, train_loss: 0.0269\n",
      "456/1088, train_loss: 0.0304\n",
      "457/1088, train_loss: 0.0291\n",
      "458/1088, train_loss: 0.0300\n",
      "459/1088, train_loss: 0.0272\n",
      "460/1088, train_loss: 0.0285\n",
      "461/1088, train_loss: 0.0299\n",
      "462/1088, train_loss: 0.0281\n",
      "463/1088, train_loss: 0.0297\n",
      "464/1088, train_loss: 0.0264\n",
      "465/1088, train_loss: 0.0287\n",
      "466/1088, train_loss: 0.0272\n",
      "467/1088, train_loss: 0.0264\n",
      "468/1088, train_loss: 0.0282\n",
      "469/1088, train_loss: 0.0303\n",
      "470/1088, train_loss: 0.0278\n",
      "471/1088, train_loss: 0.0288\n",
      "472/1088, train_loss: 0.0276\n",
      "473/1088, train_loss: 0.0281\n",
      "474/1088, train_loss: 0.0316\n",
      "475/1088, train_loss: 0.0294\n",
      "476/1088, train_loss: 0.0296\n",
      "477/1088, train_loss: 0.0300\n",
      "478/1088, train_loss: 0.0287\n",
      "479/1088, train_loss: 0.0270\n",
      "480/1088, train_loss: 0.0296\n",
      "481/1088, train_loss: 0.0286\n",
      "482/1088, train_loss: 0.0283\n",
      "483/1088, train_loss: 0.0278\n",
      "484/1088, train_loss: 0.0282\n",
      "485/1088, train_loss: 0.0278\n",
      "486/1088, train_loss: 0.0300\n",
      "487/1088, train_loss: 0.0296\n",
      "488/1088, train_loss: 0.0283\n",
      "489/1088, train_loss: 0.0329\n",
      "490/1088, train_loss: 0.0286\n",
      "491/1088, train_loss: 0.0271\n",
      "492/1088, train_loss: 0.0299\n",
      "493/1088, train_loss: 0.0288\n",
      "494/1088, train_loss: 0.0281\n",
      "495/1088, train_loss: 0.0296\n",
      "496/1088, train_loss: 0.0303\n",
      "497/1088, train_loss: 0.0271\n",
      "498/1088, train_loss: 0.0297\n",
      "499/1088, train_loss: 0.0261\n",
      "500/1088, train_loss: 0.0286\n",
      "501/1088, train_loss: 0.0313\n",
      "502/1088, train_loss: 0.0308\n",
      "503/1088, train_loss: 0.0294\n",
      "504/1088, train_loss: 0.0271\n",
      "505/1088, train_loss: 0.0287\n",
      "506/1088, train_loss: 0.0295\n",
      "507/1088, train_loss: 0.0260\n",
      "508/1088, train_loss: 0.0274\n",
      "509/1088, train_loss: 0.0285\n",
      "510/1088, train_loss: 0.0296\n",
      "511/1088, train_loss: 0.0297\n",
      "512/1088, train_loss: 0.0269\n",
      "513/1088, train_loss: 0.0288\n",
      "514/1088, train_loss: 0.0279\n",
      "515/1088, train_loss: 0.0285\n",
      "516/1088, train_loss: 0.0298\n",
      "517/1088, train_loss: 0.0278\n",
      "518/1088, train_loss: 0.0283\n",
      "519/1088, train_loss: 0.0262\n",
      "520/1088, train_loss: 0.0298\n",
      "521/1088, train_loss: 0.0260\n",
      "522/1088, train_loss: 0.0274\n",
      "523/1088, train_loss: 0.0283\n",
      "524/1088, train_loss: 0.0257\n",
      "525/1088, train_loss: 0.0280\n",
      "526/1088, train_loss: 0.0306\n",
      "527/1088, train_loss: 0.0276\n",
      "528/1088, train_loss: 0.0281\n",
      "529/1088, train_loss: 0.0259\n",
      "530/1088, train_loss: 0.0270\n",
      "531/1088, train_loss: 0.0276\n",
      "532/1088, train_loss: 0.0290\n",
      "533/1088, train_loss: 0.0322\n",
      "534/1088, train_loss: 0.0306\n",
      "535/1088, train_loss: 0.0300\n",
      "536/1088, train_loss: 0.0327\n",
      "537/1088, train_loss: 0.0290\n",
      "538/1088, train_loss: 0.0312\n",
      "539/1088, train_loss: 0.0278\n",
      "540/1088, train_loss: 0.0278\n",
      "541/1088, train_loss: 0.0287\n",
      "542/1088, train_loss: 0.0312\n",
      "543/1088, train_loss: 0.0385\n",
      "544/1088, train_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545/1088, train_loss: 0.0285\n",
      "546/1088, train_loss: 0.0294\n",
      "547/1088, train_loss: 0.0295\n",
      "548/1088, train_loss: 0.0301\n",
      "549/1088, train_loss: 0.0288\n",
      "550/1088, train_loss: 0.0293\n",
      "551/1088, train_loss: 0.0283\n",
      "552/1088, train_loss: 0.0290\n",
      "553/1088, train_loss: 0.0282\n",
      "554/1088, train_loss: 0.0290\n",
      "555/1088, train_loss: 0.0313\n",
      "556/1088, train_loss: 0.0258\n",
      "557/1088, train_loss: 0.0287\n",
      "558/1088, train_loss: 0.0286\n",
      "559/1088, train_loss: 0.0265\n",
      "560/1088, train_loss: 0.0275\n",
      "561/1088, train_loss: 0.0296\n",
      "562/1088, train_loss: 0.0286\n",
      "563/1088, train_loss: 0.0293\n",
      "564/1088, train_loss: 0.0272\n",
      "565/1088, train_loss: 0.0296\n",
      "566/1088, train_loss: 0.0287\n",
      "567/1088, train_loss: 0.0289\n",
      "568/1088, train_loss: 0.0325\n",
      "569/1088, train_loss: 0.0275\n",
      "570/1088, train_loss: 0.0278\n",
      "571/1088, train_loss: 0.0297\n",
      "572/1088, train_loss: 0.0320\n",
      "573/1088, train_loss: 0.0303\n",
      "574/1088, train_loss: 0.0274\n",
      "575/1088, train_loss: 0.0281\n",
      "576/1088, train_loss: 0.0280\n",
      "577/1088, train_loss: 0.0274\n",
      "578/1088, train_loss: 0.0319\n",
      "579/1088, train_loss: 0.0294\n",
      "580/1088, train_loss: 0.0279\n",
      "581/1088, train_loss: 0.0267\n",
      "582/1088, train_loss: 0.0272\n",
      "583/1088, train_loss: 0.0266\n",
      "584/1088, train_loss: 0.0263\n",
      "585/1088, train_loss: 0.0289\n",
      "586/1088, train_loss: 0.0246\n",
      "587/1088, train_loss: 0.0273\n",
      "588/1088, train_loss: 0.0289\n",
      "589/1088, train_loss: 0.0289\n",
      "590/1088, train_loss: 0.0275\n",
      "591/1088, train_loss: 0.0277\n",
      "592/1088, train_loss: 0.0309\n",
      "593/1088, train_loss: 0.0401\n",
      "594/1088, train_loss: 0.0305\n",
      "595/1088, train_loss: 0.0273\n",
      "596/1088, train_loss: 0.0294\n",
      "597/1088, train_loss: 0.0299\n",
      "598/1088, train_loss: 0.0267\n",
      "599/1088, train_loss: 0.0297\n",
      "600/1088, train_loss: 0.0277\n",
      "601/1088, train_loss: 0.0282\n",
      "602/1088, train_loss: 0.0272\n",
      "603/1088, train_loss: 0.0280\n",
      "604/1088, train_loss: 0.0304\n",
      "605/1088, train_loss: 0.0302\n",
      "606/1088, train_loss: 0.0300\n",
      "607/1088, train_loss: 0.0277\n",
      "608/1088, train_loss: 0.0293\n",
      "609/1088, train_loss: 0.0288\n",
      "610/1088, train_loss: 0.0281\n",
      "611/1088, train_loss: 0.0316\n",
      "612/1088, train_loss: 0.0293\n",
      "613/1088, train_loss: 0.0273\n",
      "614/1088, train_loss: 0.0272\n",
      "615/1088, train_loss: 0.0314\n",
      "616/1088, train_loss: 0.0276\n",
      "617/1088, train_loss: 0.0291\n",
      "618/1088, train_loss: 0.0303\n",
      "619/1088, train_loss: 0.0285\n",
      "620/1088, train_loss: 0.0266\n",
      "621/1088, train_loss: 0.0290\n",
      "622/1088, train_loss: 0.0285\n",
      "623/1088, train_loss: 0.0274\n",
      "624/1088, train_loss: 0.0284\n",
      "625/1088, train_loss: 0.0295\n",
      "626/1088, train_loss: 0.0297\n",
      "627/1088, train_loss: 0.0285\n",
      "628/1088, train_loss: 0.0295\n",
      "629/1088, train_loss: 0.0293\n",
      "630/1088, train_loss: 0.0300\n",
      "631/1088, train_loss: 0.0295\n",
      "632/1088, train_loss: 0.0278\n",
      "633/1088, train_loss: 0.0290\n",
      "634/1088, train_loss: 0.0303\n",
      "635/1088, train_loss: 0.0305\n",
      "636/1088, train_loss: 0.0279\n",
      "637/1088, train_loss: 0.0293\n",
      "638/1088, train_loss: 0.0295\n",
      "639/1088, train_loss: 0.0272\n",
      "640/1088, train_loss: 0.0276\n",
      "641/1088, train_loss: 0.0287\n",
      "642/1088, train_loss: 0.0287\n",
      "643/1088, train_loss: 0.0289\n",
      "644/1088, train_loss: 0.0270\n",
      "645/1088, train_loss: 0.0292\n",
      "646/1088, train_loss: 0.0277\n",
      "647/1088, train_loss: 0.0294\n",
      "648/1088, train_loss: 0.0300\n",
      "649/1088, train_loss: 0.0297\n",
      "650/1088, train_loss: 0.0288\n",
      "651/1088, train_loss: 0.0292\n",
      "652/1088, train_loss: 0.0305\n",
      "653/1088, train_loss: 0.0309\n",
      "654/1088, train_loss: 0.0285\n",
      "655/1088, train_loss: 0.0282\n",
      "656/1088, train_loss: 0.0262\n",
      "657/1088, train_loss: 0.0286\n",
      "658/1088, train_loss: 0.0284\n",
      "659/1088, train_loss: 0.0302\n",
      "660/1088, train_loss: 0.0283\n",
      "661/1088, train_loss: 0.0311\n",
      "662/1088, train_loss: 0.0308\n",
      "663/1088, train_loss: 0.0302\n",
      "664/1088, train_loss: 0.0285\n",
      "665/1088, train_loss: 0.0302\n",
      "666/1088, train_loss: 0.0305\n",
      "667/1088, train_loss: 0.0279\n",
      "668/1088, train_loss: 0.0274\n",
      "669/1088, train_loss: 0.0266\n",
      "670/1088, train_loss: 0.0305\n",
      "671/1088, train_loss: 0.0287\n",
      "672/1088, train_loss: 0.0313\n",
      "673/1088, train_loss: 0.0284\n",
      "674/1088, train_loss: 0.0278\n",
      "675/1088, train_loss: 0.0289\n",
      "676/1088, train_loss: 0.0295\n",
      "677/1088, train_loss: 0.0286\n",
      "678/1088, train_loss: 0.0278\n",
      "679/1088, train_loss: 0.0308\n",
      "680/1088, train_loss: 0.0289\n",
      "681/1088, train_loss: 0.0307\n",
      "682/1088, train_loss: 0.0291\n",
      "683/1088, train_loss: 0.0296\n",
      "684/1088, train_loss: 0.0271\n",
      "685/1088, train_loss: 0.0300\n",
      "686/1088, train_loss: 0.0266\n",
      "687/1088, train_loss: 0.0286\n",
      "688/1088, train_loss: 0.0259\n",
      "689/1088, train_loss: 0.0298\n",
      "690/1088, train_loss: 0.0307\n",
      "691/1088, train_loss: 0.0255\n",
      "692/1088, train_loss: 0.0280\n",
      "693/1088, train_loss: 0.0280\n",
      "694/1088, train_loss: 0.0267\n",
      "695/1088, train_loss: 0.0279\n",
      "696/1088, train_loss: 0.0314\n",
      "697/1088, train_loss: 0.0277\n",
      "698/1088, train_loss: 0.0283\n",
      "699/1088, train_loss: 0.0293\n",
      "700/1088, train_loss: 0.0330\n",
      "701/1088, train_loss: 0.0308\n",
      "702/1088, train_loss: 0.0291\n",
      "703/1088, train_loss: 0.0279\n",
      "704/1088, train_loss: 0.0339\n",
      "705/1088, train_loss: 0.0278\n",
      "706/1088, train_loss: 0.0300\n",
      "707/1088, train_loss: 0.0283\n",
      "708/1088, train_loss: 0.0335\n",
      "709/1088, train_loss: 0.0282\n",
      "710/1088, train_loss: 0.0273\n",
      "711/1088, train_loss: 0.0293\n",
      "712/1088, train_loss: 0.0274\n",
      "713/1088, train_loss: 0.0298\n",
      "714/1088, train_loss: 0.0298\n",
      "715/1088, train_loss: 0.0274\n",
      "716/1088, train_loss: 0.0280\n",
      "717/1088, train_loss: 0.0281\n",
      "718/1088, train_loss: 0.0278\n",
      "719/1088, train_loss: 0.0284\n",
      "720/1088, train_loss: 0.0297\n",
      "721/1088, train_loss: 0.0277\n",
      "722/1088, train_loss: 0.0281\n",
      "723/1088, train_loss: 0.0285\n",
      "724/1088, train_loss: 0.0286\n",
      "725/1088, train_loss: 0.0307\n",
      "726/1088, train_loss: 0.0297\n",
      "727/1088, train_loss: 0.0280\n",
      "728/1088, train_loss: 0.0275\n",
      "729/1088, train_loss: 0.0258\n",
      "730/1088, train_loss: 0.0282\n",
      "731/1088, train_loss: 0.0273\n",
      "732/1088, train_loss: 0.0282\n",
      "733/1088, train_loss: 0.0281\n",
      "734/1088, train_loss: 0.0304\n",
      "735/1088, train_loss: 0.0286\n",
      "736/1088, train_loss: 0.0308\n",
      "737/1088, train_loss: 0.0334\n",
      "738/1088, train_loss: 0.0308\n",
      "739/1088, train_loss: 0.0303\n",
      "740/1088, train_loss: 0.0303\n",
      "741/1088, train_loss: 0.0297\n",
      "742/1088, train_loss: 0.0311\n",
      "743/1088, train_loss: 0.0286\n",
      "744/1088, train_loss: 0.0283\n",
      "745/1088, train_loss: 0.0305\n",
      "746/1088, train_loss: 0.0305\n",
      "747/1088, train_loss: 0.0281\n",
      "748/1088, train_loss: 0.0278\n",
      "749/1088, train_loss: 0.0293\n",
      "750/1088, train_loss: 0.0298\n",
      "751/1088, train_loss: 0.0302\n",
      "752/1088, train_loss: 0.0292\n",
      "753/1088, train_loss: 0.0288\n",
      "754/1088, train_loss: 0.0349\n",
      "755/1088, train_loss: 0.0295\n",
      "756/1088, train_loss: 0.0303\n",
      "757/1088, train_loss: 0.0289\n",
      "758/1088, train_loss: 0.0325\n",
      "759/1088, train_loss: 0.0334\n",
      "760/1088, train_loss: 0.0287\n",
      "761/1088, train_loss: 0.0311\n",
      "762/1088, train_loss: 0.0281\n",
      "763/1088, train_loss: 0.0273\n",
      "764/1088, train_loss: 0.0278\n",
      "765/1088, train_loss: 0.0276\n",
      "766/1088, train_loss: 0.0304\n",
      "767/1088, train_loss: 0.0293\n",
      "768/1088, train_loss: 0.0295\n",
      "769/1088, train_loss: 0.0295\n",
      "770/1088, train_loss: 0.0283\n",
      "771/1088, train_loss: 0.0296\n",
      "772/1088, train_loss: 0.0311\n",
      "773/1088, train_loss: 0.0293\n",
      "774/1088, train_loss: 0.0275\n",
      "775/1088, train_loss: 0.0300\n",
      "776/1088, train_loss: 0.0307\n",
      "777/1088, train_loss: 0.0279\n",
      "778/1088, train_loss: 0.0291\n",
      "779/1088, train_loss: 0.0287\n",
      "780/1088, train_loss: 0.0283\n",
      "781/1088, train_loss: 0.0273\n",
      "782/1088, train_loss: 0.0307\n",
      "783/1088, train_loss: 0.0295\n",
      "784/1088, train_loss: 0.0288\n",
      "785/1088, train_loss: 0.0293\n",
      "786/1088, train_loss: 0.0258\n",
      "787/1088, train_loss: 0.0286\n",
      "788/1088, train_loss: 0.0288\n",
      "789/1088, train_loss: 0.0287\n",
      "790/1088, train_loss: 0.0279\n",
      "791/1088, train_loss: 0.0296\n",
      "792/1088, train_loss: 0.0288\n",
      "793/1088, train_loss: 0.0288\n",
      "794/1088, train_loss: 0.0270\n",
      "795/1088, train_loss: 0.0288\n",
      "796/1088, train_loss: 0.0286\n",
      "797/1088, train_loss: 0.0294\n",
      "798/1088, train_loss: 0.0283\n",
      "799/1088, train_loss: 0.0268\n",
      "800/1088, train_loss: 0.0296\n",
      "801/1088, train_loss: 0.0297\n",
      "802/1088, train_loss: 0.0297\n",
      "803/1088, train_loss: 0.0294\n",
      "804/1088, train_loss: 0.0272\n",
      "805/1088, train_loss: 0.0289\n",
      "806/1088, train_loss: 0.0306\n",
      "807/1088, train_loss: 0.0279\n",
      "808/1088, train_loss: 0.0283\n",
      "809/1088, train_loss: 0.0285\n",
      "810/1088, train_loss: 0.0274\n",
      "811/1088, train_loss: 0.0290\n",
      "812/1088, train_loss: 0.0285\n",
      "813/1088, train_loss: 0.0375\n",
      "814/1088, train_loss: 0.0340\n",
      "815/1088, train_loss: 0.0288\n",
      "816/1088, train_loss: 0.0307\n",
      "817/1088, train_loss: 0.0291\n",
      "818/1088, train_loss: 0.0274\n",
      "819/1088, train_loss: 0.0287\n",
      "820/1088, train_loss: 0.0277\n",
      "821/1088, train_loss: 0.0303\n",
      "822/1088, train_loss: 0.0282\n",
      "823/1088, train_loss: 0.0293\n",
      "824/1088, train_loss: 0.0307\n",
      "825/1088, train_loss: 0.0283\n",
      "826/1088, train_loss: 0.0265\n",
      "827/1088, train_loss: 0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "828/1088, train_loss: 0.0284\n",
      "829/1088, train_loss: 0.0268\n",
      "830/1088, train_loss: 0.0281\n",
      "831/1088, train_loss: 0.0302\n",
      "832/1088, train_loss: 0.0291\n",
      "833/1088, train_loss: 0.0310\n",
      "834/1088, train_loss: 0.0294\n",
      "835/1088, train_loss: 0.0292\n",
      "836/1088, train_loss: 0.0291\n",
      "837/1088, train_loss: 0.0289\n",
      "838/1088, train_loss: 0.0295\n",
      "839/1088, train_loss: 0.0287\n",
      "840/1088, train_loss: 0.0300\n",
      "841/1088, train_loss: 0.0302\n",
      "842/1088, train_loss: 0.0259\n",
      "843/1088, train_loss: 0.0277\n",
      "844/1088, train_loss: 0.0296\n",
      "845/1088, train_loss: 0.0274\n",
      "846/1088, train_loss: 0.0294\n",
      "847/1088, train_loss: 0.0331\n",
      "848/1088, train_loss: 0.0273\n",
      "849/1088, train_loss: 0.0279\n",
      "850/1088, train_loss: 0.0267\n",
      "851/1088, train_loss: 0.0301\n",
      "852/1088, train_loss: 0.0290\n",
      "853/1088, train_loss: 0.0331\n",
      "854/1088, train_loss: 0.0307\n",
      "855/1088, train_loss: 0.0289\n",
      "856/1088, train_loss: 0.0294\n",
      "857/1088, train_loss: 0.0277\n",
      "858/1088, train_loss: 0.0301\n",
      "859/1088, train_loss: 0.0320\n",
      "860/1088, train_loss: 0.0287\n",
      "861/1088, train_loss: 0.0299\n",
      "862/1088, train_loss: 0.0272\n",
      "863/1088, train_loss: 0.0306\n",
      "864/1088, train_loss: 0.0300\n",
      "865/1088, train_loss: 0.0294\n",
      "866/1088, train_loss: 0.0303\n",
      "867/1088, train_loss: 0.0297\n",
      "868/1088, train_loss: 0.0266\n",
      "869/1088, train_loss: 0.0295\n",
      "870/1088, train_loss: 0.0290\n",
      "871/1088, train_loss: 0.0329\n",
      "872/1088, train_loss: 0.0287\n",
      "873/1088, train_loss: 0.0300\n",
      "874/1088, train_loss: 0.0280\n",
      "875/1088, train_loss: 0.0298\n",
      "876/1088, train_loss: 0.0297\n",
      "877/1088, train_loss: 0.0290\n",
      "878/1088, train_loss: 0.0297\n",
      "879/1088, train_loss: 0.0284\n",
      "880/1088, train_loss: 0.0319\n",
      "881/1088, train_loss: 0.0288\n",
      "882/1088, train_loss: 0.0298\n",
      "883/1088, train_loss: 0.0282\n",
      "884/1088, train_loss: 0.0291\n",
      "885/1088, train_loss: 0.0284\n",
      "886/1088, train_loss: 0.0277\n",
      "887/1088, train_loss: 0.0276\n",
      "888/1088, train_loss: 0.0300\n",
      "889/1088, train_loss: 0.0279\n",
      "890/1088, train_loss: 0.0303\n",
      "891/1088, train_loss: 0.0304\n",
      "892/1088, train_loss: 0.0288\n",
      "893/1088, train_loss: 0.0273\n",
      "894/1088, train_loss: 0.0281\n",
      "895/1088, train_loss: 0.0273\n",
      "896/1088, train_loss: 0.0299\n",
      "897/1088, train_loss: 0.0288\n",
      "898/1088, train_loss: 0.0304\n",
      "899/1088, train_loss: 0.0292\n",
      "900/1088, train_loss: 0.0295\n",
      "901/1088, train_loss: 0.0267\n",
      "902/1088, train_loss: 0.0287\n",
      "903/1088, train_loss: 0.0273\n",
      "904/1088, train_loss: 0.0312\n",
      "905/1088, train_loss: 0.0291\n",
      "906/1088, train_loss: 0.0305\n",
      "907/1088, train_loss: 0.0256\n",
      "908/1088, train_loss: 0.0276\n",
      "909/1088, train_loss: 0.0300\n",
      "910/1088, train_loss: 0.0291\n",
      "911/1088, train_loss: 0.0343\n",
      "912/1088, train_loss: 0.0292\n",
      "913/1088, train_loss: 0.0306\n",
      "914/1088, train_loss: 0.0305\n",
      "915/1088, train_loss: 0.0281\n",
      "916/1088, train_loss: 0.0314\n",
      "917/1088, train_loss: 0.0285\n",
      "918/1088, train_loss: 0.0288\n",
      "919/1088, train_loss: 0.0304\n",
      "920/1088, train_loss: 0.0293\n",
      "921/1088, train_loss: 0.0270\n",
      "922/1088, train_loss: 0.0302\n",
      "923/1088, train_loss: 0.0258\n",
      "924/1088, train_loss: 0.0270\n",
      "925/1088, train_loss: 0.0277\n",
      "926/1088, train_loss: 0.0275\n",
      "927/1088, train_loss: 0.0281\n",
      "928/1088, train_loss: 0.0267\n",
      "929/1088, train_loss: 0.0303\n",
      "930/1088, train_loss: 0.0303\n",
      "931/1088, train_loss: 0.0285\n",
      "932/1088, train_loss: 0.0283\n",
      "933/1088, train_loss: 0.0282\n",
      "934/1088, train_loss: 0.0296\n",
      "935/1088, train_loss: 0.0294\n",
      "936/1088, train_loss: 0.0283\n",
      "937/1088, train_loss: 0.0286\n",
      "938/1088, train_loss: 0.0303\n",
      "939/1088, train_loss: 0.0285\n",
      "940/1088, train_loss: 0.0288\n",
      "941/1088, train_loss: 0.0285\n",
      "942/1088, train_loss: 0.0286\n",
      "943/1088, train_loss: 0.0290\n",
      "944/1088, train_loss: 0.0306\n",
      "945/1088, train_loss: 0.0298\n",
      "946/1088, train_loss: 0.0292\n",
      "947/1088, train_loss: 0.0292\n",
      "948/1088, train_loss: 0.0317\n",
      "949/1088, train_loss: 0.0294\n",
      "950/1088, train_loss: 0.0267\n",
      "951/1088, train_loss: 0.0278\n",
      "952/1088, train_loss: 0.0296\n",
      "953/1088, train_loss: 0.0280\n",
      "954/1088, train_loss: 0.0285\n",
      "955/1088, train_loss: 0.0288\n",
      "956/1088, train_loss: 0.0274\n",
      "957/1088, train_loss: 0.0264\n",
      "958/1088, train_loss: 0.0295\n",
      "959/1088, train_loss: 0.0268\n",
      "960/1088, train_loss: 0.0280\n",
      "961/1088, train_loss: 0.0290\n",
      "962/1088, train_loss: 0.0300\n",
      "963/1088, train_loss: 0.0276\n",
      "964/1088, train_loss: 0.0272\n",
      "965/1088, train_loss: 0.0287\n",
      "966/1088, train_loss: 0.0268\n",
      "967/1088, train_loss: 0.0276\n",
      "968/1088, train_loss: 0.0294\n",
      "969/1088, train_loss: 0.0266\n",
      "970/1088, train_loss: 0.0273\n",
      "971/1088, train_loss: 0.0341\n",
      "972/1088, train_loss: 0.0273\n",
      "973/1088, train_loss: 0.0270\n",
      "974/1088, train_loss: 0.0283\n",
      "975/1088, train_loss: 0.0302\n",
      "976/1088, train_loss: 0.0285\n",
      "977/1088, train_loss: 0.0277\n",
      "978/1088, train_loss: 0.0278\n",
      "979/1088, train_loss: 0.0288\n",
      "980/1088, train_loss: 0.0282\n",
      "981/1088, train_loss: 0.0291\n",
      "982/1088, train_loss: 0.0290\n",
      "983/1088, train_loss: 0.0283\n",
      "984/1088, train_loss: 0.0290\n",
      "985/1088, train_loss: 0.0289\n",
      "986/1088, train_loss: 0.0284\n",
      "987/1088, train_loss: 0.0264\n",
      "988/1088, train_loss: 0.0284\n",
      "989/1088, train_loss: 0.0288\n",
      "990/1088, train_loss: 0.0281\n",
      "991/1088, train_loss: 0.0295\n",
      "992/1088, train_loss: 0.0288\n",
      "993/1088, train_loss: 0.0280\n",
      "994/1088, train_loss: 0.0308\n",
      "995/1088, train_loss: 0.0258\n",
      "996/1088, train_loss: 0.0306\n",
      "997/1088, train_loss: 0.0294\n",
      "998/1088, train_loss: 0.0288\n",
      "999/1088, train_loss: 0.0296\n",
      "1000/1088, train_loss: 0.0298\n",
      "1001/1088, train_loss: 0.0274\n",
      "1002/1088, train_loss: 0.0299\n",
      "1003/1088, train_loss: 0.0311\n",
      "1004/1088, train_loss: 0.0274\n",
      "1005/1088, train_loss: 0.0270\n",
      "1006/1088, train_loss: 0.0267\n",
      "1007/1088, train_loss: 0.0313\n",
      "1008/1088, train_loss: 0.0279\n",
      "1009/1088, train_loss: 0.0287\n",
      "1010/1088, train_loss: 0.0285\n",
      "1011/1088, train_loss: 0.0284\n",
      "1012/1088, train_loss: 0.0291\n",
      "1013/1088, train_loss: 0.0277\n",
      "1014/1088, train_loss: 0.0301\n",
      "1015/1088, train_loss: 0.0273\n",
      "1016/1088, train_loss: 0.0290\n",
      "1017/1088, train_loss: 0.0296\n",
      "1018/1088, train_loss: 0.0276\n",
      "1019/1088, train_loss: 0.0278\n",
      "1020/1088, train_loss: 0.0276\n",
      "1021/1088, train_loss: 0.0284\n",
      "1022/1088, train_loss: 0.0279\n",
      "1023/1088, train_loss: 0.0339\n",
      "1024/1088, train_loss: 0.0290\n",
      "1025/1088, train_loss: 0.0261\n",
      "1026/1088, train_loss: 0.0302\n",
      "1027/1088, train_loss: 0.0288\n",
      "1028/1088, train_loss: 0.0313\n",
      "1029/1088, train_loss: 0.0301\n",
      "1030/1088, train_loss: 0.0300\n",
      "1031/1088, train_loss: 0.0281\n",
      "1032/1088, train_loss: 0.0293\n",
      "1033/1088, train_loss: 0.0291\n",
      "1034/1088, train_loss: 0.0299\n",
      "1035/1088, train_loss: 0.0287\n",
      "1036/1088, train_loss: 0.0289\n",
      "1037/1088, train_loss: 0.0281\n",
      "1038/1088, train_loss: 0.0279\n",
      "1039/1088, train_loss: 0.0290\n",
      "1040/1088, train_loss: 0.0262\n",
      "1041/1088, train_loss: 0.0287\n",
      "1042/1088, train_loss: 0.0271\n",
      "1043/1088, train_loss: 0.0273\n",
      "1044/1088, train_loss: 0.0275\n",
      "1045/1088, train_loss: 0.0276\n",
      "1046/1088, train_loss: 0.0288\n",
      "1047/1088, train_loss: 0.0291\n",
      "1048/1088, train_loss: 0.0291\n",
      "1049/1088, train_loss: 0.0336\n",
      "1050/1088, train_loss: 0.0300\n",
      "1051/1088, train_loss: 0.0297\n",
      "1052/1088, train_loss: 0.0296\n",
      "1053/1088, train_loss: 0.0292\n",
      "1054/1088, train_loss: 0.0284\n",
      "1055/1088, train_loss: 0.0261\n",
      "1056/1088, train_loss: 0.0297\n",
      "1057/1088, train_loss: 0.0283\n",
      "1058/1088, train_loss: 0.0284\n",
      "1059/1088, train_loss: 0.0280\n",
      "1060/1088, train_loss: 0.0265\n",
      "1061/1088, train_loss: 0.0307\n",
      "1062/1088, train_loss: 0.0275\n",
      "1063/1088, train_loss: 0.0303\n",
      "1064/1088, train_loss: 0.0266\n",
      "1065/1088, train_loss: 0.0270\n",
      "1066/1088, train_loss: 0.0272\n",
      "1067/1088, train_loss: 0.0289\n",
      "1068/1088, train_loss: 0.0302\n",
      "1069/1088, train_loss: 0.0290\n",
      "1070/1088, train_loss: 0.0290\n",
      "1071/1088, train_loss: 0.0261\n",
      "1072/1088, train_loss: 0.0266\n",
      "1073/1088, train_loss: 0.0277\n",
      "1074/1088, train_loss: 0.0281\n",
      "1075/1088, train_loss: 0.0287\n",
      "1076/1088, train_loss: 0.0280\n",
      "1077/1088, train_loss: 0.0279\n",
      "1078/1088, train_loss: 0.0299\n",
      "1079/1088, train_loss: 0.0309\n",
      "1080/1088, train_loss: 0.0311\n",
      "1081/1088, train_loss: 0.0322\n",
      "1082/1088, train_loss: 0.0293\n",
      "1083/1088, train_loss: 0.0324\n",
      "1084/1088, train_loss: 0.0282\n",
      "1085/1088, train_loss: 0.0335\n",
      "1086/1088, train_loss: 0.0292\n",
      "1087/1088, train_loss: 0.0278\n",
      "1088/1088, train_loss: 0.0288\n",
      "1089/1088, train_loss: 0.0289\n",
      "epoch 9 average loss: 0.0289, train_dice: 0.9711\n",
      "epoch 9 average loss: 0.0289\n",
      "--------------------------------------------------\n",
      "epoch 10/50\n",
      "1/1088, train_loss: 0.0261\n",
      "2/1088, train_loss: 0.0283\n",
      "3/1088, train_loss: 0.0272\n",
      "4/1088, train_loss: 0.0316\n",
      "5/1088, train_loss: 0.0288\n",
      "6/1088, train_loss: 0.0274\n",
      "7/1088, train_loss: 0.0274\n",
      "8/1088, train_loss: 0.0294\n",
      "9/1088, train_loss: 0.0304\n",
      "10/1088, train_loss: 0.0279\n",
      "11/1088, train_loss: 0.0288\n",
      "12/1088, train_loss: 0.0293\n",
      "13/1088, train_loss: 0.0295\n",
      "14/1088, train_loss: 0.0267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/1088, train_loss: 0.0290\n",
      "16/1088, train_loss: 0.0299\n",
      "17/1088, train_loss: 0.0310\n",
      "18/1088, train_loss: 0.0294\n",
      "19/1088, train_loss: 0.0283\n",
      "20/1088, train_loss: 0.0259\n",
      "21/1088, train_loss: 0.0281\n",
      "22/1088, train_loss: 0.0295\n",
      "23/1088, train_loss: 0.0289\n",
      "24/1088, train_loss: 0.0303\n",
      "25/1088, train_loss: 0.0270\n",
      "26/1088, train_loss: 0.0275\n",
      "27/1088, train_loss: 0.0293\n",
      "28/1088, train_loss: 0.0301\n",
      "29/1088, train_loss: 0.0281\n",
      "30/1088, train_loss: 0.0264\n",
      "31/1088, train_loss: 0.0296\n",
      "32/1088, train_loss: 0.0277\n",
      "33/1088, train_loss: 0.0280\n",
      "34/1088, train_loss: 0.0345\n",
      "35/1088, train_loss: 0.0299\n",
      "36/1088, train_loss: 0.0285\n",
      "37/1088, train_loss: 0.0291\n",
      "38/1088, train_loss: 0.0252\n",
      "39/1088, train_loss: 0.0303\n",
      "40/1088, train_loss: 0.0279\n",
      "41/1088, train_loss: 0.0277\n",
      "42/1088, train_loss: 0.0281\n",
      "43/1088, train_loss: 0.0267\n",
      "44/1088, train_loss: 0.0286\n",
      "45/1088, train_loss: 0.0296\n",
      "46/1088, train_loss: 0.0279\n",
      "47/1088, train_loss: 0.0285\n",
      "48/1088, train_loss: 0.0294\n",
      "49/1088, train_loss: 0.0271\n",
      "50/1088, train_loss: 0.0291\n",
      "51/1088, train_loss: 0.0289\n",
      "52/1088, train_loss: 0.0271\n",
      "53/1088, train_loss: 0.0275\n",
      "54/1088, train_loss: 0.0275\n",
      "55/1088, train_loss: 0.0309\n",
      "56/1088, train_loss: 0.0270\n",
      "57/1088, train_loss: 0.0267\n",
      "58/1088, train_loss: 0.0282\n",
      "59/1088, train_loss: 0.0331\n",
      "60/1088, train_loss: 0.0306\n",
      "61/1088, train_loss: 0.0304\n",
      "62/1088, train_loss: 0.0288\n",
      "63/1088, train_loss: 0.0302\n",
      "64/1088, train_loss: 0.0302\n",
      "65/1088, train_loss: 0.0299\n",
      "66/1088, train_loss: 0.0308\n",
      "67/1088, train_loss: 0.0283\n",
      "68/1088, train_loss: 0.0289\n",
      "69/1088, train_loss: 0.0331\n",
      "70/1088, train_loss: 0.0295\n",
      "71/1088, train_loss: 0.0311\n",
      "72/1088, train_loss: 0.0293\n",
      "73/1088, train_loss: 0.0315\n",
      "74/1088, train_loss: 0.0286\n",
      "75/1088, train_loss: 0.0292\n",
      "76/1088, train_loss: 0.0274\n",
      "77/1088, train_loss: 0.0289\n",
      "78/1088, train_loss: 0.0293\n",
      "79/1088, train_loss: 0.0282\n",
      "80/1088, train_loss: 0.0292\n",
      "81/1088, train_loss: 0.0289\n",
      "82/1088, train_loss: 0.0268\n",
      "83/1088, train_loss: 0.0278\n",
      "84/1088, train_loss: 0.0268\n",
      "85/1088, train_loss: 0.0289\n",
      "86/1088, train_loss: 0.0289\n",
      "87/1088, train_loss: 0.0316\n",
      "88/1088, train_loss: 0.0285\n",
      "89/1088, train_loss: 0.0293\n",
      "90/1088, train_loss: 0.0273\n",
      "91/1088, train_loss: 0.0284\n",
      "92/1088, train_loss: 0.0289\n",
      "93/1088, train_loss: 0.0292\n",
      "94/1088, train_loss: 0.0265\n",
      "95/1088, train_loss: 0.0366\n",
      "96/1088, train_loss: 0.0281\n",
      "97/1088, train_loss: 0.0284\n",
      "98/1088, train_loss: 0.0303\n",
      "99/1088, train_loss: 0.0287\n",
      "100/1088, train_loss: 0.0277\n",
      "101/1088, train_loss: 0.0285\n",
      "102/1088, train_loss: 0.0276\n",
      "103/1088, train_loss: 0.0288\n",
      "104/1088, train_loss: 0.0297\n",
      "105/1088, train_loss: 0.0280\n",
      "106/1088, train_loss: 0.0288\n",
      "107/1088, train_loss: 0.0302\n",
      "108/1088, train_loss: 0.0265\n",
      "109/1088, train_loss: 0.0304\n",
      "110/1088, train_loss: 0.0290\n",
      "111/1088, train_loss: 0.0291\n",
      "112/1088, train_loss: 0.0307\n",
      "113/1088, train_loss: 0.0283\n",
      "114/1088, train_loss: 0.0286\n",
      "115/1088, train_loss: 0.0306\n",
      "116/1088, train_loss: 0.0305\n",
      "117/1088, train_loss: 0.0292\n",
      "118/1088, train_loss: 0.0283\n",
      "119/1088, train_loss: 0.0288\n",
      "120/1088, train_loss: 0.0289\n",
      "121/1088, train_loss: 0.0277\n",
      "122/1088, train_loss: 0.0282\n",
      "123/1088, train_loss: 0.0297\n",
      "124/1088, train_loss: 0.0301\n",
      "125/1088, train_loss: 0.0285\n",
      "126/1088, train_loss: 0.0288\n",
      "127/1088, train_loss: 0.0299\n",
      "128/1088, train_loss: 0.0277\n",
      "129/1088, train_loss: 0.0294\n",
      "130/1088, train_loss: 0.0282\n",
      "131/1088, train_loss: 0.0275\n",
      "132/1088, train_loss: 0.0269\n",
      "133/1088, train_loss: 0.0330\n",
      "134/1088, train_loss: 0.0295\n",
      "135/1088, train_loss: 0.0325\n",
      "136/1088, train_loss: 0.0281\n",
      "137/1088, train_loss: 0.0281\n",
      "138/1088, train_loss: 0.0297\n",
      "139/1088, train_loss: 0.0315\n",
      "140/1088, train_loss: 0.0296\n",
      "141/1088, train_loss: 0.0299\n",
      "142/1088, train_loss: 0.0281\n",
      "143/1088, train_loss: 0.0315\n",
      "144/1088, train_loss: 0.0292\n",
      "145/1088, train_loss: 0.0278\n",
      "146/1088, train_loss: 0.0293\n",
      "147/1088, train_loss: 0.0288\n",
      "148/1088, train_loss: 0.0316\n",
      "149/1088, train_loss: 0.0292\n",
      "150/1088, train_loss: 0.0303\n",
      "151/1088, train_loss: 0.0291\n",
      "152/1088, train_loss: 0.0285\n",
      "153/1088, train_loss: 0.0279\n",
      "154/1088, train_loss: 0.0293\n",
      "155/1088, train_loss: 0.0293\n",
      "156/1088, train_loss: 0.0281\n",
      "157/1088, train_loss: 0.0270\n",
      "158/1088, train_loss: 0.0306\n",
      "159/1088, train_loss: 0.0280\n",
      "160/1088, train_loss: 0.0268\n",
      "161/1088, train_loss: 0.0304\n",
      "162/1088, train_loss: 0.0313\n",
      "163/1088, train_loss: 0.0307\n",
      "164/1088, train_loss: 0.0288\n",
      "165/1088, train_loss: 0.0312\n",
      "166/1088, train_loss: 0.0300\n",
      "167/1088, train_loss: 0.0340\n",
      "168/1088, train_loss: 0.0274\n",
      "169/1088, train_loss: 0.0299\n",
      "170/1088, train_loss: 0.0279\n",
      "171/1088, train_loss: 0.0290\n",
      "172/1088, train_loss: 0.0300\n",
      "173/1088, train_loss: 0.0298\n",
      "174/1088, train_loss: 0.0297\n",
      "175/1088, train_loss: 0.0295\n",
      "176/1088, train_loss: 0.0297\n",
      "177/1088, train_loss: 0.0304\n",
      "178/1088, train_loss: 0.0279\n",
      "179/1088, train_loss: 0.0288\n",
      "180/1088, train_loss: 0.0292\n",
      "181/1088, train_loss: 0.0316\n",
      "182/1088, train_loss: 0.0277\n",
      "183/1088, train_loss: 0.0267\n",
      "184/1088, train_loss: 0.0291\n",
      "185/1088, train_loss: 0.0289\n",
      "186/1088, train_loss: 0.0296\n",
      "187/1088, train_loss: 0.0292\n",
      "188/1088, train_loss: 0.0304\n",
      "189/1088, train_loss: 0.0277\n",
      "190/1088, train_loss: 0.0301\n",
      "191/1088, train_loss: 0.0273\n",
      "192/1088, train_loss: 0.0266\n",
      "193/1088, train_loss: 0.0258\n",
      "194/1088, train_loss: 0.0252\n",
      "195/1088, train_loss: 0.0277\n",
      "196/1088, train_loss: 0.0271\n",
      "197/1088, train_loss: 0.0305\n",
      "198/1088, train_loss: 0.0305\n",
      "199/1088, train_loss: 0.0293\n",
      "200/1088, train_loss: 0.0288\n",
      "201/1088, train_loss: 0.0300\n",
      "202/1088, train_loss: 0.0294\n",
      "203/1088, train_loss: 0.0290\n",
      "204/1088, train_loss: 0.0309\n",
      "205/1088, train_loss: 0.0319\n",
      "206/1088, train_loss: 0.0277\n",
      "207/1088, train_loss: 0.0272\n",
      "208/1088, train_loss: 0.0290\n",
      "209/1088, train_loss: 0.0298\n",
      "210/1088, train_loss: 0.0321\n",
      "211/1088, train_loss: 0.0286\n",
      "212/1088, train_loss: 0.0284\n",
      "213/1088, train_loss: 0.0304\n",
      "214/1088, train_loss: 0.0316\n",
      "215/1088, train_loss: 0.0292\n",
      "216/1088, train_loss: 0.0300\n",
      "217/1088, train_loss: 0.0278\n",
      "218/1088, train_loss: 0.0295\n",
      "219/1088, train_loss: 0.0281\n",
      "220/1088, train_loss: 0.0298\n",
      "221/1088, train_loss: 0.0277\n",
      "222/1088, train_loss: 0.0263\n",
      "223/1088, train_loss: 0.0286\n",
      "224/1088, train_loss: 0.0281\n",
      "225/1088, train_loss: 0.0321\n",
      "226/1088, train_loss: 0.0271\n",
      "227/1088, train_loss: 0.0246\n",
      "228/1088, train_loss: 0.0300\n",
      "229/1088, train_loss: 0.0287\n",
      "230/1088, train_loss: 0.0307\n",
      "231/1088, train_loss: 0.0297\n",
      "232/1088, train_loss: 0.0290\n",
      "233/1088, train_loss: 0.0291\n",
      "234/1088, train_loss: 0.0275\n",
      "235/1088, train_loss: 0.0314\n",
      "236/1088, train_loss: 0.0252\n",
      "237/1088, train_loss: 0.0280\n",
      "238/1088, train_loss: 0.0308\n",
      "239/1088, train_loss: 0.0284\n",
      "240/1088, train_loss: 0.0266\n",
      "241/1088, train_loss: 0.0287\n",
      "242/1088, train_loss: 0.0269\n",
      "243/1088, train_loss: 0.0289\n",
      "244/1088, train_loss: 0.0280\n",
      "245/1088, train_loss: 0.0294\n",
      "246/1088, train_loss: 0.0279\n",
      "247/1088, train_loss: 0.0274\n",
      "248/1088, train_loss: 0.0318\n",
      "249/1088, train_loss: 0.0401\n",
      "250/1088, train_loss: 0.0265\n",
      "251/1088, train_loss: 0.0266\n",
      "252/1088, train_loss: 0.0283\n",
      "253/1088, train_loss: 0.0279\n",
      "254/1088, train_loss: 0.0255\n",
      "255/1088, train_loss: 0.0310\n",
      "256/1088, train_loss: 0.0318\n",
      "257/1088, train_loss: 0.0293\n",
      "258/1088, train_loss: 0.0291\n",
      "259/1088, train_loss: 0.0296\n",
      "260/1088, train_loss: 0.0291\n",
      "261/1088, train_loss: 0.0273\n",
      "262/1088, train_loss: 0.0283\n",
      "263/1088, train_loss: 0.0291\n",
      "264/1088, train_loss: 0.0310\n",
      "265/1088, train_loss: 0.0293\n",
      "266/1088, train_loss: 0.0284\n",
      "267/1088, train_loss: 0.0296\n",
      "268/1088, train_loss: 0.0280\n",
      "269/1088, train_loss: 0.0309\n",
      "270/1088, train_loss: 0.0273\n",
      "271/1088, train_loss: 0.0269\n",
      "272/1088, train_loss: 0.0285\n",
      "273/1088, train_loss: 0.0301\n",
      "274/1088, train_loss: 0.0294\n",
      "275/1088, train_loss: 0.0271\n",
      "276/1088, train_loss: 0.0291\n",
      "277/1088, train_loss: 0.0291\n",
      "278/1088, train_loss: 0.0288\n",
      "279/1088, train_loss: 0.0291\n",
      "280/1088, train_loss: 0.0276\n",
      "281/1088, train_loss: 0.0351\n",
      "282/1088, train_loss: 0.0276\n",
      "283/1088, train_loss: 0.0263\n",
      "284/1088, train_loss: 0.0302\n",
      "285/1088, train_loss: 0.0296\n",
      "286/1088, train_loss: 0.0300\n",
      "287/1088, train_loss: 0.0265\n",
      "288/1088, train_loss: 0.0296\n",
      "289/1088, train_loss: 0.0285\n",
      "290/1088, train_loss: 0.0291\n",
      "291/1088, train_loss: 0.0297\n",
      "292/1088, train_loss: 0.0280\n",
      "293/1088, train_loss: 0.0301\n",
      "294/1088, train_loss: 0.0283\n",
      "295/1088, train_loss: 0.0286\n",
      "296/1088, train_loss: 0.0300\n",
      "297/1088, train_loss: 0.0290\n",
      "298/1088, train_loss: 0.0264\n",
      "299/1088, train_loss: 0.0295\n",
      "300/1088, train_loss: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/1088, train_loss: 0.0286\n",
      "302/1088, train_loss: 0.0291\n",
      "303/1088, train_loss: 0.0287\n",
      "304/1088, train_loss: 0.0271\n",
      "305/1088, train_loss: 0.0290\n",
      "306/1088, train_loss: 0.0297\n",
      "307/1088, train_loss: 0.0287\n",
      "308/1088, train_loss: 0.0272\n",
      "309/1088, train_loss: 0.0296\n",
      "310/1088, train_loss: 0.0281\n",
      "311/1088, train_loss: 0.0278\n",
      "312/1088, train_loss: 0.0287\n",
      "313/1088, train_loss: 0.0283\n",
      "314/1088, train_loss: 0.0270\n",
      "315/1088, train_loss: 0.0297\n",
      "316/1088, train_loss: 0.0255\n",
      "317/1088, train_loss: 0.0308\n",
      "318/1088, train_loss: 0.0322\n",
      "319/1088, train_loss: 0.0287\n",
      "320/1088, train_loss: 0.0286\n",
      "321/1088, train_loss: 0.0277\n",
      "322/1088, train_loss: 0.0285\n",
      "323/1088, train_loss: 0.0289\n",
      "324/1088, train_loss: 0.0275\n",
      "325/1088, train_loss: 0.0277\n",
      "326/1088, train_loss: 0.0271\n",
      "327/1088, train_loss: 0.0300\n",
      "328/1088, train_loss: 0.0274\n",
      "329/1088, train_loss: 0.0288\n",
      "330/1088, train_loss: 0.0275\n",
      "331/1088, train_loss: 0.0289\n",
      "332/1088, train_loss: 0.0314\n",
      "333/1088, train_loss: 0.0304\n",
      "334/1088, train_loss: 0.0304\n",
      "335/1088, train_loss: 0.0295\n",
      "336/1088, train_loss: 0.0280\n",
      "337/1088, train_loss: 0.0296\n",
      "338/1088, train_loss: 0.0295\n",
      "339/1088, train_loss: 0.0291\n",
      "340/1088, train_loss: 0.0290\n",
      "341/1088, train_loss: 0.0267\n",
      "342/1088, train_loss: 0.0270\n",
      "343/1088, train_loss: 0.0293\n",
      "344/1088, train_loss: 0.0255\n",
      "345/1088, train_loss: 0.0300\n",
      "346/1088, train_loss: 0.0293\n",
      "347/1088, train_loss: 0.0333\n",
      "348/1088, train_loss: 0.0294\n",
      "349/1088, train_loss: 0.0303\n",
      "350/1088, train_loss: 0.0273\n",
      "351/1088, train_loss: 0.0297\n",
      "352/1088, train_loss: 0.0270\n",
      "353/1088, train_loss: 0.0271\n",
      "354/1088, train_loss: 0.0290\n",
      "355/1088, train_loss: 0.0294\n",
      "356/1088, train_loss: 0.0292\n",
      "357/1088, train_loss: 0.0294\n",
      "358/1088, train_loss: 0.0283\n",
      "359/1088, train_loss: 0.0268\n",
      "360/1088, train_loss: 0.0274\n",
      "361/1088, train_loss: 0.0267\n",
      "362/1088, train_loss: 0.0309\n",
      "363/1088, train_loss: 0.0262\n",
      "364/1088, train_loss: 0.0307\n",
      "365/1088, train_loss: 0.0301\n",
      "366/1088, train_loss: 0.0285\n",
      "367/1088, train_loss: 0.0272\n",
      "368/1088, train_loss: 0.0324\n",
      "369/1088, train_loss: 0.0291\n",
      "370/1088, train_loss: 0.0299\n",
      "371/1088, train_loss: 0.0279\n",
      "372/1088, train_loss: 0.0284\n",
      "373/1088, train_loss: 0.0269\n",
      "374/1088, train_loss: 0.0286\n",
      "375/1088, train_loss: 0.0293\n",
      "376/1088, train_loss: 0.0295\n",
      "377/1088, train_loss: 0.0304\n",
      "378/1088, train_loss: 0.0294\n",
      "379/1088, train_loss: 0.0295\n",
      "380/1088, train_loss: 0.0295\n",
      "381/1088, train_loss: 0.0266\n",
      "382/1088, train_loss: 0.0290\n",
      "383/1088, train_loss: 0.0289\n",
      "384/1088, train_loss: 0.0301\n",
      "385/1088, train_loss: 0.0296\n",
      "386/1088, train_loss: 0.0276\n",
      "387/1088, train_loss: 0.0285\n",
      "388/1088, train_loss: 0.0294\n",
      "389/1088, train_loss: 0.0291\n",
      "390/1088, train_loss: 0.0299\n",
      "391/1088, train_loss: 0.0267\n",
      "392/1088, train_loss: 0.0305\n",
      "393/1088, train_loss: 0.0282\n",
      "394/1088, train_loss: 0.0290\n",
      "395/1088, train_loss: 0.0291\n",
      "396/1088, train_loss: 0.0295\n",
      "397/1088, train_loss: 0.0293\n",
      "398/1088, train_loss: 0.0310\n",
      "399/1088, train_loss: 0.0327\n",
      "400/1088, train_loss: 0.0284\n",
      "401/1088, train_loss: 0.0288\n",
      "402/1088, train_loss: 0.0270\n",
      "403/1088, train_loss: 0.0272\n",
      "404/1088, train_loss: 0.0279\n",
      "405/1088, train_loss: 0.0294\n",
      "406/1088, train_loss: 0.0295\n",
      "407/1088, train_loss: 0.0289\n",
      "408/1088, train_loss: 0.0304\n",
      "409/1088, train_loss: 0.0283\n",
      "410/1088, train_loss: 0.0309\n",
      "411/1088, train_loss: 0.0269\n",
      "412/1088, train_loss: 0.0266\n",
      "413/1088, train_loss: 0.0276\n",
      "414/1088, train_loss: 0.0300\n",
      "415/1088, train_loss: 0.0277\n",
      "416/1088, train_loss: 0.0290\n",
      "417/1088, train_loss: 0.0288\n",
      "418/1088, train_loss: 0.0285\n",
      "419/1088, train_loss: 0.0285\n",
      "420/1088, train_loss: 0.0279\n",
      "421/1088, train_loss: 0.0313\n",
      "422/1088, train_loss: 0.0275\n",
      "423/1088, train_loss: 0.0288\n",
      "424/1088, train_loss: 0.0266\n",
      "425/1088, train_loss: 0.0280\n",
      "426/1088, train_loss: 0.0313\n",
      "427/1088, train_loss: 0.0268\n",
      "428/1088, train_loss: 0.0271\n",
      "429/1088, train_loss: 0.0275\n",
      "430/1088, train_loss: 0.0279\n",
      "431/1088, train_loss: 0.0304\n",
      "432/1088, train_loss: 0.0294\n",
      "433/1088, train_loss: 0.0350\n",
      "434/1088, train_loss: 0.0279\n",
      "435/1088, train_loss: 0.0302\n",
      "436/1088, train_loss: 0.0294\n",
      "437/1088, train_loss: 0.0303\n",
      "438/1088, train_loss: 0.0299\n",
      "439/1088, train_loss: 0.0318\n",
      "440/1088, train_loss: 0.0299\n",
      "441/1088, train_loss: 0.0286\n",
      "442/1088, train_loss: 0.0263\n",
      "443/1088, train_loss: 0.0299\n",
      "444/1088, train_loss: 0.0288\n",
      "445/1088, train_loss: 0.0382\n",
      "446/1088, train_loss: 0.0293\n",
      "447/1088, train_loss: 0.0289\n",
      "448/1088, train_loss: 0.0314\n",
      "449/1088, train_loss: 0.0288\n",
      "450/1088, train_loss: 0.0304\n",
      "451/1088, train_loss: 0.0264\n",
      "452/1088, train_loss: 0.0292\n",
      "453/1088, train_loss: 0.0285\n",
      "454/1088, train_loss: 0.0289\n",
      "455/1088, train_loss: 0.0271\n",
      "456/1088, train_loss: 0.0280\n",
      "457/1088, train_loss: 0.0280\n",
      "458/1088, train_loss: 0.0281\n",
      "459/1088, train_loss: 0.0274\n",
      "460/1088, train_loss: 0.0287\n",
      "461/1088, train_loss: 0.0262\n",
      "462/1088, train_loss: 0.0282\n",
      "463/1088, train_loss: 0.0276\n",
      "464/1088, train_loss: 0.0284\n",
      "465/1088, train_loss: 0.0312\n",
      "466/1088, train_loss: 0.0301\n",
      "467/1088, train_loss: 0.0288\n",
      "468/1088, train_loss: 0.0293\n",
      "469/1088, train_loss: 0.0284\n",
      "470/1088, train_loss: 0.0293\n",
      "471/1088, train_loss: 0.0286\n",
      "472/1088, train_loss: 0.0271\n",
      "473/1088, train_loss: 0.0278\n",
      "474/1088, train_loss: 0.0278\n",
      "475/1088, train_loss: 0.0276\n",
      "476/1088, train_loss: 0.0275\n",
      "477/1088, train_loss: 0.0285\n",
      "478/1088, train_loss: 0.0292\n",
      "479/1088, train_loss: 0.0265\n",
      "480/1088, train_loss: 0.0276\n",
      "481/1088, train_loss: 0.0287\n",
      "482/1088, train_loss: 0.0278\n",
      "483/1088, train_loss: 0.0274\n",
      "484/1088, train_loss: 0.0288\n",
      "485/1088, train_loss: 0.0275\n",
      "486/1088, train_loss: 0.0293\n",
      "487/1088, train_loss: 0.0295\n",
      "488/1088, train_loss: 0.0266\n",
      "489/1088, train_loss: 0.0291\n",
      "490/1088, train_loss: 0.0279\n",
      "491/1088, train_loss: 0.0273\n",
      "492/1088, train_loss: 0.0300\n",
      "493/1088, train_loss: 0.0300\n",
      "494/1088, train_loss: 0.0274\n",
      "495/1088, train_loss: 0.0283\n",
      "496/1088, train_loss: 0.0305\n",
      "497/1088, train_loss: 0.0296\n",
      "498/1088, train_loss: 0.0298\n",
      "499/1088, train_loss: 0.0280\n",
      "500/1088, train_loss: 0.0283\n",
      "501/1088, train_loss: 0.0269\n",
      "502/1088, train_loss: 0.0290\n",
      "503/1088, train_loss: 0.0298\n",
      "504/1088, train_loss: 0.0286\n",
      "505/1088, train_loss: 0.0262\n",
      "506/1088, train_loss: 0.0283\n",
      "507/1088, train_loss: 0.0290\n",
      "508/1088, train_loss: 0.0287\n",
      "509/1088, train_loss: 0.0299\n",
      "510/1088, train_loss: 0.0305\n",
      "511/1088, train_loss: 0.0282\n",
      "512/1088, train_loss: 0.0299\n",
      "513/1088, train_loss: 0.0284\n",
      "514/1088, train_loss: 0.0272\n",
      "515/1088, train_loss: 0.0293\n",
      "516/1088, train_loss: 0.0299\n",
      "517/1088, train_loss: 0.0321\n",
      "518/1088, train_loss: 0.0296\n",
      "519/1088, train_loss: 0.0275\n",
      "520/1088, train_loss: 0.0277\n",
      "521/1088, train_loss: 0.0288\n",
      "522/1088, train_loss: 0.0263\n",
      "523/1088, train_loss: 0.0294\n",
      "524/1088, train_loss: 0.0351\n",
      "525/1088, train_loss: 0.0280\n",
      "526/1088, train_loss: 0.0296\n",
      "527/1088, train_loss: 0.0298\n",
      "528/1088, train_loss: 0.0282\n",
      "529/1088, train_loss: 0.0293\n",
      "530/1088, train_loss: 0.0288\n",
      "531/1088, train_loss: 0.0290\n",
      "532/1088, train_loss: 0.0280\n",
      "533/1088, train_loss: 0.0304\n",
      "534/1088, train_loss: 0.0273\n",
      "535/1088, train_loss: 0.0313\n",
      "536/1088, train_loss: 0.0279\n",
      "537/1088, train_loss: 0.0282\n",
      "538/1088, train_loss: 0.0284\n",
      "539/1088, train_loss: 0.0295\n",
      "540/1088, train_loss: 0.0299\n",
      "541/1088, train_loss: 0.0289\n",
      "542/1088, train_loss: 0.0281\n",
      "543/1088, train_loss: 0.0286\n",
      "544/1088, train_loss: 0.0275\n",
      "545/1088, train_loss: 0.0306\n",
      "546/1088, train_loss: 0.0277\n",
      "547/1088, train_loss: 0.0277\n",
      "548/1088, train_loss: 0.0295\n",
      "549/1088, train_loss: 0.0280\n",
      "550/1088, train_loss: 0.0307\n",
      "551/1088, train_loss: 0.0290\n",
      "552/1088, train_loss: 0.0279\n",
      "553/1088, train_loss: 0.0295\n",
      "554/1088, train_loss: 0.0316\n",
      "555/1088, train_loss: 0.0285\n",
      "556/1088, train_loss: 0.0327\n",
      "557/1088, train_loss: 0.0290\n",
      "558/1088, train_loss: 0.0276\n",
      "559/1088, train_loss: 0.0274\n",
      "560/1088, train_loss: 0.0295\n",
      "561/1088, train_loss: 0.0280\n",
      "562/1088, train_loss: 0.0280\n",
      "563/1088, train_loss: 0.0266\n",
      "564/1088, train_loss: 0.0291\n",
      "565/1088, train_loss: 0.0296\n",
      "566/1088, train_loss: 0.0263\n",
      "567/1088, train_loss: 0.0294\n",
      "568/1088, train_loss: 0.0276\n",
      "569/1088, train_loss: 0.0294\n",
      "570/1088, train_loss: 0.0276\n",
      "571/1088, train_loss: 0.0269\n",
      "572/1088, train_loss: 0.0275\n",
      "573/1088, train_loss: 0.0293\n",
      "574/1088, train_loss: 0.0296\n",
      "575/1088, train_loss: 0.0286\n",
      "576/1088, train_loss: 0.0281\n",
      "577/1088, train_loss: 0.0285\n",
      "578/1088, train_loss: 0.0303\n",
      "579/1088, train_loss: 0.0280\n",
      "580/1088, train_loss: 0.0258\n",
      "581/1088, train_loss: 0.0338\n",
      "582/1088, train_loss: 0.0317\n",
      "583/1088, train_loss: 0.0274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/1088, train_loss: 0.0293\n",
      "585/1088, train_loss: 0.0316\n",
      "586/1088, train_loss: 0.0287\n",
      "587/1088, train_loss: 0.0296\n",
      "588/1088, train_loss: 0.0284\n",
      "589/1088, train_loss: 0.0276\n",
      "590/1088, train_loss: 0.0293\n",
      "591/1088, train_loss: 0.0274\n",
      "592/1088, train_loss: 0.0296\n",
      "593/1088, train_loss: 0.0286\n",
      "594/1088, train_loss: 0.0306\n",
      "595/1088, train_loss: 0.0346\n",
      "596/1088, train_loss: 0.0330\n",
      "597/1088, train_loss: 0.0290\n",
      "598/1088, train_loss: 0.0298\n",
      "599/1088, train_loss: 0.0276\n",
      "600/1088, train_loss: 0.0323\n",
      "601/1088, train_loss: 0.0285\n",
      "602/1088, train_loss: 0.0291\n",
      "603/1088, train_loss: 0.0274\n",
      "604/1088, train_loss: 0.0286\n",
      "605/1088, train_loss: 0.0274\n",
      "606/1088, train_loss: 0.0273\n",
      "607/1088, train_loss: 0.0294\n",
      "608/1088, train_loss: 0.0302\n",
      "609/1088, train_loss: 0.0282\n",
      "610/1088, train_loss: 0.0288\n",
      "611/1088, train_loss: 0.0271\n",
      "612/1088, train_loss: 0.0267\n",
      "613/1088, train_loss: 0.0296\n",
      "614/1088, train_loss: 0.0296\n",
      "615/1088, train_loss: 0.0273\n",
      "616/1088, train_loss: 0.0282\n",
      "617/1088, train_loss: 0.0261\n",
      "618/1088, train_loss: 0.0266\n",
      "619/1088, train_loss: 0.0280\n",
      "620/1088, train_loss: 0.0285\n",
      "621/1088, train_loss: 0.0279\n",
      "622/1088, train_loss: 0.0271\n",
      "623/1088, train_loss: 0.0292\n",
      "624/1088, train_loss: 0.0294\n",
      "625/1088, train_loss: 0.0268\n",
      "626/1088, train_loss: 0.0355\n",
      "627/1088, train_loss: 0.0260\n",
      "628/1088, train_loss: 0.0271\n",
      "629/1088, train_loss: 0.0268\n",
      "630/1088, train_loss: 0.0264\n",
      "631/1088, train_loss: 0.0292\n",
      "632/1088, train_loss: 0.0289\n",
      "633/1088, train_loss: 0.0274\n",
      "634/1088, train_loss: 0.0288\n",
      "635/1088, train_loss: 0.0291\n",
      "636/1088, train_loss: 0.0260\n",
      "637/1088, train_loss: 0.0287\n",
      "638/1088, train_loss: 0.0279\n",
      "639/1088, train_loss: 0.0280\n",
      "640/1088, train_loss: 0.0326\n",
      "641/1088, train_loss: 0.0271\n",
      "642/1088, train_loss: 0.0281\n",
      "643/1088, train_loss: 0.0269\n",
      "644/1088, train_loss: 0.0272\n",
      "645/1088, train_loss: 0.0304\n",
      "646/1088, train_loss: 0.0273\n",
      "647/1088, train_loss: 0.0264\n",
      "648/1088, train_loss: 0.0291\n",
      "649/1088, train_loss: 0.0302\n",
      "650/1088, train_loss: 0.0277\n",
      "651/1088, train_loss: 0.0311\n",
      "652/1088, train_loss: 0.0300\n",
      "653/1088, train_loss: 0.0278\n",
      "654/1088, train_loss: 0.0350\n",
      "655/1088, train_loss: 0.0278\n",
      "656/1088, train_loss: 0.0294\n",
      "657/1088, train_loss: 0.0290\n",
      "658/1088, train_loss: 0.0301\n",
      "659/1088, train_loss: 0.0336\n",
      "660/1088, train_loss: 0.0306\n",
      "661/1088, train_loss: 0.0305\n",
      "662/1088, train_loss: 0.0319\n",
      "663/1088, train_loss: 0.0299\n",
      "664/1088, train_loss: 0.0272\n",
      "665/1088, train_loss: 0.0283\n",
      "666/1088, train_loss: 0.0277\n",
      "667/1088, train_loss: 0.0288\n",
      "668/1088, train_loss: 0.0283\n",
      "669/1088, train_loss: 0.0287\n",
      "670/1088, train_loss: 0.0284\n",
      "671/1088, train_loss: 0.0288\n",
      "672/1088, train_loss: 0.0298\n",
      "673/1088, train_loss: 0.0278\n",
      "674/1088, train_loss: 0.0281\n",
      "675/1088, train_loss: 0.0288\n",
      "676/1088, train_loss: 0.0250\n",
      "677/1088, train_loss: 0.0294\n",
      "678/1088, train_loss: 0.0269\n",
      "679/1088, train_loss: 0.0282\n",
      "680/1088, train_loss: 0.0277\n",
      "681/1088, train_loss: 0.0263\n",
      "682/1088, train_loss: 0.0277\n",
      "683/1088, train_loss: 0.0283\n",
      "684/1088, train_loss: 0.0283\n",
      "685/1088, train_loss: 0.0361\n",
      "686/1088, train_loss: 0.0284\n",
      "687/1088, train_loss: 0.0305\n",
      "688/1088, train_loss: 0.0292\n",
      "689/1088, train_loss: 0.0289\n",
      "690/1088, train_loss: 0.0280\n",
      "691/1088, train_loss: 0.0265\n",
      "692/1088, train_loss: 0.0305\n",
      "693/1088, train_loss: 0.0286\n",
      "694/1088, train_loss: 0.0295\n",
      "695/1088, train_loss: 0.0293\n",
      "696/1088, train_loss: 0.0304\n",
      "697/1088, train_loss: 0.0289\n",
      "698/1088, train_loss: 0.0296\n",
      "699/1088, train_loss: 0.0292\n",
      "700/1088, train_loss: 0.0289\n",
      "701/1088, train_loss: 0.0273\n",
      "702/1088, train_loss: 0.0283\n",
      "703/1088, train_loss: 0.0286\n",
      "704/1088, train_loss: 0.0282\n",
      "705/1088, train_loss: 0.0298\n",
      "706/1088, train_loss: 0.0289\n",
      "707/1088, train_loss: 0.0291\n",
      "708/1088, train_loss: 0.0293\n",
      "709/1088, train_loss: 0.0279\n",
      "710/1088, train_loss: 0.0282\n",
      "711/1088, train_loss: 0.0291\n",
      "712/1088, train_loss: 0.0300\n",
      "713/1088, train_loss: 0.0278\n",
      "714/1088, train_loss: 0.0294\n",
      "715/1088, train_loss: 0.0278\n",
      "716/1088, train_loss: 0.0265\n",
      "717/1088, train_loss: 0.0272\n",
      "718/1088, train_loss: 0.0280\n",
      "719/1088, train_loss: 0.0293\n",
      "720/1088, train_loss: 0.0285\n",
      "721/1088, train_loss: 0.0281\n",
      "722/1088, train_loss: 0.0306\n",
      "723/1088, train_loss: 0.0289\n",
      "724/1088, train_loss: 0.0283\n",
      "725/1088, train_loss: 0.0275\n",
      "726/1088, train_loss: 0.0275\n",
      "727/1088, train_loss: 0.0280\n",
      "728/1088, train_loss: 0.0278\n",
      "729/1088, train_loss: 0.0286\n",
      "730/1088, train_loss: 0.0286\n",
      "731/1088, train_loss: 0.0287\n",
      "732/1088, train_loss: 0.0293\n",
      "733/1088, train_loss: 0.0273\n",
      "734/1088, train_loss: 0.0330\n",
      "735/1088, train_loss: 0.0271\n",
      "736/1088, train_loss: 0.0290\n",
      "737/1088, train_loss: 0.0249\n",
      "738/1088, train_loss: 0.0279\n",
      "739/1088, train_loss: 0.0279\n",
      "740/1088, train_loss: 0.0275\n",
      "741/1088, train_loss: 0.0295\n",
      "742/1088, train_loss: 0.0309\n",
      "743/1088, train_loss: 0.0262\n",
      "744/1088, train_loss: 0.0273\n",
      "745/1088, train_loss: 0.0290\n",
      "746/1088, train_loss: 0.0285\n",
      "747/1088, train_loss: 0.0296\n",
      "748/1088, train_loss: 0.0266\n",
      "749/1088, train_loss: 0.0294\n",
      "750/1088, train_loss: 0.0275\n",
      "751/1088, train_loss: 0.0288\n",
      "752/1088, train_loss: 0.0271\n",
      "753/1088, train_loss: 0.0291\n",
      "754/1088, train_loss: 0.0275\n",
      "755/1088, train_loss: 0.0283\n",
      "756/1088, train_loss: 0.0289\n",
      "757/1088, train_loss: 0.0300\n",
      "758/1088, train_loss: 0.0281\n",
      "759/1088, train_loss: 0.0271\n",
      "760/1088, train_loss: 0.0292\n",
      "761/1088, train_loss: 0.0280\n",
      "762/1088, train_loss: 0.0281\n",
      "763/1088, train_loss: 0.0287\n",
      "764/1088, train_loss: 0.0291\n",
      "765/1088, train_loss: 0.0299\n",
      "766/1088, train_loss: 0.0283\n",
      "767/1088, train_loss: 0.0275\n",
      "768/1088, train_loss: 0.0263\n",
      "769/1088, train_loss: 0.0312\n",
      "770/1088, train_loss: 0.0300\n",
      "771/1088, train_loss: 0.0271\n",
      "772/1088, train_loss: 0.0276\n",
      "773/1088, train_loss: 0.0282\n",
      "774/1088, train_loss: 0.0250\n",
      "775/1088, train_loss: 0.0287\n",
      "776/1088, train_loss: 0.0275\n",
      "777/1088, train_loss: 0.0298\n",
      "778/1088, train_loss: 0.0273\n",
      "779/1088, train_loss: 0.0277\n",
      "780/1088, train_loss: 0.0302\n",
      "781/1088, train_loss: 0.0271\n",
      "782/1088, train_loss: 0.0300\n",
      "783/1088, train_loss: 0.0380\n",
      "784/1088, train_loss: 0.0278\n",
      "785/1088, train_loss: 0.0288\n",
      "786/1088, train_loss: 0.0294\n",
      "787/1088, train_loss: 0.0288\n",
      "788/1088, train_loss: 0.0279\n",
      "789/1088, train_loss: 0.0298\n",
      "790/1088, train_loss: 0.0276\n",
      "791/1088, train_loss: 0.0293\n",
      "792/1088, train_loss: 0.0266\n",
      "793/1088, train_loss: 0.0314\n",
      "794/1088, train_loss: 0.0284\n",
      "795/1088, train_loss: 0.0268\n",
      "796/1088, train_loss: 0.0290\n",
      "797/1088, train_loss: 0.0289\n",
      "798/1088, train_loss: 0.0291\n",
      "799/1088, train_loss: 0.0303\n",
      "800/1088, train_loss: 0.0258\n",
      "801/1088, train_loss: 0.0282\n",
      "802/1088, train_loss: 0.0268\n",
      "803/1088, train_loss: 0.0290\n",
      "804/1088, train_loss: 0.0302\n",
      "805/1088, train_loss: 0.0278\n",
      "806/1088, train_loss: 0.0286\n",
      "807/1088, train_loss: 0.0285\n",
      "808/1088, train_loss: 0.0285\n",
      "809/1088, train_loss: 0.0265\n",
      "810/1088, train_loss: 0.0270\n",
      "811/1088, train_loss: 0.0303\n",
      "812/1088, train_loss: 0.0303\n",
      "813/1088, train_loss: 0.0326\n",
      "814/1088, train_loss: 0.0319\n",
      "815/1088, train_loss: 0.0300\n",
      "816/1088, train_loss: 0.0269\n",
      "817/1088, train_loss: 0.0289\n",
      "818/1088, train_loss: 0.0289\n",
      "819/1088, train_loss: 0.0282\n",
      "820/1088, train_loss: 0.0277\n",
      "821/1088, train_loss: 0.0280\n",
      "822/1088, train_loss: 0.0288\n",
      "823/1088, train_loss: 0.0290\n",
      "824/1088, train_loss: 0.0278\n",
      "825/1088, train_loss: 0.0293\n",
      "826/1088, train_loss: 0.0293\n",
      "827/1088, train_loss: 0.0276\n",
      "828/1088, train_loss: 0.0271\n",
      "829/1088, train_loss: 0.0272\n",
      "830/1088, train_loss: 0.0274\n",
      "831/1088, train_loss: 0.0279\n",
      "832/1088, train_loss: 0.0287\n",
      "833/1088, train_loss: 0.0312\n",
      "834/1088, train_loss: 0.0274\n",
      "835/1088, train_loss: 0.0311\n",
      "836/1088, train_loss: 0.0285\n",
      "837/1088, train_loss: 0.0292\n",
      "838/1088, train_loss: 0.0410\n",
      "839/1088, train_loss: 0.0292\n",
      "840/1088, train_loss: 0.0331\n",
      "841/1088, train_loss: 0.0317\n",
      "842/1088, train_loss: 0.0315\n",
      "843/1088, train_loss: 0.0289\n",
      "844/1088, train_loss: 0.0286\n",
      "845/1088, train_loss: 0.0294\n",
      "846/1088, train_loss: 0.0275\n",
      "847/1088, train_loss: 0.0283\n",
      "848/1088, train_loss: 0.0276\n",
      "849/1088, train_loss: 0.0281\n",
      "850/1088, train_loss: 0.0288\n",
      "851/1088, train_loss: 0.0288\n",
      "852/1088, train_loss: 0.0291\n",
      "853/1088, train_loss: 0.0275\n",
      "854/1088, train_loss: 0.0284\n",
      "855/1088, train_loss: 0.0306\n",
      "856/1088, train_loss: 0.0287\n",
      "857/1088, train_loss: 0.0285\n",
      "858/1088, train_loss: 0.0294\n",
      "859/1088, train_loss: 0.0278\n",
      "860/1088, train_loss: 0.0282\n",
      "861/1088, train_loss: 0.0291\n",
      "862/1088, train_loss: 0.0300\n",
      "863/1088, train_loss: 0.0292\n",
      "864/1088, train_loss: 0.0291\n",
      "865/1088, train_loss: 0.0272\n",
      "866/1088, train_loss: 0.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "867/1088, train_loss: 0.0274\n",
      "868/1088, train_loss: 0.0268\n",
      "869/1088, train_loss: 0.0275\n",
      "870/1088, train_loss: 0.0298\n",
      "871/1088, train_loss: 0.0283\n",
      "872/1088, train_loss: 0.0285\n",
      "873/1088, train_loss: 0.0308\n",
      "874/1088, train_loss: 0.0300\n",
      "875/1088, train_loss: 0.0291\n",
      "876/1088, train_loss: 0.0256\n",
      "877/1088, train_loss: 0.0305\n",
      "878/1088, train_loss: 0.0285\n",
      "879/1088, train_loss: 0.0293\n",
      "880/1088, train_loss: 0.0299\n",
      "881/1088, train_loss: 0.0288\n",
      "882/1088, train_loss: 0.0303\n",
      "883/1088, train_loss: 0.0281\n",
      "884/1088, train_loss: 0.0285\n",
      "885/1088, train_loss: 0.0295\n",
      "886/1088, train_loss: 0.0323\n",
      "887/1088, train_loss: 0.0285\n",
      "888/1088, train_loss: 0.0280\n",
      "889/1088, train_loss: 0.0280\n",
      "890/1088, train_loss: 0.0279\n",
      "891/1088, train_loss: 0.0273\n",
      "892/1088, train_loss: 0.0269\n",
      "893/1088, train_loss: 0.0295\n",
      "894/1088, train_loss: 0.0304\n",
      "895/1088, train_loss: 0.0298\n",
      "896/1088, train_loss: 0.0282\n",
      "897/1088, train_loss: 0.0303\n",
      "898/1088, train_loss: 0.0282\n",
      "899/1088, train_loss: 0.0286\n",
      "900/1088, train_loss: 0.0281\n",
      "901/1088, train_loss: 0.0299\n",
      "902/1088, train_loss: 0.0257\n",
      "903/1088, train_loss: 0.0298\n",
      "904/1088, train_loss: 0.0278\n",
      "905/1088, train_loss: 0.0275\n",
      "906/1088, train_loss: 0.0294\n",
      "907/1088, train_loss: 0.0287\n",
      "908/1088, train_loss: 0.0267\n",
      "909/1088, train_loss: 0.0280\n",
      "910/1088, train_loss: 0.0271\n",
      "911/1088, train_loss: 0.0275\n",
      "912/1088, train_loss: 0.0272\n",
      "913/1088, train_loss: 0.0303\n",
      "914/1088, train_loss: 0.0285\n",
      "915/1088, train_loss: 0.0295\n",
      "916/1088, train_loss: 0.0275\n",
      "917/1088, train_loss: 0.0283\n",
      "918/1088, train_loss: 0.0312\n",
      "919/1088, train_loss: 0.0280\n",
      "920/1088, train_loss: 0.0308\n",
      "921/1088, train_loss: 0.0266\n",
      "922/1088, train_loss: 0.0294\n",
      "923/1088, train_loss: 0.0293\n",
      "924/1088, train_loss: 0.0292\n",
      "925/1088, train_loss: 0.0262\n",
      "926/1088, train_loss: 0.0280\n",
      "927/1088, train_loss: 0.0298\n",
      "928/1088, train_loss: 0.0281\n",
      "929/1088, train_loss: 0.0292\n",
      "930/1088, train_loss: 0.0287\n",
      "931/1088, train_loss: 0.0272\n",
      "932/1088, train_loss: 0.0296\n",
      "933/1088, train_loss: 0.0257\n",
      "934/1088, train_loss: 0.0305\n",
      "935/1088, train_loss: 0.0260\n",
      "936/1088, train_loss: 0.0275\n",
      "937/1088, train_loss: 0.0283\n",
      "938/1088, train_loss: 0.0294\n",
      "939/1088, train_loss: 0.0269\n",
      "940/1088, train_loss: 0.0358\n",
      "941/1088, train_loss: 0.0271\n",
      "942/1088, train_loss: 0.0275\n",
      "943/1088, train_loss: 0.0286\n",
      "944/1088, train_loss: 0.0272\n",
      "945/1088, train_loss: 0.0304\n",
      "946/1088, train_loss: 0.0287\n",
      "947/1088, train_loss: 0.0304\n",
      "948/1088, train_loss: 0.0300\n",
      "949/1088, train_loss: 0.0285\n",
      "950/1088, train_loss: 0.0284\n",
      "951/1088, train_loss: 0.0298\n",
      "952/1088, train_loss: 0.0319\n",
      "953/1088, train_loss: 0.0300\n",
      "954/1088, train_loss: 0.0274\n",
      "955/1088, train_loss: 0.0301\n",
      "956/1088, train_loss: 0.0285\n",
      "957/1088, train_loss: 0.0294\n",
      "958/1088, train_loss: 0.0283\n",
      "959/1088, train_loss: 0.0305\n",
      "960/1088, train_loss: 0.0281\n",
      "961/1088, train_loss: 0.0282\n",
      "962/1088, train_loss: 0.0277\n",
      "963/1088, train_loss: 0.0280\n",
      "964/1088, train_loss: 0.0289\n",
      "965/1088, train_loss: 0.0280\n",
      "966/1088, train_loss: 0.0310\n",
      "967/1088, train_loss: 0.0317\n",
      "968/1088, train_loss: 0.0294\n",
      "969/1088, train_loss: 0.0288\n",
      "970/1088, train_loss: 0.0317\n",
      "971/1088, train_loss: 0.0297\n",
      "972/1088, train_loss: 0.0292\n",
      "973/1088, train_loss: 0.0286\n",
      "974/1088, train_loss: 0.0298\n",
      "975/1088, train_loss: 0.0266\n",
      "976/1088, train_loss: 0.0280\n",
      "977/1088, train_loss: 0.0306\n",
      "978/1088, train_loss: 0.0284\n",
      "979/1088, train_loss: 0.0303\n",
      "980/1088, train_loss: 0.0283\n",
      "981/1088, train_loss: 0.0286\n",
      "982/1088, train_loss: 0.0275\n",
      "983/1088, train_loss: 0.0292\n",
      "984/1088, train_loss: 0.0290\n",
      "985/1088, train_loss: 0.0289\n",
      "986/1088, train_loss: 0.0292\n",
      "987/1088, train_loss: 0.0285\n",
      "988/1088, train_loss: 0.0301\n",
      "989/1088, train_loss: 0.0285\n",
      "990/1088, train_loss: 0.0286\n",
      "991/1088, train_loss: 0.0329\n",
      "992/1088, train_loss: 0.0312\n",
      "993/1088, train_loss: 0.0296\n",
      "994/1088, train_loss: 0.0275\n",
      "995/1088, train_loss: 0.0272\n",
      "996/1088, train_loss: 0.0288\n",
      "997/1088, train_loss: 0.0308\n",
      "998/1088, train_loss: 0.0289\n",
      "999/1088, train_loss: 0.0274\n",
      "1000/1088, train_loss: 0.0290\n",
      "1001/1088, train_loss: 0.0288\n",
      "1002/1088, train_loss: 0.0258\n",
      "1003/1088, train_loss: 0.0312\n",
      "1004/1088, train_loss: 0.0281\n",
      "1005/1088, train_loss: 0.0283\n",
      "1006/1088, train_loss: 0.0263\n",
      "1007/1088, train_loss: 0.0280\n",
      "1008/1088, train_loss: 0.0291\n",
      "1009/1088, train_loss: 0.0277\n",
      "1010/1088, train_loss: 0.0270\n",
      "1011/1088, train_loss: 0.0286\n",
      "1012/1088, train_loss: 0.0286\n",
      "1013/1088, train_loss: 0.0289\n",
      "1014/1088, train_loss: 0.0311\n",
      "1015/1088, train_loss: 0.0294\n",
      "1016/1088, train_loss: 0.0291\n",
      "1017/1088, train_loss: 0.0285\n",
      "1018/1088, train_loss: 0.0276\n",
      "1019/1088, train_loss: 0.0281\n",
      "1020/1088, train_loss: 0.0259\n",
      "1021/1088, train_loss: 0.0338\n",
      "1022/1088, train_loss: 0.0284\n",
      "1023/1088, train_loss: 0.0289\n",
      "1024/1088, train_loss: 0.0280\n",
      "1025/1088, train_loss: 0.0276\n",
      "1026/1088, train_loss: 0.0279\n",
      "1027/1088, train_loss: 0.0280\n",
      "1028/1088, train_loss: 0.0298\n",
      "1029/1088, train_loss: 0.0285\n",
      "1030/1088, train_loss: 0.0297\n",
      "1031/1088, train_loss: 0.0298\n",
      "1032/1088, train_loss: 0.0286\n",
      "1033/1088, train_loss: 0.0276\n",
      "1034/1088, train_loss: 0.0275\n",
      "1035/1088, train_loss: 0.0299\n",
      "1036/1088, train_loss: 0.0279\n",
      "1037/1088, train_loss: 0.0342\n",
      "1038/1088, train_loss: 0.0284\n",
      "1039/1088, train_loss: 0.0285\n",
      "1040/1088, train_loss: 0.0293\n",
      "1041/1088, train_loss: 0.0279\n",
      "1042/1088, train_loss: 0.0281\n",
      "1043/1088, train_loss: 0.0285\n",
      "1044/1088, train_loss: 0.0279\n",
      "1045/1088, train_loss: 0.0268\n",
      "1046/1088, train_loss: 0.0305\n",
      "1047/1088, train_loss: 0.0267\n",
      "1048/1088, train_loss: 0.0311\n",
      "1049/1088, train_loss: 0.0269\n",
      "1050/1088, train_loss: 0.0303\n",
      "1051/1088, train_loss: 0.0294\n",
      "1052/1088, train_loss: 0.0283\n",
      "1053/1088, train_loss: 0.0279\n",
      "1054/1088, train_loss: 0.0350\n",
      "1055/1088, train_loss: 0.0278\n",
      "1056/1088, train_loss: 0.0295\n",
      "1057/1088, train_loss: 0.0279\n",
      "1058/1088, train_loss: 0.0288\n",
      "1059/1088, train_loss: 0.0263\n",
      "1060/1088, train_loss: 0.0280\n",
      "1061/1088, train_loss: 0.0274\n",
      "1062/1088, train_loss: 0.0283\n",
      "1063/1088, train_loss: 0.0302\n",
      "1064/1088, train_loss: 0.0284\n",
      "1065/1088, train_loss: 0.0305\n",
      "1066/1088, train_loss: 0.0293\n",
      "1067/1088, train_loss: 0.0274\n",
      "1068/1088, train_loss: 0.0295\n",
      "1069/1088, train_loss: 0.0281\n",
      "1070/1088, train_loss: 0.0298\n",
      "1071/1088, train_loss: 0.0298\n",
      "1072/1088, train_loss: 0.0265\n",
      "1073/1088, train_loss: 0.0338\n",
      "1074/1088, train_loss: 0.0286\n",
      "1075/1088, train_loss: 0.0369\n",
      "1076/1088, train_loss: 0.0265\n",
      "1077/1088, train_loss: 0.0283\n",
      "1078/1088, train_loss: 0.0286\n",
      "1079/1088, train_loss: 0.0273\n",
      "1080/1088, train_loss: 0.0307\n",
      "1081/1088, train_loss: 0.0271\n",
      "1082/1088, train_loss: 0.0347\n",
      "1083/1088, train_loss: 0.0294\n",
      "1084/1088, train_loss: 0.0277\n",
      "1085/1088, train_loss: 0.0279\n",
      "1086/1088, train_loss: 0.0297\n",
      "1087/1088, train_loss: 0.0257\n",
      "1088/1088, train_loss: 0.0304\n",
      "1089/1088, train_loss: 0.0286\n",
      "epoch 10 average loss: 0.0289, train_dice: 0.9712\n",
      "epoch 10 average loss: 0.0289\n",
      "current epoch: 10 current mean dice: 0.9676 best mean dice: 0.9703 at epoch 8\n",
      "--------------------------------------------------\n",
      "epoch 11/50\n",
      "1/1088, train_loss: 0.0283\n",
      "2/1088, train_loss: 0.0289\n",
      "3/1088, train_loss: 0.0282\n",
      "4/1088, train_loss: 0.0262\n",
      "5/1088, train_loss: 0.0282\n",
      "6/1088, train_loss: 0.0278\n",
      "7/1088, train_loss: 0.0293\n",
      "8/1088, train_loss: 0.0296\n",
      "9/1088, train_loss: 0.0279\n",
      "10/1088, train_loss: 0.0288\n",
      "11/1088, train_loss: 0.0307\n",
      "12/1088, train_loss: 0.0316\n",
      "13/1088, train_loss: 0.0301\n",
      "14/1088, train_loss: 0.0307\n",
      "15/1088, train_loss: 0.0292\n",
      "16/1088, train_loss: 0.0294\n",
      "17/1088, train_loss: 0.0286\n",
      "18/1088, train_loss: 0.0273\n",
      "19/1088, train_loss: 0.0273\n",
      "20/1088, train_loss: 0.0276\n",
      "21/1088, train_loss: 0.0301\n",
      "22/1088, train_loss: 0.0277\n",
      "23/1088, train_loss: 0.0334\n",
      "24/1088, train_loss: 0.0311\n",
      "25/1088, train_loss: 0.0283\n",
      "26/1088, train_loss: 0.0283\n",
      "27/1088, train_loss: 0.0290\n",
      "28/1088, train_loss: 0.0294\n",
      "29/1088, train_loss: 0.0354\n",
      "30/1088, train_loss: 0.0286\n",
      "31/1088, train_loss: 0.0307\n",
      "32/1088, train_loss: 0.0269\n",
      "33/1088, train_loss: 0.0269\n",
      "34/1088, train_loss: 0.0252\n",
      "35/1088, train_loss: 0.0292\n",
      "36/1088, train_loss: 0.0260\n",
      "37/1088, train_loss: 0.0292\n",
      "38/1088, train_loss: 0.0315\n",
      "39/1088, train_loss: 0.0267\n",
      "40/1088, train_loss: 0.0285\n",
      "41/1088, train_loss: 0.0328\n",
      "42/1088, train_loss: 0.0283\n",
      "43/1088, train_loss: 0.0297\n",
      "44/1088, train_loss: 0.0282\n",
      "45/1088, train_loss: 0.0314\n",
      "46/1088, train_loss: 0.0288\n",
      "47/1088, train_loss: 0.0288\n",
      "48/1088, train_loss: 0.0292\n",
      "49/1088, train_loss: 0.0335\n",
      "50/1088, train_loss: 0.0310\n",
      "51/1088, train_loss: 0.0298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/1088, train_loss: 0.0303\n",
      "53/1088, train_loss: 0.0288\n",
      "54/1088, train_loss: 0.0301\n",
      "55/1088, train_loss: 0.0303\n",
      "56/1088, train_loss: 0.0318\n",
      "57/1088, train_loss: 0.0290\n",
      "58/1088, train_loss: 0.0267\n",
      "59/1088, train_loss: 0.0283\n",
      "60/1088, train_loss: 0.0338\n",
      "61/1088, train_loss: 0.0326\n",
      "62/1088, train_loss: 0.0271\n",
      "63/1088, train_loss: 0.0267\n",
      "64/1088, train_loss: 0.0268\n",
      "65/1088, train_loss: 0.0320\n",
      "66/1088, train_loss: 0.0286\n",
      "67/1088, train_loss: 0.0302\n",
      "68/1088, train_loss: 0.0300\n",
      "69/1088, train_loss: 0.0298\n",
      "70/1088, train_loss: 0.0267\n",
      "71/1088, train_loss: 0.0301\n",
      "72/1088, train_loss: 0.0291\n",
      "73/1088, train_loss: 0.0283\n",
      "74/1088, train_loss: 0.0304\n",
      "75/1088, train_loss: 0.0301\n",
      "76/1088, train_loss: 0.0289\n",
      "77/1088, train_loss: 0.0296\n",
      "78/1088, train_loss: 0.0267\n",
      "79/1088, train_loss: 0.0272\n",
      "80/1088, train_loss: 0.0279\n",
      "81/1088, train_loss: 0.0301\n",
      "82/1088, train_loss: 0.0328\n",
      "83/1088, train_loss: 0.0274\n",
      "84/1088, train_loss: 0.0297\n",
      "85/1088, train_loss: 0.0282\n",
      "86/1088, train_loss: 0.0306\n",
      "87/1088, train_loss: 0.0296\n",
      "88/1088, train_loss: 0.0271\n",
      "89/1088, train_loss: 0.0280\n",
      "90/1088, train_loss: 0.0294\n",
      "91/1088, train_loss: 0.0308\n",
      "92/1088, train_loss: 0.0290\n",
      "93/1088, train_loss: 0.0278\n",
      "94/1088, train_loss: 0.0283\n",
      "95/1088, train_loss: 0.0286\n",
      "96/1088, train_loss: 0.0314\n",
      "97/1088, train_loss: 0.0275\n",
      "98/1088, train_loss: 0.0281\n",
      "99/1088, train_loss: 0.0284\n",
      "100/1088, train_loss: 0.0279\n",
      "101/1088, train_loss: 0.0295\n",
      "102/1088, train_loss: 0.0277\n",
      "103/1088, train_loss: 0.0279\n",
      "104/1088, train_loss: 0.0283\n",
      "105/1088, train_loss: 0.0371\n",
      "106/1088, train_loss: 0.0268\n",
      "107/1088, train_loss: 0.0292\n",
      "108/1088, train_loss: 0.0295\n",
      "109/1088, train_loss: 0.0289\n",
      "110/1088, train_loss: 0.0289\n",
      "111/1088, train_loss: 0.0263\n",
      "112/1088, train_loss: 0.0303\n",
      "113/1088, train_loss: 0.0285\n",
      "114/1088, train_loss: 0.0283\n",
      "115/1088, train_loss: 0.0272\n",
      "116/1088, train_loss: 0.0280\n",
      "117/1088, train_loss: 0.0263\n",
      "118/1088, train_loss: 0.0288\n",
      "119/1088, train_loss: 0.0298\n",
      "120/1088, train_loss: 0.0295\n",
      "121/1088, train_loss: 0.0270\n",
      "122/1088, train_loss: 0.0297\n",
      "123/1088, train_loss: 0.0271\n",
      "124/1088, train_loss: 0.0261\n",
      "125/1088, train_loss: 0.0275\n",
      "126/1088, train_loss: 0.0279\n",
      "127/1088, train_loss: 0.0294\n",
      "128/1088, train_loss: 0.0278\n",
      "129/1088, train_loss: 0.0274\n",
      "130/1088, train_loss: 0.0304\n",
      "131/1088, train_loss: 0.0312\n",
      "132/1088, train_loss: 0.0276\n",
      "133/1088, train_loss: 0.0282\n",
      "134/1088, train_loss: 0.0292\n",
      "135/1088, train_loss: 0.0285\n",
      "136/1088, train_loss: 0.0294\n",
      "137/1088, train_loss: 0.0284\n",
      "138/1088, train_loss: 0.0288\n",
      "139/1088, train_loss: 0.0280\n",
      "140/1088, train_loss: 0.0282\n",
      "141/1088, train_loss: 0.0330\n",
      "142/1088, train_loss: 0.0315\n",
      "143/1088, train_loss: 0.0290\n",
      "144/1088, train_loss: 0.0285\n",
      "145/1088, train_loss: 0.0297\n",
      "146/1088, train_loss: 0.0313\n",
      "147/1088, train_loss: 0.0273\n",
      "148/1088, train_loss: 0.0299\n",
      "149/1088, train_loss: 0.0276\n",
      "150/1088, train_loss: 0.0295\n",
      "151/1088, train_loss: 0.0303\n",
      "152/1088, train_loss: 0.0283\n",
      "153/1088, train_loss: 0.0271\n",
      "154/1088, train_loss: 0.0309\n",
      "155/1088, train_loss: 0.0292\n",
      "156/1088, train_loss: 0.0291\n",
      "157/1088, train_loss: 0.0285\n",
      "158/1088, train_loss: 0.0321\n",
      "159/1088, train_loss: 0.0292\n",
      "160/1088, train_loss: 0.0291\n",
      "161/1088, train_loss: 0.0287\n",
      "162/1088, train_loss: 0.0282\n",
      "163/1088, train_loss: 0.0313\n",
      "164/1088, train_loss: 0.0284\n",
      "165/1088, train_loss: 0.0283\n",
      "166/1088, train_loss: 0.0326\n",
      "167/1088, train_loss: 0.0272\n",
      "168/1088, train_loss: 0.0286\n",
      "169/1088, train_loss: 0.0285\n",
      "170/1088, train_loss: 0.0314\n",
      "171/1088, train_loss: 0.0275\n",
      "172/1088, train_loss: 0.0268\n",
      "173/1088, train_loss: 0.0252\n",
      "174/1088, train_loss: 0.0297\n",
      "175/1088, train_loss: 0.0288\n",
      "176/1088, train_loss: 0.0310\n",
      "177/1088, train_loss: 0.0297\n",
      "178/1088, train_loss: 0.0280\n",
      "179/1088, train_loss: 0.0289\n",
      "180/1088, train_loss: 0.0276\n",
      "181/1088, train_loss: 0.0275\n",
      "182/1088, train_loss: 0.0312\n",
      "183/1088, train_loss: 0.0294\n",
      "184/1088, train_loss: 0.0328\n",
      "185/1088, train_loss: 0.0332\n",
      "186/1088, train_loss: 0.0311\n",
      "187/1088, train_loss: 0.0285\n",
      "188/1088, train_loss: 0.0268\n",
      "189/1088, train_loss: 0.0290\n",
      "190/1088, train_loss: 0.0285\n",
      "191/1088, train_loss: 0.0267\n",
      "192/1088, train_loss: 0.0296\n",
      "193/1088, train_loss: 0.0296\n",
      "194/1088, train_loss: 0.0285\n",
      "195/1088, train_loss: 0.0287\n",
      "196/1088, train_loss: 0.0296\n",
      "197/1088, train_loss: 0.0282\n",
      "198/1088, train_loss: 0.0316\n",
      "199/1088, train_loss: 0.0338\n",
      "200/1088, train_loss: 0.0262\n",
      "201/1088, train_loss: 0.0309\n",
      "202/1088, train_loss: 0.0283\n",
      "203/1088, train_loss: 0.0282\n",
      "204/1088, train_loss: 0.0265\n",
      "205/1088, train_loss: 0.0280\n",
      "206/1088, train_loss: 0.0304\n",
      "207/1088, train_loss: 0.0290\n",
      "208/1088, train_loss: 0.0271\n",
      "209/1088, train_loss: 0.0291\n",
      "210/1088, train_loss: 0.0308\n",
      "211/1088, train_loss: 0.0272\n",
      "212/1088, train_loss: 0.0340\n",
      "213/1088, train_loss: 0.0301\n",
      "214/1088, train_loss: 0.0289\n",
      "215/1088, train_loss: 0.0276\n",
      "216/1088, train_loss: 0.0282\n",
      "217/1088, train_loss: 0.0293\n",
      "218/1088, train_loss: 0.0273\n",
      "219/1088, train_loss: 0.0277\n",
      "220/1088, train_loss: 0.0276\n",
      "221/1088, train_loss: 0.0268\n",
      "222/1088, train_loss: 0.0272\n",
      "223/1088, train_loss: 0.0276\n",
      "224/1088, train_loss: 0.0306\n",
      "225/1088, train_loss: 0.0272\n",
      "226/1088, train_loss: 0.0273\n",
      "227/1088, train_loss: 0.0314\n",
      "228/1088, train_loss: 0.0291\n",
      "229/1088, train_loss: 0.0282\n",
      "230/1088, train_loss: 0.0295\n",
      "231/1088, train_loss: 0.0282\n",
      "232/1088, train_loss: 0.0286\n",
      "233/1088, train_loss: 0.0289\n",
      "234/1088, train_loss: 0.0282\n",
      "235/1088, train_loss: 0.0289\n",
      "236/1088, train_loss: 0.0276\n",
      "237/1088, train_loss: 0.0273\n",
      "238/1088, train_loss: 0.0283\n",
      "239/1088, train_loss: 0.0278\n",
      "240/1088, train_loss: 0.0305\n",
      "241/1088, train_loss: 0.0284\n",
      "242/1088, train_loss: 0.0271\n",
      "243/1088, train_loss: 0.0296\n",
      "244/1088, train_loss: 0.0292\n",
      "245/1088, train_loss: 0.0286\n",
      "246/1088, train_loss: 0.0294\n",
      "247/1088, train_loss: 0.0261\n",
      "248/1088, train_loss: 0.0280\n",
      "249/1088, train_loss: 0.0274\n",
      "250/1088, train_loss: 0.0317\n",
      "251/1088, train_loss: 0.0298\n",
      "252/1088, train_loss: 0.0284\n",
      "253/1088, train_loss: 0.0288\n",
      "254/1088, train_loss: 0.0281\n",
      "255/1088, train_loss: 0.0312\n",
      "256/1088, train_loss: 0.0291\n",
      "257/1088, train_loss: 0.0277\n",
      "258/1088, train_loss: 0.0294\n",
      "259/1088, train_loss: 0.0284\n",
      "260/1088, train_loss: 0.0274\n",
      "261/1088, train_loss: 0.0279\n",
      "262/1088, train_loss: 0.0284\n",
      "263/1088, train_loss: 0.0272\n",
      "264/1088, train_loss: 0.0285\n",
      "265/1088, train_loss: 0.0261\n",
      "266/1088, train_loss: 0.0299\n",
      "267/1088, train_loss: 0.0286\n",
      "268/1088, train_loss: 0.0271\n",
      "269/1088, train_loss: 0.0299\n",
      "270/1088, train_loss: 0.0285\n",
      "271/1088, train_loss: 0.0283\n",
      "272/1088, train_loss: 0.0283\n",
      "273/1088, train_loss: 0.0287\n",
      "274/1088, train_loss: 0.0268\n",
      "275/1088, train_loss: 0.0288\n",
      "276/1088, train_loss: 0.0292\n",
      "277/1088, train_loss: 0.0299\n",
      "278/1088, train_loss: 0.0280\n",
      "279/1088, train_loss: 0.0288\n",
      "280/1088, train_loss: 0.0286\n",
      "281/1088, train_loss: 0.0287\n",
      "282/1088, train_loss: 0.0296\n",
      "283/1088, train_loss: 0.0267\n",
      "284/1088, train_loss: 0.0279\n",
      "285/1088, train_loss: 0.0275\n",
      "286/1088, train_loss: 0.0293\n",
      "287/1088, train_loss: 0.0289\n",
      "288/1088, train_loss: 0.0287\n",
      "289/1088, train_loss: 0.0272\n",
      "290/1088, train_loss: 0.0283\n",
      "291/1088, train_loss: 0.0266\n",
      "292/1088, train_loss: 0.0300\n",
      "293/1088, train_loss: 0.0304\n",
      "294/1088, train_loss: 0.0277\n",
      "295/1088, train_loss: 0.0290\n",
      "296/1088, train_loss: 0.0335\n",
      "297/1088, train_loss: 0.0272\n",
      "298/1088, train_loss: 0.0298\n",
      "299/1088, train_loss: 0.0286\n",
      "300/1088, train_loss: 0.0273\n",
      "301/1088, train_loss: 0.0283\n",
      "302/1088, train_loss: 0.0296\n",
      "303/1088, train_loss: 0.0307\n",
      "304/1088, train_loss: 0.0286\n",
      "305/1088, train_loss: 0.0272\n",
      "306/1088, train_loss: 0.0282\n",
      "307/1088, train_loss: 0.0310\n",
      "308/1088, train_loss: 0.0282\n",
      "309/1088, train_loss: 0.0284\n",
      "310/1088, train_loss: 0.0295\n",
      "311/1088, train_loss: 0.0302\n",
      "312/1088, train_loss: 0.0253\n",
      "313/1088, train_loss: 0.0294\n",
      "314/1088, train_loss: 0.0268\n",
      "315/1088, train_loss: 0.0294\n",
      "316/1088, train_loss: 0.0259\n",
      "317/1088, train_loss: 0.0286\n",
      "318/1088, train_loss: 0.0275\n",
      "319/1088, train_loss: 0.0281\n",
      "320/1088, train_loss: 0.0269\n",
      "321/1088, train_loss: 0.0287\n",
      "322/1088, train_loss: 0.0300\n",
      "323/1088, train_loss: 0.0285\n",
      "324/1088, train_loss: 0.0293\n",
      "325/1088, train_loss: 0.0295\n",
      "326/1088, train_loss: 0.0289\n",
      "327/1088, train_loss: 0.0269\n",
      "328/1088, train_loss: 0.0270\n",
      "329/1088, train_loss: 0.0300\n",
      "330/1088, train_loss: 0.0279\n",
      "331/1088, train_loss: 0.0277\n",
      "332/1088, train_loss: 0.0304\n",
      "333/1088, train_loss: 0.0295\n",
      "334/1088, train_loss: 0.0292\n",
      "335/1088, train_loss: 0.0268\n",
      "336/1088, train_loss: 0.0278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337/1088, train_loss: 0.0283\n",
      "338/1088, train_loss: 0.0283\n",
      "339/1088, train_loss: 0.0284\n",
      "340/1088, train_loss: 0.0271\n",
      "341/1088, train_loss: 0.0280\n",
      "342/1088, train_loss: 0.0289\n",
      "343/1088, train_loss: 0.0296\n",
      "344/1088, train_loss: 0.0292\n",
      "345/1088, train_loss: 0.0303\n",
      "346/1088, train_loss: 0.0269\n",
      "347/1088, train_loss: 0.0282\n",
      "348/1088, train_loss: 0.0296\n",
      "349/1088, train_loss: 0.0286\n",
      "350/1088, train_loss: 0.0287\n",
      "351/1088, train_loss: 0.0290\n",
      "352/1088, train_loss: 0.0289\n",
      "353/1088, train_loss: 0.0294\n",
      "354/1088, train_loss: 0.0323\n",
      "355/1088, train_loss: 0.0310\n",
      "356/1088, train_loss: 0.0303\n",
      "357/1088, train_loss: 0.0282\n",
      "358/1088, train_loss: 0.0271\n",
      "359/1088, train_loss: 0.0269\n",
      "360/1088, train_loss: 0.0291\n",
      "361/1088, train_loss: 0.0276\n",
      "362/1088, train_loss: 0.0276\n",
      "363/1088, train_loss: 0.0293\n",
      "364/1088, train_loss: 0.0262\n",
      "365/1088, train_loss: 0.0293\n",
      "366/1088, train_loss: 0.0272\n",
      "367/1088, train_loss: 0.0282\n",
      "368/1088, train_loss: 0.0265\n",
      "369/1088, train_loss: 0.0304\n",
      "370/1088, train_loss: 0.0284\n",
      "371/1088, train_loss: 0.0291\n",
      "372/1088, train_loss: 0.0330\n",
      "373/1088, train_loss: 0.0295\n",
      "374/1088, train_loss: 0.0283\n",
      "375/1088, train_loss: 0.0273\n",
      "376/1088, train_loss: 0.0266\n",
      "377/1088, train_loss: 0.0287\n",
      "378/1088, train_loss: 0.0282\n",
      "379/1088, train_loss: 0.0271\n",
      "380/1088, train_loss: 0.0297\n",
      "381/1088, train_loss: 0.0275\n",
      "382/1088, train_loss: 0.0280\n",
      "383/1088, train_loss: 0.0293\n",
      "384/1088, train_loss: 0.0282\n",
      "385/1088, train_loss: 0.0286\n",
      "386/1088, train_loss: 0.0270\n",
      "387/1088, train_loss: 0.0317\n",
      "388/1088, train_loss: 0.0289\n",
      "389/1088, train_loss: 0.0314\n",
      "390/1088, train_loss: 0.0277\n",
      "391/1088, train_loss: 0.0286\n",
      "392/1088, train_loss: 0.0277\n",
      "393/1088, train_loss: 0.0301\n",
      "394/1088, train_loss: 0.0367\n",
      "395/1088, train_loss: 0.0287\n",
      "396/1088, train_loss: 0.0313\n",
      "397/1088, train_loss: 0.0310\n",
      "398/1088, train_loss: 0.0311\n",
      "399/1088, train_loss: 0.0280\n",
      "400/1088, train_loss: 0.0284\n",
      "401/1088, train_loss: 0.0279\n",
      "402/1088, train_loss: 0.0285\n",
      "403/1088, train_loss: 0.0292\n",
      "404/1088, train_loss: 0.0281\n",
      "405/1088, train_loss: 0.0344\n",
      "406/1088, train_loss: 0.0300\n",
      "407/1088, train_loss: 0.0310\n",
      "408/1088, train_loss: 0.0336\n",
      "409/1088, train_loss: 0.0288\n",
      "410/1088, train_loss: 0.0286\n",
      "411/1088, train_loss: 0.0282\n",
      "412/1088, train_loss: 0.0288\n",
      "413/1088, train_loss: 0.0280\n",
      "414/1088, train_loss: 0.0299\n",
      "415/1088, train_loss: 0.0293\n",
      "416/1088, train_loss: 0.0282\n",
      "417/1088, train_loss: 0.0291\n",
      "418/1088, train_loss: 0.0298\n",
      "419/1088, train_loss: 0.0302\n",
      "420/1088, train_loss: 0.0258\n",
      "421/1088, train_loss: 0.0263\n",
      "422/1088, train_loss: 0.0313\n",
      "423/1088, train_loss: 0.0279\n",
      "424/1088, train_loss: 0.0293\n",
      "425/1088, train_loss: 0.0277\n",
      "426/1088, train_loss: 0.0274\n",
      "427/1088, train_loss: 0.0287\n",
      "428/1088, train_loss: 0.0272\n",
      "429/1088, train_loss: 0.0282\n",
      "430/1088, train_loss: 0.0281\n",
      "431/1088, train_loss: 0.0273\n",
      "432/1088, train_loss: 0.0264\n",
      "433/1088, train_loss: 0.0282\n",
      "434/1088, train_loss: 0.0270\n",
      "435/1088, train_loss: 0.0300\n",
      "436/1088, train_loss: 0.0295\n",
      "437/1088, train_loss: 0.0296\n",
      "438/1088, train_loss: 0.0269\n",
      "439/1088, train_loss: 0.0269\n",
      "440/1088, train_loss: 0.0283\n",
      "441/1088, train_loss: 0.0286\n",
      "442/1088, train_loss: 0.0285\n",
      "443/1088, train_loss: 0.0294\n",
      "444/1088, train_loss: 0.0285\n",
      "445/1088, train_loss: 0.0262\n",
      "446/1088, train_loss: 0.0287\n",
      "447/1088, train_loss: 0.0279\n",
      "448/1088, train_loss: 0.0265\n",
      "449/1088, train_loss: 0.0294\n",
      "450/1088, train_loss: 0.0272\n",
      "451/1088, train_loss: 0.0294\n",
      "452/1088, train_loss: 0.0295\n",
      "453/1088, train_loss: 0.0357\n",
      "454/1088, train_loss: 0.0291\n",
      "455/1088, train_loss: 0.0281\n",
      "456/1088, train_loss: 0.0285\n",
      "457/1088, train_loss: 0.0321\n",
      "458/1088, train_loss: 0.0297\n",
      "459/1088, train_loss: 0.0282\n",
      "460/1088, train_loss: 0.0288\n",
      "461/1088, train_loss: 0.0285\n",
      "462/1088, train_loss: 0.0274\n",
      "463/1088, train_loss: 0.0281\n",
      "464/1088, train_loss: 0.0286\n",
      "465/1088, train_loss: 0.0298\n",
      "466/1088, train_loss: 0.0273\n",
      "467/1088, train_loss: 0.0279\n",
      "468/1088, train_loss: 0.0323\n",
      "469/1088, train_loss: 0.0286\n",
      "470/1088, train_loss: 0.0299\n",
      "471/1088, train_loss: 0.0272\n",
      "472/1088, train_loss: 0.0276\n",
      "473/1088, train_loss: 0.0276\n",
      "474/1088, train_loss: 0.0310\n",
      "475/1088, train_loss: 0.0317\n",
      "476/1088, train_loss: 0.0296\n",
      "477/1088, train_loss: 0.0276\n",
      "478/1088, train_loss: 0.0283\n",
      "479/1088, train_loss: 0.0273\n",
      "480/1088, train_loss: 0.0274\n",
      "481/1088, train_loss: 0.0304\n",
      "482/1088, train_loss: 0.0286\n",
      "483/1088, train_loss: 0.0299\n",
      "484/1088, train_loss: 0.0282\n",
      "485/1088, train_loss: 0.0262\n",
      "486/1088, train_loss: 0.0296\n",
      "487/1088, train_loss: 0.0285\n",
      "488/1088, train_loss: 0.0272\n",
      "489/1088, train_loss: 0.0291\n",
      "490/1088, train_loss: 0.0289\n",
      "491/1088, train_loss: 0.0268\n",
      "492/1088, train_loss: 0.0328\n",
      "493/1088, train_loss: 0.0297\n",
      "494/1088, train_loss: 0.0300\n",
      "495/1088, train_loss: 0.0297\n",
      "496/1088, train_loss: 0.0283\n",
      "497/1088, train_loss: 0.0293\n",
      "498/1088, train_loss: 0.0290\n",
      "499/1088, train_loss: 0.0306\n",
      "500/1088, train_loss: 0.0287\n",
      "501/1088, train_loss: 0.0275\n",
      "502/1088, train_loss: 0.0297\n",
      "503/1088, train_loss: 0.0271\n",
      "504/1088, train_loss: 0.0327\n",
      "505/1088, train_loss: 0.0283\n",
      "506/1088, train_loss: 0.0300\n",
      "507/1088, train_loss: 0.0307\n",
      "508/1088, train_loss: 0.0284\n",
      "509/1088, train_loss: 0.0293\n",
      "510/1088, train_loss: 0.0267\n",
      "511/1088, train_loss: 0.0281\n",
      "512/1088, train_loss: 0.0284\n",
      "513/1088, train_loss: 0.0316\n",
      "514/1088, train_loss: 0.0282\n",
      "515/1088, train_loss: 0.0277\n",
      "516/1088, train_loss: 0.0274\n",
      "517/1088, train_loss: 0.0297\n",
      "518/1088, train_loss: 0.0307\n",
      "519/1088, train_loss: 0.0315\n",
      "520/1088, train_loss: 0.0292\n",
      "521/1088, train_loss: 0.0268\n",
      "522/1088, train_loss: 0.0291\n",
      "523/1088, train_loss: 0.0281\n",
      "524/1088, train_loss: 0.0291\n",
      "525/1088, train_loss: 0.0279\n",
      "526/1088, train_loss: 0.0276\n",
      "527/1088, train_loss: 0.0287\n",
      "528/1088, train_loss: 0.0307\n",
      "529/1088, train_loss: 0.0268\n",
      "530/1088, train_loss: 0.0284\n",
      "531/1088, train_loss: 0.0282\n",
      "532/1088, train_loss: 0.0294\n",
      "533/1088, train_loss: 0.0258\n",
      "534/1088, train_loss: 0.0265\n",
      "535/1088, train_loss: 0.0272\n",
      "536/1088, train_loss: 0.0402\n",
      "537/1088, train_loss: 0.0285\n",
      "538/1088, train_loss: 0.0277\n",
      "539/1088, train_loss: 0.0276\n",
      "540/1088, train_loss: 0.0296\n",
      "541/1088, train_loss: 0.0300\n",
      "542/1088, train_loss: 0.0358\n",
      "543/1088, train_loss: 0.0308\n",
      "544/1088, train_loss: 0.0291\n",
      "545/1088, train_loss: 0.0277\n",
      "546/1088, train_loss: 0.0288\n",
      "547/1088, train_loss: 0.0274\n",
      "548/1088, train_loss: 0.0286\n",
      "549/1088, train_loss: 0.0271\n",
      "550/1088, train_loss: 0.0296\n",
      "551/1088, train_loss: 0.0252\n",
      "552/1088, train_loss: 0.0260\n",
      "553/1088, train_loss: 0.0324\n",
      "554/1088, train_loss: 0.0293\n",
      "555/1088, train_loss: 0.0279\n",
      "556/1088, train_loss: 0.0287\n",
      "557/1088, train_loss: 0.0324\n",
      "558/1088, train_loss: 0.0332\n",
      "559/1088, train_loss: 0.0289\n",
      "560/1088, train_loss: 0.0287\n",
      "561/1088, train_loss: 0.0297\n",
      "562/1088, train_loss: 0.0297\n",
      "563/1088, train_loss: 0.0281\n",
      "564/1088, train_loss: 0.0270\n",
      "565/1088, train_loss: 0.0267\n",
      "566/1088, train_loss: 0.0296\n",
      "567/1088, train_loss: 0.0285\n",
      "568/1088, train_loss: 0.0282\n",
      "569/1088, train_loss: 0.0295\n",
      "570/1088, train_loss: 0.0311\n",
      "571/1088, train_loss: 0.0296\n",
      "572/1088, train_loss: 0.0270\n",
      "573/1088, train_loss: 0.0293\n",
      "574/1088, train_loss: 0.0292\n",
      "575/1088, train_loss: 0.0290\n",
      "576/1088, train_loss: 0.0298\n",
      "577/1088, train_loss: 0.0303\n",
      "578/1088, train_loss: 0.0274\n",
      "579/1088, train_loss: 0.0291\n",
      "580/1088, train_loss: 0.0295\n",
      "581/1088, train_loss: 0.0300\n",
      "582/1088, train_loss: 0.0253\n",
      "583/1088, train_loss: 0.0302\n",
      "584/1088, train_loss: 0.0279\n",
      "585/1088, train_loss: 0.0274\n",
      "586/1088, train_loss: 0.0278\n",
      "587/1088, train_loss: 0.0298\n",
      "588/1088, train_loss: 0.0325\n",
      "589/1088, train_loss: 0.0342\n",
      "590/1088, train_loss: 0.0293\n",
      "591/1088, train_loss: 0.0260\n",
      "592/1088, train_loss: 0.0272\n",
      "593/1088, train_loss: 0.0293\n",
      "594/1088, train_loss: 0.0288\n",
      "595/1088, train_loss: 0.0272\n",
      "596/1088, train_loss: 0.0274\n",
      "597/1088, train_loss: 0.0278\n",
      "598/1088, train_loss: 0.0280\n",
      "599/1088, train_loss: 0.0285\n",
      "600/1088, train_loss: 0.0283\n",
      "601/1088, train_loss: 0.0305\n",
      "602/1088, train_loss: 0.0277\n",
      "603/1088, train_loss: 0.0286\n",
      "604/1088, train_loss: 0.0309\n",
      "605/1088, train_loss: 0.0266\n",
      "606/1088, train_loss: 0.0296\n",
      "607/1088, train_loss: 0.0303\n",
      "608/1088, train_loss: 0.0288\n",
      "609/1088, train_loss: 0.0304\n",
      "610/1088, train_loss: 0.0281\n",
      "611/1088, train_loss: 0.0294\n",
      "612/1088, train_loss: 0.0296\n",
      "613/1088, train_loss: 0.0273\n",
      "614/1088, train_loss: 0.0287\n",
      "615/1088, train_loss: 0.0265\n",
      "616/1088, train_loss: 0.0280\n",
      "617/1088, train_loss: 0.0283\n",
      "618/1088, train_loss: 0.0272\n",
      "619/1088, train_loss: 0.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "620/1088, train_loss: 0.0335\n",
      "621/1088, train_loss: 0.0309\n",
      "622/1088, train_loss: 0.0313\n",
      "623/1088, train_loss: 0.0280\n",
      "624/1088, train_loss: 0.0271\n",
      "625/1088, train_loss: 0.0281\n",
      "626/1088, train_loss: 0.0287\n",
      "627/1088, train_loss: 0.0292\n",
      "628/1088, train_loss: 0.0278\n",
      "629/1088, train_loss: 0.0291\n",
      "630/1088, train_loss: 0.0267\n",
      "631/1088, train_loss: 0.0317\n",
      "632/1088, train_loss: 0.0342\n",
      "633/1088, train_loss: 0.0293\n",
      "634/1088, train_loss: 0.0287\n",
      "635/1088, train_loss: 0.0268\n",
      "636/1088, train_loss: 0.0277\n",
      "637/1088, train_loss: 0.0281\n",
      "638/1088, train_loss: 0.0287\n",
      "639/1088, train_loss: 0.0294\n",
      "640/1088, train_loss: 0.0290\n",
      "641/1088, train_loss: 0.0274\n",
      "642/1088, train_loss: 0.0275\n",
      "643/1088, train_loss: 0.0286\n",
      "644/1088, train_loss: 0.0264\n",
      "645/1088, train_loss: 0.0269\n",
      "646/1088, train_loss: 0.0284\n",
      "647/1088, train_loss: 0.0304\n",
      "648/1088, train_loss: 0.0307\n",
      "649/1088, train_loss: 0.0272\n",
      "650/1088, train_loss: 0.0305\n",
      "651/1088, train_loss: 0.0284\n",
      "652/1088, train_loss: 0.0281\n",
      "653/1088, train_loss: 0.0283\n",
      "654/1088, train_loss: 0.0328\n",
      "655/1088, train_loss: 0.0348\n",
      "656/1088, train_loss: 0.0336\n",
      "657/1088, train_loss: 0.0307\n",
      "658/1088, train_loss: 0.0310\n",
      "659/1088, train_loss: 0.0303\n",
      "660/1088, train_loss: 0.0307\n",
      "661/1088, train_loss: 0.0357\n",
      "662/1088, train_loss: 0.0294\n",
      "663/1088, train_loss: 0.0309\n",
      "664/1088, train_loss: 0.0265\n",
      "665/1088, train_loss: 0.0301\n",
      "666/1088, train_loss: 0.0284\n",
      "667/1088, train_loss: 0.0316\n",
      "668/1088, train_loss: 0.0291\n",
      "669/1088, train_loss: 0.0285\n",
      "670/1088, train_loss: 0.0276\n",
      "671/1088, train_loss: 0.0282\n",
      "672/1088, train_loss: 0.0281\n",
      "673/1088, train_loss: 0.0272\n",
      "674/1088, train_loss: 0.0273\n",
      "675/1088, train_loss: 0.0314\n",
      "676/1088, train_loss: 0.0270\n",
      "677/1088, train_loss: 0.0279\n",
      "678/1088, train_loss: 0.0281\n",
      "679/1088, train_loss: 0.0281\n",
      "680/1088, train_loss: 0.0307\n",
      "681/1088, train_loss: 0.0278\n",
      "682/1088, train_loss: 0.0290\n",
      "683/1088, train_loss: 0.0302\n",
      "684/1088, train_loss: 0.0285\n",
      "685/1088, train_loss: 0.0321\n",
      "686/1088, train_loss: 0.0284\n",
      "687/1088, train_loss: 0.0269\n",
      "688/1088, train_loss: 0.0292\n",
      "689/1088, train_loss: 0.0295\n",
      "690/1088, train_loss: 0.0276\n",
      "691/1088, train_loss: 0.0281\n",
      "692/1088, train_loss: 0.0290\n",
      "693/1088, train_loss: 0.0270\n",
      "694/1088, train_loss: 0.0282\n",
      "695/1088, train_loss: 0.0254\n",
      "696/1088, train_loss: 0.0308\n",
      "697/1088, train_loss: 0.0298\n",
      "698/1088, train_loss: 0.0270\n",
      "699/1088, train_loss: 0.0315\n",
      "700/1088, train_loss: 0.0278\n",
      "701/1088, train_loss: 0.0310\n",
      "702/1088, train_loss: 0.0287\n",
      "703/1088, train_loss: 0.0312\n",
      "704/1088, train_loss: 0.0299\n",
      "705/1088, train_loss: 0.0303\n",
      "706/1088, train_loss: 0.0287\n",
      "707/1088, train_loss: 0.0287\n",
      "708/1088, train_loss: 0.0289\n",
      "709/1088, train_loss: 0.0252\n",
      "710/1088, train_loss: 0.0270\n",
      "711/1088, train_loss: 0.0302\n",
      "712/1088, train_loss: 0.0283\n",
      "713/1088, train_loss: 0.0310\n",
      "714/1088, train_loss: 0.0292\n",
      "715/1088, train_loss: 0.0284\n",
      "716/1088, train_loss: 0.0253\n",
      "717/1088, train_loss: 0.0289\n",
      "718/1088, train_loss: 0.0284\n",
      "719/1088, train_loss: 0.0282\n",
      "720/1088, train_loss: 0.0271\n",
      "721/1088, train_loss: 0.0285\n",
      "722/1088, train_loss: 0.0288\n",
      "723/1088, train_loss: 0.0316\n",
      "724/1088, train_loss: 0.0291\n",
      "725/1088, train_loss: 0.0283\n",
      "726/1088, train_loss: 0.0297\n",
      "727/1088, train_loss: 0.0306\n",
      "728/1088, train_loss: 0.0280\n",
      "729/1088, train_loss: 0.0299\n",
      "730/1088, train_loss: 0.0284\n",
      "731/1088, train_loss: 0.0284\n",
      "732/1088, train_loss: 0.0301\n",
      "733/1088, train_loss: 0.0280\n",
      "734/1088, train_loss: 0.0274\n",
      "735/1088, train_loss: 0.0285\n",
      "736/1088, train_loss: 0.0296\n",
      "737/1088, train_loss: 0.0280\n",
      "738/1088, train_loss: 0.0278\n",
      "739/1088, train_loss: 0.0303\n",
      "740/1088, train_loss: 0.0299\n",
      "741/1088, train_loss: 0.0291\n",
      "742/1088, train_loss: 0.0308\n",
      "743/1088, train_loss: 0.0311\n",
      "744/1088, train_loss: 0.0290\n",
      "745/1088, train_loss: 0.0282\n",
      "746/1088, train_loss: 0.0279\n",
      "747/1088, train_loss: 0.0301\n",
      "748/1088, train_loss: 0.0305\n",
      "749/1088, train_loss: 0.0322\n",
      "750/1088, train_loss: 0.0312\n",
      "751/1088, train_loss: 0.0364\n",
      "752/1088, train_loss: 0.0292\n",
      "753/1088, train_loss: 0.0306\n",
      "754/1088, train_loss: 0.0281\n",
      "755/1088, train_loss: 0.0290\n",
      "756/1088, train_loss: 0.0292\n",
      "757/1088, train_loss: 0.0288\n",
      "758/1088, train_loss: 0.0274\n",
      "759/1088, train_loss: 0.0291\n",
      "760/1088, train_loss: 0.0301\n",
      "761/1088, train_loss: 0.0280\n",
      "762/1088, train_loss: 0.0346\n",
      "763/1088, train_loss: 0.0271\n",
      "764/1088, train_loss: 0.0299\n",
      "765/1088, train_loss: 0.0290\n",
      "766/1088, train_loss: 0.0289\n",
      "767/1088, train_loss: 0.0273\n",
      "768/1088, train_loss: 0.0273\n",
      "769/1088, train_loss: 0.0292\n",
      "770/1088, train_loss: 0.0275\n",
      "771/1088, train_loss: 0.0279\n",
      "772/1088, train_loss: 0.0292\n",
      "773/1088, train_loss: 0.0256\n",
      "774/1088, train_loss: 0.0293\n",
      "775/1088, train_loss: 0.0268\n",
      "776/1088, train_loss: 0.0306\n",
      "777/1088, train_loss: 0.0278\n",
      "778/1088, train_loss: 0.0257\n",
      "779/1088, train_loss: 0.0275\n",
      "780/1088, train_loss: 0.0283\n",
      "781/1088, train_loss: 0.0288\n",
      "782/1088, train_loss: 0.0291\n",
      "783/1088, train_loss: 0.0263\n",
      "784/1088, train_loss: 0.0303\n",
      "785/1088, train_loss: 0.0303\n",
      "786/1088, train_loss: 0.0281\n",
      "787/1088, train_loss: 0.0300\n",
      "788/1088, train_loss: 0.0312\n",
      "789/1088, train_loss: 0.0272\n",
      "790/1088, train_loss: 0.0274\n",
      "791/1088, train_loss: 0.0280\n",
      "792/1088, train_loss: 0.0262\n",
      "793/1088, train_loss: 0.0304\n",
      "794/1088, train_loss: 0.0298\n",
      "795/1088, train_loss: 0.0308\n",
      "796/1088, train_loss: 0.0314\n",
      "797/1088, train_loss: 0.0320\n",
      "798/1088, train_loss: 0.0287\n",
      "799/1088, train_loss: 0.0289\n",
      "800/1088, train_loss: 0.0289\n",
      "801/1088, train_loss: 0.0275\n",
      "802/1088, train_loss: 0.0301\n",
      "803/1088, train_loss: 0.0263\n",
      "804/1088, train_loss: 0.0311\n",
      "805/1088, train_loss: 0.0286\n",
      "806/1088, train_loss: 0.0279\n",
      "807/1088, train_loss: 0.0296\n",
      "808/1088, train_loss: 0.0292\n",
      "809/1088, train_loss: 0.0290\n",
      "810/1088, train_loss: 0.0293\n",
      "811/1088, train_loss: 0.0288\n",
      "812/1088, train_loss: 0.0296\n",
      "813/1088, train_loss: 0.0289\n",
      "814/1088, train_loss: 0.0290\n",
      "815/1088, train_loss: 0.0298\n",
      "816/1088, train_loss: 0.0290\n",
      "817/1088, train_loss: 0.0297\n",
      "818/1088, train_loss: 0.0293\n",
      "819/1088, train_loss: 0.0264\n",
      "820/1088, train_loss: 0.0285\n",
      "821/1088, train_loss: 0.0301\n",
      "822/1088, train_loss: 0.0288\n",
      "823/1088, train_loss: 0.0266\n",
      "824/1088, train_loss: 0.0328\n",
      "825/1088, train_loss: 0.0274\n",
      "826/1088, train_loss: 0.0274\n",
      "827/1088, train_loss: 0.0282\n",
      "828/1088, train_loss: 0.0264\n",
      "829/1088, train_loss: 0.0307\n",
      "830/1088, train_loss: 0.0288\n",
      "831/1088, train_loss: 0.0287\n",
      "832/1088, train_loss: 0.0277\n",
      "833/1088, train_loss: 0.0279\n",
      "834/1088, train_loss: 0.0291\n",
      "835/1088, train_loss: 0.0313\n",
      "836/1088, train_loss: 0.0290\n",
      "837/1088, train_loss: 0.0279\n",
      "838/1088, train_loss: 0.0274\n",
      "839/1088, train_loss: 0.0265\n",
      "840/1088, train_loss: 0.0291\n",
      "841/1088, train_loss: 0.0305\n",
      "842/1088, train_loss: 0.0299\n",
      "843/1088, train_loss: 0.0273\n",
      "844/1088, train_loss: 0.0261\n",
      "845/1088, train_loss: 0.0290\n",
      "846/1088, train_loss: 0.0308\n",
      "847/1088, train_loss: 0.0299\n",
      "848/1088, train_loss: 0.0290\n",
      "849/1088, train_loss: 0.0291\n",
      "850/1088, train_loss: 0.0281\n",
      "851/1088, train_loss: 0.0259\n",
      "852/1088, train_loss: 0.0287\n",
      "853/1088, train_loss: 0.0290\n",
      "854/1088, train_loss: 0.0293\n",
      "855/1088, train_loss: 0.0293\n",
      "856/1088, train_loss: 0.0260\n",
      "857/1088, train_loss: 0.0287\n",
      "858/1088, train_loss: 0.0285\n",
      "859/1088, train_loss: 0.0292\n",
      "860/1088, train_loss: 0.0295\n",
      "861/1088, train_loss: 0.0292\n",
      "862/1088, train_loss: 0.0271\n",
      "863/1088, train_loss: 0.0267\n",
      "864/1088, train_loss: 0.0273\n",
      "865/1088, train_loss: 0.0263\n",
      "866/1088, train_loss: 0.0354\n",
      "867/1088, train_loss: 0.0299\n",
      "868/1088, train_loss: 0.0286\n",
      "869/1088, train_loss: 0.0287\n",
      "870/1088, train_loss: 0.0279\n",
      "871/1088, train_loss: 0.0281\n",
      "872/1088, train_loss: 0.0281\n",
      "873/1088, train_loss: 0.0302\n",
      "874/1088, train_loss: 0.0290\n",
      "875/1088, train_loss: 0.0283\n",
      "876/1088, train_loss: 0.0286\n",
      "877/1088, train_loss: 0.0272\n",
      "878/1088, train_loss: 0.0281\n",
      "879/1088, train_loss: 0.0272\n",
      "880/1088, train_loss: 0.0273\n",
      "881/1088, train_loss: 0.0258\n",
      "882/1088, train_loss: 0.0307\n",
      "883/1088, train_loss: 0.0291\n",
      "884/1088, train_loss: 0.0322\n",
      "885/1088, train_loss: 0.0293\n",
      "886/1088, train_loss: 0.0339\n",
      "887/1088, train_loss: 0.0304\n",
      "888/1088, train_loss: 0.0284\n",
      "889/1088, train_loss: 0.0301\n",
      "890/1088, train_loss: 0.0290\n",
      "891/1088, train_loss: 0.0298\n",
      "892/1088, train_loss: 0.0276\n",
      "893/1088, train_loss: 0.0290\n",
      "894/1088, train_loss: 0.0276\n",
      "895/1088, train_loss: 0.0277\n",
      "896/1088, train_loss: 0.0291\n",
      "897/1088, train_loss: 0.0300\n",
      "898/1088, train_loss: 0.0288\n",
      "899/1088, train_loss: 0.0287\n",
      "900/1088, train_loss: 0.0313\n",
      "901/1088, train_loss: 0.0302\n",
      "902/1088, train_loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903/1088, train_loss: 0.0283\n",
      "904/1088, train_loss: 0.0325\n",
      "905/1088, train_loss: 0.0274\n",
      "906/1088, train_loss: 0.0289\n",
      "907/1088, train_loss: 0.0301\n",
      "908/1088, train_loss: 0.0310\n",
      "909/1088, train_loss: 0.0298\n",
      "910/1088, train_loss: 0.0258\n",
      "911/1088, train_loss: 0.0268\n",
      "912/1088, train_loss: 0.0278\n",
      "913/1088, train_loss: 0.0274\n",
      "914/1088, train_loss: 0.0271\n",
      "915/1088, train_loss: 0.0288\n",
      "916/1088, train_loss: 0.0288\n",
      "917/1088, train_loss: 0.0272\n",
      "918/1088, train_loss: 0.0281\n",
      "919/1088, train_loss: 0.0281\n",
      "920/1088, train_loss: 0.0276\n",
      "921/1088, train_loss: 0.0266\n",
      "922/1088, train_loss: 0.0293\n",
      "923/1088, train_loss: 0.0283\n",
      "924/1088, train_loss: 0.0262\n",
      "925/1088, train_loss: 0.0330\n",
      "926/1088, train_loss: 0.0304\n",
      "927/1088, train_loss: 0.0302\n",
      "928/1088, train_loss: 0.0281\n",
      "929/1088, train_loss: 0.0300\n",
      "930/1088, train_loss: 0.0264\n",
      "931/1088, train_loss: 0.0265\n",
      "932/1088, train_loss: 0.0300\n",
      "933/1088, train_loss: 0.0272\n",
      "934/1088, train_loss: 0.0277\n",
      "935/1088, train_loss: 0.0277\n",
      "936/1088, train_loss: 0.0299\n",
      "937/1088, train_loss: 0.0287\n",
      "938/1088, train_loss: 0.0303\n",
      "939/1088, train_loss: 0.0294\n",
      "940/1088, train_loss: 0.0271\n",
      "941/1088, train_loss: 0.0293\n",
      "942/1088, train_loss: 0.0301\n",
      "943/1088, train_loss: 0.0258\n",
      "944/1088, train_loss: 0.0280\n",
      "945/1088, train_loss: 0.0287\n",
      "946/1088, train_loss: 0.0296\n",
      "947/1088, train_loss: 0.0277\n",
      "948/1088, train_loss: 0.0285\n",
      "949/1088, train_loss: 0.0278\n",
      "950/1088, train_loss: 0.0268\n",
      "951/1088, train_loss: 0.0273\n",
      "952/1088, train_loss: 0.0277\n",
      "953/1088, train_loss: 0.0273\n",
      "954/1088, train_loss: 0.0280\n",
      "955/1088, train_loss: 0.0287\n",
      "956/1088, train_loss: 0.0283\n",
      "957/1088, train_loss: 0.0274\n",
      "958/1088, train_loss: 0.0289\n",
      "959/1088, train_loss: 0.0282\n",
      "960/1088, train_loss: 0.0302\n",
      "961/1088, train_loss: 0.0294\n",
      "962/1088, train_loss: 0.0271\n",
      "963/1088, train_loss: 0.0288\n",
      "964/1088, train_loss: 0.0280\n",
      "965/1088, train_loss: 0.0294\n",
      "966/1088, train_loss: 0.0346\n",
      "967/1088, train_loss: 0.0274\n",
      "968/1088, train_loss: 0.0269\n",
      "969/1088, train_loss: 0.0285\n",
      "970/1088, train_loss: 0.0281\n",
      "971/1088, train_loss: 0.0309\n",
      "972/1088, train_loss: 0.0314\n",
      "973/1088, train_loss: 0.0287\n",
      "974/1088, train_loss: 0.0268\n",
      "975/1088, train_loss: 0.0271\n",
      "976/1088, train_loss: 0.0289\n",
      "977/1088, train_loss: 0.0274\n",
      "978/1088, train_loss: 0.0290\n",
      "979/1088, train_loss: 0.0286\n",
      "980/1088, train_loss: 0.0283\n",
      "981/1088, train_loss: 0.0294\n",
      "982/1088, train_loss: 0.0301\n",
      "983/1088, train_loss: 0.0303\n",
      "984/1088, train_loss: 0.0275\n",
      "985/1088, train_loss: 0.0267\n",
      "986/1088, train_loss: 0.0292\n",
      "987/1088, train_loss: 0.0266\n",
      "988/1088, train_loss: 0.0264\n",
      "989/1088, train_loss: 0.0281\n",
      "990/1088, train_loss: 0.0254\n",
      "991/1088, train_loss: 0.0284\n",
      "992/1088, train_loss: 0.0303\n",
      "993/1088, train_loss: 0.0300\n",
      "994/1088, train_loss: 0.0262\n",
      "995/1088, train_loss: 0.0292\n",
      "996/1088, train_loss: 0.0281\n",
      "997/1088, train_loss: 0.0294\n",
      "998/1088, train_loss: 0.0294\n",
      "999/1088, train_loss: 0.0286\n",
      "1000/1088, train_loss: 0.0262\n",
      "1001/1088, train_loss: 0.0284\n",
      "1002/1088, train_loss: 0.0278\n",
      "1003/1088, train_loss: 0.0275\n",
      "1004/1088, train_loss: 0.0277\n",
      "1005/1088, train_loss: 0.0259\n",
      "1006/1088, train_loss: 0.0268\n",
      "1007/1088, train_loss: 0.0284\n",
      "1008/1088, train_loss: 0.0274\n",
      "1009/1088, train_loss: 0.0292\n",
      "1010/1088, train_loss: 0.0309\n",
      "1011/1088, train_loss: 0.0276\n",
      "1012/1088, train_loss: 0.0277\n",
      "1013/1088, train_loss: 0.0280\n",
      "1014/1088, train_loss: 0.0317\n",
      "1015/1088, train_loss: 0.0271\n",
      "1016/1088, train_loss: 0.0254\n",
      "1017/1088, train_loss: 0.0269\n",
      "1018/1088, train_loss: 0.0297\n",
      "1019/1088, train_loss: 0.0353\n",
      "1020/1088, train_loss: 0.0299\n",
      "1021/1088, train_loss: 0.0273\n",
      "1022/1088, train_loss: 0.0292\n",
      "1023/1088, train_loss: 0.0292\n",
      "1024/1088, train_loss: 0.0301\n",
      "1025/1088, train_loss: 0.0283\n",
      "1026/1088, train_loss: 0.0314\n",
      "1027/1088, train_loss: 0.0279\n",
      "1028/1088, train_loss: 0.0287\n",
      "1029/1088, train_loss: 0.0295\n",
      "1030/1088, train_loss: 0.0285\n",
      "1031/1088, train_loss: 0.0269\n",
      "1032/1088, train_loss: 0.0271\n",
      "1033/1088, train_loss: 0.0265\n",
      "1034/1088, train_loss: 0.0305\n",
      "1035/1088, train_loss: 0.0303\n",
      "1036/1088, train_loss: 0.0270\n",
      "1037/1088, train_loss: 0.0259\n",
      "1038/1088, train_loss: 0.0284\n",
      "1039/1088, train_loss: 0.0277\n",
      "1040/1088, train_loss: 0.0271\n",
      "1041/1088, train_loss: 0.0294\n",
      "1042/1088, train_loss: 0.0261\n",
      "1043/1088, train_loss: 0.0286\n",
      "1044/1088, train_loss: 0.0291\n",
      "1045/1088, train_loss: 0.0276\n",
      "1046/1088, train_loss: 0.0288\n",
      "1047/1088, train_loss: 0.0311\n",
      "1048/1088, train_loss: 0.0274\n",
      "1049/1088, train_loss: 0.0294\n",
      "1050/1088, train_loss: 0.0280\n",
      "1051/1088, train_loss: 0.0300\n",
      "1052/1088, train_loss: 0.0289\n",
      "1053/1088, train_loss: 0.0290\n",
      "1054/1088, train_loss: 0.0288\n",
      "1055/1088, train_loss: 0.0275\n",
      "1056/1088, train_loss: 0.0275\n",
      "1057/1088, train_loss: 0.0318\n",
      "1058/1088, train_loss: 0.0293\n",
      "1059/1088, train_loss: 0.0271\n",
      "1060/1088, train_loss: 0.0289\n",
      "1061/1088, train_loss: 0.0281\n",
      "1062/1088, train_loss: 0.0265\n",
      "1063/1088, train_loss: 0.0274\n",
      "1064/1088, train_loss: 0.0292\n",
      "1065/1088, train_loss: 0.0278\n",
      "1066/1088, train_loss: 0.0283\n",
      "1067/1088, train_loss: 0.0285\n",
      "1068/1088, train_loss: 0.0273\n",
      "1069/1088, train_loss: 0.0297\n",
      "1070/1088, train_loss: 0.0301\n",
      "1071/1088, train_loss: 0.0292\n",
      "1072/1088, train_loss: 0.0270\n",
      "1073/1088, train_loss: 0.0291\n",
      "1074/1088, train_loss: 0.0295\n",
      "1075/1088, train_loss: 0.0283\n",
      "1076/1088, train_loss: 0.0293\n",
      "1077/1088, train_loss: 0.0295\n",
      "1078/1088, train_loss: 0.0290\n",
      "1079/1088, train_loss: 0.0301\n",
      "1080/1088, train_loss: 0.0283\n",
      "1081/1088, train_loss: 0.0305\n",
      "1082/1088, train_loss: 0.0283\n",
      "1083/1088, train_loss: 0.0306\n",
      "1084/1088, train_loss: 0.0272\n",
      "1085/1088, train_loss: 0.0297\n",
      "1086/1088, train_loss: 0.0296\n",
      "1087/1088, train_loss: 0.0298\n",
      "1088/1088, train_loss: 0.0283\n",
      "1089/1088, train_loss: 0.0298\n",
      "epoch 11 average loss: 0.0289, train_dice: 0.9712\n",
      "epoch 11 average loss: 0.0289\n",
      "--------------------------------------------------\n",
      "epoch 12/50\n",
      "1/1088, train_loss: 0.0277\n",
      "2/1088, train_loss: 0.0301\n",
      "3/1088, train_loss: 0.0271\n",
      "4/1088, train_loss: 0.0289\n",
      "5/1088, train_loss: 0.0385\n",
      "6/1088, train_loss: 0.0270\n",
      "7/1088, train_loss: 0.0271\n",
      "8/1088, train_loss: 0.0262\n",
      "9/1088, train_loss: 0.0266\n",
      "10/1088, train_loss: 0.0292\n",
      "11/1088, train_loss: 0.0280\n",
      "12/1088, train_loss: 0.0289\n",
      "13/1088, train_loss: 0.0287\n",
      "14/1088, train_loss: 0.0283\n",
      "15/1088, train_loss: 0.0286\n",
      "16/1088, train_loss: 0.0289\n",
      "17/1088, train_loss: 0.0296\n",
      "18/1088, train_loss: 0.0284\n",
      "19/1088, train_loss: 0.0292\n",
      "20/1088, train_loss: 0.0281\n",
      "21/1088, train_loss: 0.0300\n",
      "22/1088, train_loss: 0.0282\n",
      "23/1088, train_loss: 0.0295\n",
      "24/1088, train_loss: 0.0294\n",
      "25/1088, train_loss: 0.0291\n",
      "26/1088, train_loss: 0.0280\n",
      "27/1088, train_loss: 0.0261\n",
      "28/1088, train_loss: 0.0278\n",
      "29/1088, train_loss: 0.0316\n",
      "30/1088, train_loss: 0.0273\n",
      "31/1088, train_loss: 0.0251\n",
      "32/1088, train_loss: 0.0284\n",
      "33/1088, train_loss: 0.0307\n",
      "34/1088, train_loss: 0.0292\n",
      "35/1088, train_loss: 0.0274\n",
      "36/1088, train_loss: 0.0290\n",
      "37/1088, train_loss: 0.0311\n",
      "38/1088, train_loss: 0.0270\n",
      "39/1088, train_loss: 0.0282\n",
      "40/1088, train_loss: 0.0286\n",
      "41/1088, train_loss: 0.0287\n",
      "42/1088, train_loss: 0.0287\n",
      "43/1088, train_loss: 0.0289\n",
      "44/1088, train_loss: 0.0260\n",
      "45/1088, train_loss: 0.0291\n",
      "46/1088, train_loss: 0.0274\n",
      "47/1088, train_loss: 0.0256\n",
      "48/1088, train_loss: 0.0282\n",
      "49/1088, train_loss: 0.0280\n",
      "50/1088, train_loss: 0.0276\n",
      "51/1088, train_loss: 0.0288\n",
      "52/1088, train_loss: 0.0288\n",
      "53/1088, train_loss: 0.0283\n",
      "54/1088, train_loss: 0.0256\n",
      "55/1088, train_loss: 0.0309\n",
      "56/1088, train_loss: 0.0289\n",
      "57/1088, train_loss: 0.0281\n",
      "58/1088, train_loss: 0.0279\n",
      "59/1088, train_loss: 0.0270\n",
      "60/1088, train_loss: 0.0282\n",
      "61/1088, train_loss: 0.0265\n",
      "62/1088, train_loss: 0.0299\n",
      "63/1088, train_loss: 0.0253\n",
      "64/1088, train_loss: 0.0363\n",
      "65/1088, train_loss: 0.0276\n",
      "66/1088, train_loss: 0.0297\n",
      "67/1088, train_loss: 0.0287\n",
      "68/1088, train_loss: 0.0271\n",
      "69/1088, train_loss: 0.0291\n",
      "70/1088, train_loss: 0.0289\n",
      "71/1088, train_loss: 0.0266\n",
      "72/1088, train_loss: 0.0274\n",
      "73/1088, train_loss: 0.0285\n",
      "74/1088, train_loss: 0.0284\n",
      "75/1088, train_loss: 0.0267\n",
      "76/1088, train_loss: 0.0267\n",
      "77/1088, train_loss: 0.0279\n",
      "78/1088, train_loss: 0.0269\n",
      "79/1088, train_loss: 0.0281\n",
      "80/1088, train_loss: 0.0280\n",
      "81/1088, train_loss: 0.0272\n",
      "82/1088, train_loss: 0.0290\n",
      "83/1088, train_loss: 0.0289\n",
      "84/1088, train_loss: 0.0276\n",
      "85/1088, train_loss: 0.0267\n",
      "86/1088, train_loss: 0.0290\n",
      "87/1088, train_loss: 0.0272\n",
      "88/1088, train_loss: 0.0275\n",
      "89/1088, train_loss: 0.0313\n",
      "90/1088, train_loss: 0.0272\n",
      "91/1088, train_loss: 0.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/1088, train_loss: 0.0268\n",
      "93/1088, train_loss: 0.0301\n",
      "94/1088, train_loss: 0.0279\n",
      "95/1088, train_loss: 0.0288\n",
      "96/1088, train_loss: 0.0279\n",
      "97/1088, train_loss: 0.0291\n",
      "98/1088, train_loss: 0.0275\n",
      "99/1088, train_loss: 0.0302\n",
      "100/1088, train_loss: 0.0348\n",
      "101/1088, train_loss: 0.0336\n",
      "102/1088, train_loss: 0.0302\n",
      "103/1088, train_loss: 0.0294\n",
      "104/1088, train_loss: 0.0296\n",
      "105/1088, train_loss: 0.0293\n",
      "106/1088, train_loss: 0.0291\n",
      "107/1088, train_loss: 0.0293\n",
      "108/1088, train_loss: 0.0303\n",
      "109/1088, train_loss: 0.0291\n",
      "110/1088, train_loss: 0.0283\n",
      "111/1088, train_loss: 0.0302\n",
      "112/1088, train_loss: 0.0278\n",
      "113/1088, train_loss: 0.0278\n",
      "114/1088, train_loss: 0.0288\n",
      "115/1088, train_loss: 0.0291\n",
      "116/1088, train_loss: 0.0284\n",
      "117/1088, train_loss: 0.0287\n",
      "118/1088, train_loss: 0.0269\n",
      "119/1088, train_loss: 0.0286\n",
      "120/1088, train_loss: 0.0295\n",
      "121/1088, train_loss: 0.0298\n",
      "122/1088, train_loss: 0.0282\n",
      "123/1088, train_loss: 0.0333\n",
      "124/1088, train_loss: 0.0283\n",
      "125/1088, train_loss: 0.0281\n",
      "126/1088, train_loss: 0.0263\n",
      "127/1088, train_loss: 0.0280\n",
      "128/1088, train_loss: 0.0267\n",
      "129/1088, train_loss: 0.0300\n",
      "130/1088, train_loss: 0.0293\n",
      "131/1088, train_loss: 0.0276\n",
      "132/1088, train_loss: 0.0272\n",
      "133/1088, train_loss: 0.0352\n",
      "134/1088, train_loss: 0.0279\n",
      "135/1088, train_loss: 0.0276\n",
      "136/1088, train_loss: 0.0285\n",
      "137/1088, train_loss: 0.0280\n",
      "138/1088, train_loss: 0.0296\n",
      "139/1088, train_loss: 0.0281\n",
      "140/1088, train_loss: 0.0296\n",
      "141/1088, train_loss: 0.0296\n",
      "142/1088, train_loss: 0.0281\n",
      "143/1088, train_loss: 0.0274\n",
      "144/1088, train_loss: 0.0277\n",
      "145/1088, train_loss: 0.0262\n",
      "146/1088, train_loss: 0.0276\n",
      "147/1088, train_loss: 0.0271\n",
      "148/1088, train_loss: 0.0312\n",
      "149/1088, train_loss: 0.0266\n",
      "150/1088, train_loss: 0.0270\n",
      "151/1088, train_loss: 0.0278\n",
      "152/1088, train_loss: 0.0275\n",
      "153/1088, train_loss: 0.0277\n",
      "154/1088, train_loss: 0.0277\n",
      "155/1088, train_loss: 0.0277\n",
      "156/1088, train_loss: 0.0277\n",
      "157/1088, train_loss: 0.0286\n",
      "158/1088, train_loss: 0.0307\n",
      "159/1088, train_loss: 0.0279\n",
      "160/1088, train_loss: 0.0258\n",
      "161/1088, train_loss: 0.0282\n",
      "162/1088, train_loss: 0.0290\n",
      "163/1088, train_loss: 0.0277\n",
      "164/1088, train_loss: 0.0276\n",
      "165/1088, train_loss: 0.0295\n",
      "166/1088, train_loss: 0.0289\n",
      "167/1088, train_loss: 0.0310\n",
      "168/1088, train_loss: 0.0280\n",
      "169/1088, train_loss: 0.0273\n",
      "170/1088, train_loss: 0.0259\n",
      "171/1088, train_loss: 0.0290\n",
      "172/1088, train_loss: 0.0309\n",
      "173/1088, train_loss: 0.0289\n",
      "174/1088, train_loss: 0.0262\n",
      "175/1088, train_loss: 0.0276\n",
      "176/1088, train_loss: 0.0270\n",
      "177/1088, train_loss: 0.0306\n",
      "178/1088, train_loss: 0.0265\n",
      "179/1088, train_loss: 0.0304\n",
      "180/1088, train_loss: 0.0270\n",
      "181/1088, train_loss: 0.0283\n",
      "182/1088, train_loss: 0.0271\n",
      "183/1088, train_loss: 0.0295\n",
      "184/1088, train_loss: 0.0289\n",
      "185/1088, train_loss: 0.0344\n",
      "186/1088, train_loss: 0.0277\n",
      "187/1088, train_loss: 0.0257\n",
      "188/1088, train_loss: 0.0274\n",
      "189/1088, train_loss: 0.0315\n",
      "190/1088, train_loss: 0.0280\n",
      "191/1088, train_loss: 0.0267\n",
      "192/1088, train_loss: 0.0271\n",
      "193/1088, train_loss: 0.0265\n",
      "194/1088, train_loss: 0.0300\n",
      "195/1088, train_loss: 0.0273\n",
      "196/1088, train_loss: 0.0291\n",
      "197/1088, train_loss: 0.0277\n",
      "198/1088, train_loss: 0.0285\n",
      "199/1088, train_loss: 0.0289\n",
      "200/1088, train_loss: 0.0279\n",
      "201/1088, train_loss: 0.0284\n",
      "202/1088, train_loss: 0.0322\n",
      "203/1088, train_loss: 0.0284\n",
      "204/1088, train_loss: 0.0258\n",
      "205/1088, train_loss: 0.0288\n",
      "206/1088, train_loss: 0.0278\n",
      "207/1088, train_loss: 0.0297\n",
      "208/1088, train_loss: 0.0273\n",
      "209/1088, train_loss: 0.0271\n",
      "210/1088, train_loss: 0.0271\n",
      "211/1088, train_loss: 0.0267\n",
      "212/1088, train_loss: 0.0271\n",
      "213/1088, train_loss: 0.0292\n",
      "214/1088, train_loss: 0.0286\n",
      "215/1088, train_loss: 0.0286\n",
      "216/1088, train_loss: 0.0277\n",
      "217/1088, train_loss: 0.0268\n",
      "218/1088, train_loss: 0.0290\n",
      "219/1088, train_loss: 0.0277\n",
      "220/1088, train_loss: 0.0299\n",
      "221/1088, train_loss: 0.0276\n",
      "222/1088, train_loss: 0.0251\n",
      "223/1088, train_loss: 0.0275\n",
      "224/1088, train_loss: 0.0266\n",
      "225/1088, train_loss: 0.0283\n",
      "226/1088, train_loss: 0.0365\n",
      "227/1088, train_loss: 0.0289\n",
      "228/1088, train_loss: 0.0263\n",
      "229/1088, train_loss: 0.0242\n",
      "230/1088, train_loss: 0.0275\n",
      "231/1088, train_loss: 0.0277\n",
      "232/1088, train_loss: 0.0285\n",
      "233/1088, train_loss: 0.0273\n",
      "234/1088, train_loss: 0.0280\n",
      "235/1088, train_loss: 0.0304\n",
      "236/1088, train_loss: 0.0279\n",
      "237/1088, train_loss: 0.0244\n",
      "238/1088, train_loss: 0.0278\n",
      "239/1088, train_loss: 0.0291\n",
      "240/1088, train_loss: 0.0280\n",
      "241/1088, train_loss: 0.0284\n",
      "242/1088, train_loss: 0.0323\n",
      "243/1088, train_loss: 0.0285\n",
      "244/1088, train_loss: 0.0287\n",
      "245/1088, train_loss: 0.0306\n",
      "246/1088, train_loss: 0.0297\n",
      "247/1088, train_loss: 0.0290\n",
      "248/1088, train_loss: 0.0291\n",
      "249/1088, train_loss: 0.0310\n",
      "250/1088, train_loss: 0.0293\n",
      "251/1088, train_loss: 0.0267\n",
      "252/1088, train_loss: 0.0302\n",
      "253/1088, train_loss: 0.0286\n",
      "254/1088, train_loss: 0.0319\n",
      "255/1088, train_loss: 0.0305\n",
      "256/1088, train_loss: 0.0308\n",
      "257/1088, train_loss: 0.0293\n",
      "258/1088, train_loss: 0.0273\n",
      "259/1088, train_loss: 0.0278\n",
      "260/1088, train_loss: 0.0278\n",
      "261/1088, train_loss: 0.0300\n",
      "262/1088, train_loss: 0.0264\n",
      "263/1088, train_loss: 0.0296\n",
      "264/1088, train_loss: 0.0285\n",
      "265/1088, train_loss: 0.0290\n",
      "266/1088, train_loss: 0.0301\n",
      "267/1088, train_loss: 0.0262\n",
      "268/1088, train_loss: 0.0261\n",
      "269/1088, train_loss: 0.0284\n",
      "270/1088, train_loss: 0.0282\n",
      "271/1088, train_loss: 0.0297\n",
      "272/1088, train_loss: 0.0296\n",
      "273/1088, train_loss: 0.0284\n",
      "274/1088, train_loss: 0.0292\n",
      "275/1088, train_loss: 0.0279\n",
      "276/1088, train_loss: 0.0280\n",
      "277/1088, train_loss: 0.0270\n",
      "278/1088, train_loss: 0.0287\n",
      "279/1088, train_loss: 0.0261\n",
      "280/1088, train_loss: 0.0276\n",
      "281/1088, train_loss: 0.0272\n",
      "282/1088, train_loss: 0.0280\n",
      "283/1088, train_loss: 0.0276\n",
      "284/1088, train_loss: 0.0279\n",
      "285/1088, train_loss: 0.0265\n",
      "286/1088, train_loss: 0.0301\n",
      "287/1088, train_loss: 0.0290\n",
      "288/1088, train_loss: 0.0283\n",
      "289/1088, train_loss: 0.0265\n",
      "290/1088, train_loss: 0.0298\n",
      "291/1088, train_loss: 0.0301\n",
      "292/1088, train_loss: 0.0270\n",
      "293/1088, train_loss: 0.0287\n",
      "294/1088, train_loss: 0.0281\n",
      "295/1088, train_loss: 0.0274\n",
      "296/1088, train_loss: 0.0295\n",
      "297/1088, train_loss: 0.0308\n",
      "298/1088, train_loss: 0.0280\n",
      "299/1088, train_loss: 0.0269\n",
      "300/1088, train_loss: 0.0298\n",
      "301/1088, train_loss: 0.0308\n",
      "302/1088, train_loss: 0.0280\n",
      "303/1088, train_loss: 0.0297\n",
      "304/1088, train_loss: 0.0286\n",
      "305/1088, train_loss: 0.0278\n",
      "306/1088, train_loss: 0.0279\n",
      "307/1088, train_loss: 0.0575\n",
      "308/1088, train_loss: 0.0286\n",
      "309/1088, train_loss: 0.0268\n",
      "310/1088, train_loss: 0.0287\n",
      "311/1088, train_loss: 0.0251\n",
      "312/1088, train_loss: 0.0284\n",
      "313/1088, train_loss: 0.0284\n",
      "314/1088, train_loss: 0.0261\n",
      "315/1088, train_loss: 0.0284\n",
      "316/1088, train_loss: 0.0263\n",
      "317/1088, train_loss: 0.0317\n",
      "318/1088, train_loss: 0.0269\n",
      "319/1088, train_loss: 0.0279\n",
      "320/1088, train_loss: 0.0261\n",
      "321/1088, train_loss: 0.0298\n",
      "322/1088, train_loss: 0.0326\n",
      "323/1088, train_loss: 0.0301\n",
      "324/1088, train_loss: 0.0325\n",
      "325/1088, train_loss: 0.0286\n",
      "326/1088, train_loss: 0.0298\n",
      "327/1088, train_loss: 0.0283\n",
      "328/1088, train_loss: 0.0282\n",
      "329/1088, train_loss: 0.0374\n",
      "330/1088, train_loss: 0.0285\n",
      "331/1088, train_loss: 0.0294\n",
      "332/1088, train_loss: 0.0277\n",
      "333/1088, train_loss: 0.0287\n",
      "334/1088, train_loss: 0.0274\n",
      "335/1088, train_loss: 0.0276\n",
      "336/1088, train_loss: 0.0295\n",
      "337/1088, train_loss: 0.0279\n",
      "338/1088, train_loss: 0.0297\n",
      "339/1088, train_loss: 0.0283\n",
      "340/1088, train_loss: 0.0308\n",
      "341/1088, train_loss: 0.0284\n",
      "342/1088, train_loss: 0.0277\n",
      "343/1088, train_loss: 0.0284\n",
      "344/1088, train_loss: 0.0313\n",
      "345/1088, train_loss: 0.0287\n",
      "346/1088, train_loss: 0.0265\n",
      "347/1088, train_loss: 0.0283\n",
      "348/1088, train_loss: 0.0298\n",
      "349/1088, train_loss: 0.0266\n",
      "350/1088, train_loss: 0.0264\n",
      "351/1088, train_loss: 0.0296\n",
      "352/1088, train_loss: 0.0284\n",
      "353/1088, train_loss: 0.0286\n",
      "354/1088, train_loss: 0.0332\n",
      "355/1088, train_loss: 0.0254\n",
      "356/1088, train_loss: 0.0280\n",
      "357/1088, train_loss: 0.0258\n",
      "358/1088, train_loss: 0.0277\n",
      "359/1088, train_loss: 0.0268\n",
      "360/1088, train_loss: 0.0275\n",
      "361/1088, train_loss: 0.0296\n",
      "362/1088, train_loss: 0.0299\n",
      "363/1088, train_loss: 0.0262\n",
      "364/1088, train_loss: 0.0293\n",
      "365/1088, train_loss: 0.0268\n",
      "366/1088, train_loss: 0.0278\n",
      "367/1088, train_loss: 0.0282\n",
      "368/1088, train_loss: 0.0277\n",
      "369/1088, train_loss: 0.0288\n",
      "370/1088, train_loss: 0.0282\n",
      "371/1088, train_loss: 0.0275\n",
      "372/1088, train_loss: 0.0300\n",
      "373/1088, train_loss: 0.0293\n",
      "374/1088, train_loss: 0.0252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/1088, train_loss: 0.0314\n",
      "376/1088, train_loss: 0.0291\n",
      "377/1088, train_loss: 0.0281\n",
      "378/1088, train_loss: 0.0278\n",
      "379/1088, train_loss: 0.0281\n",
      "380/1088, train_loss: 0.0290\n",
      "381/1088, train_loss: 0.0296\n",
      "382/1088, train_loss: 0.0273\n",
      "383/1088, train_loss: 0.0297\n",
      "384/1088, train_loss: 0.0313\n",
      "385/1088, train_loss: 0.0293\n",
      "386/1088, train_loss: 0.0310\n",
      "387/1088, train_loss: 0.0358\n",
      "388/1088, train_loss: 0.0282\n",
      "389/1088, train_loss: 0.0301\n",
      "390/1088, train_loss: 0.0277\n",
      "391/1088, train_loss: 0.0301\n",
      "392/1088, train_loss: 0.0285\n",
      "393/1088, train_loss: 0.0312\n",
      "394/1088, train_loss: 0.0301\n",
      "395/1088, train_loss: 0.0285\n",
      "396/1088, train_loss: 0.0285\n",
      "397/1088, train_loss: 0.0274\n",
      "398/1088, train_loss: 0.0284\n",
      "399/1088, train_loss: 0.0284\n",
      "400/1088, train_loss: 0.0276\n",
      "401/1088, train_loss: 0.0273\n",
      "402/1088, train_loss: 0.0291\n",
      "403/1088, train_loss: 0.0278\n",
      "404/1088, train_loss: 0.0288\n",
      "405/1088, train_loss: 0.0306\n",
      "406/1088, train_loss: 0.0295\n",
      "407/1088, train_loss: 0.0310\n",
      "408/1088, train_loss: 0.0308\n",
      "409/1088, train_loss: 0.0293\n",
      "410/1088, train_loss: 0.0290\n",
      "411/1088, train_loss: 0.0310\n",
      "412/1088, train_loss: 0.0303\n",
      "413/1088, train_loss: 0.0303\n",
      "414/1088, train_loss: 0.0326\n",
      "415/1088, train_loss: 0.0287\n",
      "416/1088, train_loss: 0.0313\n",
      "417/1088, train_loss: 0.0290\n",
      "418/1088, train_loss: 0.0303\n",
      "419/1088, train_loss: 0.0294\n",
      "420/1088, train_loss: 0.0279\n",
      "421/1088, train_loss: 0.0269\n",
      "422/1088, train_loss: 0.0307\n",
      "423/1088, train_loss: 0.0345\n",
      "424/1088, train_loss: 0.0275\n",
      "425/1088, train_loss: 0.0301\n",
      "426/1088, train_loss: 0.0332\n",
      "427/1088, train_loss: 0.0290\n",
      "428/1088, train_loss: 0.0312\n",
      "429/1088, train_loss: 0.0281\n",
      "430/1088, train_loss: 0.0311\n",
      "431/1088, train_loss: 0.0291\n",
      "432/1088, train_loss: 0.0293\n",
      "433/1088, train_loss: 0.0281\n",
      "434/1088, train_loss: 0.0305\n",
      "435/1088, train_loss: 0.0304\n",
      "436/1088, train_loss: 0.0294\n",
      "437/1088, train_loss: 0.0302\n",
      "438/1088, train_loss: 0.0284\n",
      "439/1088, train_loss: 0.0252\n",
      "440/1088, train_loss: 0.0291\n",
      "441/1088, train_loss: 0.0282\n",
      "442/1088, train_loss: 0.0299\n",
      "443/1088, train_loss: 0.0275\n",
      "444/1088, train_loss: 0.0297\n",
      "445/1088, train_loss: 0.0295\n",
      "446/1088, train_loss: 0.0296\n",
      "447/1088, train_loss: 0.0286\n",
      "448/1088, train_loss: 0.0278\n",
      "449/1088, train_loss: 0.0283\n",
      "450/1088, train_loss: 0.0288\n",
      "451/1088, train_loss: 0.0279\n",
      "452/1088, train_loss: 0.0255\n",
      "453/1088, train_loss: 0.0292\n",
      "454/1088, train_loss: 0.0301\n",
      "455/1088, train_loss: 0.0299\n",
      "456/1088, train_loss: 0.0285\n",
      "457/1088, train_loss: 0.0267\n",
      "458/1088, train_loss: 0.0303\n",
      "459/1088, train_loss: 0.0271\n",
      "460/1088, train_loss: 0.0292\n",
      "461/1088, train_loss: 0.0291\n",
      "462/1088, train_loss: 0.0260\n",
      "463/1088, train_loss: 0.0273\n",
      "464/1088, train_loss: 0.0317\n",
      "465/1088, train_loss: 0.0276\n",
      "466/1088, train_loss: 0.0297\n",
      "467/1088, train_loss: 0.0306\n",
      "468/1088, train_loss: 0.0279\n",
      "469/1088, train_loss: 0.0313\n",
      "470/1088, train_loss: 0.0292\n",
      "471/1088, train_loss: 0.0284\n",
      "472/1088, train_loss: 0.0262\n",
      "473/1088, train_loss: 0.0277\n",
      "474/1088, train_loss: 0.0290\n",
      "475/1088, train_loss: 0.0288\n",
      "476/1088, train_loss: 0.0290\n",
      "477/1088, train_loss: 0.0285\n",
      "478/1088, train_loss: 0.0314\n",
      "479/1088, train_loss: 0.0298\n",
      "480/1088, train_loss: 0.0290\n",
      "481/1088, train_loss: 0.0291\n",
      "482/1088, train_loss: 0.0295\n",
      "483/1088, train_loss: 0.0292\n",
      "484/1088, train_loss: 0.0271\n",
      "485/1088, train_loss: 0.0310\n",
      "486/1088, train_loss: 0.0279\n",
      "487/1088, train_loss: 0.0288\n",
      "488/1088, train_loss: 0.0288\n",
      "489/1088, train_loss: 0.0277\n",
      "490/1088, train_loss: 0.0289\n",
      "491/1088, train_loss: 0.0284\n",
      "492/1088, train_loss: 0.0289\n",
      "493/1088, train_loss: 0.0294\n",
      "494/1088, train_loss: 0.0291\n",
      "495/1088, train_loss: 0.0286\n",
      "496/1088, train_loss: 0.0266\n",
      "497/1088, train_loss: 0.0298\n",
      "498/1088, train_loss: 0.0272\n",
      "499/1088, train_loss: 0.0287\n",
      "500/1088, train_loss: 0.0289\n",
      "501/1088, train_loss: 0.0281\n",
      "502/1088, train_loss: 0.0290\n",
      "503/1088, train_loss: 0.0276\n",
      "504/1088, train_loss: 0.0267\n",
      "505/1088, train_loss: 0.0284\n",
      "506/1088, train_loss: 0.0299\n",
      "507/1088, train_loss: 0.0303\n",
      "508/1088, train_loss: 0.0299\n",
      "509/1088, train_loss: 0.0290\n",
      "510/1088, train_loss: 0.0267\n",
      "511/1088, train_loss: 0.0278\n",
      "512/1088, train_loss: 0.0287\n",
      "513/1088, train_loss: 0.0296\n",
      "514/1088, train_loss: 0.0294\n",
      "515/1088, train_loss: 0.0284\n",
      "516/1088, train_loss: 0.0311\n",
      "517/1088, train_loss: 0.0268\n",
      "518/1088, train_loss: 0.0282\n",
      "519/1088, train_loss: 0.0279\n",
      "520/1088, train_loss: 0.0268\n",
      "521/1088, train_loss: 0.0280\n",
      "522/1088, train_loss: 0.0318\n",
      "523/1088, train_loss: 0.0300\n",
      "524/1088, train_loss: 0.0291\n",
      "525/1088, train_loss: 0.0307\n",
      "526/1088, train_loss: 0.0275\n",
      "527/1088, train_loss: 0.0292\n",
      "528/1088, train_loss: 0.0279\n",
      "529/1088, train_loss: 0.0260\n",
      "530/1088, train_loss: 0.0333\n",
      "531/1088, train_loss: 0.0273\n",
      "532/1088, train_loss: 0.0280\n",
      "533/1088, train_loss: 0.0295\n",
      "534/1088, train_loss: 0.0303\n",
      "535/1088, train_loss: 0.0296\n",
      "536/1088, train_loss: 0.0285\n",
      "537/1088, train_loss: 0.0265\n",
      "538/1088, train_loss: 0.0302\n",
      "539/1088, train_loss: 0.0313\n",
      "540/1088, train_loss: 0.0281\n",
      "541/1088, train_loss: 0.0290\n",
      "542/1088, train_loss: 0.0277\n",
      "543/1088, train_loss: 0.0280\n",
      "544/1088, train_loss: 0.0282\n",
      "545/1088, train_loss: 0.0287\n",
      "546/1088, train_loss: 0.0276\n",
      "547/1088, train_loss: 0.0295\n",
      "548/1088, train_loss: 0.0302\n",
      "549/1088, train_loss: 0.0276\n",
      "550/1088, train_loss: 0.0289\n",
      "551/1088, train_loss: 0.0315\n",
      "552/1088, train_loss: 0.0277\n",
      "553/1088, train_loss: 0.0288\n",
      "554/1088, train_loss: 0.0258\n",
      "555/1088, train_loss: 0.0299\n",
      "556/1088, train_loss: 0.0275\n",
      "557/1088, train_loss: 0.0286\n",
      "558/1088, train_loss: 0.0277\n",
      "559/1088, train_loss: 0.0289\n",
      "560/1088, train_loss: 0.0288\n",
      "561/1088, train_loss: 0.0292\n",
      "562/1088, train_loss: 0.0277\n",
      "563/1088, train_loss: 0.0302\n",
      "564/1088, train_loss: 0.0295\n",
      "565/1088, train_loss: 0.0271\n",
      "566/1088, train_loss: 0.0275\n",
      "567/1088, train_loss: 0.0275\n",
      "568/1088, train_loss: 0.0278\n",
      "569/1088, train_loss: 0.0291\n",
      "570/1088, train_loss: 0.0273\n",
      "571/1088, train_loss: 0.0300\n",
      "572/1088, train_loss: 0.0265\n",
      "573/1088, train_loss: 0.0272\n",
      "574/1088, train_loss: 0.0269\n",
      "575/1088, train_loss: 0.0279\n",
      "576/1088, train_loss: 0.0272\n",
      "577/1088, train_loss: 0.0269\n",
      "578/1088, train_loss: 0.0337\n",
      "579/1088, train_loss: 0.0285\n",
      "580/1088, train_loss: 0.0268\n",
      "581/1088, train_loss: 0.0311\n",
      "582/1088, train_loss: 0.0286\n",
      "583/1088, train_loss: 0.0279\n",
      "584/1088, train_loss: 0.0259\n",
      "585/1088, train_loss: 0.0302\n",
      "586/1088, train_loss: 0.0304\n",
      "587/1088, train_loss: 0.0285\n",
      "588/1088, train_loss: 0.0302\n",
      "589/1088, train_loss: 0.0281\n",
      "590/1088, train_loss: 0.0309\n",
      "591/1088, train_loss: 0.0272\n",
      "592/1088, train_loss: 0.0280\n",
      "593/1088, train_loss: 0.0265\n",
      "594/1088, train_loss: 0.0275\n",
      "595/1088, train_loss: 0.0279\n",
      "596/1088, train_loss: 0.0281\n",
      "597/1088, train_loss: 0.0316\n",
      "598/1088, train_loss: 0.0261\n",
      "599/1088, train_loss: 0.0296\n",
      "600/1088, train_loss: 0.0291\n",
      "601/1088, train_loss: 0.0284\n",
      "602/1088, train_loss: 0.0278\n",
      "603/1088, train_loss: 0.0279\n",
      "604/1088, train_loss: 0.0290\n",
      "605/1088, train_loss: 0.0276\n",
      "606/1088, train_loss: 0.0250\n",
      "607/1088, train_loss: 0.0293\n",
      "608/1088, train_loss: 0.0298\n",
      "609/1088, train_loss: 0.0340\n",
      "610/1088, train_loss: 0.0267\n",
      "611/1088, train_loss: 0.0275\n",
      "612/1088, train_loss: 0.0289\n",
      "613/1088, train_loss: 0.0260\n",
      "614/1088, train_loss: 0.0264\n",
      "615/1088, train_loss: 0.0293\n",
      "616/1088, train_loss: 0.0294\n",
      "617/1088, train_loss: 0.0273\n",
      "618/1088, train_loss: 0.0296\n",
      "619/1088, train_loss: 0.0284\n",
      "620/1088, train_loss: 0.0283\n",
      "621/1088, train_loss: 0.0290\n",
      "622/1088, train_loss: 0.0293\n",
      "623/1088, train_loss: 0.0283\n",
      "624/1088, train_loss: 0.0260\n",
      "625/1088, train_loss: 0.0272\n",
      "626/1088, train_loss: 0.0284\n",
      "627/1088, train_loss: 0.0272\n",
      "628/1088, train_loss: 0.0423\n",
      "629/1088, train_loss: 0.0253\n",
      "630/1088, train_loss: 0.0301\n",
      "631/1088, train_loss: 0.0273\n",
      "632/1088, train_loss: 0.0278\n",
      "633/1088, train_loss: 0.0296\n",
      "634/1088, train_loss: 0.0296\n",
      "635/1088, train_loss: 0.0294\n",
      "636/1088, train_loss: 0.0290\n",
      "637/1088, train_loss: 0.0281\n",
      "638/1088, train_loss: 0.0299\n",
      "639/1088, train_loss: 0.0278\n",
      "640/1088, train_loss: 0.0282\n",
      "641/1088, train_loss: 0.0290\n",
      "642/1088, train_loss: 0.0292\n",
      "643/1088, train_loss: 0.0274\n",
      "644/1088, train_loss: 0.0264\n",
      "645/1088, train_loss: 0.0291\n",
      "646/1088, train_loss: 0.0294\n",
      "647/1088, train_loss: 0.0303\n",
      "648/1088, train_loss: 0.0291\n",
      "649/1088, train_loss: 0.0283\n",
      "650/1088, train_loss: 0.0305\n",
      "651/1088, train_loss: 0.0273\n",
      "652/1088, train_loss: 0.0282\n",
      "653/1088, train_loss: 0.0298\n",
      "654/1088, train_loss: 0.0306\n",
      "655/1088, train_loss: 0.0288\n",
      "656/1088, train_loss: 0.0292\n",
      "657/1088, train_loss: 0.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658/1088, train_loss: 0.0280\n",
      "659/1088, train_loss: 0.0318\n",
      "660/1088, train_loss: 0.0291\n",
      "661/1088, train_loss: 0.0280\n",
      "662/1088, train_loss: 0.0292\n",
      "663/1088, train_loss: 0.0293\n",
      "664/1088, train_loss: 0.0273\n",
      "665/1088, train_loss: 0.0302\n",
      "666/1088, train_loss: 0.0289\n",
      "667/1088, train_loss: 0.0298\n",
      "668/1088, train_loss: 0.0282\n",
      "669/1088, train_loss: 0.0264\n",
      "670/1088, train_loss: 0.0287\n",
      "671/1088, train_loss: 0.0291\n",
      "672/1088, train_loss: 0.0287\n",
      "673/1088, train_loss: 0.0284\n",
      "674/1088, train_loss: 0.0293\n",
      "675/1088, train_loss: 0.0273\n",
      "676/1088, train_loss: 0.0299\n",
      "677/1088, train_loss: 0.0296\n",
      "678/1088, train_loss: 0.0276\n",
      "679/1088, train_loss: 0.0333\n",
      "680/1088, train_loss: 0.0274\n",
      "681/1088, train_loss: 0.0290\n",
      "682/1088, train_loss: 0.0287\n",
      "683/1088, train_loss: 0.0280\n",
      "684/1088, train_loss: 0.0294\n",
      "685/1088, train_loss: 0.0272\n",
      "686/1088, train_loss: 0.0302\n",
      "687/1088, train_loss: 0.0275\n",
      "688/1088, train_loss: 0.0291\n",
      "689/1088, train_loss: 0.0266\n",
      "690/1088, train_loss: 0.0285\n",
      "691/1088, train_loss: 0.0291\n",
      "692/1088, train_loss: 0.0305\n",
      "693/1088, train_loss: 0.0267\n",
      "694/1088, train_loss: 0.0296\n",
      "695/1088, train_loss: 0.0281\n",
      "696/1088, train_loss: 0.0298\n",
      "697/1088, train_loss: 0.0283\n",
      "698/1088, train_loss: 0.0307\n",
      "699/1088, train_loss: 0.0286\n",
      "700/1088, train_loss: 0.0262\n",
      "701/1088, train_loss: 0.0264\n",
      "702/1088, train_loss: 0.0291\n",
      "703/1088, train_loss: 0.0278\n",
      "704/1088, train_loss: 0.0273\n",
      "705/1088, train_loss: 0.0275\n",
      "706/1088, train_loss: 0.0303\n",
      "707/1088, train_loss: 0.0278\n",
      "708/1088, train_loss: 0.0309\n",
      "709/1088, train_loss: 0.0290\n",
      "710/1088, train_loss: 0.0292\n",
      "711/1088, train_loss: 0.0277\n",
      "712/1088, train_loss: 0.0281\n",
      "713/1088, train_loss: 0.0303\n",
      "714/1088, train_loss: 0.0291\n",
      "715/1088, train_loss: 0.0289\n",
      "716/1088, train_loss: 0.0285\n",
      "717/1088, train_loss: 0.0299\n",
      "718/1088, train_loss: 0.0281\n",
      "719/1088, train_loss: 0.0288\n",
      "720/1088, train_loss: 0.0283\n",
      "721/1088, train_loss: 0.0289\n",
      "722/1088, train_loss: 0.0282\n",
      "723/1088, train_loss: 0.0290\n",
      "724/1088, train_loss: 0.0261\n",
      "725/1088, train_loss: 0.0281\n",
      "726/1088, train_loss: 0.0268\n",
      "727/1088, train_loss: 0.0278\n",
      "728/1088, train_loss: 0.0286\n",
      "729/1088, train_loss: 0.0304\n",
      "730/1088, train_loss: 0.0260\n",
      "731/1088, train_loss: 0.0284\n",
      "732/1088, train_loss: 0.0279\n",
      "733/1088, train_loss: 0.0300\n",
      "734/1088, train_loss: 0.0268\n",
      "735/1088, train_loss: 0.0297\n",
      "736/1088, train_loss: 0.0287\n",
      "737/1088, train_loss: 0.0295\n",
      "738/1088, train_loss: 0.0290\n",
      "739/1088, train_loss: 0.0289\n",
      "740/1088, train_loss: 0.0288\n",
      "741/1088, train_loss: 0.0276\n",
      "742/1088, train_loss: 0.0267\n",
      "743/1088, train_loss: 0.0273\n",
      "744/1088, train_loss: 0.0297\n",
      "745/1088, train_loss: 0.0286\n",
      "746/1088, train_loss: 0.0295\n",
      "747/1088, train_loss: 0.0420\n",
      "748/1088, train_loss: 0.0279\n",
      "749/1088, train_loss: 0.0286\n",
      "750/1088, train_loss: 0.0271\n",
      "751/1088, train_loss: 0.0281\n",
      "752/1088, train_loss: 0.0285\n",
      "753/1088, train_loss: 0.0280\n",
      "754/1088, train_loss: 0.0309\n",
      "755/1088, train_loss: 0.0294\n",
      "756/1088, train_loss: 0.0280\n",
      "757/1088, train_loss: 0.0342\n",
      "758/1088, train_loss: 0.0312\n",
      "759/1088, train_loss: 0.0278\n",
      "760/1088, train_loss: 0.0265\n",
      "761/1088, train_loss: 0.0296\n",
      "762/1088, train_loss: 0.0280\n",
      "763/1088, train_loss: 0.0271\n",
      "764/1088, train_loss: 0.0280\n",
      "765/1088, train_loss: 0.0289\n",
      "766/1088, train_loss: 0.0283\n",
      "767/1088, train_loss: 0.0296\n",
      "768/1088, train_loss: 0.0284\n",
      "769/1088, train_loss: 0.0267\n",
      "770/1088, train_loss: 0.0279\n",
      "771/1088, train_loss: 0.0293\n",
      "772/1088, train_loss: 0.0260\n",
      "773/1088, train_loss: 0.0269\n",
      "774/1088, train_loss: 0.0268\n",
      "775/1088, train_loss: 0.0279\n",
      "776/1088, train_loss: 0.0271\n",
      "777/1088, train_loss: 0.0282\n",
      "778/1088, train_loss: 0.0269\n",
      "779/1088, train_loss: 0.0270\n",
      "780/1088, train_loss: 0.0300\n",
      "781/1088, train_loss: 0.0290\n",
      "782/1088, train_loss: 0.0297\n",
      "783/1088, train_loss: 0.0294\n",
      "784/1088, train_loss: 0.0281\n",
      "785/1088, train_loss: 0.0270\n",
      "786/1088, train_loss: 0.0261\n",
      "787/1088, train_loss: 0.0289\n",
      "788/1088, train_loss: 0.0310\n",
      "789/1088, train_loss: 0.0272\n",
      "790/1088, train_loss: 0.0276\n",
      "791/1088, train_loss: 0.0278\n",
      "792/1088, train_loss: 0.0278\n",
      "793/1088, train_loss: 0.0300\n",
      "794/1088, train_loss: 0.0272\n",
      "795/1088, train_loss: 0.0273\n",
      "796/1088, train_loss: 0.0287\n",
      "797/1088, train_loss: 0.0277\n",
      "798/1088, train_loss: 0.0284\n",
      "799/1088, train_loss: 0.0285\n",
      "800/1088, train_loss: 0.0284\n",
      "801/1088, train_loss: 0.0275\n",
      "802/1088, train_loss: 0.0261\n",
      "803/1088, train_loss: 0.0324\n",
      "804/1088, train_loss: 0.0334\n",
      "805/1088, train_loss: 0.0294\n",
      "806/1088, train_loss: 0.0277\n",
      "807/1088, train_loss: 0.0309\n",
      "808/1088, train_loss: 0.0271\n",
      "809/1088, train_loss: 0.0276\n",
      "810/1088, train_loss: 0.0276\n",
      "811/1088, train_loss: 0.0296\n",
      "812/1088, train_loss: 0.0287\n",
      "813/1088, train_loss: 0.0288\n",
      "814/1088, train_loss: 0.0278\n",
      "815/1088, train_loss: 0.0327\n",
      "816/1088, train_loss: 0.0287\n",
      "817/1088, train_loss: 0.0314\n",
      "818/1088, train_loss: 0.0297\n",
      "819/1088, train_loss: 0.0296\n",
      "820/1088, train_loss: 0.0290\n",
      "821/1088, train_loss: 0.0264\n",
      "822/1088, train_loss: 0.0283\n",
      "823/1088, train_loss: 0.0288\n",
      "824/1088, train_loss: 0.0275\n",
      "825/1088, train_loss: 0.0284\n",
      "826/1088, train_loss: 0.0289\n",
      "827/1088, train_loss: 0.0287\n",
      "828/1088, train_loss: 0.0276\n",
      "829/1088, train_loss: 0.0284\n",
      "830/1088, train_loss: 0.0278\n",
      "831/1088, train_loss: 0.0295\n",
      "832/1088, train_loss: 0.0286\n",
      "833/1088, train_loss: 0.0282\n",
      "834/1088, train_loss: 0.0287\n",
      "835/1088, train_loss: 0.0275\n",
      "836/1088, train_loss: 0.0256\n",
      "837/1088, train_loss: 0.0274\n",
      "838/1088, train_loss: 0.0286\n",
      "839/1088, train_loss: 0.0310\n",
      "840/1088, train_loss: 0.0281\n",
      "841/1088, train_loss: 0.0289\n",
      "842/1088, train_loss: 0.0319\n",
      "843/1088, train_loss: 0.0306\n",
      "844/1088, train_loss: 0.0294\n",
      "845/1088, train_loss: 0.0311\n",
      "846/1088, train_loss: 0.0305\n",
      "847/1088, train_loss: 0.0297\n",
      "848/1088, train_loss: 0.0296\n",
      "849/1088, train_loss: 0.0283\n",
      "850/1088, train_loss: 0.0268\n",
      "851/1088, train_loss: 0.0280\n",
      "852/1088, train_loss: 0.0284\n",
      "853/1088, train_loss: 0.0296\n",
      "854/1088, train_loss: 0.0269\n",
      "855/1088, train_loss: 0.0284\n",
      "856/1088, train_loss: 0.0280\n",
      "857/1088, train_loss: 0.0278\n",
      "858/1088, train_loss: 0.0297\n",
      "859/1088, train_loss: 0.0262\n",
      "860/1088, train_loss: 0.0275\n",
      "861/1088, train_loss: 0.0298\n",
      "862/1088, train_loss: 0.0294\n",
      "863/1088, train_loss: 0.0277\n",
      "864/1088, train_loss: 0.0285\n",
      "865/1088, train_loss: 0.0293\n",
      "866/1088, train_loss: 0.0276\n",
      "867/1088, train_loss: 0.0271\n",
      "868/1088, train_loss: 0.0270\n",
      "869/1088, train_loss: 0.0282\n",
      "870/1088, train_loss: 0.0287\n",
      "871/1088, train_loss: 0.0291\n",
      "872/1088, train_loss: 0.0307\n",
      "873/1088, train_loss: 0.0280\n",
      "874/1088, train_loss: 0.0291\n",
      "875/1088, train_loss: 0.0301\n",
      "876/1088, train_loss: 0.0312\n",
      "877/1088, train_loss: 0.0281\n",
      "878/1088, train_loss: 0.0289\n",
      "879/1088, train_loss: 0.0293\n",
      "880/1088, train_loss: 0.0316\n",
      "881/1088, train_loss: 0.0273\n",
      "882/1088, train_loss: 0.0282\n",
      "883/1088, train_loss: 0.0288\n",
      "884/1088, train_loss: 0.0311\n",
      "885/1088, train_loss: 0.0279\n",
      "886/1088, train_loss: 0.0269\n",
      "887/1088, train_loss: 0.0292\n",
      "888/1088, train_loss: 0.0285\n",
      "889/1088, train_loss: 0.0297\n",
      "890/1088, train_loss: 0.0270\n",
      "891/1088, train_loss: 0.0279\n",
      "892/1088, train_loss: 0.0262\n",
      "893/1088, train_loss: 0.0303\n",
      "894/1088, train_loss: 0.0291\n",
      "895/1088, train_loss: 0.0285\n",
      "896/1088, train_loss: 0.0286\n",
      "897/1088, train_loss: 0.0289\n",
      "898/1088, train_loss: 0.0266\n",
      "899/1088, train_loss: 0.0281\n",
      "900/1088, train_loss: 0.0280\n",
      "901/1088, train_loss: 0.0274\n",
      "902/1088, train_loss: 0.0293\n",
      "903/1088, train_loss: 0.0285\n",
      "904/1088, train_loss: 0.0270\n",
      "905/1088, train_loss: 0.0288\n",
      "906/1088, train_loss: 0.0264\n",
      "907/1088, train_loss: 0.0260\n",
      "908/1088, train_loss: 0.0262\n",
      "909/1088, train_loss: 0.0295\n",
      "910/1088, train_loss: 0.0279\n",
      "911/1088, train_loss: 0.0284\n",
      "912/1088, train_loss: 0.0284\n",
      "913/1088, train_loss: 0.0283\n",
      "914/1088, train_loss: 0.0283\n",
      "915/1088, train_loss: 0.0315\n",
      "916/1088, train_loss: 0.0292\n",
      "917/1088, train_loss: 0.0265\n",
      "918/1088, train_loss: 0.0276\n",
      "919/1088, train_loss: 0.0295\n",
      "920/1088, train_loss: 0.0263\n",
      "921/1088, train_loss: 0.0298\n",
      "922/1088, train_loss: 0.0287\n",
      "923/1088, train_loss: 0.0327\n",
      "924/1088, train_loss: 0.0276\n",
      "925/1088, train_loss: 0.0303\n",
      "926/1088, train_loss: 0.0273\n",
      "927/1088, train_loss: 0.0296\n",
      "928/1088, train_loss: 0.0295\n",
      "929/1088, train_loss: 0.0292\n",
      "930/1088, train_loss: 0.0272\n",
      "931/1088, train_loss: 0.0278\n",
      "932/1088, train_loss: 0.0319\n",
      "933/1088, train_loss: 0.0282\n",
      "934/1088, train_loss: 0.0279\n",
      "935/1088, train_loss: 0.0270\n",
      "936/1088, train_loss: 0.0286\n",
      "937/1088, train_loss: 0.0379\n",
      "938/1088, train_loss: 0.0249\n",
      "939/1088, train_loss: 0.0288\n",
      "940/1088, train_loss: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941/1088, train_loss: 0.0276\n",
      "942/1088, train_loss: 0.0284\n",
      "943/1088, train_loss: 0.0266\n",
      "944/1088, train_loss: 0.0288\n",
      "945/1088, train_loss: 0.0279\n",
      "946/1088, train_loss: 0.0303\n",
      "947/1088, train_loss: 0.0276\n",
      "948/1088, train_loss: 0.0277\n",
      "949/1088, train_loss: 0.0296\n",
      "950/1088, train_loss: 0.0258\n",
      "951/1088, train_loss: 0.0274\n",
      "952/1088, train_loss: 0.0256\n",
      "953/1088, train_loss: 0.0278\n",
      "954/1088, train_loss: 0.0306\n",
      "955/1088, train_loss: 0.0282\n",
      "956/1088, train_loss: 0.0292\n",
      "957/1088, train_loss: 0.0289\n",
      "958/1088, train_loss: 0.0282\n",
      "959/1088, train_loss: 0.0285\n",
      "960/1088, train_loss: 0.0285\n",
      "961/1088, train_loss: 0.0274\n",
      "962/1088, train_loss: 0.0297\n",
      "963/1088, train_loss: 0.0274\n",
      "964/1088, train_loss: 0.0297\n",
      "965/1088, train_loss: 0.0303\n",
      "966/1088, train_loss: 0.0303\n",
      "967/1088, train_loss: 0.0291\n",
      "968/1088, train_loss: 0.0287\n",
      "969/1088, train_loss: 0.0315\n",
      "970/1088, train_loss: 0.0314\n",
      "971/1088, train_loss: 0.0286\n",
      "972/1088, train_loss: 0.0308\n",
      "973/1088, train_loss: 0.0285\n",
      "974/1088, train_loss: 0.0315\n",
      "975/1088, train_loss: 0.0313\n",
      "976/1088, train_loss: 0.0303\n",
      "977/1088, train_loss: 0.0282\n",
      "978/1088, train_loss: 0.0295\n",
      "979/1088, train_loss: 0.0309\n",
      "980/1088, train_loss: 0.0291\n",
      "981/1088, train_loss: 0.0300\n",
      "982/1088, train_loss: 0.0265\n",
      "983/1088, train_loss: 0.0290\n",
      "984/1088, train_loss: 0.0283\n",
      "985/1088, train_loss: 0.0282\n",
      "986/1088, train_loss: 0.0324\n",
      "987/1088, train_loss: 0.0274\n",
      "988/1088, train_loss: 0.0270\n",
      "989/1088, train_loss: 0.0279\n",
      "990/1088, train_loss: 0.0285\n",
      "991/1088, train_loss: 0.0271\n",
      "992/1088, train_loss: 0.0282\n",
      "993/1088, train_loss: 0.0255\n",
      "994/1088, train_loss: 0.0289\n",
      "995/1088, train_loss: 0.0274\n",
      "996/1088, train_loss: 0.0256\n",
      "997/1088, train_loss: 0.0273\n",
      "998/1088, train_loss: 0.0275\n",
      "999/1088, train_loss: 0.0279\n",
      "1000/1088, train_loss: 0.0349\n",
      "1001/1088, train_loss: 0.0271\n",
      "1002/1088, train_loss: 0.0306\n",
      "1003/1088, train_loss: 0.0314\n",
      "1004/1088, train_loss: 0.0323\n",
      "1005/1088, train_loss: 0.0292\n",
      "1006/1088, train_loss: 0.0311\n",
      "1007/1088, train_loss: 0.0298\n",
      "1008/1088, train_loss: 0.0290\n",
      "1009/1088, train_loss: 0.0295\n",
      "1010/1088, train_loss: 0.0329\n",
      "1011/1088, train_loss: 0.0292\n",
      "1012/1088, train_loss: 0.0298\n",
      "1013/1088, train_loss: 0.0305\n",
      "1014/1088, train_loss: 0.0285\n",
      "1015/1088, train_loss: 0.0260\n",
      "1016/1088, train_loss: 0.0302\n",
      "1017/1088, train_loss: 0.0289\n",
      "1018/1088, train_loss: 0.0301\n",
      "1019/1088, train_loss: 0.0269\n",
      "1020/1088, train_loss: 0.0297\n",
      "1021/1088, train_loss: 0.0256\n",
      "1022/1088, train_loss: 0.0283\n",
      "1023/1088, train_loss: 0.0289\n",
      "1024/1088, train_loss: 0.0281\n",
      "1025/1088, train_loss: 0.0314\n",
      "1026/1088, train_loss: 0.0290\n",
      "1027/1088, train_loss: 0.0284\n",
      "1028/1088, train_loss: 0.0278\n",
      "1029/1088, train_loss: 0.0278\n",
      "1030/1088, train_loss: 0.0312\n",
      "1031/1088, train_loss: 0.0298\n",
      "1032/1088, train_loss: 0.0287\n",
      "1033/1088, train_loss: 0.0271\n",
      "1034/1088, train_loss: 0.0281\n",
      "1035/1088, train_loss: 0.0297\n",
      "1036/1088, train_loss: 0.0292\n",
      "1037/1088, train_loss: 0.0327\n",
      "1038/1088, train_loss: 0.0277\n",
      "1039/1088, train_loss: 0.0279\n",
      "1040/1088, train_loss: 0.0287\n",
      "1041/1088, train_loss: 0.0251\n",
      "1042/1088, train_loss: 0.0293\n",
      "1043/1088, train_loss: 0.0319\n",
      "1044/1088, train_loss: 0.0287\n",
      "1045/1088, train_loss: 0.0256\n",
      "1046/1088, train_loss: 0.0285\n",
      "1047/1088, train_loss: 0.0261\n",
      "1048/1088, train_loss: 0.0282\n",
      "1049/1088, train_loss: 0.0298\n",
      "1050/1088, train_loss: 0.0285\n",
      "1051/1088, train_loss: 0.0288\n",
      "1052/1088, train_loss: 0.0287\n",
      "1053/1088, train_loss: 0.0270\n",
      "1054/1088, train_loss: 0.0285\n",
      "1055/1088, train_loss: 0.0291\n",
      "1056/1088, train_loss: 0.0288\n",
      "1057/1088, train_loss: 0.0269\n",
      "1058/1088, train_loss: 0.0285\n",
      "1059/1088, train_loss: 0.0279\n",
      "1060/1088, train_loss: 0.0273\n",
      "1061/1088, train_loss: 0.0327\n",
      "1062/1088, train_loss: 0.0301\n",
      "1063/1088, train_loss: 0.0264\n",
      "1064/1088, train_loss: 0.0291\n",
      "1065/1088, train_loss: 0.0310\n",
      "1066/1088, train_loss: 0.0271\n",
      "1067/1088, train_loss: 0.0291\n",
      "1068/1088, train_loss: 0.0300\n",
      "1069/1088, train_loss: 0.0265\n",
      "1070/1088, train_loss: 0.0249\n",
      "1071/1088, train_loss: 0.0285\n",
      "1072/1088, train_loss: 0.0276\n",
      "1073/1088, train_loss: 0.0276\n",
      "1074/1088, train_loss: 0.0298\n",
      "1075/1088, train_loss: 0.0282\n",
      "1076/1088, train_loss: 0.0284\n",
      "1077/1088, train_loss: 0.0289\n",
      "1078/1088, train_loss: 0.0288\n",
      "1079/1088, train_loss: 0.0267\n",
      "1080/1088, train_loss: 0.0270\n",
      "1081/1088, train_loss: 0.0270\n",
      "1082/1088, train_loss: 0.0274\n",
      "1083/1088, train_loss: 0.0296\n",
      "1084/1088, train_loss: 0.0292\n",
      "1085/1088, train_loss: 0.0280\n",
      "1086/1088, train_loss: 0.0277\n",
      "1087/1088, train_loss: 0.0293\n",
      "1088/1088, train_loss: 0.0317\n",
      "1089/1088, train_loss: 0.0285\n",
      "epoch 12 average loss: 0.0287, train_dice: 0.9714\n",
      "epoch 12 average loss: 0.0287\n",
      "current epoch: 12 current mean dice: 0.9663 best mean dice: 0.9703 at epoch 8\n",
      "--------------------------------------------------\n",
      "epoch 13/50\n",
      "1/1088, train_loss: 0.0280\n",
      "2/1088, train_loss: 0.0300\n",
      "3/1088, train_loss: 0.0267\n",
      "4/1088, train_loss: 0.0279\n",
      "5/1088, train_loss: 0.0307\n",
      "6/1088, train_loss: 0.0299\n",
      "7/1088, train_loss: 0.0294\n",
      "8/1088, train_loss: 0.0268\n",
      "9/1088, train_loss: 0.0277\n",
      "10/1088, train_loss: 0.0282\n",
      "11/1088, train_loss: 0.0321\n",
      "12/1088, train_loss: 0.0266\n",
      "13/1088, train_loss: 0.0281\n",
      "14/1088, train_loss: 0.0327\n",
      "15/1088, train_loss: 0.0297\n",
      "16/1088, train_loss: 0.0277\n",
      "17/1088, train_loss: 0.0294\n",
      "18/1088, train_loss: 0.0258\n",
      "19/1088, train_loss: 0.0287\n",
      "20/1088, train_loss: 0.0279\n",
      "21/1088, train_loss: 0.0286\n",
      "22/1088, train_loss: 0.0286\n",
      "23/1088, train_loss: 0.0273\n",
      "24/1088, train_loss: 0.0299\n",
      "25/1088, train_loss: 0.0278\n",
      "26/1088, train_loss: 0.0284\n",
      "27/1088, train_loss: 0.0298\n",
      "28/1088, train_loss: 0.0288\n",
      "29/1088, train_loss: 0.0264\n",
      "30/1088, train_loss: 0.0291\n",
      "31/1088, train_loss: 0.0276\n",
      "32/1088, train_loss: 0.0268\n",
      "33/1088, train_loss: 0.0261\n",
      "34/1088, train_loss: 0.0280\n",
      "35/1088, train_loss: 0.0359\n",
      "36/1088, train_loss: 0.0297\n",
      "37/1088, train_loss: 0.0314\n",
      "38/1088, train_loss: 0.0271\n",
      "39/1088, train_loss: 0.0320\n",
      "40/1088, train_loss: 0.0284\n",
      "41/1088, train_loss: 0.0308\n",
      "42/1088, train_loss: 0.0271\n",
      "43/1088, train_loss: 0.0284\n",
      "44/1088, train_loss: 0.0291\n",
      "45/1088, train_loss: 0.0280\n",
      "46/1088, train_loss: 0.0286\n",
      "47/1088, train_loss: 0.0278\n",
      "48/1088, train_loss: 0.0273\n",
      "49/1088, train_loss: 0.0292\n",
      "50/1088, train_loss: 0.0278\n",
      "51/1088, train_loss: 0.0293\n",
      "52/1088, train_loss: 0.0293\n",
      "53/1088, train_loss: 0.0271\n",
      "54/1088, train_loss: 0.0297\n",
      "55/1088, train_loss: 0.0285\n",
      "56/1088, train_loss: 0.0284\n",
      "57/1088, train_loss: 0.0290\n",
      "58/1088, train_loss: 0.0276\n",
      "59/1088, train_loss: 0.0353\n",
      "60/1088, train_loss: 0.0280\n",
      "61/1088, train_loss: 0.0272\n",
      "62/1088, train_loss: 0.0318\n",
      "63/1088, train_loss: 0.0299\n",
      "64/1088, train_loss: 0.0284\n",
      "65/1088, train_loss: 0.0299\n",
      "66/1088, train_loss: 0.0301\n",
      "67/1088, train_loss: 0.0285\n",
      "68/1088, train_loss: 0.0318\n",
      "69/1088, train_loss: 0.0295\n",
      "70/1088, train_loss: 0.0326\n",
      "71/1088, train_loss: 0.0313\n",
      "72/1088, train_loss: 0.0310\n",
      "73/1088, train_loss: 0.0280\n",
      "74/1088, train_loss: 0.0278\n",
      "75/1088, train_loss: 0.0269\n",
      "76/1088, train_loss: 0.0260\n",
      "77/1088, train_loss: 0.0264\n",
      "78/1088, train_loss: 0.0321\n",
      "79/1088, train_loss: 0.0257\n",
      "80/1088, train_loss: 0.0288\n",
      "81/1088, train_loss: 0.0284\n",
      "82/1088, train_loss: 0.0277\n",
      "83/1088, train_loss: 0.0281\n",
      "84/1088, train_loss: 0.0285\n",
      "85/1088, train_loss: 0.0282\n",
      "86/1088, train_loss: 0.0305\n",
      "87/1088, train_loss: 0.0297\n",
      "88/1088, train_loss: 0.0278\n",
      "89/1088, train_loss: 0.0311\n",
      "90/1088, train_loss: 0.0307\n",
      "91/1088, train_loss: 0.0262\n",
      "92/1088, train_loss: 0.0266\n",
      "93/1088, train_loss: 0.0306\n",
      "94/1088, train_loss: 0.0278\n",
      "95/1088, train_loss: 0.0277\n",
      "96/1088, train_loss: 0.0286\n",
      "97/1088, train_loss: 0.0292\n",
      "98/1088, train_loss: 0.0290\n",
      "99/1088, train_loss: 0.0259\n",
      "100/1088, train_loss: 0.0295\n",
      "101/1088, train_loss: 0.0267\n",
      "102/1088, train_loss: 0.0279\n",
      "103/1088, train_loss: 0.0272\n",
      "104/1088, train_loss: 0.0288\n",
      "105/1088, train_loss: 0.0274\n",
      "106/1088, train_loss: 0.0320\n",
      "107/1088, train_loss: 0.0270\n",
      "108/1088, train_loss: 0.0285\n",
      "109/1088, train_loss: 0.0366\n",
      "110/1088, train_loss: 0.0277\n",
      "111/1088, train_loss: 0.0293\n",
      "112/1088, train_loss: 0.0294\n",
      "113/1088, train_loss: 0.0311\n",
      "114/1088, train_loss: 0.0260\n",
      "115/1088, train_loss: 0.0293\n",
      "116/1088, train_loss: 0.0253\n",
      "117/1088, train_loss: 0.0290\n",
      "118/1088, train_loss: 0.0318\n",
      "119/1088, train_loss: 0.0294\n",
      "120/1088, train_loss: 0.0270\n",
      "121/1088, train_loss: 0.0282\n",
      "122/1088, train_loss: 0.0302\n",
      "123/1088, train_loss: 0.0263\n",
      "124/1088, train_loss: 0.0322\n",
      "125/1088, train_loss: 0.0240\n",
      "126/1088, train_loss: 0.0299\n",
      "127/1088, train_loss: 0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128/1088, train_loss: 0.0289\n",
      "129/1088, train_loss: 0.0281\n",
      "130/1088, train_loss: 0.0257\n",
      "131/1088, train_loss: 0.0295\n",
      "132/1088, train_loss: 0.0285\n",
      "133/1088, train_loss: 0.0295\n",
      "134/1088, train_loss: 0.0280\n",
      "135/1088, train_loss: 0.0297\n",
      "136/1088, train_loss: 0.0288\n",
      "137/1088, train_loss: 0.0298\n",
      "138/1088, train_loss: 0.0298\n",
      "139/1088, train_loss: 0.0293\n",
      "140/1088, train_loss: 0.0317\n",
      "141/1088, train_loss: 0.0289\n",
      "142/1088, train_loss: 0.0274\n",
      "143/1088, train_loss: 0.0280\n",
      "144/1088, train_loss: 0.0287\n",
      "145/1088, train_loss: 0.0279\n",
      "146/1088, train_loss: 0.0291\n",
      "147/1088, train_loss: 0.0277\n",
      "148/1088, train_loss: 0.0273\n",
      "149/1088, train_loss: 0.0292\n",
      "150/1088, train_loss: 0.0297\n",
      "151/1088, train_loss: 0.0278\n",
      "152/1088, train_loss: 0.0285\n",
      "153/1088, train_loss: 0.0313\n",
      "154/1088, train_loss: 0.0263\n",
      "155/1088, train_loss: 0.0293\n",
      "156/1088, train_loss: 0.0327\n",
      "157/1088, train_loss: 0.0279\n",
      "158/1088, train_loss: 0.0280\n",
      "159/1088, train_loss: 0.0288\n",
      "160/1088, train_loss: 0.0291\n",
      "161/1088, train_loss: 0.0275\n",
      "162/1088, train_loss: 0.0302\n",
      "163/1088, train_loss: 0.0259\n",
      "164/1088, train_loss: 0.0261\n",
      "165/1088, train_loss: 0.0281\n",
      "166/1088, train_loss: 0.0279\n",
      "167/1088, train_loss: 0.0251\n",
      "168/1088, train_loss: 0.0291\n",
      "169/1088, train_loss: 0.0305\n",
      "170/1088, train_loss: 0.0288\n",
      "171/1088, train_loss: 0.0286\n",
      "172/1088, train_loss: 0.0291\n",
      "173/1088, train_loss: 0.0283\n",
      "174/1088, train_loss: 0.0276\n",
      "175/1088, train_loss: 0.0268\n",
      "176/1088, train_loss: 0.0290\n",
      "177/1088, train_loss: 0.0282\n",
      "178/1088, train_loss: 0.0278\n",
      "179/1088, train_loss: 0.0282\n",
      "180/1088, train_loss: 0.0288\n",
      "181/1088, train_loss: 0.0294\n",
      "182/1088, train_loss: 0.0266\n",
      "183/1088, train_loss: 0.0270\n",
      "184/1088, train_loss: 0.0287\n",
      "185/1088, train_loss: 0.0284\n",
      "186/1088, train_loss: 0.0284\n",
      "187/1088, train_loss: 0.0285\n",
      "188/1088, train_loss: 0.0261\n",
      "189/1088, train_loss: 0.0304\n",
      "190/1088, train_loss: 0.0291\n",
      "191/1088, train_loss: 0.0282\n",
      "192/1088, train_loss: 0.0281\n",
      "193/1088, train_loss: 0.0269\n",
      "194/1088, train_loss: 0.0277\n",
      "195/1088, train_loss: 0.0249\n",
      "196/1088, train_loss: 0.0321\n",
      "197/1088, train_loss: 0.0264\n",
      "198/1088, train_loss: 0.0268\n",
      "199/1088, train_loss: 0.0281\n",
      "200/1088, train_loss: 0.0306\n",
      "201/1088, train_loss: 0.0291\n",
      "202/1088, train_loss: 0.0270\n",
      "203/1088, train_loss: 0.0292\n",
      "204/1088, train_loss: 0.0298\n",
      "205/1088, train_loss: 0.0277\n",
      "206/1088, train_loss: 0.0296\n",
      "207/1088, train_loss: 0.0285\n",
      "208/1088, train_loss: 0.0288\n",
      "209/1088, train_loss: 0.0285\n",
      "210/1088, train_loss: 0.0278\n",
      "211/1088, train_loss: 0.0336\n",
      "212/1088, train_loss: 0.0290\n",
      "213/1088, train_loss: 0.0283\n",
      "214/1088, train_loss: 0.0280\n",
      "215/1088, train_loss: 0.0293\n",
      "216/1088, train_loss: 0.0272\n",
      "217/1088, train_loss: 0.0279\n",
      "218/1088, train_loss: 0.0265\n",
      "219/1088, train_loss: 0.0269\n",
      "220/1088, train_loss: 0.0287\n",
      "221/1088, train_loss: 0.0271\n",
      "222/1088, train_loss: 0.0262\n",
      "223/1088, train_loss: 0.0290\n",
      "224/1088, train_loss: 0.0321\n",
      "225/1088, train_loss: 0.0279\n",
      "226/1088, train_loss: 0.0294\n",
      "227/1088, train_loss: 0.0290\n",
      "228/1088, train_loss: 0.0296\n",
      "229/1088, train_loss: 0.0267\n",
      "230/1088, train_loss: 0.0296\n",
      "231/1088, train_loss: 0.0295\n",
      "232/1088, train_loss: 0.0247\n",
      "233/1088, train_loss: 0.0316\n",
      "234/1088, train_loss: 0.0314\n",
      "235/1088, train_loss: 0.0272\n",
      "236/1088, train_loss: 0.0279\n",
      "237/1088, train_loss: 0.0261\n",
      "238/1088, train_loss: 0.0274\n",
      "239/1088, train_loss: 0.0279\n",
      "240/1088, train_loss: 0.0287\n",
      "241/1088, train_loss: 0.0280\n",
      "242/1088, train_loss: 0.0276\n",
      "243/1088, train_loss: 0.0279\n",
      "244/1088, train_loss: 0.0264\n",
      "245/1088, train_loss: 0.0304\n",
      "246/1088, train_loss: 0.0274\n",
      "247/1088, train_loss: 0.0265\n",
      "248/1088, train_loss: 0.0275\n",
      "249/1088, train_loss: 0.0289\n",
      "250/1088, train_loss: 0.0293\n",
      "251/1088, train_loss: 0.0270\n",
      "252/1088, train_loss: 0.0286\n",
      "253/1088, train_loss: 0.0276\n",
      "254/1088, train_loss: 0.0282\n",
      "255/1088, train_loss: 0.0267\n",
      "256/1088, train_loss: 0.0303\n",
      "257/1088, train_loss: 0.0290\n",
      "258/1088, train_loss: 0.0295\n",
      "259/1088, train_loss: 0.0294\n",
      "260/1088, train_loss: 0.0293\n",
      "261/1088, train_loss: 0.0261\n",
      "262/1088, train_loss: 0.0280\n",
      "263/1088, train_loss: 0.0290\n",
      "264/1088, train_loss: 0.0292\n",
      "265/1088, train_loss: 0.0306\n",
      "266/1088, train_loss: 0.0273\n",
      "267/1088, train_loss: 0.0287\n",
      "268/1088, train_loss: 0.0290\n",
      "269/1088, train_loss: 0.0302\n",
      "270/1088, train_loss: 0.0287\n",
      "271/1088, train_loss: 0.0300\n",
      "272/1088, train_loss: 0.0286\n",
      "273/1088, train_loss: 0.0279\n",
      "274/1088, train_loss: 0.0260\n",
      "275/1088, train_loss: 0.0310\n",
      "276/1088, train_loss: 0.0296\n",
      "277/1088, train_loss: 0.0286\n",
      "278/1088, train_loss: 0.0276\n",
      "279/1088, train_loss: 0.0277\n",
      "280/1088, train_loss: 0.0269\n",
      "281/1088, train_loss: 0.0268\n",
      "282/1088, train_loss: 0.0289\n",
      "283/1088, train_loss: 0.0282\n",
      "284/1088, train_loss: 0.0289\n",
      "285/1088, train_loss: 0.0276\n",
      "286/1088, train_loss: 0.0290\n",
      "287/1088, train_loss: 0.0278\n",
      "288/1088, train_loss: 0.0267\n",
      "289/1088, train_loss: 0.0291\n",
      "290/1088, train_loss: 0.0283\n",
      "291/1088, train_loss: 0.0294\n",
      "292/1088, train_loss: 0.0270\n",
      "293/1088, train_loss: 0.0267\n",
      "294/1088, train_loss: 0.0275\n",
      "295/1088, train_loss: 0.0275\n",
      "296/1088, train_loss: 0.0295\n",
      "297/1088, train_loss: 0.0312\n",
      "298/1088, train_loss: 0.0280\n",
      "299/1088, train_loss: 0.0260\n",
      "300/1088, train_loss: 0.0280\n",
      "301/1088, train_loss: 0.0297\n",
      "302/1088, train_loss: 0.0277\n",
      "303/1088, train_loss: 0.0247\n",
      "304/1088, train_loss: 0.0287\n",
      "305/1088, train_loss: 0.0291\n",
      "306/1088, train_loss: 0.0322\n",
      "307/1088, train_loss: 0.0283\n",
      "308/1088, train_loss: 0.0270\n",
      "309/1088, train_loss: 0.0275\n",
      "310/1088, train_loss: 0.0276\n",
      "311/1088, train_loss: 0.0296\n",
      "312/1088, train_loss: 0.0274\n",
      "313/1088, train_loss: 0.0264\n",
      "314/1088, train_loss: 0.0281\n",
      "315/1088, train_loss: 0.0274\n",
      "316/1088, train_loss: 0.0279\n",
      "317/1088, train_loss: 0.0270\n",
      "318/1088, train_loss: 0.0281\n",
      "319/1088, train_loss: 0.0350\n",
      "320/1088, train_loss: 0.0281\n",
      "321/1088, train_loss: 0.0282\n",
      "322/1088, train_loss: 0.0299\n",
      "323/1088, train_loss: 0.0289\n",
      "324/1088, train_loss: 0.0278\n",
      "325/1088, train_loss: 0.0278\n",
      "326/1088, train_loss: 0.0291\n",
      "327/1088, train_loss: 0.0297\n",
      "328/1088, train_loss: 0.0312\n",
      "329/1088, train_loss: 0.0284\n",
      "330/1088, train_loss: 0.0279\n",
      "331/1088, train_loss: 0.0302\n",
      "332/1088, train_loss: 0.0261\n",
      "333/1088, train_loss: 0.0254\n",
      "334/1088, train_loss: 0.0294\n",
      "335/1088, train_loss: 0.0275\n",
      "336/1088, train_loss: 0.0268\n",
      "337/1088, train_loss: 0.0281\n",
      "338/1088, train_loss: 0.0289\n",
      "339/1088, train_loss: 0.0275\n",
      "340/1088, train_loss: 0.0275\n",
      "341/1088, train_loss: 0.0294\n",
      "342/1088, train_loss: 0.0274\n",
      "343/1088, train_loss: 0.0278\n",
      "344/1088, train_loss: 0.0309\n",
      "345/1088, train_loss: 0.0262\n",
      "346/1088, train_loss: 0.0291\n",
      "347/1088, train_loss: 0.0297\n",
      "348/1088, train_loss: 0.0256\n",
      "349/1088, train_loss: 0.0317\n",
      "350/1088, train_loss: 0.0269\n",
      "351/1088, train_loss: 0.0260\n",
      "352/1088, train_loss: 0.0291\n",
      "353/1088, train_loss: 0.0270\n",
      "354/1088, train_loss: 0.0261\n",
      "355/1088, train_loss: 0.0332\n",
      "356/1088, train_loss: 0.0266\n",
      "357/1088, train_loss: 0.0280\n",
      "358/1088, train_loss: 0.0285\n",
      "359/1088, train_loss: 0.0336\n",
      "360/1088, train_loss: 0.0293\n",
      "361/1088, train_loss: 0.0295\n",
      "362/1088, train_loss: 0.0289\n",
      "363/1088, train_loss: 0.0296\n",
      "364/1088, train_loss: 0.0290\n",
      "365/1088, train_loss: 0.0290\n",
      "366/1088, train_loss: 0.0282\n",
      "367/1088, train_loss: 0.0264\n",
      "368/1088, train_loss: 0.0285\n",
      "369/1088, train_loss: 0.0303\n",
      "370/1088, train_loss: 0.0287\n",
      "371/1088, train_loss: 0.0276\n",
      "372/1088, train_loss: 0.0281\n",
      "373/1088, train_loss: 0.0263\n",
      "374/1088, train_loss: 0.0309\n",
      "375/1088, train_loss: 0.0288\n",
      "376/1088, train_loss: 0.0286\n",
      "377/1088, train_loss: 0.0266\n",
      "378/1088, train_loss: 0.0275\n",
      "379/1088, train_loss: 0.0303\n",
      "380/1088, train_loss: 0.0281\n",
      "381/1088, train_loss: 0.0291\n",
      "382/1088, train_loss: 0.0267\n",
      "383/1088, train_loss: 0.0277\n",
      "384/1088, train_loss: 0.0258\n",
      "385/1088, train_loss: 0.0305\n",
      "386/1088, train_loss: 0.0301\n",
      "387/1088, train_loss: 0.0274\n",
      "388/1088, train_loss: 0.0276\n",
      "389/1088, train_loss: 0.0279\n",
      "390/1088, train_loss: 0.0280\n",
      "391/1088, train_loss: 0.0268\n",
      "392/1088, train_loss: 0.0298\n",
      "393/1088, train_loss: 0.0255\n",
      "394/1088, train_loss: 0.0332\n",
      "395/1088, train_loss: 0.0287\n",
      "396/1088, train_loss: 0.0267\n",
      "397/1088, train_loss: 0.0288\n",
      "398/1088, train_loss: 0.0289\n",
      "399/1088, train_loss: 0.0269\n",
      "400/1088, train_loss: 0.0294\n",
      "401/1088, train_loss: 0.0278\n",
      "402/1088, train_loss: 0.0268\n",
      "403/1088, train_loss: 0.0291\n",
      "404/1088, train_loss: 0.0261\n",
      "405/1088, train_loss: 0.0280\n",
      "406/1088, train_loss: 0.0282\n",
      "407/1088, train_loss: 0.0323\n",
      "408/1088, train_loss: 0.0288\n",
      "409/1088, train_loss: 0.0285\n",
      "410/1088, train_loss: 0.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411/1088, train_loss: 0.0304\n",
      "412/1088, train_loss: 0.0285\n",
      "413/1088, train_loss: 0.0247\n",
      "414/1088, train_loss: 0.0277\n",
      "415/1088, train_loss: 0.0282\n",
      "416/1088, train_loss: 0.0285\n",
      "417/1088, train_loss: 0.0256\n",
      "418/1088, train_loss: 0.0275\n",
      "419/1088, train_loss: 0.0290\n",
      "420/1088, train_loss: 0.0279\n",
      "421/1088, train_loss: 0.0271\n",
      "422/1088, train_loss: 0.0324\n",
      "423/1088, train_loss: 0.0285\n",
      "424/1088, train_loss: 0.0289\n",
      "425/1088, train_loss: 0.0271\n",
      "426/1088, train_loss: 0.0300\n",
      "427/1088, train_loss: 0.0259\n",
      "428/1088, train_loss: 0.0294\n",
      "429/1088, train_loss: 0.0298\n",
      "430/1088, train_loss: 0.0298\n",
      "431/1088, train_loss: 0.0278\n",
      "432/1088, train_loss: 0.0285\n",
      "433/1088, train_loss: 0.0290\n",
      "434/1088, train_loss: 0.0361\n",
      "435/1088, train_loss: 0.0263\n",
      "436/1088, train_loss: 0.0327\n",
      "437/1088, train_loss: 0.0285\n",
      "438/1088, train_loss: 0.0278\n",
      "439/1088, train_loss: 0.0286\n",
      "440/1088, train_loss: 0.0272\n",
      "441/1088, train_loss: 0.0287\n",
      "442/1088, train_loss: 0.0291\n",
      "443/1088, train_loss: 0.0266\n",
      "444/1088, train_loss: 0.0264\n",
      "445/1088, train_loss: 0.0335\n",
      "446/1088, train_loss: 0.0278\n",
      "447/1088, train_loss: 0.0286\n",
      "448/1088, train_loss: 0.0294\n",
      "449/1088, train_loss: 0.0254\n",
      "450/1088, train_loss: 0.0255\n",
      "451/1088, train_loss: 0.0264\n",
      "452/1088, train_loss: 0.0297\n",
      "453/1088, train_loss: 0.0304\n",
      "454/1088, train_loss: 0.0286\n",
      "455/1088, train_loss: 0.0293\n",
      "456/1088, train_loss: 0.0264\n",
      "457/1088, train_loss: 0.0254\n",
      "458/1088, train_loss: 0.0292\n",
      "459/1088, train_loss: 0.0281\n",
      "460/1088, train_loss: 0.0304\n",
      "461/1088, train_loss: 0.0248\n",
      "462/1088, train_loss: 0.0305\n",
      "463/1088, train_loss: 0.0282\n",
      "464/1088, train_loss: 0.0276\n",
      "465/1088, train_loss: 0.0270\n",
      "466/1088, train_loss: 0.0315\n",
      "467/1088, train_loss: 0.0340\n",
      "468/1088, train_loss: 0.0306\n",
      "469/1088, train_loss: 0.0265\n",
      "470/1088, train_loss: 0.0263\n",
      "471/1088, train_loss: 0.0297\n",
      "472/1088, train_loss: 0.0297\n",
      "473/1088, train_loss: 0.0273\n",
      "474/1088, train_loss: 0.0279\n",
      "475/1088, train_loss: 0.0257\n",
      "476/1088, train_loss: 0.0378\n",
      "477/1088, train_loss: 0.0287\n",
      "478/1088, train_loss: 0.0297\n",
      "479/1088, train_loss: 0.0288\n",
      "480/1088, train_loss: 0.0284\n",
      "481/1088, train_loss: 0.0319\n",
      "482/1088, train_loss: 0.0300\n",
      "483/1088, train_loss: 0.0299\n",
      "484/1088, train_loss: 0.0258\n",
      "485/1088, train_loss: 0.0294\n",
      "486/1088, train_loss: 0.0286\n",
      "487/1088, train_loss: 0.0275\n",
      "488/1088, train_loss: 0.0277\n",
      "489/1088, train_loss: 0.0288\n",
      "490/1088, train_loss: 0.0292\n",
      "491/1088, train_loss: 0.0289\n",
      "492/1088, train_loss: 0.0276\n",
      "493/1088, train_loss: 0.0295\n",
      "494/1088, train_loss: 0.0253\n",
      "495/1088, train_loss: 0.0275\n",
      "496/1088, train_loss: 0.0249\n",
      "497/1088, train_loss: 0.0266\n",
      "498/1088, train_loss: 0.0291\n",
      "499/1088, train_loss: 0.0298\n",
      "500/1088, train_loss: 0.0293\n",
      "501/1088, train_loss: 0.0287\n",
      "502/1088, train_loss: 0.0274\n",
      "503/1088, train_loss: 0.0283\n",
      "504/1088, train_loss: 0.0334\n",
      "505/1088, train_loss: 0.0278\n",
      "506/1088, train_loss: 0.0265\n",
      "507/1088, train_loss: 0.0275\n",
      "508/1088, train_loss: 0.0267\n",
      "509/1088, train_loss: 0.0300\n",
      "510/1088, train_loss: 0.0285\n",
      "511/1088, train_loss: 0.0265\n",
      "512/1088, train_loss: 0.0292\n",
      "513/1088, train_loss: 0.0261\n",
      "514/1088, train_loss: 0.0262\n",
      "515/1088, train_loss: 0.0295\n",
      "516/1088, train_loss: 0.0297\n",
      "517/1088, train_loss: 0.0274\n",
      "518/1088, train_loss: 0.0301\n",
      "519/1088, train_loss: 0.0276\n",
      "520/1088, train_loss: 0.0287\n",
      "521/1088, train_loss: 0.0285\n",
      "522/1088, train_loss: 0.0275\n",
      "523/1088, train_loss: 0.0278\n",
      "524/1088, train_loss: 0.0289\n",
      "525/1088, train_loss: 0.0286\n",
      "526/1088, train_loss: 0.0290\n",
      "527/1088, train_loss: 0.0253\n",
      "528/1088, train_loss: 0.0250\n",
      "529/1088, train_loss: 0.0283\n",
      "530/1088, train_loss: 0.0279\n",
      "531/1088, train_loss: 0.0273\n",
      "532/1088, train_loss: 0.0274\n",
      "533/1088, train_loss: 0.0290\n",
      "534/1088, train_loss: 0.0342\n",
      "535/1088, train_loss: 0.0282\n",
      "536/1088, train_loss: 0.0312\n",
      "537/1088, train_loss: 0.0291\n",
      "538/1088, train_loss: 0.0277\n",
      "539/1088, train_loss: 0.0278\n",
      "540/1088, train_loss: 0.0282\n",
      "541/1088, train_loss: 0.0283\n",
      "542/1088, train_loss: 0.0281\n",
      "543/1088, train_loss: 0.0297\n",
      "544/1088, train_loss: 0.0289\n",
      "545/1088, train_loss: 0.0263\n",
      "546/1088, train_loss: 0.0238\n",
      "547/1088, train_loss: 0.0265\n",
      "548/1088, train_loss: 0.0291\n",
      "549/1088, train_loss: 0.0276\n",
      "550/1088, train_loss: 0.0299\n",
      "551/1088, train_loss: 0.0320\n",
      "552/1088, train_loss: 0.0285\n",
      "553/1088, train_loss: 0.0295\n",
      "554/1088, train_loss: 0.0267\n",
      "555/1088, train_loss: 0.0295\n",
      "556/1088, train_loss: 0.0275\n",
      "557/1088, train_loss: 0.0312\n",
      "558/1088, train_loss: 0.0309\n",
      "559/1088, train_loss: 0.0313\n",
      "560/1088, train_loss: 0.0291\n",
      "561/1088, train_loss: 0.0300\n",
      "562/1088, train_loss: 0.0266\n",
      "563/1088, train_loss: 0.0296\n",
      "564/1088, train_loss: 0.0286\n",
      "565/1088, train_loss: 0.0279\n",
      "566/1088, train_loss: 0.0296\n",
      "567/1088, train_loss: 0.0275\n",
      "568/1088, train_loss: 0.0283\n",
      "569/1088, train_loss: 0.0281\n",
      "570/1088, train_loss: 0.0346\n",
      "571/1088, train_loss: 0.0268\n",
      "572/1088, train_loss: 0.0301\n",
      "573/1088, train_loss: 0.0268\n",
      "574/1088, train_loss: 0.0287\n",
      "575/1088, train_loss: 0.0292\n",
      "576/1088, train_loss: 0.0299\n",
      "577/1088, train_loss: 0.0288\n",
      "578/1088, train_loss: 0.0278\n",
      "579/1088, train_loss: 0.0311\n",
      "580/1088, train_loss: 0.0262\n",
      "581/1088, train_loss: 0.0304\n",
      "582/1088, train_loss: 0.0274\n",
      "583/1088, train_loss: 0.0285\n",
      "584/1088, train_loss: 0.0293\n",
      "585/1088, train_loss: 0.0252\n",
      "586/1088, train_loss: 0.0288\n",
      "587/1088, train_loss: 0.0267\n",
      "588/1088, train_loss: 0.0286\n",
      "589/1088, train_loss: 0.0281\n",
      "590/1088, train_loss: 0.0296\n",
      "591/1088, train_loss: 0.0272\n",
      "592/1088, train_loss: 0.0272\n",
      "593/1088, train_loss: 0.0288\n",
      "594/1088, train_loss: 0.0292\n",
      "595/1088, train_loss: 0.0306\n",
      "596/1088, train_loss: 0.0264\n",
      "597/1088, train_loss: 0.0287\n",
      "598/1088, train_loss: 0.0282\n",
      "599/1088, train_loss: 0.0281\n",
      "600/1088, train_loss: 0.0272\n",
      "601/1088, train_loss: 0.0286\n",
      "602/1088, train_loss: 0.0278\n",
      "603/1088, train_loss: 0.0276\n",
      "604/1088, train_loss: 0.0302\n",
      "605/1088, train_loss: 0.0263\n",
      "606/1088, train_loss: 0.0281\n",
      "607/1088, train_loss: 0.0306\n",
      "608/1088, train_loss: 0.0301\n",
      "609/1088, train_loss: 0.0283\n",
      "610/1088, train_loss: 0.0294\n",
      "611/1088, train_loss: 0.0280\n",
      "612/1088, train_loss: 0.0296\n",
      "613/1088, train_loss: 0.0266\n",
      "614/1088, train_loss: 0.0321\n",
      "615/1088, train_loss: 0.0309\n",
      "616/1088, train_loss: 0.0300\n",
      "617/1088, train_loss: 0.0302\n",
      "618/1088, train_loss: 0.0302\n",
      "619/1088, train_loss: 0.0287\n",
      "620/1088, train_loss: 0.0280\n",
      "621/1088, train_loss: 0.0274\n",
      "622/1088, train_loss: 0.0292\n",
      "623/1088, train_loss: 0.0282\n",
      "624/1088, train_loss: 0.0276\n",
      "625/1088, train_loss: 0.0281\n",
      "626/1088, train_loss: 0.0272\n",
      "627/1088, train_loss: 0.0301\n",
      "628/1088, train_loss: 0.0275\n",
      "629/1088, train_loss: 0.0251\n",
      "630/1088, train_loss: 0.0264\n",
      "631/1088, train_loss: 0.0296\n",
      "632/1088, train_loss: 0.0306\n",
      "633/1088, train_loss: 0.0297\n",
      "634/1088, train_loss: 0.0265\n",
      "635/1088, train_loss: 0.0294\n",
      "636/1088, train_loss: 0.0281\n",
      "637/1088, train_loss: 0.0273\n",
      "638/1088, train_loss: 0.0310\n",
      "639/1088, train_loss: 0.0298\n",
      "640/1088, train_loss: 0.0302\n",
      "641/1088, train_loss: 0.0274\n",
      "642/1088, train_loss: 0.0286\n",
      "643/1088, train_loss: 0.0286\n",
      "644/1088, train_loss: 0.0292\n",
      "645/1088, train_loss: 0.0299\n",
      "646/1088, train_loss: 0.0308\n",
      "647/1088, train_loss: 0.0270\n",
      "648/1088, train_loss: 0.0283\n",
      "649/1088, train_loss: 0.0293\n",
      "650/1088, train_loss: 0.0272\n",
      "651/1088, train_loss: 0.0278\n",
      "652/1088, train_loss: 0.0279\n",
      "653/1088, train_loss: 0.0276\n",
      "654/1088, train_loss: 0.0272\n",
      "655/1088, train_loss: 0.0299\n",
      "656/1088, train_loss: 0.0298\n",
      "657/1088, train_loss: 0.0293\n",
      "658/1088, train_loss: 0.0290\n",
      "659/1088, train_loss: 0.0279\n",
      "660/1088, train_loss: 0.0307\n",
      "661/1088, train_loss: 0.0287\n",
      "662/1088, train_loss: 0.0265\n",
      "663/1088, train_loss: 0.0289\n",
      "664/1088, train_loss: 0.0274\n",
      "665/1088, train_loss: 0.0297\n",
      "666/1088, train_loss: 0.0286\n",
      "667/1088, train_loss: 0.0290\n",
      "668/1088, train_loss: 0.0297\n",
      "669/1088, train_loss: 0.0260\n",
      "670/1088, train_loss: 0.0273\n",
      "671/1088, train_loss: 0.0267\n",
      "672/1088, train_loss: 0.0280\n",
      "673/1088, train_loss: 0.0273\n",
      "674/1088, train_loss: 0.0307\n",
      "675/1088, train_loss: 0.0282\n",
      "676/1088, train_loss: 0.0281\n",
      "677/1088, train_loss: 0.0297\n",
      "678/1088, train_loss: 0.0300\n",
      "679/1088, train_loss: 0.0301\n",
      "680/1088, train_loss: 0.0272\n",
      "681/1088, train_loss: 0.0282\n",
      "682/1088, train_loss: 0.0300\n",
      "683/1088, train_loss: 0.0262\n",
      "684/1088, train_loss: 0.0299\n",
      "685/1088, train_loss: 0.0305\n",
      "686/1088, train_loss: 0.0284\n",
      "687/1088, train_loss: 0.0295\n",
      "688/1088, train_loss: 0.0293\n",
      "689/1088, train_loss: 0.0270\n",
      "690/1088, train_loss: 0.0324\n",
      "691/1088, train_loss: 0.0298\n",
      "692/1088, train_loss: 0.0297\n",
      "693/1088, train_loss: 0.0281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694/1088, train_loss: 0.0267\n",
      "695/1088, train_loss: 0.0289\n",
      "696/1088, train_loss: 0.0273\n",
      "697/1088, train_loss: 0.0281\n",
      "698/1088, train_loss: 0.0295\n",
      "699/1088, train_loss: 0.0293\n",
      "700/1088, train_loss: 0.0283\n",
      "701/1088, train_loss: 0.0272\n",
      "702/1088, train_loss: 0.0298\n",
      "703/1088, train_loss: 0.0262\n",
      "704/1088, train_loss: 0.0270\n",
      "705/1088, train_loss: 0.0289\n",
      "706/1088, train_loss: 0.0264\n",
      "707/1088, train_loss: 0.0259\n",
      "708/1088, train_loss: 0.0262\n",
      "709/1088, train_loss: 0.0269\n",
      "710/1088, train_loss: 0.0295\n",
      "711/1088, train_loss: 0.0276\n",
      "712/1088, train_loss: 0.0265\n",
      "713/1088, train_loss: 0.0264\n",
      "714/1088, train_loss: 0.0277\n",
      "715/1088, train_loss: 0.0316\n",
      "716/1088, train_loss: 0.0289\n",
      "717/1088, train_loss: 0.0289\n",
      "718/1088, train_loss: 0.0296\n",
      "719/1088, train_loss: 0.0292\n",
      "720/1088, train_loss: 0.0284\n",
      "721/1088, train_loss: 0.0298\n",
      "722/1088, train_loss: 0.0298\n",
      "723/1088, train_loss: 0.0297\n",
      "724/1088, train_loss: 0.0280\n",
      "725/1088, train_loss: 0.0290\n",
      "726/1088, train_loss: 0.0271\n",
      "727/1088, train_loss: 0.0265\n",
      "728/1088, train_loss: 0.0271\n",
      "729/1088, train_loss: 0.0304\n",
      "730/1088, train_loss: 0.0279\n",
      "731/1088, train_loss: 0.0292\n",
      "732/1088, train_loss: 0.0262\n",
      "733/1088, train_loss: 0.0275\n",
      "734/1088, train_loss: 0.0279\n",
      "735/1088, train_loss: 0.0275\n",
      "736/1088, train_loss: 0.0276\n",
      "737/1088, train_loss: 0.0275\n",
      "738/1088, train_loss: 0.0276\n",
      "739/1088, train_loss: 0.0314\n",
      "740/1088, train_loss: 0.0287\n",
      "741/1088, train_loss: 0.0282\n",
      "742/1088, train_loss: 0.0290\n",
      "743/1088, train_loss: 0.0306\n",
      "744/1088, train_loss: 0.0317\n",
      "745/1088, train_loss: 0.0284\n",
      "746/1088, train_loss: 0.0276\n",
      "747/1088, train_loss: 0.0278\n",
      "748/1088, train_loss: 0.0288\n",
      "749/1088, train_loss: 0.0300\n",
      "750/1088, train_loss: 0.0265\n",
      "751/1088, train_loss: 0.0283\n",
      "752/1088, train_loss: 0.0270\n",
      "753/1088, train_loss: 0.0316\n",
      "754/1088, train_loss: 0.0272\n",
      "755/1088, train_loss: 0.0273\n",
      "756/1088, train_loss: 0.0271\n",
      "757/1088, train_loss: 0.0287\n",
      "758/1088, train_loss: 0.0310\n",
      "759/1088, train_loss: 0.0295\n",
      "760/1088, train_loss: 0.0291\n",
      "761/1088, train_loss: 0.0275\n",
      "762/1088, train_loss: 0.0282\n",
      "763/1088, train_loss: 0.0271\n",
      "764/1088, train_loss: 0.0294\n",
      "765/1088, train_loss: 0.0294\n",
      "766/1088, train_loss: 0.0267\n",
      "767/1088, train_loss: 0.0288\n",
      "768/1088, train_loss: 0.0269\n",
      "769/1088, train_loss: 0.0262\n",
      "770/1088, train_loss: 0.0277\n",
      "771/1088, train_loss: 0.0259\n",
      "772/1088, train_loss: 0.0278\n",
      "773/1088, train_loss: 0.0295\n",
      "774/1088, train_loss: 0.0281\n",
      "775/1088, train_loss: 0.0318\n",
      "776/1088, train_loss: 0.0287\n",
      "777/1088, train_loss: 0.0278\n",
      "778/1088, train_loss: 0.0292\n",
      "779/1088, train_loss: 0.0295\n",
      "780/1088, train_loss: 0.0281\n",
      "781/1088, train_loss: 0.0286\n",
      "782/1088, train_loss: 0.0263\n",
      "783/1088, train_loss: 0.0258\n",
      "784/1088, train_loss: 0.0289\n",
      "785/1088, train_loss: 0.0275\n",
      "786/1088, train_loss: 0.0283\n",
      "787/1088, train_loss: 0.0335\n",
      "788/1088, train_loss: 0.0276\n",
      "789/1088, train_loss: 0.0319\n",
      "790/1088, train_loss: 0.0299\n",
      "791/1088, train_loss: 0.0294\n",
      "792/1088, train_loss: 0.0302\n",
      "793/1088, train_loss: 0.0285\n",
      "794/1088, train_loss: 0.0300\n",
      "795/1088, train_loss: 0.0318\n",
      "796/1088, train_loss: 0.0289\n",
      "797/1088, train_loss: 0.0281\n",
      "798/1088, train_loss: 0.0278\n",
      "799/1088, train_loss: 0.0274\n",
      "800/1088, train_loss: 0.0304\n",
      "801/1088, train_loss: 0.0255\n",
      "802/1088, train_loss: 0.0274\n",
      "803/1088, train_loss: 0.0264\n",
      "804/1088, train_loss: 0.0354\n",
      "805/1088, train_loss: 0.0320\n",
      "806/1088, train_loss: 0.0291\n",
      "807/1088, train_loss: 0.0317\n",
      "808/1088, train_loss: 0.0263\n",
      "809/1088, train_loss: 0.0321\n",
      "810/1088, train_loss: 0.0282\n",
      "811/1088, train_loss: 0.0308\n",
      "812/1088, train_loss: 0.0305\n",
      "813/1088, train_loss: 0.0302\n",
      "814/1088, train_loss: 0.0314\n",
      "815/1088, train_loss: 0.0288\n",
      "816/1088, train_loss: 0.0296\n",
      "817/1088, train_loss: 0.0271\n",
      "818/1088, train_loss: 0.0315\n",
      "819/1088, train_loss: 0.0287\n",
      "820/1088, train_loss: 0.0321\n",
      "821/1088, train_loss: 0.0278\n",
      "822/1088, train_loss: 0.0290\n",
      "823/1088, train_loss: 0.0288\n",
      "824/1088, train_loss: 0.0280\n",
      "825/1088, train_loss: 0.0285\n",
      "826/1088, train_loss: 0.0280\n",
      "827/1088, train_loss: 0.0281\n",
      "828/1088, train_loss: 0.0272\n",
      "829/1088, train_loss: 0.0278\n",
      "830/1088, train_loss: 0.0254\n",
      "831/1088, train_loss: 0.0286\n",
      "832/1088, train_loss: 0.0297\n",
      "833/1088, train_loss: 0.0284\n",
      "834/1088, train_loss: 0.0286\n",
      "835/1088, train_loss: 0.0280\n",
      "836/1088, train_loss: 0.0274\n",
      "837/1088, train_loss: 0.0316\n",
      "838/1088, train_loss: 0.0294\n",
      "839/1088, train_loss: 0.0288\n",
      "840/1088, train_loss: 0.0305\n",
      "841/1088, train_loss: 0.0296\n",
      "842/1088, train_loss: 0.0296\n",
      "843/1088, train_loss: 0.0294\n",
      "844/1088, train_loss: 0.0295\n",
      "845/1088, train_loss: 0.0287\n",
      "846/1088, train_loss: 0.0256\n",
      "847/1088, train_loss: 0.0268\n",
      "848/1088, train_loss: 0.0261\n",
      "849/1088, train_loss: 0.0279\n",
      "850/1088, train_loss: 0.0280\n",
      "851/1088, train_loss: 0.0300\n",
      "852/1088, train_loss: 0.0295\n",
      "853/1088, train_loss: 0.0282\n",
      "854/1088, train_loss: 0.0279\n",
      "855/1088, train_loss: 0.0269\n",
      "856/1088, train_loss: 0.0280\n",
      "857/1088, train_loss: 0.0295\n",
      "858/1088, train_loss: 0.0272\n",
      "859/1088, train_loss: 0.0292\n",
      "860/1088, train_loss: 0.0298\n",
      "861/1088, train_loss: 0.0309\n",
      "862/1088, train_loss: 0.0286\n",
      "863/1088, train_loss: 0.0290\n",
      "864/1088, train_loss: 0.0269\n",
      "865/1088, train_loss: 0.0280\n",
      "866/1088, train_loss: 0.0292\n",
      "867/1088, train_loss: 0.0275\n",
      "868/1088, train_loss: 0.0296\n",
      "869/1088, train_loss: 0.0300\n",
      "870/1088, train_loss: 0.0306\n",
      "871/1088, train_loss: 0.0278\n",
      "872/1088, train_loss: 0.0302\n",
      "873/1088, train_loss: 0.0286\n",
      "874/1088, train_loss: 0.0270\n",
      "875/1088, train_loss: 0.0278\n",
      "876/1088, train_loss: 0.0280\n",
      "877/1088, train_loss: 0.0291\n",
      "878/1088, train_loss: 0.0295\n",
      "879/1088, train_loss: 0.0352\n",
      "880/1088, train_loss: 0.0276\n",
      "881/1088, train_loss: 0.0287\n",
      "882/1088, train_loss: 0.0291\n",
      "883/1088, train_loss: 0.0295\n",
      "884/1088, train_loss: 0.0279\n",
      "885/1088, train_loss: 0.0268\n",
      "886/1088, train_loss: 0.0275\n",
      "887/1088, train_loss: 0.0271\n",
      "888/1088, train_loss: 0.0281\n",
      "889/1088, train_loss: 0.0285\n",
      "890/1088, train_loss: 0.0316\n",
      "891/1088, train_loss: 0.0295\n",
      "892/1088, train_loss: 0.0282\n",
      "893/1088, train_loss: 0.0285\n",
      "894/1088, train_loss: 0.0293\n",
      "895/1088, train_loss: 0.0274\n",
      "896/1088, train_loss: 0.0273\n",
      "897/1088, train_loss: 0.0277\n",
      "898/1088, train_loss: 0.0301\n",
      "899/1088, train_loss: 0.0281\n",
      "900/1088, train_loss: 0.0317\n",
      "901/1088, train_loss: 0.0278\n",
      "902/1088, train_loss: 0.0281\n",
      "903/1088, train_loss: 0.0275\n",
      "904/1088, train_loss: 0.0289\n",
      "905/1088, train_loss: 0.0297\n",
      "906/1088, train_loss: 0.0291\n",
      "907/1088, train_loss: 0.0305\n",
      "908/1088, train_loss: 0.0313\n",
      "909/1088, train_loss: 0.0308\n",
      "910/1088, train_loss: 0.0310\n",
      "911/1088, train_loss: 0.0291\n",
      "912/1088, train_loss: 0.0294\n",
      "913/1088, train_loss: 0.0283\n",
      "914/1088, train_loss: 0.0273\n",
      "915/1088, train_loss: 0.0274\n",
      "916/1088, train_loss: 0.0263\n",
      "917/1088, train_loss: 0.0282\n",
      "918/1088, train_loss: 0.0293\n",
      "919/1088, train_loss: 0.0272\n",
      "920/1088, train_loss: 0.0280\n",
      "921/1088, train_loss: 0.0283\n",
      "922/1088, train_loss: 0.0281\n",
      "923/1088, train_loss: 0.0308\n",
      "924/1088, train_loss: 0.0352\n",
      "925/1088, train_loss: 0.0313\n",
      "926/1088, train_loss: 0.0288\n",
      "927/1088, train_loss: 0.0325\n",
      "928/1088, train_loss: 0.0282\n",
      "929/1088, train_loss: 0.0271\n",
      "930/1088, train_loss: 0.0295\n",
      "931/1088, train_loss: 0.0283\n",
      "932/1088, train_loss: 0.0273\n",
      "933/1088, train_loss: 0.0272\n",
      "934/1088, train_loss: 0.0341\n",
      "935/1088, train_loss: 0.0302\n",
      "936/1088, train_loss: 0.0287\n",
      "937/1088, train_loss: 0.0284\n",
      "938/1088, train_loss: 0.0283\n",
      "939/1088, train_loss: 0.0289\n",
      "940/1088, train_loss: 0.0294\n",
      "941/1088, train_loss: 0.0281\n",
      "942/1088, train_loss: 0.0265\n",
      "943/1088, train_loss: 0.0268\n",
      "944/1088, train_loss: 0.0321\n",
      "945/1088, train_loss: 0.0279\n",
      "946/1088, train_loss: 0.0300\n",
      "947/1088, train_loss: 0.0282\n",
      "948/1088, train_loss: 0.0276\n",
      "949/1088, train_loss: 0.0293\n",
      "950/1088, train_loss: 0.0297\n",
      "951/1088, train_loss: 0.0260\n",
      "952/1088, train_loss: 0.0260\n",
      "953/1088, train_loss: 0.0296\n",
      "954/1088, train_loss: 0.0285\n",
      "955/1088, train_loss: 0.0280\n",
      "956/1088, train_loss: 0.0268\n",
      "957/1088, train_loss: 0.0268\n",
      "958/1088, train_loss: 0.0280\n",
      "959/1088, train_loss: 0.0305\n",
      "960/1088, train_loss: 0.0280\n",
      "961/1088, train_loss: 0.0301\n",
      "962/1088, train_loss: 0.0268\n",
      "963/1088, train_loss: 0.0267\n",
      "964/1088, train_loss: 0.0265\n",
      "965/1088, train_loss: 0.0289\n",
      "966/1088, train_loss: 0.0310\n",
      "967/1088, train_loss: 0.0291\n",
      "968/1088, train_loss: 0.0286\n",
      "969/1088, train_loss: 0.0272\n",
      "970/1088, train_loss: 0.0272\n",
      "971/1088, train_loss: 0.0301\n",
      "972/1088, train_loss: 0.0267\n",
      "973/1088, train_loss: 0.0274\n",
      "974/1088, train_loss: 0.0282\n",
      "975/1088, train_loss: 0.0275\n",
      "976/1088, train_loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/1088, train_loss: 0.0280\n",
      "978/1088, train_loss: 0.0314\n",
      "979/1088, train_loss: 0.0279\n",
      "980/1088, train_loss: 0.0287\n",
      "981/1088, train_loss: 0.0288\n",
      "982/1088, train_loss: 0.0285\n",
      "983/1088, train_loss: 0.0311\n",
      "984/1088, train_loss: 0.0293\n",
      "985/1088, train_loss: 0.0307\n",
      "986/1088, train_loss: 0.0275\n",
      "987/1088, train_loss: 0.0274\n",
      "988/1088, train_loss: 0.0294\n",
      "989/1088, train_loss: 0.0266\n",
      "990/1088, train_loss: 0.0313\n",
      "991/1088, train_loss: 0.0258\n",
      "992/1088, train_loss: 0.0285\n",
      "993/1088, train_loss: 0.0298\n",
      "994/1088, train_loss: 0.0307\n",
      "995/1088, train_loss: 0.0286\n",
      "996/1088, train_loss: 0.0303\n",
      "997/1088, train_loss: 0.0306\n",
      "998/1088, train_loss: 0.0279\n",
      "999/1088, train_loss: 0.0299\n",
      "1000/1088, train_loss: 0.0295\n",
      "1001/1088, train_loss: 0.0301\n",
      "1002/1088, train_loss: 0.0279\n",
      "1003/1088, train_loss: 0.0259\n",
      "1004/1088, train_loss: 0.0277\n",
      "1005/1088, train_loss: 0.0285\n",
      "1006/1088, train_loss: 0.0272\n",
      "1007/1088, train_loss: 0.0256\n",
      "1008/1088, train_loss: 0.0296\n",
      "1009/1088, train_loss: 0.0272\n",
      "1010/1088, train_loss: 0.0289\n",
      "1011/1088, train_loss: 0.0289\n",
      "1012/1088, train_loss: 0.0291\n",
      "1013/1088, train_loss: 0.0299\n",
      "1014/1088, train_loss: 0.0290\n",
      "1015/1088, train_loss: 0.0271\n",
      "1016/1088, train_loss: 0.0270\n",
      "1017/1088, train_loss: 0.0291\n",
      "1018/1088, train_loss: 0.0264\n",
      "1019/1088, train_loss: 0.0344\n",
      "1020/1088, train_loss: 0.0331\n",
      "1021/1088, train_loss: 0.0274\n",
      "1022/1088, train_loss: 0.0270\n",
      "1023/1088, train_loss: 0.0261\n",
      "1024/1088, train_loss: 0.0288\n",
      "1025/1088, train_loss: 0.0276\n",
      "1026/1088, train_loss: 0.0290\n",
      "1027/1088, train_loss: 0.0283\n",
      "1028/1088, train_loss: 0.0273\n",
      "1029/1088, train_loss: 0.0286\n",
      "1030/1088, train_loss: 0.0287\n",
      "1031/1088, train_loss: 0.0285\n",
      "1032/1088, train_loss: 0.0274\n",
      "1033/1088, train_loss: 0.0307\n",
      "1034/1088, train_loss: 0.0312\n",
      "1035/1088, train_loss: 0.0299\n",
      "1036/1088, train_loss: 0.0270\n",
      "1037/1088, train_loss: 0.0269\n",
      "1038/1088, train_loss: 0.0298\n",
      "1039/1088, train_loss: 0.0295\n",
      "1040/1088, train_loss: 0.0283\n",
      "1041/1088, train_loss: 0.0280\n",
      "1042/1088, train_loss: 0.0273\n",
      "1043/1088, train_loss: 0.0248\n",
      "1044/1088, train_loss: 0.0270\n",
      "1045/1088, train_loss: 0.0269\n",
      "1046/1088, train_loss: 0.0280\n",
      "1047/1088, train_loss: 0.0292\n",
      "1048/1088, train_loss: 0.0324\n",
      "1049/1088, train_loss: 0.0292\n",
      "1050/1088, train_loss: 0.0280\n",
      "1051/1088, train_loss: 0.0285\n",
      "1052/1088, train_loss: 0.0293\n",
      "1053/1088, train_loss: 0.0299\n",
      "1054/1088, train_loss: 0.0259\n",
      "1055/1088, train_loss: 0.0273\n",
      "1056/1088, train_loss: 0.0275\n",
      "1057/1088, train_loss: 0.0262\n",
      "1058/1088, train_loss: 0.0272\n",
      "1059/1088, train_loss: 0.0264\n",
      "1060/1088, train_loss: 0.0344\n",
      "1061/1088, train_loss: 0.0295\n",
      "1062/1088, train_loss: 0.0273\n",
      "1063/1088, train_loss: 0.0274\n",
      "1064/1088, train_loss: 0.0274\n",
      "1065/1088, train_loss: 0.0289\n",
      "1066/1088, train_loss: 0.0285\n",
      "1067/1088, train_loss: 0.0277\n",
      "1068/1088, train_loss: 0.0288\n",
      "1069/1088, train_loss: 0.0272\n",
      "1070/1088, train_loss: 0.0302\n",
      "1071/1088, train_loss: 0.0288\n",
      "1072/1088, train_loss: 0.0305\n",
      "1073/1088, train_loss: 0.0273\n",
      "1074/1088, train_loss: 0.0302\n",
      "1075/1088, train_loss: 0.0299\n",
      "1076/1088, train_loss: 0.0274\n",
      "1077/1088, train_loss: 0.0271\n",
      "1078/1088, train_loss: 0.0287\n",
      "1079/1088, train_loss: 0.0278\n",
      "1080/1088, train_loss: 0.0266\n",
      "1081/1088, train_loss: 0.0272\n",
      "1082/1088, train_loss: 0.0268\n",
      "1083/1088, train_loss: 0.0277\n",
      "1084/1088, train_loss: 0.0293\n",
      "1085/1088, train_loss: 0.0276\n",
      "1086/1088, train_loss: 0.0306\n",
      "1087/1088, train_loss: 0.0298\n",
      "1088/1088, train_loss: 0.0277\n",
      "1089/1088, train_loss: 0.0289\n",
      "epoch 13 average loss: 0.0286, train_dice: 0.9715\n",
      "epoch 13 average loss: 0.0286\n",
      "--------------------------------------------------\n",
      "epoch 14/50\n",
      "1/1088, train_loss: 0.0299\n",
      "2/1088, train_loss: 0.0269\n",
      "3/1088, train_loss: 0.0281\n",
      "4/1088, train_loss: 0.0272\n",
      "5/1088, train_loss: 0.0320\n",
      "6/1088, train_loss: 0.0297\n",
      "7/1088, train_loss: 0.0291\n",
      "8/1088, train_loss: 0.0287\n",
      "9/1088, train_loss: 0.0334\n",
      "10/1088, train_loss: 0.0280\n",
      "11/1088, train_loss: 0.0268\n",
      "12/1088, train_loss: 0.0285\n",
      "13/1088, train_loss: 0.0267\n",
      "14/1088, train_loss: 0.0266\n",
      "15/1088, train_loss: 0.0290\n",
      "16/1088, train_loss: 0.0306\n",
      "17/1088, train_loss: 0.0322\n",
      "18/1088, train_loss: 0.0267\n",
      "19/1088, train_loss: 0.0279\n",
      "20/1088, train_loss: 0.0257\n",
      "21/1088, train_loss: 0.0283\n",
      "22/1088, train_loss: 0.0292\n",
      "23/1088, train_loss: 0.0286\n",
      "24/1088, train_loss: 0.0358\n",
      "25/1088, train_loss: 0.0258\n",
      "26/1088, train_loss: 0.0263\n",
      "27/1088, train_loss: 0.0319\n",
      "28/1088, train_loss: 0.0270\n",
      "29/1088, train_loss: 0.0295\n",
      "30/1088, train_loss: 0.0293\n",
      "31/1088, train_loss: 0.0266\n",
      "32/1088, train_loss: 0.0282\n",
      "33/1088, train_loss: 0.0280\n",
      "34/1088, train_loss: 0.0289\n",
      "35/1088, train_loss: 0.0291\n",
      "36/1088, train_loss: 0.0266\n",
      "37/1088, train_loss: 0.0283\n",
      "38/1088, train_loss: 0.0250\n",
      "39/1088, train_loss: 0.0265\n",
      "40/1088, train_loss: 0.0249\n",
      "41/1088, train_loss: 0.0293\n",
      "42/1088, train_loss: 0.0313\n",
      "43/1088, train_loss: 0.0264\n",
      "44/1088, train_loss: 0.0302\n",
      "45/1088, train_loss: 0.0301\n",
      "46/1088, train_loss: 0.0287\n",
      "47/1088, train_loss: 0.0274\n",
      "48/1088, train_loss: 0.0274\n",
      "49/1088, train_loss: 0.0265\n",
      "50/1088, train_loss: 0.0316\n",
      "51/1088, train_loss: 0.0312\n",
      "52/1088, train_loss: 0.0283\n",
      "53/1088, train_loss: 0.0283\n",
      "54/1088, train_loss: 0.0268\n",
      "55/1088, train_loss: 0.0261\n",
      "56/1088, train_loss: 0.0285\n",
      "57/1088, train_loss: 0.0277\n",
      "58/1088, train_loss: 0.0300\n",
      "59/1088, train_loss: 0.0300\n",
      "60/1088, train_loss: 0.0275\n",
      "61/1088, train_loss: 0.0289\n",
      "62/1088, train_loss: 0.0279\n",
      "63/1088, train_loss: 0.0307\n",
      "64/1088, train_loss: 0.0281\n",
      "65/1088, train_loss: 0.0291\n",
      "66/1088, train_loss: 0.0272\n",
      "67/1088, train_loss: 0.0287\n",
      "68/1088, train_loss: 0.0299\n",
      "69/1088, train_loss: 0.0262\n",
      "70/1088, train_loss: 0.0295\n",
      "71/1088, train_loss: 0.0294\n",
      "72/1088, train_loss: 0.0321\n",
      "73/1088, train_loss: 0.0290\n",
      "74/1088, train_loss: 0.0283\n",
      "75/1088, train_loss: 0.0282\n",
      "76/1088, train_loss: 0.0309\n",
      "77/1088, train_loss: 0.0280\n",
      "78/1088, train_loss: 0.0305\n",
      "79/1088, train_loss: 0.0241\n",
      "80/1088, train_loss: 0.0272\n",
      "81/1088, train_loss: 0.0277\n",
      "82/1088, train_loss: 0.0274\n",
      "83/1088, train_loss: 0.0262\n",
      "84/1088, train_loss: 0.0296\n",
      "85/1088, train_loss: 0.0289\n",
      "86/1088, train_loss: 0.0281\n",
      "87/1088, train_loss: 0.0270\n",
      "88/1088, train_loss: 0.0266\n",
      "89/1088, train_loss: 0.0288\n",
      "90/1088, train_loss: 0.0289\n",
      "91/1088, train_loss: 0.0302\n",
      "92/1088, train_loss: 0.0282\n",
      "93/1088, train_loss: 0.0287\n",
      "94/1088, train_loss: 0.0278\n",
      "95/1088, train_loss: 0.0280\n",
      "96/1088, train_loss: 0.0272\n",
      "97/1088, train_loss: 0.0286\n",
      "98/1088, train_loss: 0.0268\n",
      "99/1088, train_loss: 0.0280\n",
      "100/1088, train_loss: 0.0289\n",
      "101/1088, train_loss: 0.0290\n",
      "102/1088, train_loss: 0.0268\n",
      "103/1088, train_loss: 0.0336\n",
      "104/1088, train_loss: 0.0294\n",
      "105/1088, train_loss: 0.0269\n",
      "106/1088, train_loss: 0.0287\n",
      "107/1088, train_loss: 0.0273\n",
      "108/1088, train_loss: 0.0271\n",
      "109/1088, train_loss: 0.0303\n",
      "110/1088, train_loss: 0.0290\n",
      "111/1088, train_loss: 0.0290\n",
      "112/1088, train_loss: 0.0268\n",
      "113/1088, train_loss: 0.0287\n",
      "114/1088, train_loss: 0.0284\n",
      "115/1088, train_loss: 0.0280\n",
      "116/1088, train_loss: 0.0302\n",
      "117/1088, train_loss: 0.0257\n",
      "118/1088, train_loss: 0.0282\n",
      "119/1088, train_loss: 0.0292\n",
      "120/1088, train_loss: 0.0270\n",
      "121/1088, train_loss: 0.0286\n",
      "122/1088, train_loss: 0.0291\n",
      "123/1088, train_loss: 0.0278\n",
      "124/1088, train_loss: 0.0287\n",
      "125/1088, train_loss: 0.0286\n",
      "126/1088, train_loss: 0.0264\n",
      "127/1088, train_loss: 0.0276\n",
      "128/1088, train_loss: 0.0291\n",
      "129/1088, train_loss: 0.0294\n",
      "130/1088, train_loss: 0.0285\n",
      "131/1088, train_loss: 0.0274\n",
      "132/1088, train_loss: 0.0262\n",
      "133/1088, train_loss: 0.0282\n",
      "134/1088, train_loss: 0.0271\n",
      "135/1088, train_loss: 0.0272\n",
      "136/1088, train_loss: 0.0289\n",
      "137/1088, train_loss: 0.0260\n",
      "138/1088, train_loss: 0.0284\n",
      "139/1088, train_loss: 0.0302\n",
      "140/1088, train_loss: 0.0294\n",
      "141/1088, train_loss: 0.0291\n",
      "142/1088, train_loss: 0.0270\n",
      "143/1088, train_loss: 0.0267\n",
      "144/1088, train_loss: 0.0275\n",
      "145/1088, train_loss: 0.0304\n",
      "146/1088, train_loss: 0.0284\n",
      "147/1088, train_loss: 0.0253\n",
      "148/1088, train_loss: 0.0275\n",
      "149/1088, train_loss: 0.0274\n",
      "150/1088, train_loss: 0.0288\n",
      "151/1088, train_loss: 0.0289\n",
      "152/1088, train_loss: 0.0283\n",
      "153/1088, train_loss: 0.0280\n",
      "154/1088, train_loss: 0.0305\n",
      "155/1088, train_loss: 0.0303\n",
      "156/1088, train_loss: 0.0305\n",
      "157/1088, train_loss: 0.0291\n",
      "158/1088, train_loss: 0.0266\n",
      "159/1088, train_loss: 0.0303\n",
      "160/1088, train_loss: 0.0281\n",
      "161/1088, train_loss: 0.0274\n",
      "162/1088, train_loss: 0.0315\n",
      "163/1088, train_loss: 0.0270\n",
      "164/1088, train_loss: 0.0288\n",
      "165/1088, train_loss: 0.0289\n",
      "166/1088, train_loss: 0.0268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/1088, train_loss: 0.0294\n",
      "168/1088, train_loss: 0.0294\n",
      "169/1088, train_loss: 0.0281\n",
      "170/1088, train_loss: 0.0262\n",
      "171/1088, train_loss: 0.0284\n",
      "172/1088, train_loss: 0.0316\n",
      "173/1088, train_loss: 0.0271\n",
      "174/1088, train_loss: 0.0268\n",
      "175/1088, train_loss: 0.0276\n",
      "176/1088, train_loss: 0.0276\n",
      "177/1088, train_loss: 0.0271\n",
      "178/1088, train_loss: 0.0294\n",
      "179/1088, train_loss: 0.0273\n",
      "180/1088, train_loss: 0.0287\n",
      "181/1088, train_loss: 0.0279\n",
      "182/1088, train_loss: 0.0294\n",
      "183/1088, train_loss: 0.0284\n",
      "184/1088, train_loss: 0.0279\n",
      "185/1088, train_loss: 0.0264\n",
      "186/1088, train_loss: 0.0269\n",
      "187/1088, train_loss: 0.0278\n",
      "188/1088, train_loss: 0.0296\n",
      "189/1088, train_loss: 0.0260\n",
      "190/1088, train_loss: 0.0276\n",
      "191/1088, train_loss: 0.0284\n",
      "192/1088, train_loss: 0.0291\n",
      "193/1088, train_loss: 0.0279\n",
      "194/1088, train_loss: 0.0273\n",
      "195/1088, train_loss: 0.0282\n",
      "196/1088, train_loss: 0.0260\n",
      "197/1088, train_loss: 0.0268\n",
      "198/1088, train_loss: 0.0293\n",
      "199/1088, train_loss: 0.0289\n",
      "200/1088, train_loss: 0.0272\n",
      "201/1088, train_loss: 0.0296\n",
      "202/1088, train_loss: 0.0248\n",
      "203/1088, train_loss: 0.0294\n",
      "204/1088, train_loss: 0.0273\n",
      "205/1088, train_loss: 0.0281\n",
      "206/1088, train_loss: 0.0279\n",
      "207/1088, train_loss: 0.0277\n",
      "208/1088, train_loss: 0.0284\n",
      "209/1088, train_loss: 0.0274\n",
      "210/1088, train_loss: 0.0297\n",
      "211/1088, train_loss: 0.0266\n",
      "212/1088, train_loss: 0.0292\n",
      "213/1088, train_loss: 0.0275\n",
      "214/1088, train_loss: 0.0265\n",
      "215/1088, train_loss: 0.0280\n",
      "216/1088, train_loss: 0.0308\n",
      "217/1088, train_loss: 0.0274\n",
      "218/1088, train_loss: 0.0275\n",
      "219/1088, train_loss: 0.0296\n",
      "220/1088, train_loss: 0.0331\n",
      "221/1088, train_loss: 0.0267\n",
      "222/1088, train_loss: 0.0281\n",
      "223/1088, train_loss: 0.0290\n",
      "224/1088, train_loss: 0.0277\n",
      "225/1088, train_loss: 0.0273\n",
      "226/1088, train_loss: 0.0262\n",
      "227/1088, train_loss: 0.0256\n",
      "228/1088, train_loss: 0.0276\n",
      "229/1088, train_loss: 0.0291\n",
      "230/1088, train_loss: 0.0276\n",
      "231/1088, train_loss: 0.0284\n",
      "232/1088, train_loss: 0.0281\n",
      "233/1088, train_loss: 0.0289\n",
      "234/1088, train_loss: 0.0295\n",
      "235/1088, train_loss: 0.0294\n",
      "236/1088, train_loss: 0.0254\n",
      "237/1088, train_loss: 0.0302\n",
      "238/1088, train_loss: 0.0313\n",
      "239/1088, train_loss: 0.0279\n",
      "240/1088, train_loss: 0.0289\n",
      "241/1088, train_loss: 0.0302\n",
      "242/1088, train_loss: 0.0268\n",
      "243/1088, train_loss: 0.0256\n",
      "244/1088, train_loss: 0.0272\n",
      "245/1088, train_loss: 0.0276\n",
      "246/1088, train_loss: 0.0291\n",
      "247/1088, train_loss: 0.0279\n",
      "248/1088, train_loss: 0.0278\n",
      "249/1088, train_loss: 0.0324\n",
      "250/1088, train_loss: 0.0295\n",
      "251/1088, train_loss: 0.0303\n",
      "252/1088, train_loss: 0.0307\n",
      "253/1088, train_loss: 0.0281\n",
      "254/1088, train_loss: 0.0298\n",
      "255/1088, train_loss: 0.0266\n",
      "256/1088, train_loss: 0.0285\n",
      "257/1088, train_loss: 0.0292\n",
      "258/1088, train_loss: 0.0296\n",
      "259/1088, train_loss: 0.0297\n",
      "260/1088, train_loss: 0.0286\n",
      "261/1088, train_loss: 0.0269\n",
      "262/1088, train_loss: 0.0293\n",
      "263/1088, train_loss: 0.0299\n",
      "264/1088, train_loss: 0.0301\n",
      "265/1088, train_loss: 0.0284\n",
      "266/1088, train_loss: 0.0290\n",
      "267/1088, train_loss: 0.0274\n",
      "268/1088, train_loss: 0.0283\n",
      "269/1088, train_loss: 0.0245\n",
      "270/1088, train_loss: 0.0257\n",
      "271/1088, train_loss: 0.0287\n",
      "272/1088, train_loss: 0.0297\n",
      "273/1088, train_loss: 0.0287\n",
      "274/1088, train_loss: 0.0286\n",
      "275/1088, train_loss: 0.0263\n",
      "276/1088, train_loss: 0.0305\n",
      "277/1088, train_loss: 0.0269\n",
      "278/1088, train_loss: 0.0249\n",
      "279/1088, train_loss: 0.0282\n",
      "280/1088, train_loss: 0.0287\n",
      "281/1088, train_loss: 0.0275\n",
      "282/1088, train_loss: 0.0285\n",
      "283/1088, train_loss: 0.0275\n",
      "284/1088, train_loss: 0.0285\n",
      "285/1088, train_loss: 0.0292\n",
      "286/1088, train_loss: 0.0307\n",
      "287/1088, train_loss: 0.0277\n",
      "288/1088, train_loss: 0.0306\n",
      "289/1088, train_loss: 0.0272\n",
      "290/1088, train_loss: 0.0275\n",
      "291/1088, train_loss: 0.0276\n",
      "292/1088, train_loss: 0.0284\n",
      "293/1088, train_loss: 0.0286\n",
      "294/1088, train_loss: 0.0266\n",
      "295/1088, train_loss: 0.0273\n",
      "296/1088, train_loss: 0.0281\n",
      "297/1088, train_loss: 0.0277\n",
      "298/1088, train_loss: 0.0286\n",
      "299/1088, train_loss: 0.0257\n",
      "300/1088, train_loss: 0.0367\n",
      "301/1088, train_loss: 0.0295\n",
      "302/1088, train_loss: 0.0255\n",
      "303/1088, train_loss: 0.0283\n",
      "304/1088, train_loss: 0.0279\n",
      "305/1088, train_loss: 0.0287\n",
      "306/1088, train_loss: 0.0271\n",
      "307/1088, train_loss: 0.0295\n",
      "308/1088, train_loss: 0.0273\n",
      "309/1088, train_loss: 0.0263\n",
      "310/1088, train_loss: 0.0263\n",
      "311/1088, train_loss: 0.0275\n",
      "312/1088, train_loss: 0.0276\n",
      "313/1088, train_loss: 0.0290\n",
      "314/1088, train_loss: 0.0268\n",
      "315/1088, train_loss: 0.0278\n",
      "316/1088, train_loss: 0.0291\n",
      "317/1088, train_loss: 0.0283\n",
      "318/1088, train_loss: 0.0265\n",
      "319/1088, train_loss: 0.0274\n",
      "320/1088, train_loss: 0.0269\n",
      "321/1088, train_loss: 0.0291\n",
      "322/1088, train_loss: 0.0268\n",
      "323/1088, train_loss: 0.0295\n",
      "324/1088, train_loss: 0.0284\n",
      "325/1088, train_loss: 0.0261\n",
      "326/1088, train_loss: 0.0251\n",
      "327/1088, train_loss: 0.0289\n",
      "328/1088, train_loss: 0.0271\n",
      "329/1088, train_loss: 0.0302\n",
      "330/1088, train_loss: 0.0282\n",
      "331/1088, train_loss: 0.0284\n",
      "332/1088, train_loss: 0.0290\n",
      "333/1088, train_loss: 0.0260\n",
      "334/1088, train_loss: 0.0263\n",
      "335/1088, train_loss: 0.0262\n",
      "336/1088, train_loss: 0.0272\n",
      "337/1088, train_loss: 0.0313\n",
      "338/1088, train_loss: 0.0281\n",
      "339/1088, train_loss: 0.0291\n",
      "340/1088, train_loss: 0.0286\n",
      "341/1088, train_loss: 0.0288\n",
      "342/1088, train_loss: 0.0296\n",
      "343/1088, train_loss: 0.0263\n",
      "344/1088, train_loss: 0.0302\n",
      "345/1088, train_loss: 0.0302\n",
      "346/1088, train_loss: 0.0269\n",
      "347/1088, train_loss: 0.0258\n",
      "348/1088, train_loss: 0.0301\n",
      "349/1088, train_loss: 0.0281\n",
      "350/1088, train_loss: 0.0261\n",
      "351/1088, train_loss: 0.0284\n",
      "352/1088, train_loss: 0.0273\n",
      "353/1088, train_loss: 0.0291\n",
      "354/1088, train_loss: 0.0271\n",
      "355/1088, train_loss: 0.0281\n",
      "356/1088, train_loss: 0.0311\n",
      "357/1088, train_loss: 0.0270\n",
      "358/1088, train_loss: 0.0274\n",
      "359/1088, train_loss: 0.0296\n",
      "360/1088, train_loss: 0.0305\n",
      "361/1088, train_loss: 0.0275\n",
      "362/1088, train_loss: 0.0271\n",
      "363/1088, train_loss: 0.0282\n",
      "364/1088, train_loss: 0.0274\n",
      "365/1088, train_loss: 0.0271\n",
      "366/1088, train_loss: 0.0258\n",
      "367/1088, train_loss: 0.0289\n",
      "368/1088, train_loss: 0.0277\n",
      "369/1088, train_loss: 0.0308\n",
      "370/1088, train_loss: 0.0277\n",
      "371/1088, train_loss: 0.0282\n",
      "372/1088, train_loss: 0.0284\n",
      "373/1088, train_loss: 0.0296\n",
      "374/1088, train_loss: 0.0260\n",
      "375/1088, train_loss: 0.0278\n",
      "376/1088, train_loss: 0.0269\n",
      "377/1088, train_loss: 0.0283\n",
      "378/1088, train_loss: 0.0265\n",
      "379/1088, train_loss: 0.0262\n",
      "380/1088, train_loss: 0.0279\n",
      "381/1088, train_loss: 0.0258\n",
      "382/1088, train_loss: 0.0280\n",
      "383/1088, train_loss: 0.0277\n",
      "384/1088, train_loss: 0.0286\n",
      "385/1088, train_loss: 0.0304\n",
      "386/1088, train_loss: 0.0284\n",
      "387/1088, train_loss: 0.0253\n",
      "388/1088, train_loss: 0.0268\n",
      "389/1088, train_loss: 0.0295\n",
      "390/1088, train_loss: 0.0297\n",
      "391/1088, train_loss: 0.0270\n",
      "392/1088, train_loss: 0.0290\n",
      "393/1088, train_loss: 0.0265\n",
      "394/1088, train_loss: 0.0255\n",
      "395/1088, train_loss: 0.0288\n",
      "396/1088, train_loss: 0.0274\n",
      "397/1088, train_loss: 0.0322\n",
      "398/1088, train_loss: 0.0266\n",
      "399/1088, train_loss: 0.0275\n",
      "400/1088, train_loss: 0.0291\n",
      "401/1088, train_loss: 0.0286\n",
      "402/1088, train_loss: 0.0293\n",
      "403/1088, train_loss: 0.0265\n",
      "404/1088, train_loss: 0.0276\n",
      "405/1088, train_loss: 0.0283\n",
      "406/1088, train_loss: 0.0258\n",
      "407/1088, train_loss: 0.0270\n",
      "408/1088, train_loss: 0.0263\n",
      "409/1088, train_loss: 0.0294\n",
      "410/1088, train_loss: 0.0255\n",
      "411/1088, train_loss: 0.0293\n",
      "412/1088, train_loss: 0.0279\n",
      "413/1088, train_loss: 0.0272\n",
      "414/1088, train_loss: 0.0275\n",
      "415/1088, train_loss: 0.0296\n",
      "416/1088, train_loss: 0.0293\n",
      "417/1088, train_loss: 0.0325\n",
      "418/1088, train_loss: 0.0285\n",
      "419/1088, train_loss: 0.0283\n",
      "420/1088, train_loss: 0.0290\n",
      "421/1088, train_loss: 0.0283\n",
      "422/1088, train_loss: 0.0284\n",
      "423/1088, train_loss: 0.0303\n",
      "424/1088, train_loss: 0.0274\n",
      "425/1088, train_loss: 0.0263\n",
      "426/1088, train_loss: 0.0272\n",
      "427/1088, train_loss: 0.0286\n",
      "428/1088, train_loss: 0.0272\n",
      "429/1088, train_loss: 0.0261\n",
      "430/1088, train_loss: 0.0296\n",
      "431/1088, train_loss: 0.0286\n",
      "432/1088, train_loss: 0.0289\n",
      "433/1088, train_loss: 0.0288\n",
      "434/1088, train_loss: 0.0322\n",
      "435/1088, train_loss: 0.0369\n",
      "436/1088, train_loss: 0.0274\n",
      "437/1088, train_loss: 0.0292\n",
      "438/1088, train_loss: 0.0288\n",
      "439/1088, train_loss: 0.0290\n",
      "440/1088, train_loss: 0.0278\n",
      "441/1088, train_loss: 0.0279\n",
      "442/1088, train_loss: 0.0272\n",
      "443/1088, train_loss: 0.0259\n",
      "444/1088, train_loss: 0.0278\n",
      "445/1088, train_loss: 0.0262\n",
      "446/1088, train_loss: 0.0253\n",
      "447/1088, train_loss: 0.0272\n",
      "448/1088, train_loss: 0.0249\n",
      "449/1088, train_loss: 0.0280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/1088, train_loss: 0.0275\n",
      "451/1088, train_loss: 0.0330\n",
      "452/1088, train_loss: 0.0276\n",
      "453/1088, train_loss: 0.0274\n",
      "454/1088, train_loss: 0.0280\n",
      "455/1088, train_loss: 0.0280\n",
      "456/1088, train_loss: 0.0299\n",
      "457/1088, train_loss: 0.0274\n",
      "458/1088, train_loss: 0.0278\n",
      "459/1088, train_loss: 0.0291\n",
      "460/1088, train_loss: 0.0283\n",
      "461/1088, train_loss: 0.0287\n",
      "462/1088, train_loss: 0.0291\n",
      "463/1088, train_loss: 0.0278\n",
      "464/1088, train_loss: 0.0285\n",
      "465/1088, train_loss: 0.0275\n",
      "466/1088, train_loss: 0.0295\n",
      "467/1088, train_loss: 0.0271\n",
      "468/1088, train_loss: 0.0305\n",
      "469/1088, train_loss: 0.0306\n",
      "470/1088, train_loss: 0.0281\n",
      "471/1088, train_loss: 0.0255\n",
      "472/1088, train_loss: 0.0280\n",
      "473/1088, train_loss: 0.0287\n",
      "474/1088, train_loss: 0.0284\n",
      "475/1088, train_loss: 0.0300\n",
      "476/1088, train_loss: 0.0291\n",
      "477/1088, train_loss: 0.0270\n",
      "478/1088, train_loss: 0.0277\n",
      "479/1088, train_loss: 0.0267\n",
      "480/1088, train_loss: 0.0290\n",
      "481/1088, train_loss: 0.0282\n",
      "482/1088, train_loss: 0.0275\n",
      "483/1088, train_loss: 0.0284\n",
      "484/1088, train_loss: 0.0268\n",
      "485/1088, train_loss: 0.0274\n",
      "486/1088, train_loss: 0.0284\n",
      "487/1088, train_loss: 0.0277\n",
      "488/1088, train_loss: 0.0304\n",
      "489/1088, train_loss: 0.0259\n",
      "490/1088, train_loss: 0.0343\n",
      "491/1088, train_loss: 0.0268\n",
      "492/1088, train_loss: 0.0265\n",
      "493/1088, train_loss: 0.0283\n",
      "494/1088, train_loss: 0.0273\n",
      "495/1088, train_loss: 0.0285\n",
      "496/1088, train_loss: 0.0304\n",
      "497/1088, train_loss: 0.0298\n",
      "498/1088, train_loss: 0.0290\n",
      "499/1088, train_loss: 0.0274\n",
      "500/1088, train_loss: 0.0293\n",
      "501/1088, train_loss: 0.0271\n",
      "502/1088, train_loss: 0.0274\n",
      "503/1088, train_loss: 0.0286\n",
      "504/1088, train_loss: 0.0276\n",
      "505/1088, train_loss: 0.0341\n",
      "506/1088, train_loss: 0.0265\n",
      "507/1088, train_loss: 0.0287\n",
      "508/1088, train_loss: 0.0262\n",
      "509/1088, train_loss: 0.0275\n",
      "510/1088, train_loss: 0.0278\n",
      "511/1088, train_loss: 0.0273\n",
      "512/1088, train_loss: 0.0287\n",
      "513/1088, train_loss: 0.0269\n",
      "514/1088, train_loss: 0.0284\n",
      "515/1088, train_loss: 0.0272\n",
      "516/1088, train_loss: 0.0290\n",
      "517/1088, train_loss: 0.0289\n",
      "518/1088, train_loss: 0.0289\n",
      "519/1088, train_loss: 0.0292\n",
      "520/1088, train_loss: 0.0274\n",
      "521/1088, train_loss: 0.0290\n",
      "522/1088, train_loss: 0.0288\n",
      "523/1088, train_loss: 0.0262\n",
      "524/1088, train_loss: 0.0276\n",
      "525/1088, train_loss: 0.0282\n",
      "526/1088, train_loss: 0.0270\n",
      "527/1088, train_loss: 0.0281\n",
      "528/1088, train_loss: 0.0292\n",
      "529/1088, train_loss: 0.0287\n",
      "530/1088, train_loss: 0.0272\n",
      "531/1088, train_loss: 0.0275\n",
      "532/1088, train_loss: 0.0273\n",
      "533/1088, train_loss: 0.0270\n",
      "534/1088, train_loss: 0.0278\n",
      "535/1088, train_loss: 0.0266\n",
      "536/1088, train_loss: 0.0294\n",
      "537/1088, train_loss: 0.0270\n",
      "538/1088, train_loss: 0.0282\n",
      "539/1088, train_loss: 0.0283\n",
      "540/1088, train_loss: 0.0270\n",
      "541/1088, train_loss: 0.0270\n",
      "542/1088, train_loss: 0.0308\n",
      "543/1088, train_loss: 0.0264\n",
      "544/1088, train_loss: 0.0300\n",
      "545/1088, train_loss: 0.0258\n",
      "546/1088, train_loss: 0.0298\n",
      "547/1088, train_loss: 0.0306\n",
      "548/1088, train_loss: 0.0276\n",
      "549/1088, train_loss: 0.0267\n",
      "550/1088, train_loss: 0.0285\n",
      "551/1088, train_loss: 0.0303\n",
      "552/1088, train_loss: 0.0256\n",
      "553/1088, train_loss: 0.0266\n",
      "554/1088, train_loss: 0.0257\n",
      "555/1088, train_loss: 0.0291\n",
      "556/1088, train_loss: 0.0283\n",
      "557/1088, train_loss: 0.0280\n",
      "558/1088, train_loss: 0.0303\n",
      "559/1088, train_loss: 0.0292\n",
      "560/1088, train_loss: 0.0268\n",
      "561/1088, train_loss: 0.0280\n",
      "562/1088, train_loss: 0.0301\n",
      "563/1088, train_loss: 0.0276\n",
      "564/1088, train_loss: 0.0304\n",
      "565/1088, train_loss: 0.0266\n",
      "566/1088, train_loss: 0.0294\n",
      "567/1088, train_loss: 0.0294\n",
      "568/1088, train_loss: 0.0298\n",
      "569/1088, train_loss: 0.0264\n",
      "570/1088, train_loss: 0.0275\n",
      "571/1088, train_loss: 0.0268\n",
      "572/1088, train_loss: 0.0264\n",
      "573/1088, train_loss: 0.0272\n",
      "574/1088, train_loss: 0.0261\n",
      "575/1088, train_loss: 0.0275\n",
      "576/1088, train_loss: 0.0296\n",
      "577/1088, train_loss: 0.0303\n",
      "578/1088, train_loss: 0.0287\n",
      "579/1088, train_loss: 0.0259\n",
      "580/1088, train_loss: 0.0274\n",
      "581/1088, train_loss: 0.0305\n",
      "582/1088, train_loss: 0.0296\n",
      "583/1088, train_loss: 0.0286\n",
      "584/1088, train_loss: 0.0269\n",
      "585/1088, train_loss: 0.0262\n",
      "586/1088, train_loss: 0.0360\n",
      "587/1088, train_loss: 0.0275\n",
      "588/1088, train_loss: 0.0291\n",
      "589/1088, train_loss: 0.0285\n",
      "590/1088, train_loss: 0.0290\n",
      "591/1088, train_loss: 0.0258\n",
      "592/1088, train_loss: 0.0297\n",
      "593/1088, train_loss: 0.0303\n",
      "594/1088, train_loss: 0.0278\n",
      "595/1088, train_loss: 0.0262\n",
      "596/1088, train_loss: 0.0269\n",
      "597/1088, train_loss: 0.0330\n",
      "598/1088, train_loss: 0.0279\n",
      "599/1088, train_loss: 0.0323\n",
      "600/1088, train_loss: 0.0308\n",
      "601/1088, train_loss: 0.0316\n",
      "602/1088, train_loss: 0.0290\n",
      "603/1088, train_loss: 0.0280\n",
      "604/1088, train_loss: 0.0303\n",
      "605/1088, train_loss: 0.0289\n",
      "606/1088, train_loss: 0.0286\n",
      "607/1088, train_loss: 0.0286\n",
      "608/1088, train_loss: 0.0276\n",
      "609/1088, train_loss: 0.0282\n",
      "610/1088, train_loss: 0.0264\n",
      "611/1088, train_loss: 0.0282\n",
      "612/1088, train_loss: 0.0292\n",
      "613/1088, train_loss: 0.0296\n",
      "614/1088, train_loss: 0.0277\n",
      "615/1088, train_loss: 0.0269\n",
      "616/1088, train_loss: 0.0272\n",
      "617/1088, train_loss: 0.0283\n",
      "618/1088, train_loss: 0.0282\n",
      "619/1088, train_loss: 0.0283\n",
      "620/1088, train_loss: 0.0279\n",
      "621/1088, train_loss: 0.0302\n",
      "622/1088, train_loss: 0.0268\n",
      "623/1088, train_loss: 0.0307\n",
      "624/1088, train_loss: 0.0288\n",
      "625/1088, train_loss: 0.0274\n",
      "626/1088, train_loss: 0.0278\n",
      "627/1088, train_loss: 0.0319\n",
      "628/1088, train_loss: 0.0250\n",
      "629/1088, train_loss: 0.0314\n",
      "630/1088, train_loss: 0.0294\n",
      "631/1088, train_loss: 0.0279\n",
      "632/1088, train_loss: 0.0305\n",
      "633/1088, train_loss: 0.0275\n",
      "634/1088, train_loss: 0.0272\n",
      "635/1088, train_loss: 0.0305\n",
      "636/1088, train_loss: 0.0270\n",
      "637/1088, train_loss: 0.0290\n",
      "638/1088, train_loss: 0.0281\n",
      "639/1088, train_loss: 0.0292\n",
      "640/1088, train_loss: 0.0298\n",
      "641/1088, train_loss: 0.0288\n",
      "642/1088, train_loss: 0.0302\n",
      "643/1088, train_loss: 0.0301\n",
      "644/1088, train_loss: 0.0301\n",
      "645/1088, train_loss: 0.0303\n",
      "646/1088, train_loss: 0.0268\n",
      "647/1088, train_loss: 0.0291\n",
      "648/1088, train_loss: 0.0278\n",
      "649/1088, train_loss: 0.0291\n",
      "650/1088, train_loss: 0.0279\n",
      "651/1088, train_loss: 0.0288\n",
      "652/1088, train_loss: 0.0264\n",
      "653/1088, train_loss: 0.0277\n",
      "654/1088, train_loss: 0.0284\n",
      "655/1088, train_loss: 0.0268\n",
      "656/1088, train_loss: 0.0285\n",
      "657/1088, train_loss: 0.0276\n",
      "658/1088, train_loss: 0.0299\n",
      "659/1088, train_loss: 0.0297\n",
      "660/1088, train_loss: 0.0278\n",
      "661/1088, train_loss: 0.0257\n",
      "662/1088, train_loss: 0.0264\n",
      "663/1088, train_loss: 0.0278\n",
      "664/1088, train_loss: 0.0283\n",
      "665/1088, train_loss: 0.0272\n",
      "666/1088, train_loss: 0.0301\n",
      "667/1088, train_loss: 0.0313\n",
      "668/1088, train_loss: 0.0284\n",
      "669/1088, train_loss: 0.0278\n",
      "670/1088, train_loss: 0.0298\n",
      "671/1088, train_loss: 0.0293\n",
      "672/1088, train_loss: 0.0277\n",
      "673/1088, train_loss: 0.0287\n",
      "674/1088, train_loss: 0.0261\n",
      "675/1088, train_loss: 0.0271\n",
      "676/1088, train_loss: 0.0279\n",
      "677/1088, train_loss: 0.0268\n",
      "678/1088, train_loss: 0.0286\n",
      "679/1088, train_loss: 0.0296\n",
      "680/1088, train_loss: 0.0279\n",
      "681/1088, train_loss: 0.0350\n",
      "682/1088, train_loss: 0.0271\n",
      "683/1088, train_loss: 0.0303\n",
      "684/1088, train_loss: 0.0258\n",
      "685/1088, train_loss: 0.0340\n",
      "686/1088, train_loss: 0.0270\n",
      "687/1088, train_loss: 0.0267\n",
      "688/1088, train_loss: 0.0272\n",
      "689/1088, train_loss: 0.0259\n",
      "690/1088, train_loss: 0.0279\n",
      "691/1088, train_loss: 0.0290\n",
      "692/1088, train_loss: 0.0281\n",
      "693/1088, train_loss: 0.0269\n",
      "694/1088, train_loss: 0.0298\n",
      "695/1088, train_loss: 0.0280\n",
      "696/1088, train_loss: 0.0279\n",
      "697/1088, train_loss: 0.0274\n",
      "698/1088, train_loss: 0.0273\n",
      "699/1088, train_loss: 0.0277\n",
      "700/1088, train_loss: 0.0309\n",
      "701/1088, train_loss: 0.0288\n",
      "702/1088, train_loss: 0.0289\n",
      "703/1088, train_loss: 0.0269\n",
      "704/1088, train_loss: 0.0263\n",
      "705/1088, train_loss: 0.0421\n",
      "706/1088, train_loss: 0.0286\n",
      "707/1088, train_loss: 0.0289\n",
      "708/1088, train_loss: 0.0290\n",
      "709/1088, train_loss: 0.0263\n",
      "710/1088, train_loss: 0.0284\n",
      "711/1088, train_loss: 0.0268\n",
      "712/1088, train_loss: 0.0315\n",
      "713/1088, train_loss: 0.0286\n",
      "714/1088, train_loss: 0.0288\n",
      "715/1088, train_loss: 0.0307\n",
      "716/1088, train_loss: 0.0290\n",
      "717/1088, train_loss: 0.0272\n",
      "718/1088, train_loss: 0.0298\n",
      "719/1088, train_loss: 0.0279\n",
      "720/1088, train_loss: 0.0286\n",
      "721/1088, train_loss: 0.0295\n",
      "722/1088, train_loss: 0.0269\n",
      "723/1088, train_loss: 0.0273\n",
      "724/1088, train_loss: 0.0294\n",
      "725/1088, train_loss: 0.0313\n",
      "726/1088, train_loss: 0.0296\n",
      "727/1088, train_loss: 0.0310\n",
      "728/1088, train_loss: 0.0267\n",
      "729/1088, train_loss: 0.0284\n",
      "730/1088, train_loss: 0.0272\n",
      "731/1088, train_loss: 0.0287\n",
      "732/1088, train_loss: 0.0299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733/1088, train_loss: 0.0297\n",
      "734/1088, train_loss: 0.0260\n",
      "735/1088, train_loss: 0.0296\n",
      "736/1088, train_loss: 0.0305\n",
      "737/1088, train_loss: 0.0288\n",
      "738/1088, train_loss: 0.0297\n",
      "739/1088, train_loss: 0.0297\n",
      "740/1088, train_loss: 0.0284\n",
      "741/1088, train_loss: 0.0277\n",
      "742/1088, train_loss: 0.0276\n",
      "743/1088, train_loss: 0.0283\n",
      "744/1088, train_loss: 0.0286\n",
      "745/1088, train_loss: 0.0278\n",
      "746/1088, train_loss: 0.0293\n",
      "747/1088, train_loss: 0.0303\n",
      "748/1088, train_loss: 0.0269\n",
      "749/1088, train_loss: 0.0260\n",
      "750/1088, train_loss: 0.0302\n",
      "751/1088, train_loss: 0.0281\n",
      "752/1088, train_loss: 0.0320\n",
      "753/1088, train_loss: 0.0271\n",
      "754/1088, train_loss: 0.0302\n",
      "755/1088, train_loss: 0.0296\n",
      "756/1088, train_loss: 0.0289\n",
      "757/1088, train_loss: 0.0295\n",
      "758/1088, train_loss: 0.0311\n",
      "759/1088, train_loss: 0.0280\n",
      "760/1088, train_loss: 0.0288\n",
      "761/1088, train_loss: 0.0291\n",
      "762/1088, train_loss: 0.0290\n",
      "763/1088, train_loss: 0.0290\n",
      "764/1088, train_loss: 0.0271\n",
      "765/1088, train_loss: 0.0301\n",
      "766/1088, train_loss: 0.0303\n",
      "767/1088, train_loss: 0.0278\n",
      "768/1088, train_loss: 0.0280\n",
      "769/1088, train_loss: 0.0296\n",
      "770/1088, train_loss: 0.0264\n",
      "771/1088, train_loss: 0.0278\n",
      "772/1088, train_loss: 0.0340\n",
      "773/1088, train_loss: 0.0301\n",
      "774/1088, train_loss: 0.0305\n",
      "775/1088, train_loss: 0.0294\n",
      "776/1088, train_loss: 0.0280\n",
      "777/1088, train_loss: 0.0289\n",
      "778/1088, train_loss: 0.0281\n",
      "779/1088, train_loss: 0.0281\n",
      "780/1088, train_loss: 0.0268\n",
      "781/1088, train_loss: 0.0297\n",
      "782/1088, train_loss: 0.0273\n",
      "783/1088, train_loss: 0.0291\n",
      "784/1088, train_loss: 0.0283\n",
      "785/1088, train_loss: 0.0268\n",
      "786/1088, train_loss: 0.0278\n",
      "787/1088, train_loss: 0.0293\n",
      "788/1088, train_loss: 0.0277\n",
      "789/1088, train_loss: 0.0293\n",
      "790/1088, train_loss: 0.0292\n",
      "791/1088, train_loss: 0.0295\n",
      "792/1088, train_loss: 0.0280\n",
      "793/1088, train_loss: 0.0277\n",
      "794/1088, train_loss: 0.0264\n",
      "795/1088, train_loss: 0.0307\n",
      "796/1088, train_loss: 0.0287\n",
      "797/1088, train_loss: 0.0282\n",
      "798/1088, train_loss: 0.0301\n",
      "799/1088, train_loss: 0.0318\n",
      "800/1088, train_loss: 0.0295\n",
      "801/1088, train_loss: 0.0307\n",
      "802/1088, train_loss: 0.0305\n",
      "803/1088, train_loss: 0.0294\n",
      "804/1088, train_loss: 0.0290\n",
      "805/1088, train_loss: 0.0277\n",
      "806/1088, train_loss: 0.0278\n",
      "807/1088, train_loss: 0.0283\n",
      "808/1088, train_loss: 0.0304\n",
      "809/1088, train_loss: 0.0294\n",
      "810/1088, train_loss: 0.0295\n",
      "811/1088, train_loss: 0.0275\n",
      "812/1088, train_loss: 0.0264\n",
      "813/1088, train_loss: 0.0268\n",
      "814/1088, train_loss: 0.0302\n",
      "815/1088, train_loss: 0.0292\n",
      "816/1088, train_loss: 0.0281\n",
      "817/1088, train_loss: 0.0303\n",
      "818/1088, train_loss: 0.0277\n",
      "819/1088, train_loss: 0.0292\n",
      "820/1088, train_loss: 0.0286\n",
      "821/1088, train_loss: 0.0261\n",
      "822/1088, train_loss: 0.0313\n",
      "823/1088, train_loss: 0.0298\n",
      "824/1088, train_loss: 0.0293\n",
      "825/1088, train_loss: 0.0256\n",
      "826/1088, train_loss: 0.0296\n",
      "827/1088, train_loss: 0.0281\n",
      "828/1088, train_loss: 0.0289\n",
      "829/1088, train_loss: 0.0295\n",
      "830/1088, train_loss: 0.0280\n",
      "831/1088, train_loss: 0.0266\n",
      "832/1088, train_loss: 0.0289\n",
      "833/1088, train_loss: 0.0305\n",
      "834/1088, train_loss: 0.0273\n",
      "835/1088, train_loss: 0.0283\n",
      "836/1088, train_loss: 0.0281\n",
      "837/1088, train_loss: 0.0300\n",
      "838/1088, train_loss: 0.0276\n",
      "839/1088, train_loss: 0.0294\n",
      "840/1088, train_loss: 0.0271\n",
      "841/1088, train_loss: 0.0278\n",
      "842/1088, train_loss: 0.0289\n",
      "843/1088, train_loss: 0.0299\n",
      "844/1088, train_loss: 0.0261\n",
      "845/1088, train_loss: 0.0299\n",
      "846/1088, train_loss: 0.0280\n",
      "847/1088, train_loss: 0.0288\n",
      "848/1088, train_loss: 0.0292\n",
      "849/1088, train_loss: 0.0288\n",
      "850/1088, train_loss: 0.0277\n",
      "851/1088, train_loss: 0.0284\n",
      "852/1088, train_loss: 0.0306\n",
      "853/1088, train_loss: 0.0303\n",
      "854/1088, train_loss: 0.0295\n",
      "855/1088, train_loss: 0.0294\n",
      "856/1088, train_loss: 0.0300\n",
      "857/1088, train_loss: 0.0273\n",
      "858/1088, train_loss: 0.0267\n",
      "859/1088, train_loss: 0.0283\n",
      "860/1088, train_loss: 0.0270\n",
      "861/1088, train_loss: 0.0298\n",
      "862/1088, train_loss: 0.0313\n",
      "863/1088, train_loss: 0.0285\n",
      "864/1088, train_loss: 0.0284\n",
      "865/1088, train_loss: 0.0324\n",
      "866/1088, train_loss: 0.0291\n",
      "867/1088, train_loss: 0.0264\n",
      "868/1088, train_loss: 0.0292\n",
      "869/1088, train_loss: 0.0306\n",
      "870/1088, train_loss: 0.0294\n",
      "871/1088, train_loss: 0.0287\n",
      "872/1088, train_loss: 0.0267\n",
      "873/1088, train_loss: 0.0289\n",
      "874/1088, train_loss: 0.0311\n",
      "875/1088, train_loss: 0.0267\n",
      "876/1088, train_loss: 0.0267\n",
      "877/1088, train_loss: 0.0298\n",
      "878/1088, train_loss: 0.0283\n",
      "879/1088, train_loss: 0.0268\n",
      "880/1088, train_loss: 0.0287\n",
      "881/1088, train_loss: 0.0277\n",
      "882/1088, train_loss: 0.0304\n",
      "883/1088, train_loss: 0.0290\n",
      "884/1088, train_loss: 0.0309\n",
      "885/1088, train_loss: 0.0264\n",
      "886/1088, train_loss: 0.0269\n",
      "887/1088, train_loss: 0.0293\n",
      "888/1088, train_loss: 0.0280\n",
      "889/1088, train_loss: 0.0267\n",
      "890/1088, train_loss: 0.0336\n",
      "891/1088, train_loss: 0.0345\n",
      "892/1088, train_loss: 0.0274\n",
      "893/1088, train_loss: 0.0270\n",
      "894/1088, train_loss: 0.0282\n",
      "895/1088, train_loss: 0.0277\n",
      "896/1088, train_loss: 0.0296\n",
      "897/1088, train_loss: 0.0266\n",
      "898/1088, train_loss: 0.0273\n",
      "899/1088, train_loss: 0.0276\n",
      "900/1088, train_loss: 0.0274\n",
      "901/1088, train_loss: 0.0286\n",
      "902/1088, train_loss: 0.0288\n",
      "903/1088, train_loss: 0.0266\n",
      "904/1088, train_loss: 0.0280\n",
      "905/1088, train_loss: 0.0288\n",
      "906/1088, train_loss: 0.0296\n",
      "907/1088, train_loss: 0.0285\n",
      "908/1088, train_loss: 0.0269\n",
      "909/1088, train_loss: 0.0287\n",
      "910/1088, train_loss: 0.0248\n",
      "911/1088, train_loss: 0.0287\n",
      "912/1088, train_loss: 0.0280\n",
      "913/1088, train_loss: 0.0282\n",
      "914/1088, train_loss: 0.0266\n",
      "915/1088, train_loss: 0.0270\n",
      "916/1088, train_loss: 0.0265\n",
      "917/1088, train_loss: 0.0291\n",
      "918/1088, train_loss: 0.0300\n",
      "919/1088, train_loss: 0.0274\n",
      "920/1088, train_loss: 0.0268\n",
      "921/1088, train_loss: 0.0299\n",
      "922/1088, train_loss: 0.0274\n",
      "923/1088, train_loss: 0.0292\n",
      "924/1088, train_loss: 0.0267\n",
      "925/1088, train_loss: 0.0271\n",
      "926/1088, train_loss: 0.0277\n",
      "927/1088, train_loss: 0.0302\n",
      "928/1088, train_loss: 0.0261\n",
      "929/1088, train_loss: 0.0283\n",
      "930/1088, train_loss: 0.0288\n",
      "931/1088, train_loss: 0.0277\n",
      "932/1088, train_loss: 0.0275\n",
      "933/1088, train_loss: 0.0275\n",
      "934/1088, train_loss: 0.0299\n",
      "935/1088, train_loss: 0.0312\n",
      "936/1088, train_loss: 0.0275\n",
      "937/1088, train_loss: 0.0300\n",
      "938/1088, train_loss: 0.0309\n",
      "939/1088, train_loss: 0.0284\n",
      "940/1088, train_loss: 0.0269\n",
      "941/1088, train_loss: 0.0272\n",
      "942/1088, train_loss: 0.0292\n",
      "943/1088, train_loss: 0.0262\n",
      "944/1088, train_loss: 0.0282\n",
      "945/1088, train_loss: 0.0263\n",
      "946/1088, train_loss: 0.0267\n",
      "947/1088, train_loss: 0.0278\n",
      "948/1088, train_loss: 0.0286\n",
      "949/1088, train_loss: 0.0298\n",
      "950/1088, train_loss: 0.0280\n",
      "951/1088, train_loss: 0.0277\n",
      "952/1088, train_loss: 0.0272\n",
      "953/1088, train_loss: 0.0251\n",
      "954/1088, train_loss: 0.0284\n",
      "955/1088, train_loss: 0.0269\n",
      "956/1088, train_loss: 0.0254\n",
      "957/1088, train_loss: 0.0366\n",
      "958/1088, train_loss: 0.0294\n",
      "959/1088, train_loss: 0.0310\n",
      "960/1088, train_loss: 0.0310\n",
      "961/1088, train_loss: 0.0285\n",
      "962/1088, train_loss: 0.0259\n",
      "963/1088, train_loss: 0.0276\n",
      "964/1088, train_loss: 0.0272\n",
      "965/1088, train_loss: 0.0257\n",
      "966/1088, train_loss: 0.0266\n",
      "967/1088, train_loss: 0.0301\n",
      "968/1088, train_loss: 0.0272\n",
      "969/1088, train_loss: 0.0280\n",
      "970/1088, train_loss: 0.0278\n",
      "971/1088, train_loss: 0.0295\n",
      "972/1088, train_loss: 0.0335\n",
      "973/1088, train_loss: 0.0286\n",
      "974/1088, train_loss: 0.0288\n",
      "975/1088, train_loss: 0.0294\n",
      "976/1088, train_loss: 0.0304\n",
      "977/1088, train_loss: 0.0287\n",
      "978/1088, train_loss: 0.0297\n",
      "979/1088, train_loss: 0.0341\n",
      "980/1088, train_loss: 0.0293\n",
      "981/1088, train_loss: 0.0306\n",
      "982/1088, train_loss: 0.0296\n",
      "983/1088, train_loss: 0.0298\n",
      "984/1088, train_loss: 0.0276\n",
      "985/1088, train_loss: 0.0302\n",
      "986/1088, train_loss: 0.0303\n",
      "987/1088, train_loss: 0.0276\n",
      "988/1088, train_loss: 0.0293\n",
      "989/1088, train_loss: 0.0305\n",
      "990/1088, train_loss: 0.0296\n",
      "991/1088, train_loss: 0.0292\n",
      "992/1088, train_loss: 0.0297\n",
      "993/1088, train_loss: 0.0268\n",
      "994/1088, train_loss: 0.0282\n",
      "995/1088, train_loss: 0.0293\n",
      "996/1088, train_loss: 0.0286\n",
      "997/1088, train_loss: 0.0271\n",
      "998/1088, train_loss: 0.0281\n",
      "999/1088, train_loss: 0.0278\n",
      "1000/1088, train_loss: 0.0304\n",
      "1001/1088, train_loss: 0.0284\n",
      "1002/1088, train_loss: 0.0309\n",
      "1003/1088, train_loss: 0.0279\n",
      "1004/1088, train_loss: 0.0285\n",
      "1005/1088, train_loss: 0.0300\n",
      "1006/1088, train_loss: 0.0267\n",
      "1007/1088, train_loss: 0.0272\n",
      "1008/1088, train_loss: 0.0276\n",
      "1009/1088, train_loss: 0.0302\n",
      "1010/1088, train_loss: 0.0322\n",
      "1011/1088, train_loss: 0.0334\n",
      "1012/1088, train_loss: 0.0277\n",
      "1013/1088, train_loss: 0.0298\n",
      "1014/1088, train_loss: 0.0288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015/1088, train_loss: 0.0275\n",
      "1016/1088, train_loss: 0.0283\n",
      "1017/1088, train_loss: 0.0299\n",
      "1018/1088, train_loss: 0.0282\n",
      "1019/1088, train_loss: 0.0271\n",
      "1020/1088, train_loss: 0.0270\n",
      "1021/1088, train_loss: 0.0287\n",
      "1022/1088, train_loss: 0.0282\n",
      "1023/1088, train_loss: 0.0304\n",
      "1024/1088, train_loss: 0.0263\n",
      "1025/1088, train_loss: 0.0271\n",
      "1026/1088, train_loss: 0.0294\n",
      "1027/1088, train_loss: 0.0266\n",
      "1028/1088, train_loss: 0.0281\n",
      "1029/1088, train_loss: 0.0270\n",
      "1030/1088, train_loss: 0.0289\n",
      "1031/1088, train_loss: 0.0297\n",
      "1032/1088, train_loss: 0.0300\n",
      "1033/1088, train_loss: 0.0276\n",
      "1034/1088, train_loss: 0.0269\n",
      "1035/1088, train_loss: 0.0308\n",
      "1036/1088, train_loss: 0.0313\n",
      "1037/1088, train_loss: 0.0284\n",
      "1038/1088, train_loss: 0.0327\n",
      "1039/1088, train_loss: 0.0271\n",
      "1040/1088, train_loss: 0.0296\n",
      "1041/1088, train_loss: 0.0302\n",
      "1042/1088, train_loss: 0.0289\n",
      "1043/1088, train_loss: 0.0277\n",
      "1044/1088, train_loss: 0.0276\n",
      "1045/1088, train_loss: 0.0285\n",
      "1046/1088, train_loss: 0.0340\n",
      "1047/1088, train_loss: 0.0296\n",
      "1048/1088, train_loss: 0.0256\n",
      "1049/1088, train_loss: 0.0251\n",
      "1050/1088, train_loss: 0.0287\n",
      "1051/1088, train_loss: 0.0268\n",
      "1052/1088, train_loss: 0.0309\n",
      "1053/1088, train_loss: 0.0284\n",
      "1054/1088, train_loss: 0.0247\n",
      "1055/1088, train_loss: 0.0278\n",
      "1056/1088, train_loss: 0.0270\n",
      "1057/1088, train_loss: 0.0294\n",
      "1058/1088, train_loss: 0.0305\n",
      "1059/1088, train_loss: 0.0288\n",
      "1060/1088, train_loss: 0.0300\n",
      "1061/1088, train_loss: 0.0274\n",
      "1062/1088, train_loss: 0.0293\n",
      "1063/1088, train_loss: 0.0266\n",
      "1064/1088, train_loss: 0.0303\n",
      "1065/1088, train_loss: 0.0264\n",
      "1066/1088, train_loss: 0.0311\n",
      "1067/1088, train_loss: 0.0302\n",
      "1068/1088, train_loss: 0.0285\n",
      "1069/1088, train_loss: 0.0266\n",
      "1070/1088, train_loss: 0.0270\n",
      "1071/1088, train_loss: 0.0293\n",
      "1072/1088, train_loss: 0.0272\n",
      "1073/1088, train_loss: 0.0311\n",
      "1074/1088, train_loss: 0.0284\n",
      "1075/1088, train_loss: 0.0273\n",
      "1076/1088, train_loss: 0.0280\n",
      "1077/1088, train_loss: 0.0292\n",
      "1078/1088, train_loss: 0.0263\n",
      "1079/1088, train_loss: 0.0265\n",
      "1080/1088, train_loss: 0.0281\n",
      "1081/1088, train_loss: 0.0277\n",
      "1082/1088, train_loss: 0.0290\n",
      "1083/1088, train_loss: 0.0300\n",
      "1084/1088, train_loss: 0.0297\n",
      "1085/1088, train_loss: 0.0293\n",
      "1086/1088, train_loss: 0.0295\n",
      "1087/1088, train_loss: 0.0290\n",
      "1088/1088, train_loss: 0.0290\n",
      "1089/1088, train_loss: 0.0374\n",
      "epoch 14 average loss: 0.0284, train_dice: 0.9716\n",
      "epoch 14 average loss: 0.0284\n",
      "current epoch: 14 current mean dice: 0.9663 best mean dice: 0.9703 at epoch 8\n",
      "--------------------------------------------------\n",
      "epoch 15/50\n",
      "1/1088, train_loss: 0.0300\n",
      "2/1088, train_loss: 0.0294\n",
      "3/1088, train_loss: 0.0479\n",
      "4/1088, train_loss: 0.0291\n",
      "5/1088, train_loss: 0.0283\n",
      "6/1088, train_loss: 0.0320\n",
      "7/1088, train_loss: 0.0325\n",
      "8/1088, train_loss: 0.0272\n",
      "9/1088, train_loss: 0.0296\n",
      "10/1088, train_loss: 0.0273\n",
      "11/1088, train_loss: 0.0300\n",
      "12/1088, train_loss: 0.0302\n",
      "13/1088, train_loss: 0.0270\n",
      "14/1088, train_loss: 0.0286\n",
      "15/1088, train_loss: 0.0302\n",
      "16/1088, train_loss: 0.0284\n",
      "17/1088, train_loss: 0.0302\n",
      "18/1088, train_loss: 0.0297\n",
      "19/1088, train_loss: 0.0289\n",
      "20/1088, train_loss: 0.0286\n",
      "21/1088, train_loss: 0.0281\n",
      "22/1088, train_loss: 0.0285\n",
      "23/1088, train_loss: 0.0288\n",
      "24/1088, train_loss: 0.0281\n",
      "25/1088, train_loss: 0.0271\n",
      "26/1088, train_loss: 0.0388\n",
      "27/1088, train_loss: 0.0282\n",
      "28/1088, train_loss: 0.0314\n",
      "29/1088, train_loss: 0.0287\n",
      "30/1088, train_loss: 0.0305\n",
      "31/1088, train_loss: 0.0291\n",
      "32/1088, train_loss: 0.0259\n",
      "33/1088, train_loss: 0.0298\n",
      "34/1088, train_loss: 0.0293\n",
      "35/1088, train_loss: 0.0400\n",
      "36/1088, train_loss: 0.0285\n",
      "37/1088, train_loss: 0.0280\n",
      "38/1088, train_loss: 0.0271\n",
      "39/1088, train_loss: 0.0289\n",
      "40/1088, train_loss: 0.0316\n",
      "41/1088, train_loss: 0.0283\n",
      "42/1088, train_loss: 0.0278\n",
      "43/1088, train_loss: 0.0299\n",
      "44/1088, train_loss: 0.0289\n",
      "45/1088, train_loss: 0.0282\n",
      "46/1088, train_loss: 0.0281\n",
      "47/1088, train_loss: 0.0282\n",
      "48/1088, train_loss: 0.0315\n",
      "49/1088, train_loss: 0.0265\n",
      "50/1088, train_loss: 0.0295\n",
      "51/1088, train_loss: 0.0277\n",
      "52/1088, train_loss: 0.0289\n",
      "53/1088, train_loss: 0.0282\n",
      "54/1088, train_loss: 0.0300\n",
      "55/1088, train_loss: 0.0288\n",
      "56/1088, train_loss: 0.0257\n",
      "57/1088, train_loss: 0.0286\n",
      "58/1088, train_loss: 0.0265\n",
      "59/1088, train_loss: 0.0305\n",
      "60/1088, train_loss: 0.0297\n",
      "61/1088, train_loss: 0.0286\n",
      "62/1088, train_loss: 0.0273\n",
      "63/1088, train_loss: 0.0293\n",
      "64/1088, train_loss: 0.0294\n",
      "65/1088, train_loss: 0.0285\n",
      "66/1088, train_loss: 0.0297\n",
      "67/1088, train_loss: 0.0279\n",
      "68/1088, train_loss: 0.0266\n",
      "69/1088, train_loss: 0.0277\n",
      "70/1088, train_loss: 0.0286\n",
      "71/1088, train_loss: 0.0286\n",
      "72/1088, train_loss: 0.0278\n",
      "73/1088, train_loss: 0.0272\n",
      "74/1088, train_loss: 0.0281\n",
      "75/1088, train_loss: 0.0313\n",
      "76/1088, train_loss: 0.0294\n",
      "77/1088, train_loss: 0.0306\n",
      "78/1088, train_loss: 0.0272\n",
      "79/1088, train_loss: 0.0309\n",
      "80/1088, train_loss: 0.0290\n",
      "81/1088, train_loss: 0.0284\n",
      "82/1088, train_loss: 0.0280\n",
      "83/1088, train_loss: 0.0386\n",
      "84/1088, train_loss: 0.0290\n",
      "85/1088, train_loss: 0.0362\n",
      "86/1088, train_loss: 0.0305\n",
      "87/1088, train_loss: 0.0285\n",
      "88/1088, train_loss: 0.0286\n",
      "89/1088, train_loss: 0.0287\n",
      "90/1088, train_loss: 0.0278\n",
      "91/1088, train_loss: 0.0305\n",
      "92/1088, train_loss: 0.0311\n",
      "93/1088, train_loss: 0.0283\n",
      "94/1088, train_loss: 0.0297\n",
      "95/1088, train_loss: 0.0307\n",
      "96/1088, train_loss: 0.0278\n",
      "97/1088, train_loss: 0.0305\n",
      "98/1088, train_loss: 0.0293\n",
      "99/1088, train_loss: 0.0275\n",
      "100/1088, train_loss: 0.0263\n",
      "101/1088, train_loss: 0.0300\n",
      "102/1088, train_loss: 0.0277\n",
      "103/1088, train_loss: 0.0311\n",
      "104/1088, train_loss: 0.0293\n",
      "105/1088, train_loss: 0.0306\n",
      "106/1088, train_loss: 0.0297\n",
      "107/1088, train_loss: 0.0281\n",
      "108/1088, train_loss: 0.0296\n",
      "109/1088, train_loss: 0.0302\n",
      "110/1088, train_loss: 0.0292\n",
      "111/1088, train_loss: 0.0298\n",
      "112/1088, train_loss: 0.0287\n",
      "113/1088, train_loss: 0.0269\n",
      "114/1088, train_loss: 0.0279\n",
      "115/1088, train_loss: 0.0283\n",
      "116/1088, train_loss: 0.0292\n",
      "117/1088, train_loss: 0.0293\n",
      "118/1088, train_loss: 0.0320\n",
      "119/1088, train_loss: 0.0267\n",
      "120/1088, train_loss: 0.0281\n",
      "121/1088, train_loss: 0.0277\n",
      "122/1088, train_loss: 0.0299\n",
      "123/1088, train_loss: 0.0311\n",
      "124/1088, train_loss: 0.0297\n",
      "125/1088, train_loss: 0.0322\n",
      "126/1088, train_loss: 0.0305\n",
      "127/1088, train_loss: 0.0305\n",
      "128/1088, train_loss: 0.0322\n",
      "129/1088, train_loss: 0.0304\n",
      "130/1088, train_loss: 0.0267\n",
      "131/1088, train_loss: 0.0298\n",
      "132/1088, train_loss: 0.0287\n",
      "133/1088, train_loss: 0.0304\n",
      "134/1088, train_loss: 0.0298\n",
      "135/1088, train_loss: 0.0263\n",
      "136/1088, train_loss: 0.0299\n",
      "137/1088, train_loss: 0.0292\n",
      "138/1088, train_loss: 0.0313\n",
      "139/1088, train_loss: 0.0291\n",
      "140/1088, train_loss: 0.0293\n",
      "141/1088, train_loss: 0.0302\n",
      "142/1088, train_loss: 0.0284\n",
      "143/1088, train_loss: 0.0274\n",
      "144/1088, train_loss: 0.0283\n",
      "145/1088, train_loss: 0.0296\n",
      "146/1088, train_loss: 0.0283\n",
      "147/1088, train_loss: 0.0291\n",
      "148/1088, train_loss: 0.0347\n",
      "149/1088, train_loss: 0.0272\n",
      "150/1088, train_loss: 0.0315\n",
      "151/1088, train_loss: 0.0300\n",
      "152/1088, train_loss: 0.0305\n",
      "153/1088, train_loss: 0.0320\n",
      "154/1088, train_loss: 0.0293\n",
      "155/1088, train_loss: 0.0280\n",
      "156/1088, train_loss: 0.0301\n",
      "157/1088, train_loss: 0.0313\n",
      "158/1088, train_loss: 0.0284\n",
      "159/1088, train_loss: 0.0296\n",
      "160/1088, train_loss: 0.0283\n",
      "161/1088, train_loss: 0.0296\n",
      "162/1088, train_loss: 0.0303\n",
      "163/1088, train_loss: 0.0286\n",
      "164/1088, train_loss: 0.0279\n",
      "165/1088, train_loss: 0.0286\n",
      "166/1088, train_loss: 0.0286\n",
      "167/1088, train_loss: 0.0282\n",
      "168/1088, train_loss: 0.0280\n",
      "169/1088, train_loss: 0.0289\n",
      "170/1088, train_loss: 0.0281\n",
      "171/1088, train_loss: 0.0290\n",
      "172/1088, train_loss: 0.0289\n",
      "173/1088, train_loss: 0.0256\n",
      "174/1088, train_loss: 0.0301\n",
      "175/1088, train_loss: 0.0274\n",
      "176/1088, train_loss: 0.0292\n",
      "177/1088, train_loss: 0.0283\n",
      "178/1088, train_loss: 0.0277\n",
      "179/1088, train_loss: 0.0312\n",
      "180/1088, train_loss: 0.0280\n",
      "181/1088, train_loss: 0.0291\n",
      "182/1088, train_loss: 0.0264\n",
      "183/1088, train_loss: 0.0271\n",
      "184/1088, train_loss: 0.0279\n",
      "185/1088, train_loss: 0.0312\n",
      "186/1088, train_loss: 0.0415\n",
      "187/1088, train_loss: 0.0292\n",
      "188/1088, train_loss: 0.0310\n",
      "189/1088, train_loss: 0.0293\n",
      "190/1088, train_loss: 0.0264\n",
      "191/1088, train_loss: 0.0261\n",
      "192/1088, train_loss: 0.0285\n",
      "193/1088, train_loss: 0.0289\n",
      "194/1088, train_loss: 0.0276\n",
      "195/1088, train_loss: 0.0289\n",
      "196/1088, train_loss: 0.0270\n",
      "197/1088, train_loss: 0.0309\n",
      "198/1088, train_loss: 0.0336\n",
      "199/1088, train_loss: 0.0313\n",
      "200/1088, train_loss: 0.0295\n",
      "201/1088, train_loss: 0.0295\n",
      "202/1088, train_loss: 0.0313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/1088, train_loss: 0.0293\n",
      "204/1088, train_loss: 0.0281\n",
      "205/1088, train_loss: 0.0315\n",
      "206/1088, train_loss: 0.0313\n",
      "207/1088, train_loss: 0.0277\n",
      "208/1088, train_loss: 0.0294\n",
      "209/1088, train_loss: 0.0265\n",
      "210/1088, train_loss: 0.0304\n",
      "211/1088, train_loss: 0.0311\n",
      "212/1088, train_loss: 0.0265\n",
      "213/1088, train_loss: 0.0278\n",
      "214/1088, train_loss: 0.0302\n",
      "215/1088, train_loss: 0.0278\n",
      "216/1088, train_loss: 0.0266\n",
      "217/1088, train_loss: 0.0289\n",
      "218/1088, train_loss: 0.0294\n",
      "219/1088, train_loss: 0.0288\n",
      "220/1088, train_loss: 0.0266\n",
      "221/1088, train_loss: 0.0304\n",
      "222/1088, train_loss: 0.0304\n",
      "223/1088, train_loss: 0.0302\n",
      "224/1088, train_loss: 0.0276\n",
      "225/1088, train_loss: 0.0265\n",
      "226/1088, train_loss: 0.0280\n",
      "227/1088, train_loss: 0.0300\n",
      "228/1088, train_loss: 0.0280\n",
      "229/1088, train_loss: 0.0291\n",
      "230/1088, train_loss: 0.0311\n",
      "231/1088, train_loss: 0.0314\n",
      "232/1088, train_loss: 0.0284\n",
      "233/1088, train_loss: 0.0291\n",
      "234/1088, train_loss: 0.0284\n",
      "235/1088, train_loss: 0.0279\n",
      "236/1088, train_loss: 0.0282\n",
      "237/1088, train_loss: 0.0322\n",
      "238/1088, train_loss: 0.0283\n",
      "239/1088, train_loss: 0.0320\n",
      "240/1088, train_loss: 0.0307\n",
      "241/1088, train_loss: 0.0299\n",
      "242/1088, train_loss: 0.0278\n",
      "243/1088, train_loss: 0.0273\n",
      "244/1088, train_loss: 0.0294\n",
      "245/1088, train_loss: 0.0288\n",
      "246/1088, train_loss: 0.0274\n",
      "247/1088, train_loss: 0.0297\n",
      "248/1088, train_loss: 0.0297\n",
      "249/1088, train_loss: 0.0302\n",
      "250/1088, train_loss: 0.0293\n",
      "251/1088, train_loss: 0.0271\n",
      "252/1088, train_loss: 0.0292\n",
      "253/1088, train_loss: 0.0290\n",
      "254/1088, train_loss: 0.0280\n",
      "255/1088, train_loss: 0.0290\n",
      "256/1088, train_loss: 0.0293\n",
      "257/1088, train_loss: 0.0272\n",
      "258/1088, train_loss: 0.0293\n",
      "259/1088, train_loss: 0.0287\n",
      "260/1088, train_loss: 0.0305\n",
      "261/1088, train_loss: 0.0276\n",
      "262/1088, train_loss: 0.0288\n",
      "263/1088, train_loss: 0.0297\n",
      "264/1088, train_loss: 0.0294\n",
      "265/1088, train_loss: 0.0282\n",
      "266/1088, train_loss: 0.0284\n",
      "267/1088, train_loss: 0.0287\n",
      "268/1088, train_loss: 0.0315\n",
      "269/1088, train_loss: 0.0280\n",
      "270/1088, train_loss: 0.0268\n",
      "271/1088, train_loss: 0.0284\n",
      "272/1088, train_loss: 0.0282\n",
      "273/1088, train_loss: 0.0293\n",
      "274/1088, train_loss: 0.0283\n",
      "275/1088, train_loss: 0.0274\n",
      "276/1088, train_loss: 0.0268\n",
      "277/1088, train_loss: 0.0283\n",
      "278/1088, train_loss: 0.0311\n",
      "279/1088, train_loss: 0.0293\n",
      "280/1088, train_loss: 0.0283\n",
      "281/1088, train_loss: 0.0303\n",
      "282/1088, train_loss: 0.0309\n",
      "283/1088, train_loss: 0.0287\n",
      "284/1088, train_loss: 0.0293\n",
      "285/1088, train_loss: 0.0282\n",
      "286/1088, train_loss: 0.0290\n",
      "287/1088, train_loss: 0.0282\n",
      "288/1088, train_loss: 0.0274\n",
      "289/1088, train_loss: 0.0286\n",
      "290/1088, train_loss: 0.0291\n",
      "291/1088, train_loss: 0.0272\n",
      "292/1088, train_loss: 0.0287\n",
      "293/1088, train_loss: 0.0283\n",
      "294/1088, train_loss: 0.0327\n",
      "295/1088, train_loss: 0.0284\n",
      "296/1088, train_loss: 0.0301\n",
      "297/1088, train_loss: 0.0394\n",
      "298/1088, train_loss: 0.0275\n",
      "299/1088, train_loss: 0.0261\n",
      "300/1088, train_loss: 0.0285\n",
      "301/1088, train_loss: 0.0290\n",
      "302/1088, train_loss: 0.0333\n",
      "303/1088, train_loss: 0.0292\n",
      "304/1088, train_loss: 0.0276\n",
      "305/1088, train_loss: 0.0273\n",
      "306/1088, train_loss: 0.0281\n",
      "307/1088, train_loss: 0.0292\n",
      "308/1088, train_loss: 0.0322\n",
      "309/1088, train_loss: 0.0303\n",
      "310/1088, train_loss: 0.0292\n",
      "311/1088, train_loss: 0.0269\n",
      "312/1088, train_loss: 0.0286\n",
      "313/1088, train_loss: 0.0282\n",
      "314/1088, train_loss: 0.0314\n",
      "315/1088, train_loss: 0.0271\n",
      "316/1088, train_loss: 0.0281\n",
      "317/1088, train_loss: 0.0301\n",
      "318/1088, train_loss: 0.0292\n",
      "319/1088, train_loss: 0.0293\n",
      "320/1088, train_loss: 0.0280\n",
      "321/1088, train_loss: 0.0270\n",
      "322/1088, train_loss: 0.0264\n",
      "323/1088, train_loss: 0.0282\n",
      "324/1088, train_loss: 0.0285\n",
      "325/1088, train_loss: 0.0281\n",
      "326/1088, train_loss: 0.0263\n",
      "327/1088, train_loss: 0.0350\n",
      "328/1088, train_loss: 0.0279\n",
      "329/1088, train_loss: 0.0282\n",
      "330/1088, train_loss: 0.0255\n",
      "331/1088, train_loss: 0.0293\n",
      "332/1088, train_loss: 0.0284\n",
      "333/1088, train_loss: 0.0302\n",
      "334/1088, train_loss: 0.0318\n",
      "335/1088, train_loss: 0.0276\n",
      "336/1088, train_loss: 0.0312\n",
      "337/1088, train_loss: 0.0285\n",
      "338/1088, train_loss: 0.0301\n",
      "339/1088, train_loss: 0.0280\n",
      "340/1088, train_loss: 0.0289\n",
      "341/1088, train_loss: 0.0319\n",
      "342/1088, train_loss: 0.0277\n",
      "343/1088, train_loss: 0.0317\n",
      "344/1088, train_loss: 0.0302\n",
      "345/1088, train_loss: 0.0291\n",
      "346/1088, train_loss: 0.0335\n",
      "347/1088, train_loss: 0.0336\n",
      "348/1088, train_loss: 0.0317\n",
      "349/1088, train_loss: 0.0313\n",
      "350/1088, train_loss: 0.0286\n",
      "351/1088, train_loss: 0.0290\n",
      "352/1088, train_loss: 0.0278\n",
      "353/1088, train_loss: 0.0289\n",
      "354/1088, train_loss: 0.0285\n",
      "355/1088, train_loss: 0.0264\n",
      "356/1088, train_loss: 0.0289\n",
      "357/1088, train_loss: 0.0309\n",
      "358/1088, train_loss: 0.0296\n",
      "359/1088, train_loss: 0.0293\n",
      "360/1088, train_loss: 0.0276\n",
      "361/1088, train_loss: 0.0272\n",
      "362/1088, train_loss: 0.0307\n",
      "363/1088, train_loss: 0.0259\n",
      "364/1088, train_loss: 0.0270\n",
      "365/1088, train_loss: 0.0261\n",
      "366/1088, train_loss: 0.0306\n",
      "367/1088, train_loss: 0.0288\n",
      "368/1088, train_loss: 0.0257\n",
      "369/1088, train_loss: 0.0265\n",
      "370/1088, train_loss: 0.0298\n",
      "371/1088, train_loss: 0.0288\n",
      "372/1088, train_loss: 0.0281\n",
      "373/1088, train_loss: 0.0318\n",
      "374/1088, train_loss: 0.0297\n",
      "375/1088, train_loss: 0.0255\n",
      "376/1088, train_loss: 0.0299\n",
      "377/1088, train_loss: 0.0286\n",
      "378/1088, train_loss: 0.0284\n",
      "379/1088, train_loss: 0.0272\n",
      "380/1088, train_loss: 0.0264\n",
      "381/1088, train_loss: 0.0278\n",
      "382/1088, train_loss: 0.0294\n",
      "383/1088, train_loss: 0.0258\n",
      "384/1088, train_loss: 0.0307\n",
      "385/1088, train_loss: 0.0286\n",
      "386/1088, train_loss: 0.0282\n",
      "387/1088, train_loss: 0.0272\n",
      "388/1088, train_loss: 0.0264\n",
      "389/1088, train_loss: 0.0318\n",
      "390/1088, train_loss: 0.0283\n",
      "391/1088, train_loss: 0.0267\n",
      "392/1088, train_loss: 0.0292\n",
      "393/1088, train_loss: 0.0287\n",
      "394/1088, train_loss: 0.0279\n",
      "395/1088, train_loss: 0.0279\n",
      "396/1088, train_loss: 0.0273\n",
      "397/1088, train_loss: 0.0290\n",
      "398/1088, train_loss: 0.0282\n",
      "399/1088, train_loss: 0.0283\n",
      "400/1088, train_loss: 0.0267\n",
      "401/1088, train_loss: 0.0303\n",
      "402/1088, train_loss: 0.0290\n",
      "403/1088, train_loss: 0.0294\n",
      "404/1088, train_loss: 0.0288\n",
      "405/1088, train_loss: 0.0276\n",
      "406/1088, train_loss: 0.0274\n",
      "407/1088, train_loss: 0.0312\n",
      "408/1088, train_loss: 0.0325\n",
      "409/1088, train_loss: 0.0330\n",
      "410/1088, train_loss: 0.0307\n",
      "411/1088, train_loss: 0.0307\n",
      "412/1088, train_loss: 0.0279\n",
      "413/1088, train_loss: 0.0282\n",
      "414/1088, train_loss: 0.0312\n",
      "415/1088, train_loss: 0.0272\n",
      "416/1088, train_loss: 0.0297\n",
      "417/1088, train_loss: 0.0316\n",
      "418/1088, train_loss: 0.0290\n",
      "419/1088, train_loss: 0.0277\n",
      "420/1088, train_loss: 0.0279\n",
      "421/1088, train_loss: 0.0292\n",
      "422/1088, train_loss: 0.0300\n",
      "423/1088, train_loss: 0.0278\n",
      "424/1088, train_loss: 0.0270\n",
      "425/1088, train_loss: 0.0272\n",
      "426/1088, train_loss: 0.0286\n",
      "427/1088, train_loss: 0.0301\n",
      "428/1088, train_loss: 0.0260\n",
      "429/1088, train_loss: 0.0320\n",
      "430/1088, train_loss: 0.0303\n",
      "431/1088, train_loss: 0.0279\n",
      "432/1088, train_loss: 0.0299\n",
      "433/1088, train_loss: 0.0292\n",
      "434/1088, train_loss: 0.0269\n",
      "435/1088, train_loss: 0.0292\n",
      "436/1088, train_loss: 0.0283\n",
      "437/1088, train_loss: 0.0264\n",
      "438/1088, train_loss: 0.0277\n",
      "439/1088, train_loss: 0.0290\n",
      "440/1088, train_loss: 0.0299\n",
      "441/1088, train_loss: 0.0294\n",
      "442/1088, train_loss: 0.0286\n",
      "443/1088, train_loss: 0.0263\n",
      "444/1088, train_loss: 0.0287\n",
      "445/1088, train_loss: 0.0299\n",
      "446/1088, train_loss: 0.0294\n",
      "447/1088, train_loss: 0.0296\n",
      "448/1088, train_loss: 0.0316\n",
      "449/1088, train_loss: 0.0293\n",
      "450/1088, train_loss: 0.0269\n",
      "451/1088, train_loss: 0.0283\n",
      "452/1088, train_loss: 0.0285\n",
      "453/1088, train_loss: 0.0283\n",
      "454/1088, train_loss: 0.0267\n",
      "455/1088, train_loss: 0.0289\n",
      "456/1088, train_loss: 0.0287\n",
      "457/1088, train_loss: 0.0286\n",
      "458/1088, train_loss: 0.0311\n",
      "459/1088, train_loss: 0.0287\n",
      "460/1088, train_loss: 0.0269\n",
      "461/1088, train_loss: 0.0298\n",
      "462/1088, train_loss: 0.0268\n",
      "463/1088, train_loss: 0.0311\n",
      "464/1088, train_loss: 0.0328\n",
      "465/1088, train_loss: 0.0316\n",
      "466/1088, train_loss: 0.0279\n",
      "467/1088, train_loss: 0.0308\n",
      "468/1088, train_loss: 0.0283\n",
      "469/1088, train_loss: 0.0287\n",
      "470/1088, train_loss: 0.0295\n",
      "471/1088, train_loss: 0.0294\n",
      "472/1088, train_loss: 0.0258\n",
      "473/1088, train_loss: 0.0300\n",
      "474/1088, train_loss: 0.0282\n",
      "475/1088, train_loss: 0.0281\n",
      "476/1088, train_loss: 0.0279\n",
      "477/1088, train_loss: 0.0281\n",
      "478/1088, train_loss: 0.0296\n",
      "479/1088, train_loss: 0.0289\n",
      "480/1088, train_loss: 0.0286\n",
      "481/1088, train_loss: 0.0259\n",
      "482/1088, train_loss: 0.0293\n",
      "483/1088, train_loss: 0.0260\n",
      "484/1088, train_loss: 0.0326\n",
      "485/1088, train_loss: 0.0269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/1088, train_loss: 0.0275\n",
      "487/1088, train_loss: 0.0322\n",
      "488/1088, train_loss: 0.0264\n",
      "489/1088, train_loss: 0.0284\n",
      "490/1088, train_loss: 0.0285\n",
      "491/1088, train_loss: 0.0309\n",
      "492/1088, train_loss: 0.0281\n",
      "493/1088, train_loss: 0.0276\n",
      "494/1088, train_loss: 0.0295\n",
      "495/1088, train_loss: 0.0275\n",
      "496/1088, train_loss: 0.0278\n",
      "497/1088, train_loss: 0.0290\n",
      "498/1088, train_loss: 0.0287\n",
      "499/1088, train_loss: 0.0271\n",
      "500/1088, train_loss: 0.0284\n",
      "501/1088, train_loss: 0.0287\n",
      "502/1088, train_loss: 0.0292\n",
      "503/1088, train_loss: 0.0324\n",
      "504/1088, train_loss: 0.0318\n",
      "505/1088, train_loss: 0.0316\n",
      "506/1088, train_loss: 0.0344\n",
      "507/1088, train_loss: 0.0269\n",
      "508/1088, train_loss: 0.0277\n",
      "509/1088, train_loss: 0.0273\n",
      "510/1088, train_loss: 0.0299\n",
      "511/1088, train_loss: 0.0306\n",
      "512/1088, train_loss: 0.0300\n",
      "513/1088, train_loss: 0.0306\n",
      "514/1088, train_loss: 0.0298\n",
      "515/1088, train_loss: 0.0301\n",
      "516/1088, train_loss: 0.0306\n",
      "517/1088, train_loss: 0.0294\n",
      "518/1088, train_loss: 0.0277\n",
      "519/1088, train_loss: 0.0292\n",
      "520/1088, train_loss: 0.0259\n",
      "521/1088, train_loss: 0.0270\n",
      "522/1088, train_loss: 0.0320\n",
      "523/1088, train_loss: 0.0294\n",
      "524/1088, train_loss: 0.0278\n",
      "525/1088, train_loss: 0.0287\n",
      "526/1088, train_loss: 0.0301\n",
      "527/1088, train_loss: 0.0304\n",
      "528/1088, train_loss: 0.0291\n",
      "529/1088, train_loss: 0.0303\n",
      "530/1088, train_loss: 0.0285\n",
      "531/1088, train_loss: 0.0301\n",
      "532/1088, train_loss: 0.0266\n",
      "533/1088, train_loss: 0.0284\n",
      "534/1088, train_loss: 0.0328\n",
      "535/1088, train_loss: 0.0276\n",
      "536/1088, train_loss: 0.0258\n",
      "537/1088, train_loss: 0.0277\n",
      "538/1088, train_loss: 0.0292\n",
      "539/1088, train_loss: 0.0306\n",
      "540/1088, train_loss: 0.0301\n",
      "541/1088, train_loss: 0.0305\n",
      "542/1088, train_loss: 0.0304\n",
      "543/1088, train_loss: 0.0305\n",
      "544/1088, train_loss: 0.0283\n",
      "545/1088, train_loss: 0.0295\n",
      "546/1088, train_loss: 0.0317\n",
      "547/1088, train_loss: 0.0278\n",
      "548/1088, train_loss: 0.0292\n",
      "549/1088, train_loss: 0.0271\n",
      "550/1088, train_loss: 0.0290\n",
      "551/1088, train_loss: 0.0286\n",
      "552/1088, train_loss: 0.0263\n",
      "553/1088, train_loss: 0.0263\n",
      "554/1088, train_loss: 0.0274\n",
      "555/1088, train_loss: 0.0291\n",
      "556/1088, train_loss: 0.0327\n",
      "557/1088, train_loss: 0.0279\n",
      "558/1088, train_loss: 0.0265\n",
      "559/1088, train_loss: 0.0284\n",
      "560/1088, train_loss: 0.0312\n",
      "561/1088, train_loss: 0.0274\n",
      "562/1088, train_loss: 0.0259\n",
      "563/1088, train_loss: 0.0288\n",
      "564/1088, train_loss: 0.0314\n",
      "565/1088, train_loss: 0.0292\n",
      "566/1088, train_loss: 0.0282\n",
      "567/1088, train_loss: 0.0274\n",
      "568/1088, train_loss: 0.0259\n",
      "569/1088, train_loss: 0.0277\n",
      "570/1088, train_loss: 0.0275\n",
      "571/1088, train_loss: 0.0265\n",
      "572/1088, train_loss: 0.0300\n",
      "573/1088, train_loss: 0.0281\n",
      "574/1088, train_loss: 0.0301\n",
      "575/1088, train_loss: 0.0288\n",
      "576/1088, train_loss: 0.0300\n",
      "577/1088, train_loss: 0.0259\n",
      "578/1088, train_loss: 0.0317\n",
      "579/1088, train_loss: 0.0335\n",
      "580/1088, train_loss: 0.0312\n",
      "581/1088, train_loss: 0.0326\n",
      "582/1088, train_loss: 0.0263\n",
      "583/1088, train_loss: 0.0286\n",
      "584/1088, train_loss: 0.0262\n",
      "585/1088, train_loss: 0.0294\n",
      "586/1088, train_loss: 0.0293\n",
      "587/1088, train_loss: 0.0297\n",
      "588/1088, train_loss: 0.0279\n",
      "589/1088, train_loss: 0.0269\n",
      "590/1088, train_loss: 0.0288\n",
      "591/1088, train_loss: 0.0309\n",
      "592/1088, train_loss: 0.0277\n",
      "593/1088, train_loss: 0.0280\n",
      "594/1088, train_loss: 0.0292\n",
      "595/1088, train_loss: 0.0287\n",
      "596/1088, train_loss: 0.0278\n",
      "597/1088, train_loss: 0.0286\n",
      "598/1088, train_loss: 0.0296\n",
      "599/1088, train_loss: 0.0301\n",
      "600/1088, train_loss: 0.0272\n",
      "601/1088, train_loss: 0.0296\n",
      "602/1088, train_loss: 0.0334\n",
      "603/1088, train_loss: 0.0304\n",
      "604/1088, train_loss: 0.0299\n",
      "605/1088, train_loss: 0.0306\n",
      "606/1088, train_loss: 0.0264\n",
      "607/1088, train_loss: 0.0275\n",
      "608/1088, train_loss: 0.0282\n",
      "609/1088, train_loss: 0.0306\n",
      "610/1088, train_loss: 0.0301\n",
      "611/1088, train_loss: 0.0299\n",
      "612/1088, train_loss: 0.0325\n",
      "613/1088, train_loss: 0.0270\n",
      "614/1088, train_loss: 0.0274\n",
      "615/1088, train_loss: 0.0284\n",
      "616/1088, train_loss: 0.0265\n",
      "617/1088, train_loss: 0.0288\n",
      "618/1088, train_loss: 0.0284\n",
      "619/1088, train_loss: 0.0271\n",
      "620/1088, train_loss: 0.0293\n",
      "621/1088, train_loss: 0.0295\n",
      "622/1088, train_loss: 0.0289\n",
      "623/1088, train_loss: 0.0279\n",
      "624/1088, train_loss: 0.0285\n",
      "625/1088, train_loss: 0.0283\n",
      "626/1088, train_loss: 0.0293\n",
      "627/1088, train_loss: 0.0289\n",
      "628/1088, train_loss: 0.0282\n",
      "629/1088, train_loss: 0.0272\n",
      "630/1088, train_loss: 0.0301\n",
      "631/1088, train_loss: 0.0281\n",
      "632/1088, train_loss: 0.0299\n",
      "633/1088, train_loss: 0.0301\n",
      "634/1088, train_loss: 0.0271\n",
      "635/1088, train_loss: 0.0269\n",
      "636/1088, train_loss: 0.0245\n",
      "637/1088, train_loss: 0.0266\n",
      "638/1088, train_loss: 0.0285\n",
      "639/1088, train_loss: 0.0288\n",
      "640/1088, train_loss: 0.0289\n",
      "641/1088, train_loss: 0.0302\n",
      "642/1088, train_loss: 0.0302\n",
      "643/1088, train_loss: 0.0309\n",
      "644/1088, train_loss: 0.0278\n",
      "645/1088, train_loss: 0.0283\n",
      "646/1088, train_loss: 0.0300\n",
      "647/1088, train_loss: 0.0269\n",
      "648/1088, train_loss: 0.0383\n",
      "649/1088, train_loss: 0.0281\n",
      "650/1088, train_loss: 0.0299\n",
      "651/1088, train_loss: 0.0269\n",
      "652/1088, train_loss: 0.0273\n",
      "653/1088, train_loss: 0.0284\n",
      "654/1088, train_loss: 0.0307\n",
      "655/1088, train_loss: 0.0275\n",
      "656/1088, train_loss: 0.0284\n",
      "657/1088, train_loss: 0.0322\n",
      "658/1088, train_loss: 0.0305\n",
      "659/1088, train_loss: 0.0280\n",
      "660/1088, train_loss: 0.0301\n",
      "661/1088, train_loss: 0.0298\n",
      "662/1088, train_loss: 0.0273\n",
      "663/1088, train_loss: 0.0285\n",
      "664/1088, train_loss: 0.0307\n",
      "665/1088, train_loss: 0.0266\n",
      "666/1088, train_loss: 0.0295\n",
      "667/1088, train_loss: 0.0265\n",
      "668/1088, train_loss: 0.0262\n",
      "669/1088, train_loss: 0.0309\n",
      "670/1088, train_loss: 0.0270\n",
      "671/1088, train_loss: 0.0267\n",
      "672/1088, train_loss: 0.0294\n",
      "673/1088, train_loss: 0.0275\n",
      "674/1088, train_loss: 0.0278\n",
      "675/1088, train_loss: 0.0290\n",
      "676/1088, train_loss: 0.0292\n",
      "677/1088, train_loss: 0.0294\n",
      "678/1088, train_loss: 0.0300\n",
      "679/1088, train_loss: 0.0299\n",
      "680/1088, train_loss: 0.0267\n",
      "681/1088, train_loss: 0.0337\n",
      "682/1088, train_loss: 0.0288\n",
      "683/1088, train_loss: 0.0265\n",
      "684/1088, train_loss: 0.0263\n",
      "685/1088, train_loss: 0.0275\n",
      "686/1088, train_loss: 0.0324\n",
      "687/1088, train_loss: 0.0270\n",
      "688/1088, train_loss: 0.0308\n",
      "689/1088, train_loss: 0.0286\n",
      "690/1088, train_loss: 0.0307\n",
      "691/1088, train_loss: 0.0292\n",
      "692/1088, train_loss: 0.0273\n",
      "693/1088, train_loss: 0.0282\n",
      "694/1088, train_loss: 0.0277\n",
      "695/1088, train_loss: 0.0273\n",
      "696/1088, train_loss: 0.0278\n",
      "697/1088, train_loss: 0.0291\n",
      "698/1088, train_loss: 0.0275\n",
      "699/1088, train_loss: 0.0301\n",
      "700/1088, train_loss: 0.0278\n",
      "701/1088, train_loss: 0.0293\n",
      "702/1088, train_loss: 0.0277\n",
      "703/1088, train_loss: 0.0287\n",
      "704/1088, train_loss: 0.0273\n",
      "705/1088, train_loss: 0.0280\n",
      "706/1088, train_loss: 0.0301\n",
      "707/1088, train_loss: 0.0295\n",
      "708/1088, train_loss: 0.0345\n",
      "709/1088, train_loss: 0.0279\n",
      "710/1088, train_loss: 0.0283\n",
      "711/1088, train_loss: 0.0313\n",
      "712/1088, train_loss: 0.0320\n",
      "713/1088, train_loss: 0.0289\n",
      "714/1088, train_loss: 0.0322\n",
      "715/1088, train_loss: 0.0283\n",
      "716/1088, train_loss: 0.0323\n",
      "717/1088, train_loss: 0.0278\n",
      "718/1088, train_loss: 0.0296\n",
      "719/1088, train_loss: 0.0278\n",
      "720/1088, train_loss: 0.0341\n",
      "721/1088, train_loss: 0.0299\n",
      "722/1088, train_loss: 0.0282\n",
      "723/1088, train_loss: 0.0305\n",
      "724/1088, train_loss: 0.0265\n",
      "725/1088, train_loss: 0.0299\n",
      "726/1088, train_loss: 0.0302\n",
      "727/1088, train_loss: 0.0266\n",
      "728/1088, train_loss: 0.0288\n",
      "729/1088, train_loss: 0.0282\n",
      "730/1088, train_loss: 0.0282\n",
      "731/1088, train_loss: 0.0266\n",
      "732/1088, train_loss: 0.0295\n",
      "733/1088, train_loss: 0.0289\n",
      "734/1088, train_loss: 0.0307\n",
      "735/1088, train_loss: 0.0298\n",
      "736/1088, train_loss: 0.0266\n",
      "737/1088, train_loss: 0.0304\n",
      "738/1088, train_loss: 0.0260\n",
      "739/1088, train_loss: 0.0288\n",
      "740/1088, train_loss: 0.0300\n",
      "741/1088, train_loss: 0.0293\n",
      "742/1088, train_loss: 0.0257\n",
      "743/1088, train_loss: 0.0284\n",
      "744/1088, train_loss: 0.0326\n",
      "745/1088, train_loss: 0.0301\n",
      "746/1088, train_loss: 0.0261\n",
      "747/1088, train_loss: 0.0291\n",
      "748/1088, train_loss: 0.0293\n",
      "749/1088, train_loss: 0.0290\n",
      "750/1088, train_loss: 0.0256\n",
      "751/1088, train_loss: 0.0282\n",
      "752/1088, train_loss: 0.0278\n",
      "753/1088, train_loss: 0.0290\n",
      "754/1088, train_loss: 0.0288\n",
      "755/1088, train_loss: 0.0260\n",
      "756/1088, train_loss: 0.0278\n",
      "757/1088, train_loss: 0.0281\n",
      "758/1088, train_loss: 0.0301\n",
      "759/1088, train_loss: 0.0289\n",
      "760/1088, train_loss: 0.0296\n",
      "761/1088, train_loss: 0.0268\n",
      "762/1088, train_loss: 0.0278\n",
      "763/1088, train_loss: 0.0300\n",
      "764/1088, train_loss: 0.0292\n",
      "765/1088, train_loss: 0.0290\n",
      "766/1088, train_loss: 0.0278\n",
      "767/1088, train_loss: 0.0297\n",
      "768/1088, train_loss: 0.0277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769/1088, train_loss: 0.0284\n",
      "770/1088, train_loss: 0.0289\n",
      "771/1088, train_loss: 0.0271\n",
      "772/1088, train_loss: 0.0313\n",
      "773/1088, train_loss: 0.0308\n",
      "774/1088, train_loss: 0.0296\n",
      "775/1088, train_loss: 0.0264\n",
      "776/1088, train_loss: 0.0277\n",
      "777/1088, train_loss: 0.0280\n",
      "778/1088, train_loss: 0.0266\n",
      "779/1088, train_loss: 0.0261\n",
      "780/1088, train_loss: 0.0286\n",
      "781/1088, train_loss: 0.0334\n",
      "782/1088, train_loss: 0.0272\n",
      "783/1088, train_loss: 0.0279\n",
      "784/1088, train_loss: 0.0280\n",
      "785/1088, train_loss: 0.0293\n",
      "786/1088, train_loss: 0.0276\n",
      "787/1088, train_loss: 0.0287\n",
      "788/1088, train_loss: 0.0305\n",
      "789/1088, train_loss: 0.0302\n",
      "790/1088, train_loss: 0.0277\n",
      "791/1088, train_loss: 0.0276\n",
      "792/1088, train_loss: 0.0310\n",
      "793/1088, train_loss: 0.0277\n",
      "794/1088, train_loss: 0.0265\n",
      "795/1088, train_loss: 0.0282\n",
      "796/1088, train_loss: 0.0275\n",
      "797/1088, train_loss: 0.0284\n",
      "798/1088, train_loss: 0.0278\n",
      "799/1088, train_loss: 0.0287\n",
      "800/1088, train_loss: 0.0272\n",
      "801/1088, train_loss: 0.0332\n",
      "802/1088, train_loss: 0.0307\n",
      "803/1088, train_loss: 0.0339\n",
      "804/1088, train_loss: 0.0320\n",
      "805/1088, train_loss: 0.0293\n",
      "806/1088, train_loss: 0.0306\n",
      "807/1088, train_loss: 0.0308\n",
      "808/1088, train_loss: 0.0298\n",
      "809/1088, train_loss: 0.0280\n",
      "810/1088, train_loss: 0.0297\n",
      "811/1088, train_loss: 0.0325\n",
      "812/1088, train_loss: 0.0340\n",
      "813/1088, train_loss: 0.0291\n",
      "814/1088, train_loss: 0.0385\n",
      "815/1088, train_loss: 0.0301\n",
      "816/1088, train_loss: 0.0286\n",
      "817/1088, train_loss: 0.0254\n",
      "818/1088, train_loss: 0.0319\n",
      "819/1088, train_loss: 0.0288\n",
      "820/1088, train_loss: 0.0296\n",
      "821/1088, train_loss: 0.0290\n",
      "822/1088, train_loss: 0.0286\n",
      "823/1088, train_loss: 0.0278\n",
      "824/1088, train_loss: 0.0283\n",
      "825/1088, train_loss: 0.0281\n",
      "826/1088, train_loss: 0.0283\n",
      "827/1088, train_loss: 0.0305\n",
      "828/1088, train_loss: 0.0305\n",
      "829/1088, train_loss: 0.0291\n",
      "830/1088, train_loss: 0.0288\n",
      "831/1088, train_loss: 0.0291\n",
      "832/1088, train_loss: 0.0305\n",
      "833/1088, train_loss: 0.0313\n",
      "834/1088, train_loss: 0.0267\n",
      "835/1088, train_loss: 0.0283\n",
      "836/1088, train_loss: 0.0298\n",
      "837/1088, train_loss: 0.0287\n",
      "838/1088, train_loss: 0.0292\n",
      "839/1088, train_loss: 0.0335\n",
      "840/1088, train_loss: 0.0294\n",
      "841/1088, train_loss: 0.0276\n",
      "842/1088, train_loss: 0.0289\n",
      "843/1088, train_loss: 0.0268\n",
      "844/1088, train_loss: 0.0288\n",
      "845/1088, train_loss: 0.0305\n",
      "846/1088, train_loss: 0.0296\n",
      "847/1088, train_loss: 0.0291\n",
      "848/1088, train_loss: 0.0269\n",
      "849/1088, train_loss: 0.0298\n",
      "850/1088, train_loss: 0.0274\n",
      "851/1088, train_loss: 0.0269\n",
      "852/1088, train_loss: 0.0285\n",
      "853/1088, train_loss: 0.0332\n",
      "854/1088, train_loss: 0.0294\n",
      "855/1088, train_loss: 0.0294\n",
      "856/1088, train_loss: 0.0291\n",
      "857/1088, train_loss: 0.0317\n",
      "858/1088, train_loss: 0.0305\n",
      "859/1088, train_loss: 0.0282\n",
      "860/1088, train_loss: 0.0289\n",
      "861/1088, train_loss: 0.0285\n",
      "862/1088, train_loss: 0.0280\n",
      "863/1088, train_loss: 0.0293\n",
      "864/1088, train_loss: 0.0266\n",
      "865/1088, train_loss: 0.0314\n",
      "866/1088, train_loss: 0.0278\n",
      "867/1088, train_loss: 0.0295\n",
      "868/1088, train_loss: 0.0290\n",
      "869/1088, train_loss: 0.0301\n",
      "870/1088, train_loss: 0.0297\n",
      "871/1088, train_loss: 0.0311\n",
      "872/1088, train_loss: 0.0301\n",
      "873/1088, train_loss: 0.0286\n",
      "874/1088, train_loss: 0.0275\n",
      "875/1088, train_loss: 0.0274\n",
      "876/1088, train_loss: 0.0284\n",
      "877/1088, train_loss: 0.0329\n",
      "878/1088, train_loss: 0.0268\n",
      "879/1088, train_loss: 0.0268\n",
      "880/1088, train_loss: 0.0268\n",
      "881/1088, train_loss: 0.0306\n",
      "882/1088, train_loss: 0.0274\n",
      "883/1088, train_loss: 0.0272\n",
      "884/1088, train_loss: 0.0270\n",
      "885/1088, train_loss: 0.0285\n",
      "886/1088, train_loss: 0.0284\n",
      "887/1088, train_loss: 0.0281\n",
      "888/1088, train_loss: 0.0316\n",
      "889/1088, train_loss: 0.0311\n",
      "890/1088, train_loss: 0.0302\n",
      "891/1088, train_loss: 0.0286\n",
      "892/1088, train_loss: 0.0297\n",
      "893/1088, train_loss: 0.0294\n",
      "894/1088, train_loss: 0.0309\n",
      "895/1088, train_loss: 0.0311\n",
      "896/1088, train_loss: 0.0326\n",
      "897/1088, train_loss: 0.0281\n",
      "898/1088, train_loss: 0.0296\n",
      "899/1088, train_loss: 0.0298\n",
      "900/1088, train_loss: 0.0289\n",
      "901/1088, train_loss: 0.0292\n",
      "902/1088, train_loss: 0.0282\n",
      "903/1088, train_loss: 0.0270\n",
      "904/1088, train_loss: 0.0266\n",
      "905/1088, train_loss: 0.0313\n",
      "906/1088, train_loss: 0.0264\n",
      "907/1088, train_loss: 0.0293\n",
      "908/1088, train_loss: 0.0291\n",
      "909/1088, train_loss: 0.0292\n",
      "910/1088, train_loss: 0.0301\n",
      "911/1088, train_loss: 0.0296\n",
      "912/1088, train_loss: 0.0293\n",
      "913/1088, train_loss: 0.0299\n",
      "914/1088, train_loss: 0.0294\n",
      "915/1088, train_loss: 0.0292\n",
      "916/1088, train_loss: 0.0293\n",
      "917/1088, train_loss: 0.0281\n",
      "918/1088, train_loss: 0.0299\n",
      "919/1088, train_loss: 0.0288\n",
      "920/1088, train_loss: 0.0278\n",
      "921/1088, train_loss: 0.0270\n",
      "922/1088, train_loss: 0.0289\n",
      "923/1088, train_loss: 0.0300\n",
      "924/1088, train_loss: 0.0288\n",
      "925/1088, train_loss: 0.0285\n",
      "926/1088, train_loss: 0.0307\n",
      "927/1088, train_loss: 0.0292\n",
      "928/1088, train_loss: 0.0275\n",
      "929/1088, train_loss: 0.0296\n",
      "930/1088, train_loss: 0.0290\n",
      "931/1088, train_loss: 0.0281\n",
      "932/1088, train_loss: 0.0284\n",
      "933/1088, train_loss: 0.0258\n",
      "934/1088, train_loss: 0.0283\n",
      "935/1088, train_loss: 0.0301\n",
      "936/1088, train_loss: 0.0273\n",
      "937/1088, train_loss: 0.0283\n",
      "938/1088, train_loss: 0.0276\n",
      "939/1088, train_loss: 0.0340\n",
      "940/1088, train_loss: 0.0274\n",
      "941/1088, train_loss: 0.0284\n",
      "942/1088, train_loss: 0.0278\n",
      "943/1088, train_loss: 0.0288\n",
      "944/1088, train_loss: 0.0287\n",
      "945/1088, train_loss: 0.0279\n",
      "946/1088, train_loss: 0.0289\n",
      "947/1088, train_loss: 0.0282\n",
      "948/1088, train_loss: 0.0293\n",
      "949/1088, train_loss: 0.0288\n",
      "950/1088, train_loss: 0.0282\n",
      "951/1088, train_loss: 0.0292\n",
      "952/1088, train_loss: 0.0281\n",
      "953/1088, train_loss: 0.0281\n",
      "954/1088, train_loss: 0.0292\n",
      "955/1088, train_loss: 0.0304\n",
      "956/1088, train_loss: 0.0297\n",
      "957/1088, train_loss: 0.0276\n",
      "958/1088, train_loss: 0.0287\n",
      "959/1088, train_loss: 0.0300\n",
      "960/1088, train_loss: 0.0351\n",
      "961/1088, train_loss: 0.0292\n",
      "962/1088, train_loss: 0.0284\n",
      "963/1088, train_loss: 0.0268\n",
      "964/1088, train_loss: 0.0297\n",
      "965/1088, train_loss: 0.0266\n",
      "966/1088, train_loss: 0.0269\n",
      "967/1088, train_loss: 0.0285\n",
      "968/1088, train_loss: 0.0267\n",
      "969/1088, train_loss: 0.0265\n",
      "970/1088, train_loss: 0.0262\n",
      "971/1088, train_loss: 0.0262\n",
      "972/1088, train_loss: 0.0283\n",
      "973/1088, train_loss: 0.0316\n",
      "974/1088, train_loss: 0.0287\n",
      "975/1088, train_loss: 0.0300\n",
      "976/1088, train_loss: 0.0263\n",
      "977/1088, train_loss: 0.0279\n",
      "978/1088, train_loss: 0.0266\n",
      "979/1088, train_loss: 0.0295\n",
      "980/1088, train_loss: 0.0281\n",
      "981/1088, train_loss: 0.0290\n",
      "982/1088, train_loss: 0.0270\n",
      "983/1088, train_loss: 0.0292\n",
      "984/1088, train_loss: 0.0279\n",
      "985/1088, train_loss: 0.0280\n",
      "986/1088, train_loss: 0.0280\n",
      "987/1088, train_loss: 0.0275\n",
      "988/1088, train_loss: 0.0305\n",
      "989/1088, train_loss: 0.0312\n",
      "990/1088, train_loss: 0.0273\n",
      "991/1088, train_loss: 0.0287\n",
      "992/1088, train_loss: 0.0267\n",
      "993/1088, train_loss: 0.0257\n",
      "994/1088, train_loss: 0.0287\n",
      "995/1088, train_loss: 0.0320\n",
      "996/1088, train_loss: 0.0283\n",
      "997/1088, train_loss: 0.0290\n",
      "998/1088, train_loss: 0.0275\n",
      "999/1088, train_loss: 0.0313\n",
      "1000/1088, train_loss: 0.0318\n",
      "1001/1088, train_loss: 0.0295\n",
      "1002/1088, train_loss: 0.0309\n",
      "1003/1088, train_loss: 0.0313\n",
      "1004/1088, train_loss: 0.0291\n",
      "1005/1088, train_loss: 0.0263\n",
      "1006/1088, train_loss: 0.0313\n",
      "1007/1088, train_loss: 0.0271\n",
      "1008/1088, train_loss: 0.0289\n",
      "1009/1088, train_loss: 0.0293\n",
      "1010/1088, train_loss: 0.0347\n",
      "1011/1088, train_loss: 0.0287\n",
      "1012/1088, train_loss: 0.0295\n",
      "1013/1088, train_loss: 0.0294\n",
      "1014/1088, train_loss: 0.0346\n",
      "1015/1088, train_loss: 0.0281\n",
      "1016/1088, train_loss: 0.0295\n",
      "1017/1088, train_loss: 0.0301\n",
      "1018/1088, train_loss: 0.0277\n",
      "1019/1088, train_loss: 0.0265\n",
      "1020/1088, train_loss: 0.0277\n",
      "1021/1088, train_loss: 0.0288\n",
      "1022/1088, train_loss: 0.0296\n",
      "1023/1088, train_loss: 0.0303\n",
      "1024/1088, train_loss: 0.0285\n",
      "1025/1088, train_loss: 0.0286\n",
      "1026/1088, train_loss: 0.0272\n",
      "1027/1088, train_loss: 0.0306\n",
      "1028/1088, train_loss: 0.0296\n",
      "1029/1088, train_loss: 0.0278\n",
      "1030/1088, train_loss: 0.0288\n",
      "1031/1088, train_loss: 0.0285\n",
      "1032/1088, train_loss: 0.0284\n",
      "1033/1088, train_loss: 0.0293\n",
      "1034/1088, train_loss: 0.0302\n",
      "1035/1088, train_loss: 0.0294\n",
      "1036/1088, train_loss: 0.0285\n",
      "1037/1088, train_loss: 0.0286\n",
      "1038/1088, train_loss: 0.0283\n",
      "1039/1088, train_loss: 0.0281\n",
      "1040/1088, train_loss: 0.0298\n",
      "1041/1088, train_loss: 0.0284\n",
      "1042/1088, train_loss: 0.0295\n",
      "1043/1088, train_loss: 0.0284\n",
      "1044/1088, train_loss: 0.0277\n",
      "1045/1088, train_loss: 0.0301\n",
      "1046/1088, train_loss: 0.0270\n",
      "1047/1088, train_loss: 0.0318\n",
      "1048/1088, train_loss: 0.0266\n",
      "1049/1088, train_loss: 0.0296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1088, train_loss: 0.0278\n",
      "1051/1088, train_loss: 0.0281\n",
      "1052/1088, train_loss: 0.0276\n",
      "1053/1088, train_loss: 0.0298\n",
      "1054/1088, train_loss: 0.0285\n",
      "1055/1088, train_loss: 0.0275\n",
      "1056/1088, train_loss: 0.0294\n",
      "1057/1088, train_loss: 0.0304\n",
      "1058/1088, train_loss: 0.0295\n",
      "1059/1088, train_loss: 0.0297\n",
      "1060/1088, train_loss: 0.0283\n",
      "1061/1088, train_loss: 0.0322\n",
      "1062/1088, train_loss: 0.0287\n",
      "1063/1088, train_loss: 0.0287\n",
      "1064/1088, train_loss: 0.0298\n",
      "1065/1088, train_loss: 0.0297\n",
      "1066/1088, train_loss: 0.0305\n",
      "1067/1088, train_loss: 0.0308\n",
      "1068/1088, train_loss: 0.0273\n",
      "1069/1088, train_loss: 0.0286\n",
      "1070/1088, train_loss: 0.0288\n",
      "1071/1088, train_loss: 0.0305\n",
      "1072/1088, train_loss: 0.0310\n",
      "1073/1088, train_loss: 0.0262\n",
      "1074/1088, train_loss: 0.0300\n",
      "1075/1088, train_loss: 0.0283\n",
      "1076/1088, train_loss: 0.0284\n",
      "1077/1088, train_loss: 0.0312\n",
      "1078/1088, train_loss: 0.0283\n",
      "1079/1088, train_loss: 0.0279\n",
      "1080/1088, train_loss: 0.0283\n",
      "1081/1088, train_loss: 0.0302\n",
      "1082/1088, train_loss: 0.0303\n",
      "1083/1088, train_loss: 0.0276\n",
      "1084/1088, train_loss: 0.0265\n",
      "1085/1088, train_loss: 0.0315\n",
      "1086/1088, train_loss: 0.0275\n",
      "1087/1088, train_loss: 0.0290\n",
      "1088/1088, train_loss: 0.0294\n",
      "1089/1088, train_loss: 0.0270\n",
      "epoch 15 average loss: 0.0290, train_dice: 0.9710\n",
      "epoch 15 average loss: 0.0290\n",
      "--------------------------------------------------\n",
      "epoch 16/50\n",
      "1/1088, train_loss: 0.0283\n",
      "2/1088, train_loss: 0.0291\n",
      "3/1088, train_loss: 0.0290\n",
      "4/1088, train_loss: 0.0281\n",
      "5/1088, train_loss: 0.0284\n",
      "6/1088, train_loss: 0.0287\n",
      "7/1088, train_loss: 0.0280\n",
      "8/1088, train_loss: 0.0282\n",
      "9/1088, train_loss: 0.0290\n",
      "10/1088, train_loss: 0.0306\n",
      "11/1088, train_loss: 0.0308\n",
      "12/1088, train_loss: 0.0281\n",
      "13/1088, train_loss: 0.0271\n",
      "14/1088, train_loss: 0.0277\n",
      "15/1088, train_loss: 0.0293\n",
      "16/1088, train_loss: 0.0293\n",
      "17/1088, train_loss: 0.0275\n",
      "18/1088, train_loss: 0.0307\n",
      "19/1088, train_loss: 0.0266\n",
      "20/1088, train_loss: 0.0308\n",
      "21/1088, train_loss: 0.0308\n",
      "22/1088, train_loss: 0.0309\n",
      "23/1088, train_loss: 0.0276\n",
      "24/1088, train_loss: 0.0263\n",
      "25/1088, train_loss: 0.0272\n",
      "26/1088, train_loss: 0.0355\n",
      "27/1088, train_loss: 0.0280\n",
      "28/1088, train_loss: 0.0265\n",
      "29/1088, train_loss: 0.0288\n",
      "30/1088, train_loss: 0.0270\n",
      "31/1088, train_loss: 0.0299\n",
      "32/1088, train_loss: 0.0288\n",
      "33/1088, train_loss: 0.0273\n",
      "34/1088, train_loss: 0.0302\n",
      "35/1088, train_loss: 0.0269\n",
      "36/1088, train_loss: 0.0279\n",
      "37/1088, train_loss: 0.0268\n",
      "38/1088, train_loss: 0.0282\n",
      "39/1088, train_loss: 0.0278\n",
      "40/1088, train_loss: 0.0293\n",
      "41/1088, train_loss: 0.0305\n",
      "42/1088, train_loss: 0.0276\n",
      "43/1088, train_loss: 0.0284\n",
      "44/1088, train_loss: 0.0259\n",
      "45/1088, train_loss: 0.0280\n",
      "46/1088, train_loss: 0.0269\n",
      "47/1088, train_loss: 0.0291\n",
      "48/1088, train_loss: 0.0304\n",
      "49/1088, train_loss: 0.0297\n",
      "50/1088, train_loss: 0.0297\n",
      "51/1088, train_loss: 0.0309\n",
      "52/1088, train_loss: 0.0306\n",
      "53/1088, train_loss: 0.0286\n",
      "54/1088, train_loss: 0.0273\n",
      "55/1088, train_loss: 0.0261\n",
      "56/1088, train_loss: 0.0291\n",
      "57/1088, train_loss: 0.0270\n",
      "58/1088, train_loss: 0.0268\n",
      "59/1088, train_loss: 0.0291\n",
      "60/1088, train_loss: 0.0284\n",
      "61/1088, train_loss: 0.0297\n",
      "62/1088, train_loss: 0.0347\n",
      "63/1088, train_loss: 0.0292\n",
      "64/1088, train_loss: 0.0298\n",
      "65/1088, train_loss: 0.0296\n",
      "66/1088, train_loss: 0.0296\n",
      "67/1088, train_loss: 0.0282\n",
      "68/1088, train_loss: 0.0319\n",
      "69/1088, train_loss: 0.0278\n",
      "70/1088, train_loss: 0.0308\n",
      "71/1088, train_loss: 0.0280\n",
      "72/1088, train_loss: 0.0310\n",
      "73/1088, train_loss: 0.0259\n",
      "74/1088, train_loss: 0.0269\n",
      "75/1088, train_loss: 0.0271\n",
      "76/1088, train_loss: 0.0293\n",
      "77/1088, train_loss: 0.0290\n",
      "78/1088, train_loss: 0.0298\n",
      "79/1088, train_loss: 0.0314\n",
      "80/1088, train_loss: 0.0279\n",
      "81/1088, train_loss: 0.0308\n",
      "82/1088, train_loss: 0.0277\n",
      "83/1088, train_loss: 0.0298\n",
      "84/1088, train_loss: 0.0284\n",
      "85/1088, train_loss: 0.0279\n",
      "86/1088, train_loss: 0.0292\n",
      "87/1088, train_loss: 0.0294\n",
      "88/1088, train_loss: 0.0297\n",
      "89/1088, train_loss: 0.0284\n",
      "90/1088, train_loss: 0.0272\n",
      "91/1088, train_loss: 0.0296\n",
      "92/1088, train_loss: 0.0278\n",
      "93/1088, train_loss: 0.0281\n",
      "94/1088, train_loss: 0.0274\n",
      "95/1088, train_loss: 0.0288\n",
      "96/1088, train_loss: 0.0285\n",
      "97/1088, train_loss: 0.0291\n",
      "98/1088, train_loss: 0.0295\n",
      "99/1088, train_loss: 0.0291\n",
      "100/1088, train_loss: 0.0292\n",
      "101/1088, train_loss: 0.0284\n",
      "102/1088, train_loss: 0.0312\n",
      "103/1088, train_loss: 0.0292\n",
      "104/1088, train_loss: 0.0295\n",
      "105/1088, train_loss: 0.0277\n",
      "106/1088, train_loss: 0.0283\n",
      "107/1088, train_loss: 0.0328\n",
      "108/1088, train_loss: 0.0320\n",
      "109/1088, train_loss: 0.0294\n",
      "110/1088, train_loss: 0.0280\n",
      "111/1088, train_loss: 0.0293\n",
      "112/1088, train_loss: 0.0262\n",
      "113/1088, train_loss: 0.0289\n",
      "114/1088, train_loss: 0.0284\n",
      "115/1088, train_loss: 0.0292\n",
      "116/1088, train_loss: 0.0292\n",
      "117/1088, train_loss: 0.0291\n",
      "118/1088, train_loss: 0.0293\n",
      "119/1088, train_loss: 0.0278\n",
      "120/1088, train_loss: 0.0281\n",
      "121/1088, train_loss: 0.0279\n",
      "122/1088, train_loss: 0.0303\n",
      "123/1088, train_loss: 0.0254\n",
      "124/1088, train_loss: 0.0275\n",
      "125/1088, train_loss: 0.0268\n",
      "126/1088, train_loss: 0.0297\n",
      "127/1088, train_loss: 0.0267\n",
      "128/1088, train_loss: 0.0282\n",
      "129/1088, train_loss: 0.0268\n",
      "130/1088, train_loss: 0.0294\n",
      "131/1088, train_loss: 0.0272\n",
      "132/1088, train_loss: 0.0284\n",
      "133/1088, train_loss: 0.0289\n",
      "134/1088, train_loss: 0.0331\n",
      "135/1088, train_loss: 0.0303\n",
      "136/1088, train_loss: 0.0288\n",
      "137/1088, train_loss: 0.0297\n",
      "138/1088, train_loss: 0.0282\n",
      "139/1088, train_loss: 0.0284\n",
      "140/1088, train_loss: 0.0300\n",
      "141/1088, train_loss: 0.0283\n",
      "142/1088, train_loss: 0.0274\n",
      "143/1088, train_loss: 0.0303\n",
      "144/1088, train_loss: 0.0283\n",
      "145/1088, train_loss: 0.0278\n",
      "146/1088, train_loss: 0.0294\n",
      "147/1088, train_loss: 0.0305\n",
      "148/1088, train_loss: 0.0267\n",
      "149/1088, train_loss: 0.0284\n",
      "150/1088, train_loss: 0.0272\n",
      "151/1088, train_loss: 0.0287\n",
      "152/1088, train_loss: 0.0286\n",
      "153/1088, train_loss: 0.0273\n",
      "154/1088, train_loss: 0.0263\n",
      "155/1088, train_loss: 0.0301\n",
      "156/1088, train_loss: 0.0274\n",
      "157/1088, train_loss: 0.0280\n",
      "158/1088, train_loss: 0.0279\n",
      "159/1088, train_loss: 0.0270\n",
      "160/1088, train_loss: 0.0303\n",
      "161/1088, train_loss: 0.0299\n",
      "162/1088, train_loss: 0.0278\n",
      "163/1088, train_loss: 0.0316\n",
      "164/1088, train_loss: 0.0269\n",
      "165/1088, train_loss: 0.0293\n",
      "166/1088, train_loss: 0.0290\n",
      "167/1088, train_loss: 0.0267\n",
      "168/1088, train_loss: 0.0275\n",
      "169/1088, train_loss: 0.0326\n",
      "170/1088, train_loss: 0.0298\n",
      "171/1088, train_loss: 0.0261\n",
      "172/1088, train_loss: 0.0282\n",
      "173/1088, train_loss: 0.0281\n",
      "174/1088, train_loss: 0.0293\n",
      "175/1088, train_loss: 0.0326\n",
      "176/1088, train_loss: 0.0285\n",
      "177/1088, train_loss: 0.0274\n",
      "178/1088, train_loss: 0.0273\n",
      "179/1088, train_loss: 0.0284\n",
      "180/1088, train_loss: 0.0272\n",
      "181/1088, train_loss: 0.0286\n",
      "182/1088, train_loss: 0.0378\n",
      "183/1088, train_loss: 0.0289\n",
      "184/1088, train_loss: 0.0277\n",
      "185/1088, train_loss: 0.0278\n",
      "186/1088, train_loss: 0.0278\n",
      "187/1088, train_loss: 0.0320\n",
      "188/1088, train_loss: 0.0263\n",
      "189/1088, train_loss: 0.0293\n",
      "190/1088, train_loss: 0.0294\n",
      "191/1088, train_loss: 0.0289\n",
      "192/1088, train_loss: 0.0302\n",
      "193/1088, train_loss: 0.0272\n",
      "194/1088, train_loss: 0.0293\n",
      "195/1088, train_loss: 0.0318\n",
      "196/1088, train_loss: 0.0297\n",
      "197/1088, train_loss: 0.0270\n",
      "198/1088, train_loss: 0.0285\n",
      "199/1088, train_loss: 0.0275\n",
      "200/1088, train_loss: 0.0366\n",
      "201/1088, train_loss: 0.0300\n",
      "202/1088, train_loss: 0.0258\n",
      "203/1088, train_loss: 0.0281\n",
      "204/1088, train_loss: 0.0296\n",
      "205/1088, train_loss: 0.0272\n",
      "206/1088, train_loss: 0.0294\n",
      "207/1088, train_loss: 0.0285\n",
      "208/1088, train_loss: 0.0278\n",
      "209/1088, train_loss: 0.0284\n",
      "210/1088, train_loss: 0.0293\n",
      "211/1088, train_loss: 0.0272\n",
      "212/1088, train_loss: 0.0314\n",
      "213/1088, train_loss: 0.0296\n",
      "214/1088, train_loss: 0.0276\n",
      "215/1088, train_loss: 0.0298\n",
      "216/1088, train_loss: 0.0294\n",
      "217/1088, train_loss: 0.0284\n",
      "218/1088, train_loss: 0.0275\n",
      "219/1088, train_loss: 0.0277\n",
      "220/1088, train_loss: 0.0292\n",
      "221/1088, train_loss: 0.0288\n",
      "222/1088, train_loss: 0.0301\n",
      "223/1088, train_loss: 0.0271\n",
      "224/1088, train_loss: 0.0294\n",
      "225/1088, train_loss: 0.0292\n",
      "226/1088, train_loss: 0.0275\n",
      "227/1088, train_loss: 0.0291\n",
      "228/1088, train_loss: 0.0288\n",
      "229/1088, train_loss: 0.0270\n",
      "230/1088, train_loss: 0.0280\n",
      "231/1088, train_loss: 0.0273\n",
      "232/1088, train_loss: 0.0286\n",
      "233/1088, train_loss: 0.0297\n",
      "234/1088, train_loss: 0.0287\n",
      "235/1088, train_loss: 0.0311\n",
      "236/1088, train_loss: 0.0312\n",
      "237/1088, train_loss: 0.0293\n",
      "238/1088, train_loss: 0.0286\n",
      "239/1088, train_loss: 0.0281\n",
      "240/1088, train_loss: 0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/1088, train_loss: 0.0286\n",
      "242/1088, train_loss: 0.0273\n",
      "243/1088, train_loss: 0.0312\n",
      "244/1088, train_loss: 0.0305\n",
      "245/1088, train_loss: 0.0275\n",
      "246/1088, train_loss: 0.0298\n",
      "247/1088, train_loss: 0.0293\n",
      "248/1088, train_loss: 0.0286\n",
      "249/1088, train_loss: 0.0287\n",
      "250/1088, train_loss: 0.0276\n",
      "251/1088, train_loss: 0.0270\n",
      "252/1088, train_loss: 0.0269\n",
      "253/1088, train_loss: 0.0299\n",
      "254/1088, train_loss: 0.0267\n",
      "255/1088, train_loss: 0.0306\n",
      "256/1088, train_loss: 0.0277\n",
      "257/1088, train_loss: 0.0279\n",
      "258/1088, train_loss: 0.0287\n",
      "259/1088, train_loss: 0.0289\n",
      "260/1088, train_loss: 0.0274\n",
      "261/1088, train_loss: 0.0298\n",
      "262/1088, train_loss: 0.0285\n",
      "263/1088, train_loss: 0.0259\n",
      "264/1088, train_loss: 0.0308\n",
      "265/1088, train_loss: 0.0288\n",
      "266/1088, train_loss: 0.0266\n",
      "267/1088, train_loss: 0.0300\n",
      "268/1088, train_loss: 0.0279\n",
      "269/1088, train_loss: 0.0253\n",
      "270/1088, train_loss: 0.0286\n",
      "271/1088, train_loss: 0.0274\n",
      "272/1088, train_loss: 0.0293\n",
      "273/1088, train_loss: 0.0282\n",
      "274/1088, train_loss: 0.0298\n",
      "275/1088, train_loss: 0.0270\n",
      "276/1088, train_loss: 0.0307\n",
      "277/1088, train_loss: 0.0286\n",
      "278/1088, train_loss: 0.0262\n",
      "279/1088, train_loss: 0.0276\n",
      "280/1088, train_loss: 0.0293\n",
      "281/1088, train_loss: 0.0272\n",
      "282/1088, train_loss: 0.0314\n",
      "283/1088, train_loss: 0.0289\n",
      "284/1088, train_loss: 0.0284\n",
      "285/1088, train_loss: 0.0290\n",
      "286/1088, train_loss: 0.0299\n",
      "287/1088, train_loss: 0.0294\n",
      "288/1088, train_loss: 0.0306\n",
      "289/1088, train_loss: 0.0269\n",
      "290/1088, train_loss: 0.0293\n",
      "291/1088, train_loss: 0.0295\n",
      "292/1088, train_loss: 0.0268\n",
      "293/1088, train_loss: 0.0304\n",
      "294/1088, train_loss: 0.0273\n",
      "295/1088, train_loss: 0.0281\n",
      "296/1088, train_loss: 0.0292\n",
      "297/1088, train_loss: 0.0289\n",
      "298/1088, train_loss: 0.0278\n",
      "299/1088, train_loss: 0.0271\n",
      "300/1088, train_loss: 0.0281\n",
      "301/1088, train_loss: 0.0277\n",
      "302/1088, train_loss: 0.0308\n",
      "303/1088, train_loss: 0.0274\n",
      "304/1088, train_loss: 0.0277\n",
      "305/1088, train_loss: 0.0265\n",
      "306/1088, train_loss: 0.0311\n",
      "307/1088, train_loss: 0.0280\n",
      "308/1088, train_loss: 0.0296\n",
      "309/1088, train_loss: 0.0271\n",
      "310/1088, train_loss: 0.0314\n",
      "311/1088, train_loss: 0.0298\n",
      "312/1088, train_loss: 0.0298\n",
      "313/1088, train_loss: 0.0294\n",
      "314/1088, train_loss: 0.0287\n",
      "315/1088, train_loss: 0.0304\n",
      "316/1088, train_loss: 0.0293\n",
      "317/1088, train_loss: 0.0297\n",
      "318/1088, train_loss: 0.0295\n",
      "319/1088, train_loss: 0.0303\n",
      "320/1088, train_loss: 0.0286\n",
      "321/1088, train_loss: 0.0313\n",
      "322/1088, train_loss: 0.0299\n",
      "323/1088, train_loss: 0.0291\n",
      "324/1088, train_loss: 0.0269\n",
      "325/1088, train_loss: 0.0271\n",
      "326/1088, train_loss: 0.0293\n",
      "327/1088, train_loss: 0.0289\n",
      "328/1088, train_loss: 0.0304\n",
      "329/1088, train_loss: 0.0304\n",
      "330/1088, train_loss: 0.0283\n",
      "331/1088, train_loss: 0.0308\n",
      "332/1088, train_loss: 0.0312\n",
      "333/1088, train_loss: 0.0283\n",
      "334/1088, train_loss: 0.0281\n",
      "335/1088, train_loss: 0.0285\n",
      "336/1088, train_loss: 0.0269\n",
      "337/1088, train_loss: 0.0308\n",
      "338/1088, train_loss: 0.0282\n",
      "339/1088, train_loss: 0.0298\n",
      "340/1088, train_loss: 0.0287\n",
      "341/1088, train_loss: 0.0339\n",
      "342/1088, train_loss: 0.0293\n",
      "343/1088, train_loss: 0.0291\n",
      "344/1088, train_loss: 0.0282\n",
      "345/1088, train_loss: 0.0286\n",
      "346/1088, train_loss: 0.0275\n",
      "347/1088, train_loss: 0.0311\n",
      "348/1088, train_loss: 0.0261\n",
      "349/1088, train_loss: 0.0283\n",
      "350/1088, train_loss: 0.0303\n",
      "351/1088, train_loss: 0.0274\n",
      "352/1088, train_loss: 0.0273\n",
      "353/1088, train_loss: 0.0275\n",
      "354/1088, train_loss: 0.0276\n",
      "355/1088, train_loss: 0.0284\n",
      "356/1088, train_loss: 0.0283\n",
      "357/1088, train_loss: 0.0261\n",
      "358/1088, train_loss: 0.0286\n",
      "359/1088, train_loss: 0.0254\n",
      "360/1088, train_loss: 0.0283\n",
      "361/1088, train_loss: 0.0296\n",
      "362/1088, train_loss: 0.0295\n",
      "363/1088, train_loss: 0.0306\n",
      "364/1088, train_loss: 0.0277\n",
      "365/1088, train_loss: 0.0269\n",
      "366/1088, train_loss: 0.0306\n",
      "367/1088, train_loss: 0.0297\n",
      "368/1088, train_loss: 0.0270\n",
      "369/1088, train_loss: 0.0265\n",
      "370/1088, train_loss: 0.0273\n",
      "371/1088, train_loss: 0.0279\n",
      "372/1088, train_loss: 0.0298\n",
      "373/1088, train_loss: 0.0279\n",
      "374/1088, train_loss: 0.0312\n",
      "375/1088, train_loss: 0.0261\n",
      "376/1088, train_loss: 0.0268\n",
      "377/1088, train_loss: 0.0279\n",
      "378/1088, train_loss: 0.0279\n",
      "379/1088, train_loss: 0.0289\n",
      "380/1088, train_loss: 0.0281\n",
      "381/1088, train_loss: 0.0268\n",
      "382/1088, train_loss: 0.0293\n",
      "383/1088, train_loss: 0.0291\n",
      "384/1088, train_loss: 0.0262\n",
      "385/1088, train_loss: 0.0268\n",
      "386/1088, train_loss: 0.0267\n",
      "387/1088, train_loss: 0.0295\n",
      "388/1088, train_loss: 0.0267\n",
      "389/1088, train_loss: 0.0334\n",
      "390/1088, train_loss: 0.0366\n",
      "391/1088, train_loss: 0.0300\n",
      "392/1088, train_loss: 0.0287\n",
      "393/1088, train_loss: 0.0296\n",
      "394/1088, train_loss: 0.0303\n",
      "395/1088, train_loss: 0.0313\n",
      "396/1088, train_loss: 0.0319\n",
      "397/1088, train_loss: 0.0288\n",
      "398/1088, train_loss: 0.0275\n",
      "399/1088, train_loss: 0.0295\n",
      "400/1088, train_loss: 0.0282\n",
      "401/1088, train_loss: 0.0284\n",
      "402/1088, train_loss: 0.0253\n",
      "403/1088, train_loss: 0.0284\n",
      "404/1088, train_loss: 0.0261\n",
      "405/1088, train_loss: 0.0263\n",
      "406/1088, train_loss: 0.0312\n",
      "407/1088, train_loss: 0.0310\n",
      "408/1088, train_loss: 0.0297\n",
      "409/1088, train_loss: 0.0270\n",
      "410/1088, train_loss: 0.0297\n",
      "411/1088, train_loss: 0.0300\n",
      "412/1088, train_loss: 0.0307\n",
      "413/1088, train_loss: 0.0295\n",
      "414/1088, train_loss: 0.0273\n",
      "415/1088, train_loss: 0.0300\n",
      "416/1088, train_loss: 0.0296\n",
      "417/1088, train_loss: 0.0283\n",
      "418/1088, train_loss: 0.0278\n",
      "419/1088, train_loss: 0.0289\n",
      "420/1088, train_loss: 0.0299\n",
      "421/1088, train_loss: 0.0280\n",
      "422/1088, train_loss: 0.0286\n",
      "423/1088, train_loss: 0.0286\n",
      "424/1088, train_loss: 0.0308\n",
      "425/1088, train_loss: 0.0378\n",
      "426/1088, train_loss: 0.0276\n",
      "427/1088, train_loss: 0.0275\n",
      "428/1088, train_loss: 0.0286\n",
      "429/1088, train_loss: 0.0292\n",
      "430/1088, train_loss: 0.0285\n",
      "431/1088, train_loss: 0.0285\n",
      "432/1088, train_loss: 0.0285\n",
      "433/1088, train_loss: 0.0362\n",
      "434/1088, train_loss: 0.0294\n",
      "435/1088, train_loss: 0.0300\n",
      "436/1088, train_loss: 0.0299\n",
      "437/1088, train_loss: 0.0283\n",
      "438/1088, train_loss: 0.0284\n",
      "439/1088, train_loss: 0.0279\n",
      "440/1088, train_loss: 0.0274\n",
      "441/1088, train_loss: 0.0281\n",
      "442/1088, train_loss: 0.0291\n",
      "443/1088, train_loss: 0.0287\n",
      "444/1088, train_loss: 0.0345\n",
      "445/1088, train_loss: 0.0305\n",
      "446/1088, train_loss: 0.0291\n",
      "447/1088, train_loss: 0.0297\n",
      "448/1088, train_loss: 0.0275\n",
      "449/1088, train_loss: 0.0310\n",
      "450/1088, train_loss: 0.0293\n",
      "451/1088, train_loss: 0.0302\n",
      "452/1088, train_loss: 0.0308\n",
      "453/1088, train_loss: 0.0291\n",
      "454/1088, train_loss: 0.0293\n",
      "455/1088, train_loss: 0.0283\n",
      "456/1088, train_loss: 0.0284\n",
      "457/1088, train_loss: 0.0270\n",
      "458/1088, train_loss: 0.0284\n",
      "459/1088, train_loss: 0.0295\n",
      "460/1088, train_loss: 0.0286\n",
      "461/1088, train_loss: 0.0266\n",
      "462/1088, train_loss: 0.0288\n",
      "463/1088, train_loss: 0.0284\n",
      "464/1088, train_loss: 0.0302\n",
      "465/1088, train_loss: 0.0295\n",
      "466/1088, train_loss: 0.0289\n",
      "467/1088, train_loss: 0.0270\n",
      "468/1088, train_loss: 0.0310\n",
      "469/1088, train_loss: 0.0293\n",
      "470/1088, train_loss: 0.0302\n",
      "471/1088, train_loss: 0.0264\n",
      "472/1088, train_loss: 0.0263\n",
      "473/1088, train_loss: 0.0293\n",
      "474/1088, train_loss: 0.0273\n",
      "475/1088, train_loss: 0.0268\n",
      "476/1088, train_loss: 0.0309\n",
      "477/1088, train_loss: 0.0304\n",
      "478/1088, train_loss: 0.0281\n",
      "479/1088, train_loss: 0.0291\n",
      "480/1088, train_loss: 0.0274\n",
      "481/1088, train_loss: 0.0266\n",
      "482/1088, train_loss: 0.0292\n",
      "483/1088, train_loss: 0.0299\n",
      "484/1088, train_loss: 0.0296\n",
      "485/1088, train_loss: 0.0271\n",
      "486/1088, train_loss: 0.0286\n",
      "487/1088, train_loss: 0.0277\n",
      "488/1088, train_loss: 0.0309\n",
      "489/1088, train_loss: 0.0288\n",
      "490/1088, train_loss: 0.0280\n",
      "491/1088, train_loss: 0.0292\n",
      "492/1088, train_loss: 0.0288\n",
      "493/1088, train_loss: 0.0263\n",
      "494/1088, train_loss: 0.0303\n",
      "495/1088, train_loss: 0.0300\n",
      "496/1088, train_loss: 0.0287\n",
      "497/1088, train_loss: 0.0264\n",
      "498/1088, train_loss: 0.0294\n",
      "499/1088, train_loss: 0.0280\n",
      "500/1088, train_loss: 0.0289\n",
      "501/1088, train_loss: 0.0301\n",
      "502/1088, train_loss: 0.0314\n",
      "503/1088, train_loss: 0.0280\n",
      "504/1088, train_loss: 0.0284\n",
      "505/1088, train_loss: 0.0274\n",
      "506/1088, train_loss: 0.0285\n",
      "507/1088, train_loss: 0.0286\n",
      "508/1088, train_loss: 0.0272\n",
      "509/1088, train_loss: 0.0281\n",
      "510/1088, train_loss: 0.0329\n",
      "511/1088, train_loss: 0.0295\n",
      "512/1088, train_loss: 0.0292\n",
      "513/1088, train_loss: 0.0254\n",
      "514/1088, train_loss: 0.0272\n",
      "515/1088, train_loss: 0.0285\n",
      "516/1088, train_loss: 0.0290\n",
      "517/1088, train_loss: 0.0293\n",
      "518/1088, train_loss: 0.0280\n",
      "519/1088, train_loss: 0.0291\n",
      "520/1088, train_loss: 0.0291\n",
      "521/1088, train_loss: 0.0297\n",
      "522/1088, train_loss: 0.0284\n",
      "523/1088, train_loss: 0.0286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/1088, train_loss: 0.0336\n",
      "525/1088, train_loss: 0.0296\n",
      "526/1088, train_loss: 0.0281\n",
      "527/1088, train_loss: 0.0266\n",
      "528/1088, train_loss: 0.0288\n",
      "529/1088, train_loss: 0.0292\n",
      "530/1088, train_loss: 0.0286\n",
      "531/1088, train_loss: 0.0282\n",
      "532/1088, train_loss: 0.0289\n",
      "533/1088, train_loss: 0.0295\n",
      "534/1088, train_loss: 0.0285\n",
      "535/1088, train_loss: 0.0277\n",
      "536/1088, train_loss: 0.0282\n",
      "537/1088, train_loss: 0.0290\n",
      "538/1088, train_loss: 0.0273\n",
      "539/1088, train_loss: 0.0269\n",
      "540/1088, train_loss: 0.0296\n",
      "541/1088, train_loss: 0.0274\n",
      "542/1088, train_loss: 0.0292\n",
      "543/1088, train_loss: 0.0272\n",
      "544/1088, train_loss: 0.0274\n",
      "545/1088, train_loss: 0.0292\n",
      "546/1088, train_loss: 0.0312\n",
      "547/1088, train_loss: 0.0277\n",
      "548/1088, train_loss: 0.0291\n",
      "549/1088, train_loss: 0.0288\n",
      "550/1088, train_loss: 0.0332\n",
      "551/1088, train_loss: 0.0275\n",
      "552/1088, train_loss: 0.0278\n",
      "553/1088, train_loss: 0.0296\n",
      "554/1088, train_loss: 0.0292\n",
      "555/1088, train_loss: 0.0294\n",
      "556/1088, train_loss: 0.0272\n",
      "557/1088, train_loss: 0.0284\n",
      "558/1088, train_loss: 0.0279\n",
      "559/1088, train_loss: 0.0313\n",
      "560/1088, train_loss: 0.0291\n",
      "561/1088, train_loss: 0.0275\n",
      "562/1088, train_loss: 0.0281\n",
      "563/1088, train_loss: 0.0276\n",
      "564/1088, train_loss: 0.0276\n",
      "565/1088, train_loss: 0.0290\n",
      "566/1088, train_loss: 0.0292\n",
      "567/1088, train_loss: 0.0295\n",
      "568/1088, train_loss: 0.0290\n",
      "569/1088, train_loss: 0.0284\n",
      "570/1088, train_loss: 0.0310\n",
      "571/1088, train_loss: 0.0275\n",
      "572/1088, train_loss: 0.0289\n",
      "573/1088, train_loss: 0.0276\n",
      "574/1088, train_loss: 0.0277\n",
      "575/1088, train_loss: 0.0269\n",
      "576/1088, train_loss: 0.0270\n",
      "577/1088, train_loss: 0.0292\n",
      "578/1088, train_loss: 0.0285\n",
      "579/1088, train_loss: 0.0299\n",
      "580/1088, train_loss: 0.0278\n",
      "581/1088, train_loss: 0.0259\n",
      "582/1088, train_loss: 0.0335\n",
      "583/1088, train_loss: 0.0300\n",
      "584/1088, train_loss: 0.0289\n",
      "585/1088, train_loss: 0.0292\n",
      "586/1088, train_loss: 0.0277\n",
      "587/1088, train_loss: 0.0282\n",
      "588/1088, train_loss: 0.0282\n",
      "589/1088, train_loss: 0.0278\n",
      "590/1088, train_loss: 0.0270\n",
      "591/1088, train_loss: 0.0290\n",
      "592/1088, train_loss: 0.0283\n",
      "593/1088, train_loss: 0.0257\n",
      "594/1088, train_loss: 0.0249\n",
      "595/1088, train_loss: 0.0290\n",
      "596/1088, train_loss: 0.0304\n",
      "597/1088, train_loss: 0.0290\n",
      "598/1088, train_loss: 0.0310\n",
      "599/1088, train_loss: 0.0287\n",
      "600/1088, train_loss: 0.0291\n",
      "601/1088, train_loss: 0.0282\n",
      "602/1088, train_loss: 0.0291\n",
      "603/1088, train_loss: 0.0297\n",
      "604/1088, train_loss: 0.0276\n",
      "605/1088, train_loss: 0.0267\n",
      "606/1088, train_loss: 0.0272\n",
      "607/1088, train_loss: 0.0284\n",
      "608/1088, train_loss: 0.0286\n",
      "609/1088, train_loss: 0.0268\n",
      "610/1088, train_loss: 0.0295\n",
      "611/1088, train_loss: 0.0296\n",
      "612/1088, train_loss: 0.0286\n",
      "613/1088, train_loss: 0.0287\n",
      "614/1088, train_loss: 0.0295\n",
      "615/1088, train_loss: 0.0298\n",
      "616/1088, train_loss: 0.0280\n",
      "617/1088, train_loss: 0.0287\n",
      "618/1088, train_loss: 0.0274\n",
      "619/1088, train_loss: 0.0282\n",
      "620/1088, train_loss: 0.0301\n",
      "621/1088, train_loss: 0.0289\n",
      "622/1088, train_loss: 0.0281\n",
      "623/1088, train_loss: 0.0279\n",
      "624/1088, train_loss: 0.0281\n",
      "625/1088, train_loss: 0.0302\n",
      "626/1088, train_loss: 0.0263\n",
      "627/1088, train_loss: 0.0346\n",
      "628/1088, train_loss: 0.0274\n",
      "629/1088, train_loss: 0.0318\n",
      "630/1088, train_loss: 0.0309\n",
      "631/1088, train_loss: 0.0313\n",
      "632/1088, train_loss: 0.0271\n",
      "633/1088, train_loss: 0.0294\n",
      "634/1088, train_loss: 0.0292\n",
      "635/1088, train_loss: 0.0311\n",
      "636/1088, train_loss: 0.0315\n",
      "637/1088, train_loss: 0.0297\n",
      "638/1088, train_loss: 0.0294\n",
      "639/1088, train_loss: 0.0282\n",
      "640/1088, train_loss: 0.0279\n",
      "641/1088, train_loss: 0.0289\n",
      "642/1088, train_loss: 0.0284\n",
      "643/1088, train_loss: 0.0278\n",
      "644/1088, train_loss: 0.0305\n",
      "645/1088, train_loss: 0.0290\n",
      "646/1088, train_loss: 0.0280\n",
      "647/1088, train_loss: 0.0277\n",
      "648/1088, train_loss: 0.0286\n",
      "649/1088, train_loss: 0.0288\n",
      "650/1088, train_loss: 0.0286\n",
      "651/1088, train_loss: 0.0288\n",
      "652/1088, train_loss: 0.0261\n",
      "653/1088, train_loss: 0.0300\n",
      "654/1088, train_loss: 0.0286\n",
      "655/1088, train_loss: 0.0310\n",
      "656/1088, train_loss: 0.0284\n",
      "657/1088, train_loss: 0.0300\n",
      "658/1088, train_loss: 0.0274\n",
      "659/1088, train_loss: 0.0301\n",
      "660/1088, train_loss: 0.0292\n",
      "661/1088, train_loss: 0.0280\n",
      "662/1088, train_loss: 0.0294\n",
      "663/1088, train_loss: 0.0293\n",
      "664/1088, train_loss: 0.0314\n",
      "665/1088, train_loss: 0.0336\n",
      "666/1088, train_loss: 0.0278\n",
      "667/1088, train_loss: 0.0307\n",
      "668/1088, train_loss: 0.0293\n",
      "669/1088, train_loss: 0.0267\n",
      "670/1088, train_loss: 0.0289\n",
      "671/1088, train_loss: 0.0263\n",
      "672/1088, train_loss: 0.0269\n",
      "673/1088, train_loss: 0.0285\n",
      "674/1088, train_loss: 0.0265\n",
      "675/1088, train_loss: 0.0252\n",
      "676/1088, train_loss: 0.0279\n",
      "677/1088, train_loss: 0.0305\n",
      "678/1088, train_loss: 0.0268\n",
      "679/1088, train_loss: 0.0284\n",
      "680/1088, train_loss: 0.0270\n",
      "681/1088, train_loss: 0.0305\n",
      "682/1088, train_loss: 0.0311\n",
      "683/1088, train_loss: 0.0294\n",
      "684/1088, train_loss: 0.0281\n",
      "685/1088, train_loss: 0.0298\n",
      "686/1088, train_loss: 0.0314\n",
      "687/1088, train_loss: 0.0278\n",
      "688/1088, train_loss: 0.0295\n",
      "689/1088, train_loss: 0.0332\n",
      "690/1088, train_loss: 0.0270\n",
      "691/1088, train_loss: 0.0272\n",
      "692/1088, train_loss: 0.0282\n",
      "693/1088, train_loss: 0.0288\n",
      "694/1088, train_loss: 0.0312\n",
      "695/1088, train_loss: 0.0278\n",
      "696/1088, train_loss: 0.0284\n",
      "697/1088, train_loss: 0.0298\n",
      "698/1088, train_loss: 0.0283\n",
      "699/1088, train_loss: 0.0297\n",
      "700/1088, train_loss: 0.0279\n",
      "701/1088, train_loss: 0.0305\n",
      "702/1088, train_loss: 0.0282\n",
      "703/1088, train_loss: 0.0293\n",
      "704/1088, train_loss: 0.0310\n",
      "705/1088, train_loss: 0.0274\n",
      "706/1088, train_loss: 0.0289\n",
      "707/1088, train_loss: 0.0273\n",
      "708/1088, train_loss: 0.0293\n",
      "709/1088, train_loss: 0.0268\n",
      "710/1088, train_loss: 0.0329\n",
      "711/1088, train_loss: 0.0296\n",
      "712/1088, train_loss: 0.0279\n",
      "713/1088, train_loss: 0.0281\n",
      "714/1088, train_loss: 0.0296\n",
      "715/1088, train_loss: 0.0295\n",
      "716/1088, train_loss: 0.0297\n",
      "717/1088, train_loss: 0.0283\n",
      "718/1088, train_loss: 0.0268\n",
      "719/1088, train_loss: 0.0284\n",
      "720/1088, train_loss: 0.0309\n",
      "721/1088, train_loss: 0.0296\n",
      "722/1088, train_loss: 0.0282\n",
      "723/1088, train_loss: 0.0303\n",
      "724/1088, train_loss: 0.0293\n",
      "725/1088, train_loss: 0.0338\n",
      "726/1088, train_loss: 0.0275\n",
      "727/1088, train_loss: 0.0292\n",
      "728/1088, train_loss: 0.0270\n",
      "729/1088, train_loss: 0.0267\n",
      "730/1088, train_loss: 0.0289\n",
      "731/1088, train_loss: 0.0281\n",
      "732/1088, train_loss: 0.0291\n",
      "733/1088, train_loss: 0.0291\n",
      "734/1088, train_loss: 0.0264\n",
      "735/1088, train_loss: 0.0298\n",
      "736/1088, train_loss: 0.0270\n",
      "737/1088, train_loss: 0.0281\n",
      "738/1088, train_loss: 0.0295\n",
      "739/1088, train_loss: 0.0288\n",
      "740/1088, train_loss: 0.0279\n",
      "741/1088, train_loss: 0.0291\n",
      "742/1088, train_loss: 0.0274\n",
      "743/1088, train_loss: 0.0259\n",
      "744/1088, train_loss: 0.0277\n",
      "745/1088, train_loss: 0.0281\n",
      "746/1088, train_loss: 0.0250\n",
      "747/1088, train_loss: 0.0260\n",
      "748/1088, train_loss: 0.0267\n",
      "749/1088, train_loss: 0.0284\n",
      "750/1088, train_loss: 0.0286\n",
      "751/1088, train_loss: 0.0266\n",
      "752/1088, train_loss: 0.0284\n",
      "753/1088, train_loss: 0.0283\n",
      "754/1088, train_loss: 0.0272\n",
      "755/1088, train_loss: 0.0265\n",
      "756/1088, train_loss: 0.0283\n",
      "757/1088, train_loss: 0.0281\n",
      "758/1088, train_loss: 0.0288\n",
      "759/1088, train_loss: 0.0274\n",
      "760/1088, train_loss: 0.0248\n",
      "761/1088, train_loss: 0.0286\n",
      "762/1088, train_loss: 0.0290\n",
      "763/1088, train_loss: 0.0290\n",
      "764/1088, train_loss: 0.0306\n",
      "765/1088, train_loss: 0.0296\n",
      "766/1088, train_loss: 0.0316\n",
      "767/1088, train_loss: 0.0287\n",
      "768/1088, train_loss: 0.0300\n",
      "769/1088, train_loss: 0.0287\n",
      "770/1088, train_loss: 0.0281\n",
      "771/1088, train_loss: 0.0260\n",
      "772/1088, train_loss: 0.0302\n",
      "773/1088, train_loss: 0.0303\n",
      "774/1088, train_loss: 0.0285\n",
      "775/1088, train_loss: 0.0285\n",
      "776/1088, train_loss: 0.0281\n",
      "777/1088, train_loss: 0.0280\n",
      "778/1088, train_loss: 0.0268\n",
      "779/1088, train_loss: 0.0282\n",
      "780/1088, train_loss: 0.0337\n",
      "781/1088, train_loss: 0.0281\n",
      "782/1088, train_loss: 0.0268\n",
      "783/1088, train_loss: 0.0283\n",
      "784/1088, train_loss: 0.0285\n",
      "785/1088, train_loss: 0.0281\n",
      "786/1088, train_loss: 0.0271\n",
      "787/1088, train_loss: 0.0251\n",
      "788/1088, train_loss: 0.0271\n",
      "789/1088, train_loss: 0.0289\n",
      "790/1088, train_loss: 0.0291\n",
      "791/1088, train_loss: 0.0278\n",
      "792/1088, train_loss: 0.0275\n",
      "793/1088, train_loss: 0.0289\n",
      "794/1088, train_loss: 0.0315\n",
      "795/1088, train_loss: 0.0329\n",
      "796/1088, train_loss: 0.0308\n",
      "797/1088, train_loss: 0.0296\n",
      "798/1088, train_loss: 0.0336\n",
      "799/1088, train_loss: 0.0277\n",
      "800/1088, train_loss: 0.0279\n",
      "801/1088, train_loss: 0.0292\n",
      "802/1088, train_loss: 0.0290\n",
      "803/1088, train_loss: 0.0315\n",
      "804/1088, train_loss: 0.0284\n",
      "805/1088, train_loss: 0.0300\n",
      "806/1088, train_loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "807/1088, train_loss: 0.0284\n",
      "808/1088, train_loss: 0.0311\n",
      "809/1088, train_loss: 0.0288\n",
      "810/1088, train_loss: 0.0288\n",
      "811/1088, train_loss: 0.0263\n",
      "812/1088, train_loss: 0.0292\n",
      "813/1088, train_loss: 0.0275\n",
      "814/1088, train_loss: 0.0279\n",
      "815/1088, train_loss: 0.0303\n",
      "816/1088, train_loss: 0.0316\n",
      "817/1088, train_loss: 0.0253\n",
      "818/1088, train_loss: 0.0286\n",
      "819/1088, train_loss: 0.0266\n",
      "820/1088, train_loss: 0.0279\n",
      "821/1088, train_loss: 0.0297\n",
      "822/1088, train_loss: 0.0299\n",
      "823/1088, train_loss: 0.0297\n",
      "824/1088, train_loss: 0.0281\n",
      "825/1088, train_loss: 0.0286\n",
      "826/1088, train_loss: 0.0279\n",
      "827/1088, train_loss: 0.0278\n",
      "828/1088, train_loss: 0.0263\n",
      "829/1088, train_loss: 0.0289\n",
      "830/1088, train_loss: 0.0306\n",
      "831/1088, train_loss: 0.0267\n",
      "832/1088, train_loss: 0.0291\n",
      "833/1088, train_loss: 0.0292\n",
      "834/1088, train_loss: 0.0265\n",
      "835/1088, train_loss: 0.0298\n",
      "836/1088, train_loss: 0.0311\n",
      "837/1088, train_loss: 0.0283\n",
      "838/1088, train_loss: 0.0279\n",
      "839/1088, train_loss: 0.0282\n",
      "840/1088, train_loss: 0.0258\n",
      "841/1088, train_loss: 0.0274\n",
      "842/1088, train_loss: 0.0264\n",
      "843/1088, train_loss: 0.0304\n",
      "844/1088, train_loss: 0.0274\n",
      "845/1088, train_loss: 0.0280\n",
      "846/1088, train_loss: 0.0270\n",
      "847/1088, train_loss: 0.0328\n",
      "848/1088, train_loss: 0.0286\n",
      "849/1088, train_loss: 0.0276\n",
      "850/1088, train_loss: 0.0258\n",
      "851/1088, train_loss: 0.0289\n",
      "852/1088, train_loss: 0.0254\n",
      "853/1088, train_loss: 0.0256\n",
      "854/1088, train_loss: 0.0253\n",
      "855/1088, train_loss: 0.0287\n",
      "856/1088, train_loss: 0.0274\n",
      "857/1088, train_loss: 0.0283\n",
      "858/1088, train_loss: 0.0360\n",
      "859/1088, train_loss: 0.0288\n",
      "860/1088, train_loss: 0.0254\n",
      "861/1088, train_loss: 0.0295\n",
      "862/1088, train_loss: 0.0295\n",
      "863/1088, train_loss: 0.0271\n",
      "864/1088, train_loss: 0.0281\n",
      "865/1088, train_loss: 0.0289\n",
      "866/1088, train_loss: 0.0267\n",
      "867/1088, train_loss: 0.0314\n",
      "868/1088, train_loss: 0.0300\n",
      "869/1088, train_loss: 0.0294\n",
      "870/1088, train_loss: 0.0307\n",
      "871/1088, train_loss: 0.0305\n",
      "872/1088, train_loss: 0.0278\n",
      "873/1088, train_loss: 0.0281\n",
      "874/1088, train_loss: 0.0282\n",
      "875/1088, train_loss: 0.0291\n",
      "876/1088, train_loss: 0.0293\n",
      "877/1088, train_loss: 0.0289\n",
      "878/1088, train_loss: 0.0270\n",
      "879/1088, train_loss: 0.0294\n",
      "880/1088, train_loss: 0.0294\n",
      "881/1088, train_loss: 0.0291\n",
      "882/1088, train_loss: 0.0280\n",
      "883/1088, train_loss: 0.0288\n",
      "884/1088, train_loss: 0.0272\n",
      "885/1088, train_loss: 0.0275\n",
      "886/1088, train_loss: 0.0293\n",
      "887/1088, train_loss: 0.0305\n",
      "888/1088, train_loss: 0.0275\n",
      "889/1088, train_loss: 0.0284\n",
      "890/1088, train_loss: 0.0263\n",
      "891/1088, train_loss: 0.0354\n",
      "892/1088, train_loss: 0.0290\n",
      "893/1088, train_loss: 0.0272\n",
      "894/1088, train_loss: 0.0280\n",
      "895/1088, train_loss: 0.0286\n",
      "896/1088, train_loss: 0.0310\n",
      "897/1088, train_loss: 0.0287\n",
      "898/1088, train_loss: 0.0270\n",
      "899/1088, train_loss: 0.0290\n",
      "900/1088, train_loss: 0.0270\n",
      "901/1088, train_loss: 0.0280\n",
      "902/1088, train_loss: 0.0295\n",
      "903/1088, train_loss: 0.0278\n",
      "904/1088, train_loss: 0.0312\n",
      "905/1088, train_loss: 0.0265\n",
      "906/1088, train_loss: 0.0279\n",
      "907/1088, train_loss: 0.0279\n",
      "908/1088, train_loss: 0.0303\n",
      "909/1088, train_loss: 0.0285\n",
      "910/1088, train_loss: 0.0303\n",
      "911/1088, train_loss: 0.0291\n",
      "912/1088, train_loss: 0.0298\n",
      "913/1088, train_loss: 0.0285\n",
      "914/1088, train_loss: 0.0293\n",
      "915/1088, train_loss: 0.0271\n",
      "916/1088, train_loss: 0.0281\n",
      "917/1088, train_loss: 0.0262\n",
      "918/1088, train_loss: 0.0284\n",
      "919/1088, train_loss: 0.0274\n",
      "920/1088, train_loss: 0.0357\n",
      "921/1088, train_loss: 0.0260\n",
      "922/1088, train_loss: 0.0265\n",
      "923/1088, train_loss: 0.0258\n",
      "924/1088, train_loss: 0.0278\n",
      "925/1088, train_loss: 0.0268\n",
      "926/1088, train_loss: 0.0285\n",
      "927/1088, train_loss: 0.0297\n",
      "928/1088, train_loss: 0.0278\n",
      "929/1088, train_loss: 0.0285\n",
      "930/1088, train_loss: 0.0277\n",
      "931/1088, train_loss: 0.0289\n",
      "932/1088, train_loss: 0.0258\n",
      "933/1088, train_loss: 0.0266\n",
      "934/1088, train_loss: 0.0282\n",
      "935/1088, train_loss: 0.0266\n",
      "936/1088, train_loss: 0.0285\n",
      "937/1088, train_loss: 0.0290\n",
      "938/1088, train_loss: 0.0259\n",
      "939/1088, train_loss: 0.0287\n",
      "940/1088, train_loss: 0.0284\n",
      "941/1088, train_loss: 0.0269\n",
      "942/1088, train_loss: 0.0289\n",
      "943/1088, train_loss: 0.0271\n",
      "944/1088, train_loss: 0.0301\n",
      "945/1088, train_loss: 0.0281\n",
      "946/1088, train_loss: 0.0276\n",
      "947/1088, train_loss: 0.0261\n",
      "948/1088, train_loss: 0.0269\n",
      "949/1088, train_loss: 0.0297\n",
      "950/1088, train_loss: 0.0289\n",
      "951/1088, train_loss: 0.0266\n",
      "952/1088, train_loss: 0.0300\n",
      "953/1088, train_loss: 0.0302\n",
      "954/1088, train_loss: 0.0263\n",
      "955/1088, train_loss: 0.0263\n",
      "956/1088, train_loss: 0.0287\n",
      "957/1088, train_loss: 0.0258\n",
      "958/1088, train_loss: 0.0285\n",
      "959/1088, train_loss: 0.0252\n",
      "960/1088, train_loss: 0.0258\n",
      "961/1088, train_loss: 0.0273\n",
      "962/1088, train_loss: 0.0313\n",
      "963/1088, train_loss: 0.0284\n",
      "964/1088, train_loss: 0.0303\n",
      "965/1088, train_loss: 0.0287\n",
      "966/1088, train_loss: 0.0271\n",
      "967/1088, train_loss: 0.0306\n",
      "968/1088, train_loss: 0.0300\n",
      "969/1088, train_loss: 0.0269\n",
      "970/1088, train_loss: 0.0282\n",
      "971/1088, train_loss: 0.0274\n",
      "972/1088, train_loss: 0.0281\n",
      "973/1088, train_loss: 0.0288\n",
      "974/1088, train_loss: 0.0268\n",
      "975/1088, train_loss: 0.0263\n",
      "976/1088, train_loss: 0.0277\n",
      "977/1088, train_loss: 0.0263\n",
      "978/1088, train_loss: 0.0340\n",
      "979/1088, train_loss: 0.0292\n",
      "980/1088, train_loss: 0.0266\n",
      "981/1088, train_loss: 0.0289\n",
      "982/1088, train_loss: 0.0283\n",
      "983/1088, train_loss: 0.0284\n",
      "984/1088, train_loss: 0.0273\n",
      "985/1088, train_loss: 0.0286\n",
      "986/1088, train_loss: 0.0289\n",
      "987/1088, train_loss: 0.0281\n",
      "988/1088, train_loss: 0.0282\n",
      "989/1088, train_loss: 0.0274\n",
      "990/1088, train_loss: 0.0252\n",
      "991/1088, train_loss: 0.0307\n",
      "992/1088, train_loss: 0.0275\n",
      "993/1088, train_loss: 0.0284\n",
      "994/1088, train_loss: 0.0273\n",
      "995/1088, train_loss: 0.0268\n",
      "996/1088, train_loss: 0.0295\n",
      "997/1088, train_loss: 0.0274\n",
      "998/1088, train_loss: 0.0276\n",
      "999/1088, train_loss: 0.0268\n",
      "1000/1088, train_loss: 0.0292\n",
      "1001/1088, train_loss: 0.0279\n",
      "1002/1088, train_loss: 0.0282\n",
      "1003/1088, train_loss: 0.0287\n",
      "1004/1088, train_loss: 0.0267\n",
      "1005/1088, train_loss: 0.0273\n",
      "1006/1088, train_loss: 0.0279\n",
      "1007/1088, train_loss: 0.0272\n",
      "1008/1088, train_loss: 0.0271\n",
      "1009/1088, train_loss: 0.0280\n",
      "1010/1088, train_loss: 0.0271\n",
      "1011/1088, train_loss: 0.0285\n",
      "1012/1088, train_loss: 0.0273\n",
      "1013/1088, train_loss: 0.0283\n",
      "1014/1088, train_loss: 0.0296\n",
      "1015/1088, train_loss: 0.0272\n",
      "1016/1088, train_loss: 0.0297\n",
      "1017/1088, train_loss: 0.0300\n",
      "1018/1088, train_loss: 0.0271\n",
      "1019/1088, train_loss: 0.0286\n",
      "1020/1088, train_loss: 0.0269\n",
      "1021/1088, train_loss: 0.0290\n",
      "1022/1088, train_loss: 0.0286\n",
      "1023/1088, train_loss: 0.0268\n",
      "1024/1088, train_loss: 0.0294\n",
      "1025/1088, train_loss: 0.0289\n",
      "1026/1088, train_loss: 0.0277\n",
      "1027/1088, train_loss: 0.0262\n",
      "1028/1088, train_loss: 0.0281\n",
      "1029/1088, train_loss: 0.0285\n",
      "1030/1088, train_loss: 0.0358\n",
      "1031/1088, train_loss: 0.0281\n",
      "1032/1088, train_loss: 0.0413\n",
      "1033/1088, train_loss: 0.0309\n",
      "1034/1088, train_loss: 0.0298\n",
      "1035/1088, train_loss: 0.0294\n",
      "1036/1088, train_loss: 0.0300\n",
      "1037/1088, train_loss: 0.0279\n",
      "1038/1088, train_loss: 0.0276\n",
      "1039/1088, train_loss: 0.0297\n",
      "1040/1088, train_loss: 0.0299\n",
      "1041/1088, train_loss: 0.0299\n",
      "1042/1088, train_loss: 0.0294\n",
      "1043/1088, train_loss: 0.0309\n",
      "1044/1088, train_loss: 0.0308\n",
      "1045/1088, train_loss: 0.0258\n",
      "1046/1088, train_loss: 0.0280\n",
      "1047/1088, train_loss: 0.0282\n",
      "1048/1088, train_loss: 0.0296\n",
      "1049/1088, train_loss: 0.0272\n",
      "1050/1088, train_loss: 0.0307\n",
      "1051/1088, train_loss: 0.0288\n",
      "1052/1088, train_loss: 0.0308\n",
      "1053/1088, train_loss: 0.0267\n",
      "1054/1088, train_loss: 0.0279\n",
      "1055/1088, train_loss: 0.0277\n",
      "1056/1088, train_loss: 0.0281\n",
      "1057/1088, train_loss: 0.0267\n",
      "1058/1088, train_loss: 0.0307\n",
      "1059/1088, train_loss: 0.0277\n",
      "1060/1088, train_loss: 0.0260\n",
      "1061/1088, train_loss: 0.0276\n",
      "1062/1088, train_loss: 0.0277\n",
      "1063/1088, train_loss: 0.0278\n",
      "1064/1088, train_loss: 0.0302\n",
      "1065/1088, train_loss: 0.0267\n",
      "1066/1088, train_loss: 0.0276\n",
      "1067/1088, train_loss: 0.0275\n",
      "1068/1088, train_loss: 0.0286\n",
      "1069/1088, train_loss: 0.0307\n",
      "1070/1088, train_loss: 0.0273\n",
      "1071/1088, train_loss: 0.0278\n",
      "1072/1088, train_loss: 0.0304\n",
      "1073/1088, train_loss: 0.0275\n",
      "1074/1088, train_loss: 0.0285\n",
      "1075/1088, train_loss: 0.0281\n",
      "1076/1088, train_loss: 0.0274\n",
      "1077/1088, train_loss: 0.0296\n",
      "1078/1088, train_loss: 0.0272\n",
      "1079/1088, train_loss: 0.0314\n",
      "1080/1088, train_loss: 0.0282\n",
      "1081/1088, train_loss: 0.0278\n",
      "1082/1088, train_loss: 0.0301\n",
      "1083/1088, train_loss: 0.0276\n",
      "1084/1088, train_loss: 0.0278\n",
      "1085/1088, train_loss: 0.0268\n",
      "1086/1088, train_loss: 0.0294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087/1088, train_loss: 0.0314\n",
      "1088/1088, train_loss: 0.0290\n",
      "1089/1088, train_loss: 0.0268\n",
      "epoch 16 average loss: 0.0287, train_dice: 0.9713\n",
      "epoch 16 average loss: 0.0287\n",
      "current epoch: 16 current mean dice: 0.9690 best mean dice: 0.9703 at epoch 8\n",
      "--------------------------------------------------\n",
      "epoch 17/50\n",
      "1/1088, train_loss: 0.0265\n",
      "2/1088, train_loss: 0.0271\n",
      "3/1088, train_loss: 0.0252\n",
      "4/1088, train_loss: 0.0284\n",
      "5/1088, train_loss: 0.0293\n",
      "6/1088, train_loss: 0.0262\n",
      "7/1088, train_loss: 0.0281\n",
      "8/1088, train_loss: 0.0297\n",
      "9/1088, train_loss: 0.0294\n",
      "10/1088, train_loss: 0.0279\n",
      "11/1088, train_loss: 0.0298\n",
      "12/1088, train_loss: 0.0266\n",
      "13/1088, train_loss: 0.0291\n",
      "14/1088, train_loss: 0.0296\n",
      "15/1088, train_loss: 0.0291\n",
      "16/1088, train_loss: 0.0262\n",
      "17/1088, train_loss: 0.0281\n",
      "18/1088, train_loss: 0.0282\n",
      "19/1088, train_loss: 0.0296\n",
      "20/1088, train_loss: 0.0285\n",
      "21/1088, train_loss: 0.0275\n",
      "22/1088, train_loss: 0.0283\n",
      "23/1088, train_loss: 0.0290\n",
      "24/1088, train_loss: 0.0267\n",
      "25/1088, train_loss: 0.0279\n",
      "26/1088, train_loss: 0.0271\n",
      "27/1088, train_loss: 0.0273\n",
      "28/1088, train_loss: 0.0319\n",
      "29/1088, train_loss: 0.0272\n",
      "30/1088, train_loss: 0.0279\n",
      "31/1088, train_loss: 0.0281\n",
      "32/1088, train_loss: 0.0270\n",
      "33/1088, train_loss: 0.0277\n",
      "34/1088, train_loss: 0.0283\n",
      "35/1088, train_loss: 0.0270\n",
      "36/1088, train_loss: 0.0260\n",
      "37/1088, train_loss: 0.0268\n",
      "38/1088, train_loss: 0.0331\n",
      "39/1088, train_loss: 0.0251\n",
      "40/1088, train_loss: 0.0299\n",
      "41/1088, train_loss: 0.0284\n",
      "42/1088, train_loss: 0.0311\n",
      "43/1088, train_loss: 0.0288\n",
      "44/1088, train_loss: 0.0288\n",
      "45/1088, train_loss: 0.0287\n",
      "46/1088, train_loss: 0.0293\n",
      "47/1088, train_loss: 0.0264\n",
      "48/1088, train_loss: 0.0246\n",
      "49/1088, train_loss: 0.0288\n",
      "50/1088, train_loss: 0.0296\n",
      "51/1088, train_loss: 0.0274\n",
      "52/1088, train_loss: 0.0306\n",
      "53/1088, train_loss: 0.0291\n",
      "54/1088, train_loss: 0.0297\n",
      "55/1088, train_loss: 0.0276\n",
      "56/1088, train_loss: 0.0291\n",
      "57/1088, train_loss: 0.0298\n",
      "58/1088, train_loss: 0.0283\n",
      "59/1088, train_loss: 0.0262\n",
      "60/1088, train_loss: 0.0289\n",
      "61/1088, train_loss: 0.0277\n",
      "62/1088, train_loss: 0.0291\n",
      "63/1088, train_loss: 0.0279\n",
      "64/1088, train_loss: 0.0300\n",
      "65/1088, train_loss: 0.0269\n",
      "66/1088, train_loss: 0.0278\n",
      "67/1088, train_loss: 0.0299\n",
      "68/1088, train_loss: 0.0266\n",
      "69/1088, train_loss: 0.0282\n",
      "70/1088, train_loss: 0.0293\n",
      "71/1088, train_loss: 0.0282\n",
      "72/1088, train_loss: 0.0290\n",
      "73/1088, train_loss: 0.0276\n",
      "74/1088, train_loss: 0.0281\n",
      "75/1088, train_loss: 0.0284\n",
      "76/1088, train_loss: 0.0258\n",
      "77/1088, train_loss: 0.0275\n",
      "78/1088, train_loss: 0.0270\n",
      "79/1088, train_loss: 0.0276\n",
      "80/1088, train_loss: 0.0273\n",
      "81/1088, train_loss: 0.0276\n",
      "82/1088, train_loss: 0.0288\n",
      "83/1088, train_loss: 0.0275\n",
      "84/1088, train_loss: 0.0267\n",
      "85/1088, train_loss: 0.0282\n",
      "86/1088, train_loss: 0.0270\n",
      "87/1088, train_loss: 0.0297\n",
      "88/1088, train_loss: 0.0289\n",
      "89/1088, train_loss: 0.0259\n",
      "90/1088, train_loss: 0.0272\n",
      "91/1088, train_loss: 0.0276\n",
      "92/1088, train_loss: 0.0278\n",
      "93/1088, train_loss: 0.0274\n",
      "94/1088, train_loss: 0.0287\n",
      "95/1088, train_loss: 0.0288\n",
      "96/1088, train_loss: 0.0266\n",
      "97/1088, train_loss: 0.0238\n",
      "98/1088, train_loss: 0.0292\n",
      "99/1088, train_loss: 0.0310\n",
      "100/1088, train_loss: 0.0274\n",
      "101/1088, train_loss: 0.0277\n",
      "102/1088, train_loss: 0.0264\n",
      "103/1088, train_loss: 0.0286\n",
      "104/1088, train_loss: 0.0278\n",
      "105/1088, train_loss: 0.0263\n",
      "106/1088, train_loss: 0.0271\n",
      "107/1088, train_loss: 0.0278\n",
      "108/1088, train_loss: 0.0262\n",
      "109/1088, train_loss: 0.0269\n",
      "110/1088, train_loss: 0.0272\n",
      "111/1088, train_loss: 0.0275\n",
      "112/1088, train_loss: 0.0265\n",
      "113/1088, train_loss: 0.0270\n",
      "114/1088, train_loss: 0.0280\n",
      "115/1088, train_loss: 0.0269\n",
      "116/1088, train_loss: 0.0280\n",
      "117/1088, train_loss: 0.0269\n",
      "118/1088, train_loss: 0.0293\n",
      "119/1088, train_loss: 0.0298\n",
      "120/1088, train_loss: 0.0262\n",
      "121/1088, train_loss: 0.0259\n",
      "122/1088, train_loss: 0.0289\n",
      "123/1088, train_loss: 0.0306\n",
      "124/1088, train_loss: 0.0258\n",
      "125/1088, train_loss: 0.0305\n",
      "126/1088, train_loss: 0.0257\n",
      "127/1088, train_loss: 0.0331\n",
      "128/1088, train_loss: 0.0271\n",
      "129/1088, train_loss: 0.0272\n",
      "130/1088, train_loss: 0.0272\n",
      "131/1088, train_loss: 0.0251\n",
      "132/1088, train_loss: 0.0302\n",
      "133/1088, train_loss: 0.0289\n",
      "134/1088, train_loss: 0.0307\n",
      "135/1088, train_loss: 0.0310\n",
      "136/1088, train_loss: 0.0270\n",
      "137/1088, train_loss: 0.0288\n",
      "138/1088, train_loss: 0.0267\n",
      "139/1088, train_loss: 0.0275\n",
      "140/1088, train_loss: 0.0246\n",
      "141/1088, train_loss: 0.0257\n",
      "142/1088, train_loss: 0.0261\n",
      "143/1088, train_loss: 0.0301\n",
      "144/1088, train_loss: 0.0286\n",
      "145/1088, train_loss: 0.0293\n",
      "146/1088, train_loss: 0.0281\n",
      "147/1088, train_loss: 0.0254\n",
      "148/1088, train_loss: 0.0325\n",
      "149/1088, train_loss: 0.0300\n",
      "150/1088, train_loss: 0.0262\n",
      "151/1088, train_loss: 0.0286\n",
      "152/1088, train_loss: 0.0288\n",
      "153/1088, train_loss: 0.0325\n",
      "154/1088, train_loss: 0.0275\n",
      "155/1088, train_loss: 0.0284\n",
      "156/1088, train_loss: 0.0284\n",
      "157/1088, train_loss: 0.0290\n",
      "158/1088, train_loss: 0.0257\n",
      "159/1088, train_loss: 0.0278\n",
      "160/1088, train_loss: 0.0258\n",
      "161/1088, train_loss: 0.0350\n",
      "162/1088, train_loss: 0.0287\n",
      "163/1088, train_loss: 0.0271\n",
      "164/1088, train_loss: 0.0258\n",
      "165/1088, train_loss: 0.0260\n",
      "166/1088, train_loss: 0.0300\n",
      "167/1088, train_loss: 0.0276\n",
      "168/1088, train_loss: 0.0292\n",
      "169/1088, train_loss: 0.0295\n",
      "170/1088, train_loss: 0.0286\n",
      "171/1088, train_loss: 0.0272\n",
      "172/1088, train_loss: 0.0310\n",
      "173/1088, train_loss: 0.0285\n",
      "174/1088, train_loss: 0.0275\n",
      "175/1088, train_loss: 0.0281\n",
      "176/1088, train_loss: 0.0287\n",
      "177/1088, train_loss: 0.0266\n",
      "178/1088, train_loss: 0.0255\n",
      "179/1088, train_loss: 0.0258\n",
      "180/1088, train_loss: 0.0318\n",
      "181/1088, train_loss: 0.0288\n",
      "182/1088, train_loss: 0.0285\n",
      "183/1088, train_loss: 0.0270\n",
      "184/1088, train_loss: 0.0270\n",
      "185/1088, train_loss: 0.0268\n",
      "186/1088, train_loss: 0.0271\n",
      "187/1088, train_loss: 0.0293\n",
      "188/1088, train_loss: 0.0293\n",
      "189/1088, train_loss: 0.0291\n",
      "190/1088, train_loss: 0.0290\n",
      "191/1088, train_loss: 0.0273\n",
      "192/1088, train_loss: 0.0276\n",
      "193/1088, train_loss: 0.0248\n",
      "194/1088, train_loss: 0.0267\n",
      "195/1088, train_loss: 0.0299\n",
      "196/1088, train_loss: 0.0275\n",
      "197/1088, train_loss: 0.0330\n",
      "198/1088, train_loss: 0.0296\n",
      "199/1088, train_loss: 0.0318\n",
      "200/1088, train_loss: 0.0266\n",
      "201/1088, train_loss: 0.0282\n",
      "202/1088, train_loss: 0.0296\n",
      "203/1088, train_loss: 0.0272\n",
      "204/1088, train_loss: 0.0277\n",
      "205/1088, train_loss: 0.0260\n",
      "206/1088, train_loss: 0.0293\n",
      "207/1088, train_loss: 0.0277\n",
      "208/1088, train_loss: 0.0293\n",
      "209/1088, train_loss: 0.0288\n",
      "210/1088, train_loss: 0.0277\n",
      "211/1088, train_loss: 0.0275\n",
      "212/1088, train_loss: 0.0301\n",
      "213/1088, train_loss: 0.0260\n",
      "214/1088, train_loss: 0.0262\n",
      "215/1088, train_loss: 0.0260\n",
      "216/1088, train_loss: 0.0315\n",
      "217/1088, train_loss: 0.0272\n",
      "218/1088, train_loss: 0.0285\n",
      "219/1088, train_loss: 0.0290\n",
      "220/1088, train_loss: 0.0271\n",
      "221/1088, train_loss: 0.0265\n",
      "222/1088, train_loss: 0.0289\n",
      "223/1088, train_loss: 0.0286\n",
      "224/1088, train_loss: 0.0276\n",
      "225/1088, train_loss: 0.0277\n",
      "226/1088, train_loss: 0.0275\n",
      "227/1088, train_loss: 0.0280\n",
      "228/1088, train_loss: 0.0288\n",
      "229/1088, train_loss: 0.0304\n",
      "230/1088, train_loss: 0.0285\n",
      "231/1088, train_loss: 0.0309\n",
      "232/1088, train_loss: 0.0290\n",
      "233/1088, train_loss: 0.0247\n",
      "234/1088, train_loss: 0.0275\n",
      "235/1088, train_loss: 0.0286\n",
      "236/1088, train_loss: 0.0297\n",
      "237/1088, train_loss: 0.0276\n",
      "238/1088, train_loss: 0.0291\n",
      "239/1088, train_loss: 0.0276\n",
      "240/1088, train_loss: 0.0273\n",
      "241/1088, train_loss: 0.0276\n",
      "242/1088, train_loss: 0.0266\n",
      "243/1088, train_loss: 0.0323\n",
      "244/1088, train_loss: 0.0255\n",
      "245/1088, train_loss: 0.0288\n",
      "246/1088, train_loss: 0.0276\n",
      "247/1088, train_loss: 0.0260\n",
      "248/1088, train_loss: 0.0307\n",
      "249/1088, train_loss: 0.0292\n",
      "250/1088, train_loss: 0.0302\n",
      "251/1088, train_loss: 0.0301\n",
      "252/1088, train_loss: 0.0256\n",
      "253/1088, train_loss: 0.0291\n",
      "254/1088, train_loss: 0.0277\n",
      "255/1088, train_loss: 0.0276\n",
      "256/1088, train_loss: 0.0264\n",
      "257/1088, train_loss: 0.0274\n",
      "258/1088, train_loss: 0.0280\n",
      "259/1088, train_loss: 0.0278\n",
      "260/1088, train_loss: 0.0297\n",
      "261/1088, train_loss: 0.0277\n",
      "262/1088, train_loss: 0.0285\n",
      "263/1088, train_loss: 0.0266\n",
      "264/1088, train_loss: 0.0296\n",
      "265/1088, train_loss: 0.0271\n",
      "266/1088, train_loss: 0.0306\n",
      "267/1088, train_loss: 0.0278\n",
      "268/1088, train_loss: 0.0300\n",
      "269/1088, train_loss: 0.0288\n",
      "270/1088, train_loss: 0.0299\n",
      "271/1088, train_loss: 0.0275\n",
      "272/1088, train_loss: 0.0285\n",
      "273/1088, train_loss: 0.0269\n",
      "274/1088, train_loss: 0.0270\n",
      "275/1088, train_loss: 0.0279\n",
      "276/1088, train_loss: 0.0279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277/1088, train_loss: 0.0384\n",
      "278/1088, train_loss: 0.0268\n",
      "279/1088, train_loss: 0.0281\n",
      "280/1088, train_loss: 0.0273\n",
      "281/1088, train_loss: 0.0280\n",
      "282/1088, train_loss: 0.0286\n",
      "283/1088, train_loss: 0.0280\n",
      "284/1088, train_loss: 0.0294\n",
      "285/1088, train_loss: 0.0283\n",
      "286/1088, train_loss: 0.0286\n",
      "287/1088, train_loss: 0.0286\n",
      "288/1088, train_loss: 0.0272\n",
      "289/1088, train_loss: 0.0303\n",
      "290/1088, train_loss: 0.0368\n",
      "291/1088, train_loss: 0.0278\n",
      "292/1088, train_loss: 0.0276\n",
      "293/1088, train_loss: 0.0271\n",
      "294/1088, train_loss: 0.0290\n",
      "295/1088, train_loss: 0.0249\n",
      "296/1088, train_loss: 0.0257\n",
      "297/1088, train_loss: 0.0259\n",
      "298/1088, train_loss: 0.0288\n",
      "299/1088, train_loss: 0.0272\n",
      "300/1088, train_loss: 0.0281\n",
      "301/1088, train_loss: 0.0304\n",
      "302/1088, train_loss: 0.0289\n",
      "303/1088, train_loss: 0.0257\n",
      "304/1088, train_loss: 0.0293\n",
      "305/1088, train_loss: 0.0258\n",
      "306/1088, train_loss: 0.0276\n",
      "307/1088, train_loss: 0.0269\n",
      "308/1088, train_loss: 0.0280\n",
      "309/1088, train_loss: 0.0301\n",
      "310/1088, train_loss: 0.0275\n",
      "311/1088, train_loss: 0.0276\n",
      "312/1088, train_loss: 0.0263\n",
      "313/1088, train_loss: 0.0266\n",
      "314/1088, train_loss: 0.0332\n",
      "315/1088, train_loss: 0.0297\n",
      "316/1088, train_loss: 0.0265\n",
      "317/1088, train_loss: 0.0285\n",
      "318/1088, train_loss: 0.0276\n",
      "319/1088, train_loss: 0.0280\n",
      "320/1088, train_loss: 0.0266\n",
      "321/1088, train_loss: 0.0293\n",
      "322/1088, train_loss: 0.0259\n",
      "323/1088, train_loss: 0.0261\n",
      "324/1088, train_loss: 0.0312\n",
      "325/1088, train_loss: 0.0278\n",
      "326/1088, train_loss: 0.0277\n",
      "327/1088, train_loss: 0.0290\n",
      "328/1088, train_loss: 0.0399\n",
      "329/1088, train_loss: 0.0269\n",
      "330/1088, train_loss: 0.0282\n",
      "331/1088, train_loss: 0.0314\n",
      "332/1088, train_loss: 0.0270\n",
      "333/1088, train_loss: 0.0297\n",
      "334/1088, train_loss: 0.0293\n",
      "335/1088, train_loss: 0.0251\n",
      "336/1088, train_loss: 0.0287\n",
      "337/1088, train_loss: 0.0275\n",
      "338/1088, train_loss: 0.0297\n",
      "339/1088, train_loss: 0.0293\n",
      "340/1088, train_loss: 0.0291\n",
      "341/1088, train_loss: 0.0293\n",
      "342/1088, train_loss: 0.0284\n",
      "343/1088, train_loss: 0.0265\n",
      "344/1088, train_loss: 0.0275\n",
      "345/1088, train_loss: 0.0281\n",
      "346/1088, train_loss: 0.0279\n",
      "347/1088, train_loss: 0.0265\n",
      "348/1088, train_loss: 0.0265\n",
      "349/1088, train_loss: 0.0272\n",
      "350/1088, train_loss: 0.0287\n",
      "351/1088, train_loss: 0.0264\n",
      "352/1088, train_loss: 0.0293\n",
      "353/1088, train_loss: 0.0262\n",
      "354/1088, train_loss: 0.0284\n",
      "355/1088, train_loss: 0.0267\n",
      "356/1088, train_loss: 0.0284\n",
      "357/1088, train_loss: 0.0283\n",
      "358/1088, train_loss: 0.0271\n",
      "359/1088, train_loss: 0.0288\n",
      "360/1088, train_loss: 0.0279\n",
      "361/1088, train_loss: 0.0271\n",
      "362/1088, train_loss: 0.0268\n",
      "363/1088, train_loss: 0.0296\n",
      "364/1088, train_loss: 0.0282\n",
      "365/1088, train_loss: 0.0296\n",
      "366/1088, train_loss: 0.0284\n",
      "367/1088, train_loss: 0.0306\n",
      "368/1088, train_loss: 0.0265\n",
      "369/1088, train_loss: 0.0253\n",
      "370/1088, train_loss: 0.0281\n",
      "371/1088, train_loss: 0.0253\n",
      "372/1088, train_loss: 0.0298\n",
      "373/1088, train_loss: 0.0272\n",
      "374/1088, train_loss: 0.0273\n",
      "375/1088, train_loss: 0.0301\n",
      "376/1088, train_loss: 0.0279\n",
      "377/1088, train_loss: 0.0263\n",
      "378/1088, train_loss: 0.0286\n",
      "379/1088, train_loss: 0.0282\n",
      "380/1088, train_loss: 0.0371\n",
      "381/1088, train_loss: 0.0287\n",
      "382/1088, train_loss: 0.0287\n",
      "383/1088, train_loss: 0.0310\n",
      "384/1088, train_loss: 0.0278\n",
      "385/1088, train_loss: 0.0286\n",
      "386/1088, train_loss: 0.0280\n",
      "387/1088, train_loss: 0.0278\n",
      "388/1088, train_loss: 0.0276\n",
      "389/1088, train_loss: 0.0281\n",
      "390/1088, train_loss: 0.0277\n",
      "391/1088, train_loss: 0.0283\n",
      "392/1088, train_loss: 0.0283\n",
      "393/1088, train_loss: 0.0265\n",
      "394/1088, train_loss: 0.0298\n",
      "395/1088, train_loss: 0.0282\n",
      "396/1088, train_loss: 0.0259\n",
      "397/1088, train_loss: 0.0276\n",
      "398/1088, train_loss: 0.0270\n",
      "399/1088, train_loss: 0.0265\n",
      "400/1088, train_loss: 0.0292\n",
      "401/1088, train_loss: 0.0266\n",
      "402/1088, train_loss: 0.0280\n",
      "403/1088, train_loss: 0.0280\n",
      "404/1088, train_loss: 0.0345\n",
      "405/1088, train_loss: 0.0276\n",
      "406/1088, train_loss: 0.0261\n",
      "407/1088, train_loss: 0.0268\n",
      "408/1088, train_loss: 0.0294\n",
      "409/1088, train_loss: 0.0276\n",
      "410/1088, train_loss: 0.0275\n",
      "411/1088, train_loss: 0.0256\n",
      "412/1088, train_loss: 0.0316\n",
      "413/1088, train_loss: 0.0283\n",
      "414/1088, train_loss: 0.0290\n",
      "415/1088, train_loss: 0.0251\n",
      "416/1088, train_loss: 0.0277\n",
      "417/1088, train_loss: 0.0271\n",
      "418/1088, train_loss: 0.0275\n",
      "419/1088, train_loss: 0.0289\n",
      "420/1088, train_loss: 0.0274\n",
      "421/1088, train_loss: 0.0267\n",
      "422/1088, train_loss: 0.0277\n",
      "423/1088, train_loss: 0.0287\n",
      "424/1088, train_loss: 0.0303\n",
      "425/1088, train_loss: 0.0272\n",
      "426/1088, train_loss: 0.0266\n",
      "427/1088, train_loss: 0.0293\n",
      "428/1088, train_loss: 0.0281\n",
      "429/1088, train_loss: 0.0302\n",
      "430/1088, train_loss: 0.0281\n",
      "431/1088, train_loss: 0.0292\n",
      "432/1088, train_loss: 0.0284\n",
      "433/1088, train_loss: 0.0283\n",
      "434/1088, train_loss: 0.0278\n",
      "435/1088, train_loss: 0.0289\n",
      "436/1088, train_loss: 0.0285\n",
      "437/1088, train_loss: 0.0278\n",
      "438/1088, train_loss: 0.0282\n",
      "439/1088, train_loss: 0.0271\n",
      "440/1088, train_loss: 0.0280\n",
      "441/1088, train_loss: 0.0319\n",
      "442/1088, train_loss: 0.0278\n",
      "443/1088, train_loss: 0.0291\n",
      "444/1088, train_loss: 0.0274\n",
      "445/1088, train_loss: 0.0350\n",
      "446/1088, train_loss: 0.0307\n",
      "447/1088, train_loss: 0.0295\n",
      "448/1088, train_loss: 0.0285\n",
      "449/1088, train_loss: 0.0291\n",
      "450/1088, train_loss: 0.0256\n",
      "451/1088, train_loss: 0.0285\n",
      "452/1088, train_loss: 0.0285\n",
      "453/1088, train_loss: 0.0274\n",
      "454/1088, train_loss: 0.0294\n",
      "455/1088, train_loss: 0.0292\n",
      "456/1088, train_loss: 0.0280\n",
      "457/1088, train_loss: 0.0252\n",
      "458/1088, train_loss: 0.0277\n",
      "459/1088, train_loss: 0.0256\n",
      "460/1088, train_loss: 0.0290\n",
      "461/1088, train_loss: 0.0273\n",
      "462/1088, train_loss: 0.0273\n",
      "463/1088, train_loss: 0.0278\n",
      "464/1088, train_loss: 0.0287\n",
      "465/1088, train_loss: 0.0288\n",
      "466/1088, train_loss: 0.0295\n",
      "467/1088, train_loss: 0.0314\n",
      "468/1088, train_loss: 0.0293\n",
      "469/1088, train_loss: 0.0288\n",
      "470/1088, train_loss: 0.0273\n",
      "471/1088, train_loss: 0.0289\n",
      "472/1088, train_loss: 0.0297\n",
      "473/1088, train_loss: 0.0279\n",
      "474/1088, train_loss: 0.0269\n",
      "475/1088, train_loss: 0.0271\n",
      "476/1088, train_loss: 0.0306\n",
      "477/1088, train_loss: 0.0284\n",
      "478/1088, train_loss: 0.0275\n",
      "479/1088, train_loss: 0.0278\n",
      "480/1088, train_loss: 0.0268\n",
      "481/1088, train_loss: 0.0258\n",
      "482/1088, train_loss: 0.0278\n",
      "483/1088, train_loss: 0.0273\n",
      "484/1088, train_loss: 0.0309\n",
      "485/1088, train_loss: 0.0285\n",
      "486/1088, train_loss: 0.0288\n",
      "487/1088, train_loss: 0.0272\n",
      "488/1088, train_loss: 0.0252\n",
      "489/1088, train_loss: 0.0257\n",
      "490/1088, train_loss: 0.0309\n",
      "491/1088, train_loss: 0.0309\n",
      "492/1088, train_loss: 0.0272\n",
      "493/1088, train_loss: 0.0306\n",
      "494/1088, train_loss: 0.0271\n",
      "495/1088, train_loss: 0.0286\n",
      "496/1088, train_loss: 0.0281\n",
      "497/1088, train_loss: 0.0244\n",
      "498/1088, train_loss: 0.0271\n",
      "499/1088, train_loss: 0.0265\n",
      "500/1088, train_loss: 0.0277\n",
      "501/1088, train_loss: 0.0293\n",
      "502/1088, train_loss: 0.0262\n",
      "503/1088, train_loss: 0.0309\n",
      "504/1088, train_loss: 0.0280\n",
      "505/1088, train_loss: 0.0287\n",
      "506/1088, train_loss: 0.0292\n",
      "507/1088, train_loss: 0.0268\n",
      "508/1088, train_loss: 0.0294\n",
      "509/1088, train_loss: 0.0298\n",
      "510/1088, train_loss: 0.0294\n",
      "511/1088, train_loss: 0.0302\n",
      "512/1088, train_loss: 0.0279\n",
      "513/1088, train_loss: 0.0277\n",
      "514/1088, train_loss: 0.0295\n",
      "515/1088, train_loss: 0.0306\n",
      "516/1088, train_loss: 0.0313\n",
      "517/1088, train_loss: 0.0273\n",
      "518/1088, train_loss: 0.0285\n",
      "519/1088, train_loss: 0.0289\n",
      "520/1088, train_loss: 0.0267\n",
      "521/1088, train_loss: 0.0310\n",
      "522/1088, train_loss: 0.0270\n",
      "523/1088, train_loss: 0.0277\n",
      "524/1088, train_loss: 0.0282\n",
      "525/1088, train_loss: 0.0291\n",
      "526/1088, train_loss: 0.0254\n",
      "527/1088, train_loss: 0.0284\n",
      "528/1088, train_loss: 0.0286\n",
      "529/1088, train_loss: 0.0294\n",
      "530/1088, train_loss: 0.0279\n",
      "531/1088, train_loss: 0.0267\n",
      "532/1088, train_loss: 0.0266\n",
      "533/1088, train_loss: 0.0264\n",
      "534/1088, train_loss: 0.0264\n",
      "535/1088, train_loss: 0.0248\n",
      "536/1088, train_loss: 0.0316\n",
      "537/1088, train_loss: 0.0288\n",
      "538/1088, train_loss: 0.0294\n",
      "539/1088, train_loss: 0.0302\n",
      "540/1088, train_loss: 0.0265\n",
      "541/1088, train_loss: 0.0292\n",
      "542/1088, train_loss: 0.0278\n",
      "543/1088, train_loss: 0.0274\n",
      "544/1088, train_loss: 0.0281\n",
      "545/1088, train_loss: 0.0287\n",
      "546/1088, train_loss: 0.0267\n",
      "547/1088, train_loss: 0.0298\n",
      "548/1088, train_loss: 0.0289\n",
      "549/1088, train_loss: 0.0290\n",
      "550/1088, train_loss: 0.0274\n",
      "551/1088, train_loss: 0.0274\n",
      "552/1088, train_loss: 0.0274\n",
      "553/1088, train_loss: 0.0281\n",
      "554/1088, train_loss: 0.0263\n",
      "555/1088, train_loss: 0.0258\n",
      "556/1088, train_loss: 0.0275\n",
      "557/1088, train_loss: 0.0294\n",
      "558/1088, train_loss: 0.0280\n",
      "559/1088, train_loss: 0.0282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560/1088, train_loss: 0.0298\n",
      "561/1088, train_loss: 0.0270\n",
      "562/1088, train_loss: 0.0279\n",
      "563/1088, train_loss: 0.0282\n",
      "564/1088, train_loss: 0.0272\n",
      "565/1088, train_loss: 0.0282\n",
      "566/1088, train_loss: 0.0274\n",
      "567/1088, train_loss: 0.0294\n",
      "568/1088, train_loss: 0.0287\n",
      "569/1088, train_loss: 0.0279\n",
      "570/1088, train_loss: 0.0266\n",
      "571/1088, train_loss: 0.0279\n",
      "572/1088, train_loss: 0.0300\n",
      "573/1088, train_loss: 0.0271\n",
      "574/1088, train_loss: 0.0288\n",
      "575/1088, train_loss: 0.0290\n",
      "576/1088, train_loss: 0.0281\n",
      "577/1088, train_loss: 0.0265\n",
      "578/1088, train_loss: 0.0282\n",
      "579/1088, train_loss: 0.0298\n",
      "580/1088, train_loss: 0.0282\n",
      "581/1088, train_loss: 0.0272\n",
      "582/1088, train_loss: 0.0290\n",
      "583/1088, train_loss: 0.0248\n",
      "584/1088, train_loss: 0.0264\n",
      "585/1088, train_loss: 0.0287\n",
      "586/1088, train_loss: 0.0280\n",
      "587/1088, train_loss: 0.0275\n",
      "588/1088, train_loss: 0.0279\n",
      "589/1088, train_loss: 0.0368\n",
      "590/1088, train_loss: 0.0269\n",
      "591/1088, train_loss: 0.0279\n",
      "592/1088, train_loss: 0.0261\n",
      "593/1088, train_loss: 0.0275\n",
      "594/1088, train_loss: 0.0279\n",
      "595/1088, train_loss: 0.0283\n",
      "596/1088, train_loss: 0.0290\n",
      "597/1088, train_loss: 0.0302\n",
      "598/1088, train_loss: 0.0273\n",
      "599/1088, train_loss: 0.0286\n",
      "600/1088, train_loss: 0.0278\n",
      "601/1088, train_loss: 0.0302\n",
      "602/1088, train_loss: 0.0287\n",
      "603/1088, train_loss: 0.0279\n",
      "604/1088, train_loss: 0.0269\n",
      "605/1088, train_loss: 0.0283\n",
      "606/1088, train_loss: 0.0308\n",
      "607/1088, train_loss: 0.0282\n",
      "608/1088, train_loss: 0.0284\n",
      "609/1088, train_loss: 0.0306\n",
      "610/1088, train_loss: 0.0280\n",
      "611/1088, train_loss: 0.0273\n",
      "612/1088, train_loss: 0.0286\n",
      "613/1088, train_loss: 0.0312\n",
      "614/1088, train_loss: 0.0291\n",
      "615/1088, train_loss: 0.0281\n",
      "616/1088, train_loss: 0.0275\n",
      "617/1088, train_loss: 0.0269\n",
      "618/1088, train_loss: 0.0288\n",
      "619/1088, train_loss: 0.0287\n",
      "620/1088, train_loss: 0.0294\n",
      "621/1088, train_loss: 0.0280\n",
      "622/1088, train_loss: 0.0267\n",
      "623/1088, train_loss: 0.0300\n",
      "624/1088, train_loss: 0.0267\n",
      "625/1088, train_loss: 0.0296\n",
      "626/1088, train_loss: 0.0271\n",
      "627/1088, train_loss: 0.0342\n",
      "628/1088, train_loss: 0.0317\n",
      "629/1088, train_loss: 0.0257\n",
      "630/1088, train_loss: 0.0283\n",
      "631/1088, train_loss: 0.0263\n",
      "632/1088, train_loss: 0.0289\n",
      "633/1088, train_loss: 0.0305\n",
      "634/1088, train_loss: 0.0280\n",
      "635/1088, train_loss: 0.0284\n",
      "636/1088, train_loss: 0.0266\n",
      "637/1088, train_loss: 0.0296\n",
      "638/1088, train_loss: 0.0284\n",
      "639/1088, train_loss: 0.0282\n",
      "640/1088, train_loss: 0.0276\n",
      "641/1088, train_loss: 0.0289\n",
      "642/1088, train_loss: 0.0299\n",
      "643/1088, train_loss: 0.0264\n",
      "644/1088, train_loss: 0.0290\n",
      "645/1088, train_loss: 0.0278\n",
      "646/1088, train_loss: 0.0277\n",
      "647/1088, train_loss: 0.0270\n",
      "648/1088, train_loss: 0.0327\n",
      "649/1088, train_loss: 0.0276\n",
      "650/1088, train_loss: 0.0297\n",
      "651/1088, train_loss: 0.0317\n",
      "652/1088, train_loss: 0.0281\n",
      "653/1088, train_loss: 0.0273\n",
      "654/1088, train_loss: 0.0297\n",
      "655/1088, train_loss: 0.0288\n",
      "656/1088, train_loss: 0.0287\n",
      "657/1088, train_loss: 0.0265\n",
      "658/1088, train_loss: 0.0281\n",
      "659/1088, train_loss: 0.0282\n",
      "660/1088, train_loss: 0.0272\n",
      "661/1088, train_loss: 0.0279\n",
      "662/1088, train_loss: 0.0254\n",
      "663/1088, train_loss: 0.0301\n",
      "664/1088, train_loss: 0.0287\n",
      "665/1088, train_loss: 0.0280\n",
      "666/1088, train_loss: 0.0283\n",
      "667/1088, train_loss: 0.0280\n",
      "668/1088, train_loss: 0.0279\n",
      "669/1088, train_loss: 0.0280\n",
      "670/1088, train_loss: 0.0293\n",
      "671/1088, train_loss: 0.0288\n",
      "672/1088, train_loss: 0.0271\n",
      "673/1088, train_loss: 0.0298\n",
      "674/1088, train_loss: 0.0271\n",
      "675/1088, train_loss: 0.0270\n",
      "676/1088, train_loss: 0.0281\n",
      "677/1088, train_loss: 0.0287\n",
      "678/1088, train_loss: 0.0290\n",
      "679/1088, train_loss: 0.0285\n",
      "680/1088, train_loss: 0.0299\n",
      "681/1088, train_loss: 0.0305\n",
      "682/1088, train_loss: 0.0267\n",
      "683/1088, train_loss: 0.0263\n",
      "684/1088, train_loss: 0.0283\n",
      "685/1088, train_loss: 0.0264\n",
      "686/1088, train_loss: 0.0298\n",
      "687/1088, train_loss: 0.0289\n",
      "688/1088, train_loss: 0.0280\n",
      "689/1088, train_loss: 0.0285\n",
      "690/1088, train_loss: 0.0288\n",
      "691/1088, train_loss: 0.0289\n",
      "692/1088, train_loss: 0.0283\n",
      "693/1088, train_loss: 0.0291\n",
      "694/1088, train_loss: 0.0285\n",
      "695/1088, train_loss: 0.0274\n",
      "696/1088, train_loss: 0.0277\n",
      "697/1088, train_loss: 0.0285\n",
      "698/1088, train_loss: 0.0298\n",
      "699/1088, train_loss: 0.0278\n",
      "700/1088, train_loss: 0.0269\n",
      "701/1088, train_loss: 0.0289\n",
      "702/1088, train_loss: 0.0297\n",
      "703/1088, train_loss: 0.0279\n",
      "704/1088, train_loss: 0.0292\n",
      "705/1088, train_loss: 0.0310\n",
      "706/1088, train_loss: 0.0259\n",
      "707/1088, train_loss: 0.0258\n",
      "708/1088, train_loss: 0.0274\n",
      "709/1088, train_loss: 0.0299\n",
      "710/1088, train_loss: 0.0276\n",
      "711/1088, train_loss: 0.0278\n",
      "712/1088, train_loss: 0.0301\n",
      "713/1088, train_loss: 0.0262\n",
      "714/1088, train_loss: 0.0267\n",
      "715/1088, train_loss: 0.0288\n",
      "716/1088, train_loss: 0.0271\n",
      "717/1088, train_loss: 0.0280\n",
      "718/1088, train_loss: 0.0259\n",
      "719/1088, train_loss: 0.0276\n",
      "720/1088, train_loss: 0.0296\n",
      "721/1088, train_loss: 0.0261\n",
      "722/1088, train_loss: 0.0271\n",
      "723/1088, train_loss: 0.0249\n",
      "724/1088, train_loss: 0.0308\n",
      "725/1088, train_loss: 0.0261\n",
      "726/1088, train_loss: 0.0250\n",
      "727/1088, train_loss: 0.0283\n",
      "728/1088, train_loss: 0.0271\n",
      "729/1088, train_loss: 0.0288\n",
      "730/1088, train_loss: 0.0298\n",
      "731/1088, train_loss: 0.0272\n",
      "732/1088, train_loss: 0.0271\n",
      "733/1088, train_loss: 0.0254\n",
      "734/1088, train_loss: 0.0291\n",
      "735/1088, train_loss: 0.0284\n",
      "736/1088, train_loss: 0.0280\n",
      "737/1088, train_loss: 0.0263\n",
      "738/1088, train_loss: 0.0287\n",
      "739/1088, train_loss: 0.0273\n",
      "740/1088, train_loss: 0.0293\n",
      "741/1088, train_loss: 0.0267\n",
      "742/1088, train_loss: 0.0257\n",
      "743/1088, train_loss: 0.0276\n",
      "744/1088, train_loss: 0.0299\n",
      "745/1088, train_loss: 0.0264\n",
      "746/1088, train_loss: 0.0297\n",
      "747/1088, train_loss: 0.0276\n",
      "748/1088, train_loss: 0.0285\n",
      "749/1088, train_loss: 0.0305\n",
      "750/1088, train_loss: 0.0274\n",
      "751/1088, train_loss: 0.0288\n",
      "752/1088, train_loss: 0.0282\n",
      "753/1088, train_loss: 0.0277\n",
      "754/1088, train_loss: 0.0261\n",
      "755/1088, train_loss: 0.0269\n",
      "756/1088, train_loss: 0.0310\n",
      "757/1088, train_loss: 0.0303\n",
      "758/1088, train_loss: 0.0298\n",
      "759/1088, train_loss: 0.0311\n",
      "760/1088, train_loss: 0.0273\n",
      "761/1088, train_loss: 0.0276\n",
      "762/1088, train_loss: 0.0278\n",
      "763/1088, train_loss: 0.0285\n",
      "764/1088, train_loss: 0.0341\n",
      "765/1088, train_loss: 0.0292\n",
      "766/1088, train_loss: 0.0284\n",
      "767/1088, train_loss: 0.0388\n",
      "768/1088, train_loss: 0.0358\n",
      "769/1088, train_loss: 0.0301\n",
      "770/1088, train_loss: 0.0298\n",
      "771/1088, train_loss: 0.0276\n",
      "772/1088, train_loss: 0.0247\n",
      "773/1088, train_loss: 0.0274\n",
      "774/1088, train_loss: 0.0252\n",
      "775/1088, train_loss: 0.0259\n",
      "776/1088, train_loss: 0.0272\n",
      "777/1088, train_loss: 0.0270\n",
      "778/1088, train_loss: 0.0273\n",
      "779/1088, train_loss: 0.0296\n",
      "780/1088, train_loss: 0.0304\n",
      "781/1088, train_loss: 0.0276\n",
      "782/1088, train_loss: 0.0289\n",
      "783/1088, train_loss: 0.0289\n",
      "784/1088, train_loss: 0.0300\n",
      "785/1088, train_loss: 0.0285\n",
      "786/1088, train_loss: 0.0306\n",
      "787/1088, train_loss: 0.0286\n",
      "788/1088, train_loss: 0.0307\n",
      "789/1088, train_loss: 0.0291\n",
      "790/1088, train_loss: 0.0268\n",
      "791/1088, train_loss: 0.0280\n",
      "792/1088, train_loss: 0.0284\n",
      "793/1088, train_loss: 0.0293\n",
      "794/1088, train_loss: 0.0292\n",
      "795/1088, train_loss: 0.0284\n",
      "796/1088, train_loss: 0.0280\n",
      "797/1088, train_loss: 0.0264\n",
      "798/1088, train_loss: 0.0285\n",
      "799/1088, train_loss: 0.0278\n",
      "800/1088, train_loss: 0.0279\n",
      "801/1088, train_loss: 0.0276\n",
      "802/1088, train_loss: 0.0301\n",
      "803/1088, train_loss: 0.0266\n",
      "804/1088, train_loss: 0.0260\n",
      "805/1088, train_loss: 0.0296\n",
      "806/1088, train_loss: 0.0287\n",
      "807/1088, train_loss: 0.0280\n",
      "808/1088, train_loss: 0.0285\n",
      "809/1088, train_loss: 0.0265\n",
      "810/1088, train_loss: 0.0293\n",
      "811/1088, train_loss: 0.0277\n",
      "812/1088, train_loss: 0.0283\n",
      "813/1088, train_loss: 0.0291\n",
      "814/1088, train_loss: 0.0302\n",
      "815/1088, train_loss: 0.0295\n",
      "816/1088, train_loss: 0.0274\n",
      "817/1088, train_loss: 0.0269\n",
      "818/1088, train_loss: 0.0264\n",
      "819/1088, train_loss: 0.0279\n",
      "820/1088, train_loss: 0.0349\n",
      "821/1088, train_loss: 0.0296\n",
      "822/1088, train_loss: 0.0308\n",
      "823/1088, train_loss: 0.0298\n",
      "824/1088, train_loss: 0.0268\n",
      "825/1088, train_loss: 0.0269\n",
      "826/1088, train_loss: 0.0295\n",
      "827/1088, train_loss: 0.0307\n",
      "828/1088, train_loss: 0.0289\n",
      "829/1088, train_loss: 0.0281\n",
      "830/1088, train_loss: 0.0296\n",
      "831/1088, train_loss: 0.0306\n",
      "832/1088, train_loss: 0.0376\n",
      "833/1088, train_loss: 0.0287\n",
      "834/1088, train_loss: 0.0286\n",
      "835/1088, train_loss: 0.0280\n",
      "836/1088, train_loss: 0.0276\n",
      "837/1088, train_loss: 0.0274\n",
      "838/1088, train_loss: 0.0280\n",
      "839/1088, train_loss: 0.0291\n",
      "840/1088, train_loss: 0.0295\n",
      "841/1088, train_loss: 0.0282\n",
      "842/1088, train_loss: 0.0318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843/1088, train_loss: 0.0288\n",
      "844/1088, train_loss: 0.0263\n",
      "845/1088, train_loss: 0.0306\n",
      "846/1088, train_loss: 0.0277\n",
      "847/1088, train_loss: 0.0301\n",
      "848/1088, train_loss: 0.0280\n",
      "849/1088, train_loss: 0.0267\n",
      "850/1088, train_loss: 0.0295\n",
      "851/1088, train_loss: 0.0284\n",
      "852/1088, train_loss: 0.0335\n",
      "853/1088, train_loss: 0.0264\n",
      "854/1088, train_loss: 0.0272\n",
      "855/1088, train_loss: 0.0252\n",
      "856/1088, train_loss: 0.0284\n",
      "857/1088, train_loss: 0.0306\n",
      "858/1088, train_loss: 0.0296\n",
      "859/1088, train_loss: 0.0282\n",
      "860/1088, train_loss: 0.0309\n",
      "861/1088, train_loss: 0.0284\n",
      "862/1088, train_loss: 0.0290\n",
      "863/1088, train_loss: 0.0286\n",
      "864/1088, train_loss: 0.0283\n",
      "865/1088, train_loss: 0.0304\n",
      "866/1088, train_loss: 0.0279\n",
      "867/1088, train_loss: 0.0259\n",
      "868/1088, train_loss: 0.0303\n",
      "869/1088, train_loss: 0.0265\n",
      "870/1088, train_loss: 0.0292\n",
      "871/1088, train_loss: 0.0292\n",
      "872/1088, train_loss: 0.0292\n",
      "873/1088, train_loss: 0.0298\n",
      "874/1088, train_loss: 0.0275\n",
      "875/1088, train_loss: 0.0253\n",
      "876/1088, train_loss: 0.0293\n",
      "877/1088, train_loss: 0.0271\n",
      "878/1088, train_loss: 0.0279\n",
      "879/1088, train_loss: 0.0285\n",
      "880/1088, train_loss: 0.0267\n",
      "881/1088, train_loss: 0.0281\n",
      "882/1088, train_loss: 0.0277\n",
      "883/1088, train_loss: 0.0280\n",
      "884/1088, train_loss: 0.0295\n",
      "885/1088, train_loss: 0.0249\n",
      "886/1088, train_loss: 0.0300\n",
      "887/1088, train_loss: 0.0288\n",
      "888/1088, train_loss: 0.0277\n",
      "889/1088, train_loss: 0.0323\n",
      "890/1088, train_loss: 0.0283\n",
      "891/1088, train_loss: 0.0279\n",
      "892/1088, train_loss: 0.0319\n",
      "893/1088, train_loss: 0.0284\n",
      "894/1088, train_loss: 0.0282\n",
      "895/1088, train_loss: 0.0293\n",
      "896/1088, train_loss: 0.0280\n",
      "897/1088, train_loss: 0.0272\n",
      "898/1088, train_loss: 0.0304\n",
      "899/1088, train_loss: 0.0280\n",
      "900/1088, train_loss: 0.0273\n",
      "901/1088, train_loss: 0.0296\n",
      "902/1088, train_loss: 0.0271\n",
      "903/1088, train_loss: 0.0322\n",
      "904/1088, train_loss: 0.0314\n",
      "905/1088, train_loss: 0.0283\n",
      "906/1088, train_loss: 0.0296\n",
      "907/1088, train_loss: 0.0300\n",
      "908/1088, train_loss: 0.0259\n",
      "909/1088, train_loss: 0.0250\n",
      "910/1088, train_loss: 0.0275\n",
      "911/1088, train_loss: 0.0288\n",
      "912/1088, train_loss: 0.0276\n",
      "913/1088, train_loss: 0.0260\n",
      "914/1088, train_loss: 0.0280\n",
      "915/1088, train_loss: 0.0294\n",
      "916/1088, train_loss: 0.0327\n",
      "917/1088, train_loss: 0.0280\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 364\u001b[0m\n\u001b[0;32m    356\u001b[0m     writer\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 364\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[28], line 270\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Calculate the Dice score during training\u001b[39;00m\n\u001b[0;32m    269\u001b[0m post_outputs \u001b[38;5;241m=\u001b[39m post_trans(outputs)\n\u001b[1;32m--> 270\u001b[0m train_dice_metric(y_pred\u001b[38;5;241m=\u001b[39mpost_outputs, y\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m    272\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m#scaler.unscale_(optimizer)  # Unscales the gradients of optimizer's assigned params in-place\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m############## Gradient Clipping Part ###################\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\metrics\\metric.py:344\u001b[0m, in \u001b[0;36mCumulativeIterationMetric.__call__\u001b[1;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m, y_pred: TensorOrList, y: TensorOrList \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[0;32m    326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m Sequence[torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m|\u001b[39m Sequence[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m    327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;124;03m    Execute basic computation for model prediction and ground truth.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;124;03m    It can support  both `list of channel-first Tensor` and `batch-first Tensor`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;124;03m        a `batch-first` tensor (BC[HWD]) or a list of `batch-first` tensors.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(y_pred\u001b[38;5;241m=\u001b[39my_pred, y\u001b[38;5;241m=\u001b[39my, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;241m*\u001b[39mret)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\metrics\\metric.py:77\u001b[0m, in \u001b[0;36mIterationMetric.__call__\u001b[1;34m(self, y_pred, y, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y_pred, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     76\u001b[0m     y_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_tensor(y_pred\u001b[38;5;241m.\u001b[39mdetach(), y_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred or y must be a list/tuple of `channel-first` Tensors or a `batch-first` Tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\metrics\\meandice.py:95\u001b[0m, in \u001b[0;36mDiceMetric._compute_tensor\u001b[1;34m(self, y_pred, y)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred should have at least 3 dimensions (batch, channel, spatial), got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# compute dice (BxC) for each channel for each batch\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdice_helper(y_pred\u001b[38;5;241m=\u001b[39my_pred, y\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\metrics\\meandice.py:260\u001b[0m, in \u001b[0;36mDiceHelper.__call__\u001b[1;34m(self, y_pred, y)\u001b[0m\n\u001b[0;32m    258\u001b[0m         x_pred \u001b[38;5;241m=\u001b[39m (y_pred[b, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;28;01mif\u001b[39;00m (y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m y_pred[b, c]\u001b[38;5;241m.\u001b[39mbool()\n\u001b[0;32m    259\u001b[0m         x \u001b[38;5;241m=\u001b[39m (y[b, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m c) \u001b[38;5;28;01mif\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m y[b, c]\n\u001b[1;32m--> 260\u001b[0m         c_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_channel(x_pred, x))\n\u001b[0;32m    261\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mstack(c_list))\n\u001b[0;32m    262\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(data, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\metrics\\meandice.py:219\u001b[0m, in \u001b[0;36mDiceHelper.compute_channel\u001b[1;34m(self, y_pred, y)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m y_o \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(y)\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_o \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mmasked_select(y, y_pred))) \u001b[38;5;241m/\u001b[39m (y_o \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(y_pred))\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_empty:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\monai\\data\\meta_tensor.py:276\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 276\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m__torch_function__(func, types, args, kwargs)\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\deepsight\\Lib\\site-packages\\torch\\_tensor.py:1295\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[1;32m-> 1295\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[0;32m   1297\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_files, segmentation_files, transform=None):\n",
    "        self.input_files = input_files\n",
    "        self.segmentation_files = segmentation_files\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_path = self.input_files[idx]\n",
    "        segmentation_path = self.segmentation_files[idx]\n",
    "\n",
    "        # Load input image (TIFF)\n",
    "        input_image = Image.open(input_path)\n",
    "        input_image = np.array(input_image, dtype=np.float32)  # Convert to NumPy array\n",
    "\n",
    "        # Load segmentation image (TIFF)\n",
    "        segmentation_image = Image.open(segmentation_path)\n",
    "        segmentation_image = np.array(segmentation_image, dtype=np.float32)  # Convert to NumPy array\n",
    "\n",
    "        # Initialize variables\n",
    "        input_data = input_image\n",
    "        segmentation_data = segmentation_image\n",
    "\n",
    "        if self.transform is not None:\n",
    "            # Apply the specified transforms to input_data and segmentation_data\n",
    "            transformed_data = self.transform({\"img\": input_data, \"seg\": segmentation_data})\n",
    "            input_data, segmentation_data = transformed_data[\"img\"], transformed_data[\"seg\"]\n",
    "\n",
    "        return {\"img\": input_data, \"seg\": segmentation_data}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "max_grad_norm = 1.0\n",
    "# Define a custom transform to threshold the segmentation tensor\n",
    "class ThresholdSegmentation(Transform):\n",
    "    def __init__(self, keys, threshold=0):\n",
    "        super().__init__()\n",
    "        self.keys = keys\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def __call__(self, data):\n",
    "        for key in self.keys:\n",
    "            if key == \"seg\":\n",
    "                data[key] = (data[key] > self.threshold).float()\n",
    "        return data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.transforms import ToNumpy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    log_dir = \"D:/Aytekin/CovidMasterThesis/red_runs/resize512_epoch50_highlr\"\n",
    "    monai.config.print_config()\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "\n",
    "    #print(len(updated_raw_dict))\n",
    "    #print(len(new_analyzed_dict))\n",
    "    # Check and convert data format only once\n",
    "    #converted_raw_dict, converted_analyzed_dict = check_and_convert_format(updated_raw_dict, new_analyzed_dict)\n",
    "\n",
    "    # Remove red for now!!!!\n",
    "    #converted_raw_dict = {k: v for k, v in converted_raw_dict.items() if 'red' not in k}\n",
    "\n",
    "    # Remove elements where the key contains \"red\" for converted_analyzed_dict\n",
    "    #converted_analyzed_dict = {k: v for k, v in converted_analyzed_dict.items() if 'red' not in k}\n",
    "\n",
    "\n",
    "    # Check if the dictionaries contain the same length or not, then create train val test:\n",
    "    #if len(converted_raw_dict) != len(converted_analyzed_dict):\n",
    "    #    raise ValueError(\"The lengths of converted_raw_dict and converted_analyzed_dict do not match.\")\n",
    "\n",
    "    #num_images = len(converted_raw_dict)\n",
    "    #print(\"Length of converted_raw_dict to be used: {}\".format(num_images))\n",
    "    # Calculate the number of images for training, validation, and test, e.g., using an 80-10-10 split\n",
    "\n",
    "    #\n",
    "    #converted_raw_dict.keys()\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "        # define transforms for image and segmentation\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            #ToTensor(),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=\"no_channel\"),  # Use channel_dim=-1 for NumPy arrays\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            Resized(keys=[\"img\", \"seg\"],spatial_size=(512, 512), mode=\"nearest\"),\n",
    "            ThresholdSegmentation(keys=[\"img\", \"seg\"], threshold=0),\n",
    "\n",
    "            #DivisiblePadd(keys=[\"img\", \"seg\"],k=16),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            #ToTensor(),\n",
    "            EnsureChannelFirstd(keys=[\"img\", \"seg\"], channel_dim=\"no_channel\"),  # Use channel_dim=-1 for NumPy arrays\n",
    "            ScaleIntensityd(keys=[\"img\", \"seg\"]),\n",
    "            Resized(keys=[\"img\", \"seg\"],spatial_size=(512, 512), mode=\"nearest\"),\n",
    "            ThresholdSegmentation(keys=[\"img\", \"seg\"], threshold=0),\n",
    "            #DivisiblePadd(keys=[\"img\", \"seg\"],k=16),\n",
    "\n",
    "\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    # Directory paths for input and segmentation images\n",
    "    input_image_dir = r\"E:\\Aytekin\\TrainingDataRed\\Input\"\n",
    "    segmentation_dir = r\"E:\\Aytekin\\TrainingDataRed\\Segmentation\"\n",
    "    test_input_dir = r\"E:\\Aytekin\\Data\\Test\\Input\"\n",
    "\n",
    "    # List of strings to exclude from image names\n",
    "    exclude_strings = [\"12_0500\", \"29_0520\", \"01_0520\", \"08_0420\", \"29_0820\",\"29_1120\",\"29_1420\",\"29_1720\",\"29_2020\",\"29_2320\"]  # Add more strings if needed\n",
    "\n",
    "    # List all .tif image files in the directories and filter out images with excluded strings\n",
    "    input_image_files = [os.path.join(input_image_dir, filename) for filename in os.listdir(input_image_dir) if filename.endswith(\".tif\") and all(exclude not in filename for exclude in exclude_strings)]\n",
    "    segmentation_files = [os.path.join(segmentation_dir, filename) for filename in os.listdir(segmentation_dir) if filename.endswith(\".tif\") and all(exclude not in filename for exclude in exclude_strings)]\n",
    "\n",
    "    # Get the list of files in the \"Test Input\" folder\n",
    "    test_input_files = [os.path.splitext(os.path.basename(filename))[0] for filename in os.listdir(test_input_dir) if filename.endswith(\".tif\")]\n",
    "\n",
    "    # Exclude images with the same names as those in the \"Test Input\" folder\n",
    "    input_image_files = [filename for filename in input_image_files if os.path.splitext(os.path.basename(filename))[0] not in test_input_files]\n",
    "    segmentation_files = [filename for filename in segmentation_files if os.path.splitext(os.path.basename(filename))[0] not in test_input_files]\n",
    "\n",
    "    # List all .tif image files in the directories\n",
    "    input_image_files = [os.path.join(input_image_dir, filename) for filename in os.listdir(input_image_dir) if filename.endswith(\".tif\")]\n",
    "    segmentation_files = [os.path.join(segmentation_dir, filename) for filename in os.listdir(segmentation_dir) if filename.endswith(\".tif\")]\n",
    "\n",
    "    # Extract file names without extensions\n",
    "    input_image_names = [os.path.splitext(os.path.basename(filename))[0] for filename in input_image_files]\n",
    "    segmentation_names = [os.path.splitext(os.path.basename(filename))[0] for filename in segmentation_files]\n",
    "\n",
    "    # Find the common file names between input and segmentation\n",
    "    common_names = set(input_image_names) & set(segmentation_names)\n",
    "\n",
    "    # Filter input_image_files and segmentation_files based on common names\n",
    "    input_image_files = [filename for filename in input_image_files if os.path.splitext(os.path.basename(filename))[0] in common_names]\n",
    "    segmentation_files = [filename for filename in segmentation_files if os.path.splitext(os.path.basename(filename))[0] in common_names]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Split the data into training and validation sets\n",
    "    input_image_train, input_image_val, segmentation_train, segmentation_val = train_test_split(\n",
    "        input_image_files, segmentation_files, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create instances of the custom dataset for training and validation\n",
    "    train_dataset = CustomDataset(input_image_train, segmentation_train, transform=train_transforms)\n",
    "    val_dataset = CustomDataset(input_image_val, segmentation_val, transform=val_transforms)\n",
    "\n",
    "    # Define data loaders for training and validation\n",
    "    train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0, collate_fn=list_data_collate, pin_memory=torch.cuda.is_available())\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1, num_workers=0, collate_fn=list_data_collate)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # define dataset, data loader\n",
    "    #check_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    #check_loader = DataLoader(check_ds, batch_size=2, num_workers=0, collate_fn=list_data_collate)\n",
    "    #check_data = monai.utils.misc.first(check_loader)\n",
    "    #print(check_data[\"img\"].shape, check_data[\"seg\"].shape)\n",
    "    #print(\"------\\n\")\n",
    "    #print(torch.unique(check_data[\"seg\"]))\n",
    "    # create a training data loader\n",
    "    #train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
    "    # use batch_size=2 to load images and use RandCropByPosNegLabeld to generate 2 x 4 images for network training\n",
    "    #train_loader = DataLoader(\n",
    "    #    train_ds,\n",
    "    #    batch_size=2,\n",
    "    #    shuffle=False,\n",
    "    #    num_workers=0,\n",
    "    #    collate_fn=list_data_collate,\n",
    "    #    pin_memory=torch.cuda.is_available(),\n",
    "    #)\n",
    "    # create a validation data loader\n",
    "    #val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "    #val_loader = DataLoader(val_ds, batch_size=1, num_workers=0, collate_fn=list_data_collate)\n",
    "    dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    # create UNet, DiceLoss and Adam optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "    ######## Different Models Can be Tested ##############\n",
    "    model = monai.networks.nets.UNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=1,\n",
    "        out_channels=1,\n",
    "        channels=(64, 128, 256, 512, 1024),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=4,\n",
    "        norm = Norm.BATCH,\n",
    "    ).to(device)\n",
    "    \n",
    "    \n",
    "    ######## Different Models Can be Tested ##############\n",
    "    #model = monai.networks.nets.UNet(\n",
    "    #    spatial_dims=2,\n",
    "    #    in_channels=1,\n",
    "    #    out_channels=1,\n",
    "    #    channels=(64, 128, 256, 512, 1024, 2048),\n",
    "    #    strides=(2, 2, 2, 2, 2),\n",
    "    #    num_res_units=4,\n",
    "    #    norm=None  # Remove normalization layers\n",
    "    #).to(device)\n",
    "    \n",
    "    loss_function = monai.losses.DiceLoss(include_background=True,sigmoid=True,smooth_nr=1e-05, smooth_dr=1e-05) #, weight = [1/0.9892240500840984, 1/0.01077594991590156]\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2 ) #1e-3\n",
    "    #optimizer = Novograd(model.parameters(), lr=1e-2, clip=1.0)\n",
    "    # start a typical PyTorch training\n",
    "    val_interval = 2\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    epoch_loss_values = list()\n",
    "    metric_values = list()\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "\n",
    "    autograd.set_detect_anomaly(True)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Define the step size and gamma (decay factor)\n",
    "    step_size = 1000  # Adjust this according to your training schedule\n",
    "    gamma = 0.5     # Adjust this according to your preference\n",
    "\n",
    "    # Create a learning rate scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    # Create a DiceMetric instance for training\n",
    "    train_dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
    "\n",
    "    for epoch in range(50):\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"epoch {epoch + 1}/{50}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        step = 0\n",
    "        # Clear the DiceMetric for the new epoch\n",
    "        train_dice_metric.reset()\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[\"img\"].to(device), batch_data[\"seg\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "            # Calculate the Dice score during training\n",
    "            post_outputs = post_trans(outputs)\n",
    "            train_dice_metric(y_pred=post_outputs, y=labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            #scaler.unscale_(optimizer)  # Unscales the gradients of optimizer's assigned params in-place\n",
    "            ############## Gradient Clipping Part ###################\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Add this line to clip gradients\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_len = len(train_dataset) // train_loader.batch_size\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        epoch_loss /= step\n",
    "        epoch_loss_values.append(epoch_loss)\n",
    "        # Calculate the average Dice score for the epoch\n",
    "        train_dice_score = train_dice_metric.aggregate().item()\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}, train_dice: {train_dice_score:.4f}\")\n",
    "        writer.add_scalar(\"train_dice\", train_dice_score, epoch + 1)\n",
    "\n",
    "\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "        scheduler.step()\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_images = None\n",
    "                val_labels = None\n",
    "                val_outputs = None\n",
    "                for val_data in val_loader:\n",
    "                    val_images, val_labels = val_data[\"img\"].to(device), val_data[\"seg\"].to(device)\n",
    "                    roi_size = (96, 96)\n",
    "                    sw_batch_size = 4\n",
    "                    val_outputs = sliding_window_inference(val_images, roi_size, sw_batch_size, model)\n",
    "                    val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
    "                    # compute metric for current iteration\n",
    "                    dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "                    for i in range(len(val_images)):\n",
    "                        input_image = val_images[i:i + 1]  # Get the i-th image\n",
    "                        ground_truth = val_labels[i:i + 1]  # Get the i-th ground truth\n",
    "                        prediction = val_outputs[i:i + 1]  # Get the i-th prediction\n",
    "\n",
    "                        # Perform intensity scaling if needed\n",
    "                        #a_min = 0.0\n",
    "                        #a_max = 255.0\n",
    "                        #b_min = 0.0\n",
    "                        #b_max = 1.0\n",
    "\n",
    "                        if isinstance(prediction, list):\n",
    "                            prediction = prediction[0]\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        writer.add_image('Validation/Input', input_image, global_step=epoch,dataformats='NCHW')\n",
    "                        writer.add_image('Validation/GroundTruth', ground_truth, global_step=epoch,dataformats='NCHW')\n",
    "                        writer.add_image('Validation/Prediction', prediction, global_step=epoch,dataformats='CHW')\n",
    "\n",
    "\n",
    "                # aggregate the final mean dice result\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                # reset the status for next validation round\n",
    "                dice_metric.reset()\n",
    "                metric_values.append(metric)\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), \"512red_alldata_seg2d_epoch50_highlr.pth\")\n",
    "                    print(\"saved new best metric model\")\n",
    "                print(\n",
    "                    \"current epoch: {} current mean dice: {:.4f} best mean dice: {:.4f} at epoch {}\".format(\n",
    "                        epoch + 1, metric, best_metric, best_metric_epoch\n",
    "                    )\n",
    "                )\n",
    "                writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                # plot the last model output as GIF image in TensorBoard with the corresponding image and label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    autograd.set_detect_anomaly(False)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b1a530c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=D:/Aytekin/CovidMasterThesis/red_runs/resize512_epoch50_highlr --port=6017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "os_gzBiMMQv9",
   "metadata": {
    "id": "os_gzBiMMQv9"
   },
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72c795",
   "metadata": {
    "id": "6b72c795"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "#os.system(\"pkill -f 'tensorboard'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18a4d82",
   "metadata": {
    "id": "d18a4d82"
   },
   "outputs": [],
   "source": [
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be200395",
   "metadata": {
    "id": "be200395"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b15eee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:deepsight] *",
   "language": "python",
   "name": "conda-env-deepsight-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
